<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dcat%3Acs.CL%26id_list%3D%26start%3D0%26max_results%3D1000" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=cat:cs.CL&amp;id_list=&amp;start=0&amp;max_results=1000</title>
  <id>http://arxiv.org/api/SyKFFvFKHFYxHUiOq8tm9Ptxy4c</id>
  <updated>2020-03-11T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">17762</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1000</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2003.04887v1</id>
    <updated>2020-03-10T17:58:01Z</updated>
    <published>2020-03-10T17:58:01Z</published>
    <title>ReZero is All You Need: Fast Convergence at Large Depth</title>
    <summary>  Deep networks have enabled significant performance gains across domains, but
they often suffer from vanishing/exploding gradients. This is especially true
for Transformer architectures where depth beyond 12 layers is difficult to
train without large datasets and computational budgets. In general, we find
that inefficient signal propagation impedes learning in deep networks. In
Transformers, multi-head self-attention is the main cause of this poor signal
propagation. To facilitate deep signal propagation, we propose ReZero, a simple
change to the architecture that initializes an arbitrary layer as the identity
map, using a single additional learned parameter per layer. We apply this
technique to language modeling and find that we can easily train
ReZero-Transformer networks over a hundred layers. When applied to 12 layer
Transformers, ReZero converges 56% faster on enwiki8. ReZero applies beyond
Transformers to other residual networks, enabling 1,500% faster convergence for
deep fully connected networks and 32% faster convergence for a ResNet-56
trained on CIFAR 10.
</summary>
    <author>
      <name>Thomas Bachlechner</name>
    </author>
    <author>
      <name>Bodhisattwa Prasad Majumder</name>
    </author>
    <author>
      <name>Huanru Henry Mao</name>
    </author>
    <author>
      <name>Garrison W. Cottrell</name>
    </author>
    <author>
      <name>Julian McAuley</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04866v1</id>
    <updated>2020-03-10T17:17:01Z</updated>
    <published>2020-03-10T17:17:01Z</published>
    <title>Multi-SimLex: A Large-Scale Evaluation of Multilingual and Cross-Lingual
  Lexical Semantic Similarity</title>
    <summary>  We introduce Multi-SimLex, a large-scale lexical resource and evaluation
benchmark covering datasets for 12 typologically diverse languages, including
major languages (e.g., Mandarin Chinese, Spanish, Russian) as well as
less-resourced ones (e.g., Welsh, Kiswahili). Each language dataset is
annotated for the lexical relation of semantic similarity and contains 1,888
semantically aligned concept pairs, providing a representative coverage of word
classes (nouns, verbs, adjectives, adverbs), frequency ranks, similarity
intervals, lexical fields, and concreteness levels. Additionally, owing to the
alignment of concepts across languages, we provide a suite of 66 cross-lingual
semantic similarity datasets. Due to its extensive size and language coverage,
Multi-SimLex provides entirely novel opportunities for experimental evaluation
and analysis. On its monolingual and cross-lingual benchmarks, we evaluate and
analyze a wide array of recent state-of-the-art monolingual and cross-lingual
representation models, including static and contextualized word embeddings
(such as fastText, M-BERT and XLM), externally informed lexical
representations, as well as fully unsupervised and (weakly) supervised
cross-lingual word embeddings. We also present a step-by-step dataset creation
protocol for creating consistent, Multi-Simlex-style resources for additional
languages. We make these contributions -- the public release of Multi-SimLex
datasets, their creation protocol, strong baseline results, and in-depth
analyses which can be be helpful in guiding future developments in multilingual
lexical semantics and representation learning -- available via a website which
will encourage community effort in further expansion of Multi-Simlex to many
more languages. Such a large-scale semantic resource could inspire significant
further advances in NLP across languages.
</summary>
    <author>
      <name>Ivan Vulić</name>
    </author>
    <author>
      <name>Simon Baker</name>
    </author>
    <author>
      <name>Edoardo Maria Ponti</name>
    </author>
    <author>
      <name>Ulla Petti</name>
    </author>
    <author>
      <name>Ira Leviant</name>
    </author>
    <author>
      <name>Kelly Wing</name>
    </author>
    <author>
      <name>Olga Majewska</name>
    </author>
    <author>
      <name>Eden Bar</name>
    </author>
    <author>
      <name>Matt Malone</name>
    </author>
    <author>
      <name>Thierry Poibeau</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <author>
      <name>Anna Korhonen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Data and guidelines available at https://multisimlex.com/</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04865v1</id>
    <updated>2020-03-10T17:15:48Z</updated>
    <published>2020-03-10T17:15:48Z</published>
    <title>Video Caption Dataset for Describing Human Actions in Japanese</title>
    <summary>  In recent years, automatic video caption generation has attracted
considerable attention. This paper focuses on the generation of Japanese
captions for describing human actions. While most currently available video
caption datasets have been constructed for English, there is no equivalent
Japanese dataset. To address this, we constructed a large-scale Japanese video
caption dataset consisting of 79,822 videos and 399,233 captions. Each caption
in our dataset describes a video in the form of "who does what and where." To
describe human actions, it is important to identify the details of a person,
place, and action. Indeed, when we describe human actions, we usually mention
the scene, person, and action. In our experiments, we evaluated two caption
generation methods to obtain benchmark results. Further, we investigated
whether those generation methods could specify "who does what and where."
</summary>
    <author>
      <name>Yutaro Shigeto</name>
    </author>
    <author>
      <name>Yuya Yoshikawa</name>
    </author>
    <author>
      <name>Jiaqing Lin</name>
    </author>
    <author>
      <name>Akikazu Takeuchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for LREC 2020. Dataset available at
  https://actions.stair.center/captions.html</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04807v1</id>
    <updated>2020-03-10T15:33:54Z</updated>
    <published>2020-03-10T15:33:54Z</published>
    <title>Efficient Intent Detection with Dual Sentence Encoders</title>
    <summary>  Building conversational systems in new domains and with added functionality
requires resource-efficient models that work under low-data regimes (i.e., in
few-shot setups). Motivated by these requirements, we introduce intent
detection methods backed by pretrained dual sentence encoders such as USE and
ConveRT. We demonstrate the usefulness and wide applicability of the proposed
intent detectors, showing that: 1) they outperform intent detectors based on
fine-tuning the full BERT-Large model or using BERT as a fixed black-box
encoder on three diverse intent detection data sets; 2) the gains are
especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated
examples per intent); 3) our intent detectors can be trained in a matter of
minutes on a single CPU; and 4) they are stable across different hyperparameter
settings. In hope of facilitating and democratizing research focused on
intention detection, we release our code, as well as a new challenging
single-domain intent detection dataset comprising 13,083 annotated examples
over 77 intents.
</summary>
    <author>
      <name>Iñigo Casanueva</name>
    </author>
    <author>
      <name>Tadas Temčinas</name>
    </author>
    <author>
      <name>Daniela Gerz</name>
    </author>
    <author>
      <name>Matthew Henderson</name>
    </author>
    <author>
      <name>Ivan Vulić</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04748v1</id>
    <updated>2020-03-10T14:06:55Z</updated>
    <published>2020-03-10T14:06:55Z</published>
    <title>On the coexistence of competing languages</title>
    <summary>  We investigate the evolution of competing languages, a subject where much
previous literature suggests that the outcome is always the domination of one
language over all the others. Since coexistence of languages is observed in
reality, we here revisit the question of language competition, with an emphasis
on uncovering the ways in which coexistence might emerge. We find that this
emergence is related to symmetry breaking, and explore two particular scenarios
-- the first relating to an imbalance in the population dynamics of language
speakers in a single geographical area, and the second to do with spatial
heterogeneity, where language preferences are specific to different
geographical regions. For each of these, the investigation of paradigmatic
situations leads us to a quantitative understanding of the conditions leading
to language coexistence. We also obtain predictions of the number of surviving
languages as a function of various model parameters.
</summary>
    <author>
      <name>Jean-Marc Luck</name>
    </author>
    <author>
      <name>Anita Mehta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 12 figures, 47 references. To appear in EPJ B</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04679v1</id>
    <updated>2020-03-10T13:10:26Z</updated>
    <published>2020-03-10T13:10:26Z</published>
    <title>Learning to Respond with Stickers: A Framework of Unifying
  Multi-Modality in Multi-Turn Dialog</title>
    <summary>  Stickers with vivid and engaging expressions are becoming increasingly
popular in online messaging apps, and some works are dedicated to automatically
select sticker response by matching text labels of stickers with previous
utterances. However, due to their large quantities, it is impractical to
require text labels for the all stickers. Hence, in this paper, we propose to
recommend an appropriate sticker to user based on multi-turn dialog context
history without any external labels. Two main challenges are confronted in this
task. One is to learn semantic meaning of stickers without corresponding text
labels. Another challenge is to jointly model the candidate sticker with the
multi-turn dialog context. To tackle these challenges, we propose a sticker
response selector (SRS) model. Specifically, SRS first employs a convolutional
based sticker image encoder and a self-attention based multi-turn dialog
encoder to obtain the representation of stickers and utterances. Next, deep
interaction network is proposed to conduct deep matching between the sticker
with each utterance in the dialog history. SRS then learns the short-term and
long-term dependency between all interaction results by a fusion network to
output the the final matching score. To evaluate our proposed method, we
collect a large-scale real-world dialog dataset with stickers from one of the
most popular online chatting platform. Extensive experiments conducted on this
dataset show that our model achieves the state-of-the-art performance for all
commonly-used metrics. Experiments also verify the effectiveness of each
component of SRS. To facilitate further research in sticker selection field, we
release this dataset of 340K multi-turn dialog and sticker pairs.
</summary>
    <author>
      <name>Shen Gao</name>
    </author>
    <author>
      <name>Xiuying Chen</name>
    </author>
    <author>
      <name>Chang Liu</name>
    </author>
    <author>
      <name>Li Liu</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Rui Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by The Web Conference 2020 (WWW 2020). Equal contribution
  from first two authors. Dataset and code are released at
  https://github.com/gsh199449/stickerchat</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04642v1</id>
    <updated>2020-03-10T11:30:22Z</updated>
    <published>2020-03-10T11:30:22Z</published>
    <title>A Framework for Evaluation of Machine Reading Comprehension Gold
  Standards</title>
    <summary>  Machine Reading Comprehension (MRC) is the task of answering a question over
a paragraph of text. While neural MRC systems gain popularity and achieve
noticeable performance, issues are being raised with the methodology used to
establish their performance, particularly concerning the data design of gold
standards that are used to evaluate them. There is but a limited understanding
of the challenges present in this data, which makes it hard to draw comparisons
and formulate reliable hypotheses. As a first step towards alleviating the
problem, this paper proposes a unifying framework to systematically investigate
the present linguistic features, required reasoning and background knowledge
and factual correctness on one hand, and the presence of lexical cues as a
lower bound for the requirement of understanding on the other hand. We propose
a qualitative annotation schema for the first and a set of approximative
metrics for the latter. In a first application of the framework, we analyse
modern MRC gold standards and present our findings: the absence of features
that contribute towards lexical ambiguity, the varying factual correctness of
the expected answers and the presence of lexical cues, all of which potentially
lower the reading comprehension complexity and quality of the evaluation data.
</summary>
    <author>
      <name>Viktor Schlegel</name>
    </author>
    <author>
      <name>Marco Valentino</name>
    </author>
    <author>
      <name>André Freitas</name>
    </author>
    <author>
      <name>Goran Nenadic</name>
    </author>
    <author>
      <name>Riza Batista-Navarro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 12th International Conference on Language
  Resources and Evaluation (LREC 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04642v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04642v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04567v1</id>
    <updated>2020-03-10T08:24:41Z</updated>
    <published>2020-03-10T08:24:41Z</published>
    <title>Ecological Semantics: Programming Environments for Situated Language
  Understanding</title>
    <summary>  Large-scale natural language understanding (NLU) systems have made impressive
progress: they can be applied flexibly across a variety of tasks, and employ
minimal structural assumptions. However, extensive empirical research has shown
this to be a double-edged sword, coming at the cost of shallow understanding:
inferior generalization, grounding and explainability. Grounded language
learning approaches offer the promise of deeper understanding by situating
learning in richer, more structured training environments, but are limited in
scale to relatively narrow, predefined domains. How might we enjoy the best of
both worlds: grounded, general NLU? Following extensive contemporary cognitive
science, we propose treating environments as ``first-class citizens'' in
semantic representations, worthy of research and development in their own
right. Importantly, models should also be partners in the creation and
configuration of environments, rather than just actors within them, as in
existing approaches. To do so, we argue that models must begin to understand
and program in the language of affordances (which define possible actions in a
given situation) both for online, situated discourse comprehension, as well as
large-scale, offline common-sense knowledge mining. To this end we propose an
environment-oriented ecological semantics, outlining theoretical and practical
approaches towards implementation. We further provide actual demonstrations
building upon interactive fiction programming languages.
</summary>
    <author>
      <name>Ronen Tamari</name>
    </author>
    <author>
      <name>Gabriel Stanovsky</name>
    </author>
    <author>
      <name>Dafna Shahaf</name>
    </author>
    <author>
      <name>Reut Tsarfaty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Bridging AI and Cognitive Science (BAICS) workshop at
  ICLR2020. For interactive demos, see https://eco-sem.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04419v1</id>
    <updated>2020-03-09T21:30:55Z</updated>
    <published>2020-03-09T21:30:55Z</published>
    <title>Combining Pretrained High-Resource Embeddings and Subword
  Representations for Low-Resource Languages</title>
    <summary>  The contrast between the need for large amounts of data for current Natural
Language Processing (NLP) techniques, and the lack thereof, is accentuated in
the case of African languages, most of which are considered low-resource. To
help circumvent this issue, we explore techniques exploiting the qualities of
morphologically rich languages (MRLs), while leveraging pretrained word vectors
in well-resourced languages. In our exploration, we show that a meta-embedding
approach combining both pretrained and morphologically-informed word embeddings
performs best in the downstream task of Xhosa-English translation.
</summary>
    <author>
      <name>Machel Reid</name>
    </author>
    <author>
      <name>Edison Marrese-Taylor</name>
    </author>
    <author>
      <name>Yutaka Matsuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at ICLR (International Conference of Learning
  Representations) 2020 Africa NLP Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04195v1</id>
    <updated>2020-03-09T15:20:21Z</updated>
    <published>2020-03-09T15:20:21Z</published>
    <title>An Empirical Investigation of Pre-Trained Transformer Language Models
  for Open-Domain Dialogue Generation</title>
    <summary>  We present an empirical investigation of pre-trained Transformer-based
auto-regressive language models for the task of open-domain dialogue
generation. Training paradigm of pre-training and fine-tuning is employed to
conduct the parameter learning. Corpora of News and Wikipedia in Chinese and
English are collected for the pre-training stage respectively. Dialogue context
and response are concatenated into a single sequence utilized as the input of
the models during the fine-tuning stage. A weighted joint prediction paradigm
for both context and response is designed to evaluate the performance of models
with or without the loss term for context prediction. Various of decoding
strategies such as greedy search, beam search, top-k sampling, etc. are
employed to conduct the response text generation. Extensive experiments are
conducted on the typical single-turn and multi-turn dialogue corpora such as
Weibo, Douban, Reddit, DailyDialog, and Persona-Chat. Detailed numbers of
automatic evaluation metrics on relevance and diversity of the generated
results for the languages models as well as the baseline approaches are
reported.
</summary>
    <author>
      <name>Piji Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04195v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04195v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04707v1</id>
    <updated>2020-03-09T15:04:07Z</updated>
    <published>2020-03-09T15:04:07Z</published>
    <title>Neuro-symbolic Architectures for Context Understanding</title>
    <summary>  Computational context understanding refers to an agent's ability to fuse
disparate sources of information for decision-making and is, therefore,
generally regarded as a prerequisite for sophisticated machine reasoning
capabilities, such as in artificial intelligence (AI). Data-driven and
knowledge-driven methods are two classical techniques in the pursuit of such
machine sense-making capability. However, while data-driven methods seek to
model the statistical regularities of events by making observations in the
real-world, they remain difficult to interpret and they lack mechanisms for
naturally incorporating external knowledge. Conversely, knowledge-driven
methods, combine structured knowledge bases, perform symbolic reasoning based
on axiomatic principles, and are more interpretable in their inferential
processing; however, they often lack the ability to estimate the statistical
salience of an inference. To combat these issues, we propose the use of hybrid
AI methodology as a general framework for combining the strengths of both
approaches. Specifically, we inherit the concept of neuro-symbolism as a way of
using knowledge-bases to guide the learning progress of deep neural networks.
We further ground our discussion in two applications of neuro-symbolism and, in
both cases, show that our systems maintain interpretability while achieving
comparable performance, relative to the state-of-the-art.
</summary>
    <author>
      <name>Alessandro Oltramari</name>
    </author>
    <author>
      <name>Jonathan Francis</name>
    </author>
    <author>
      <name>Cory Henson</name>
    </author>
    <author>
      <name>Kaixin Ma</name>
    </author>
    <author>
      <name>Ruwan Wickramarachchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge
  Graphs for eXplainable AI -- Foundations, Applications and Challenges.
  Studies on the Semantic Web, IOS Press, Amsterdam, 2020. arXiv admin note:
  text overlap with arXiv:1910.14087</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04073v1</id>
    <updated>2020-03-09T12:34:48Z</updated>
    <published>2020-03-09T12:34:48Z</published>
    <title>A Multi-Source Entity-Level Sentiment Corpus for the Financial Domain:
  The FinLin Corpus</title>
    <summary>  We introduce FinLin, a novel corpus containing investor reports, company
reports, news articles, and microblogs from StockTwits, targeting multiple
entities stemming from the automobile industry and covering a 3-month period.
FinLin was annotated with a sentiment score and a relevance score in the range
[-1.0, 1.0] and [0.0, 1.0], respectively. The annotations also include the text
spans selected for the sentiment, thus, providing additional insight into the
annotators' reasoning. Overall, FinLin aims to complement the current knowledge
by providing a novel and publicly available financial sentiment corpus and to
foster research on the topic of financial sentiment analysis and potential
applications in behavioural science.
</summary>
    <author>
      <name>Tobias Daudert</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04038v1</id>
    <updated>2020-03-09T11:04:36Z</updated>
    <published>2020-03-09T11:04:36Z</published>
    <title>TEDL: A Text Encryption Method Based on Deep Learning</title>
    <summary>  Recent years have seen an increasing emphasis on information security, and
various encryption methods have been proposed. However, for symmetric
encryption methods, the well-known encryption techniques still rely on the key
space to guarantee security and suffer from frequent key updating. Aiming to
solve those problems, this paper proposes a novel text encryption method based
on deep learning called TEDL, where the secret key includes hyperparameters in
deep learning model and the core step of encryption is transforming input data
into weights trained under hyperparameters. Firstly, both communication parties
establish a word vector table by training a deep learning model according to
specified hyperparameters. Then, a self-update codebook is constructed on the
word vector table with the SHA-256 function and other tricks. When
communication starts, encryption and decryption are equivalent to indexing and
inverted indexing on the codebook, respectively, thus achieving the
transformation between plaintext and ciphertext. Results of experiments and
relevant analyses show that TEDL performs well for security, efficiency,
generality, and has a lower demand for the frequency of key redistribution.
Especially, as a supplement to current encryption methods, the time-consuming
process of constructing a codebook increases the difficulty of brute-force
attacks while not degrade the communication efficiency.
</summary>
    <author>
      <name>Xiang Li</name>
    </author>
    <author>
      <name>Peng Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04036v1</id>
    <updated>2020-03-09T10:58:38Z</updated>
    <published>2020-03-09T10:58:38Z</published>
    <title>Sentence Analogies: Exploring Linguistic Relationships and Regularities
  in Sentence Embeddings</title>
    <summary>  While important properties of word vector representations have been studied
extensively, far less is known about the properties of sentence vector
representations. Word vectors are often evaluated by assessing to what degree
they exhibit regularities with regard to relationships of the sort considered
in word analogies. In this paper, we investigate to what extent commonly used
sentence vector representation spaces as well reflect certain kinds of
regularities. We propose a number of schemes to induce evaluation data, based
on lexical analogy data as well as semantic relationships between sentences.
Our experiments consider a wide range of sentence embedding methods, including
ones based on BERT-style contextual embeddings. We find that different models
differ substantially in their ability to reflect such regularities.
</summary>
    <author>
      <name>Xunjie Zhu</name>
    </author>
    <author>
      <name>Gerard de Melo</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04032v1</id>
    <updated>2020-03-09T10:50:16Z</updated>
    <published>2020-03-09T10:50:16Z</published>
    <title>Shallow Discourse Annotation for Chinese TED Talks</title>
    <summary>  Text corpora annotated with language-related properties are an important
resource for the development of Language Technology. The current work
contributes a new resource for Chinese Language Technology and for
Chinese-English translation, in the form of a set of TED talks (some originally
given in English, some in Chinese) that have been annotated with discourse
relations in the style of the Penn Discourse TreeBank, adapted to properties of
Chinese text that are not present in English. The resource is currently unique
in annotating discourse-level properties of planned spoken monologues rather
than of written text. An inter-annotator agreement study demonstrates that the
annotation scheme is able to achieve highly reliable results.
</summary>
    <author>
      <name>Wanqiu Long</name>
    </author>
    <author>
      <name>Xinyi Cai</name>
    </author>
    <author>
      <name>James E. M. Reid</name>
    </author>
    <author>
      <name>Bonnie Webber</name>
    </author>
    <author>
      <name>Deyi Xiong</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03875v1</id>
    <updated>2020-03-09T00:32:13Z</updated>
    <published>2020-03-09T00:32:13Z</published>
    <title>Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,
  Relation, Event and QA</title>
    <summary>  Knowledge graph models world knowledge as concepts, entities, and the
relationships between them, which has been widely used in many real-world
tasks. CCKS 2019 held an evaluation track with 6 tasks and attracted more than
1,600 teams. In this paper, we give an overview of the knowledge graph
evaluation tract at CCKS 2019. By reviewing the task definition, successful
methods, useful resources, good strategies and research challenges associated
with each task in CCKS 2019, this paper can provide a helpful reference for
developing knowledge graph applications and conducting future knowledge graph
researches.
</summary>
    <author>
      <name>Xianpei Han</name>
    </author>
    <author>
      <name>Zhichun Wang</name>
    </author>
    <author>
      <name>Jiangtao Zhang</name>
    </author>
    <author>
      <name>Qinghua Wen</name>
    </author>
    <author>
      <name>Wenqi Li</name>
    </author>
    <author>
      <name>Buzhou Tang</name>
    </author>
    <author>
      <name>Qi Wang</name>
    </author>
    <author>
      <name>Zhifan Feng</name>
    </author>
    <author>
      <name>Yang Zhang</name>
    </author>
    <author>
      <name>Yajuan Lu</name>
    </author>
    <author>
      <name>Haitao Wang</name>
    </author>
    <author>
      <name>Wenliang Chen</name>
    </author>
    <author>
      <name>Hao Shao</name>
    </author>
    <author>
      <name>Yubo Chen</name>
    </author>
    <author>
      <name>Kang Liu</name>
    </author>
    <author>
      <name>Jun Zhao</name>
    </author>
    <author>
      <name>Taifeng Wang</name>
    </author>
    <author>
      <name>Kezun Zhang</name>
    </author>
    <author>
      <name>Meng Wang</name>
    </author>
    <author>
      <name>Yinlin Jiang</name>
    </author>
    <author>
      <name>Guilin Qi</name>
    </author>
    <author>
      <name>Lei Zou</name>
    </author>
    <author>
      <name>Sen Hu</name>
    </author>
    <author>
      <name>Minhao Zhang</name>
    </author>
    <author>
      <name>Yinnian Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, in Chinese, 9 figures and 17 tables, CCKS 2019 held an
  evaluation track about knowledge graph with 6 tasks and attracted more than
  1,600 teams</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03813v1</id>
    <updated>2020-03-08T17:07:08Z</updated>
    <published>2020-03-08T17:07:08Z</published>
    <title>Keeping it simple: Implementation and performance of the proto-principle
  of adaptation and learning in the language sciences</title>
    <summary>  In this paper we present the Widrow-Hoff rule and its applications to
language data. After contextualizing the rule historically and placing it in
the chain of neurally inspired artificial learning models, we explain its
rationale and implementational considerations. Using a number of case studies
we illustrate how the Widrow-Hoff rule offers unexpected opportunities for the
computational simulation of a range of language phenomena that make it possible
to approach old problems from a novel perspective.
</summary>
    <author>
      <name>Petar Milin</name>
    </author>
    <author>
      <name>Harish Tayyar Madabushi</name>
    </author>
    <author>
      <name>Michael Croucher</name>
    </author>
    <author>
      <name>Dagmar Divjak</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03728v1</id>
    <updated>2020-03-08T06:00:15Z</updated>
    <published>2020-03-08T06:00:15Z</published>
    <title>Pseudo Labeling and Negative Feedback Learning for Large-scale
  Multi-label Domain Classification</title>
    <summary>  In large-scale domain classification, an utterance can be handled by multiple
domains with overlapped capabilities. However, only a limited number of
ground-truth domains are provided for each training utterance in practice while
knowing as many as correct target labels is helpful for improving the model
performance. In this paper, given one ground-truth domain for each training
utterance, we regard domains consistently predicted with the highest
confidences as additional pseudo labels for the training. In order to reduce
prediction errors due to incorrect pseudo labels, we leverage utterances with
negative system responses to decrease the confidences of the incorrectly
predicted domains. Evaluating on user utterances from an intelligent
conversational system, we show that the proposed approach significantly
improves the performance of domain classification with hypothesis reranking.
</summary>
    <author>
      <name>Joo-Kyung Kim</name>
    </author>
    <author>
      <name>Young-Bum Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03716v1</id>
    <updated>2020-03-08T04:36:04Z</updated>
    <published>2020-03-08T04:36:04Z</published>
    <title>Investigating the Decoders of Maximum Likelihood Sequence Models: A
  Look-ahead Approach</title>
    <summary>  We demonstrate how we can practically incorporate multi-step future
information into a decoder of maximum likelihood sequence models. We propose a
"k-step look-ahead" module to consider the likelihood information of a rollout
up to k steps. Unlike other approaches that need to train another value network
to evaluate the rollouts, we can directly apply this look-ahead module to
improve the decoding of any sequence model trained in a maximum likelihood
framework. We evaluate our look-ahead module on three datasets of varying
difficulties: IM2LATEX-100k OCR image to LaTeX, WMT16 multimodal machine
translation, and WMT14 machine translation. Our look-ahead module improves the
performance of the simpler datasets such as IM2LATEX-100k and WMT16 multimodal
machine translation. However, the improvement of the more difficult dataset
(e.g., containing longer sequences), WMT14 machine translation, becomes
marginal. Our further investigation using the k-step look-ahead suggests that
the more difficult tasks suffer from the overestimated EOS (end-of-sentence)
probability. We argue that the overestimated EOS probability also causes the
decreased performance of beam search when increasing its beam width. We tackle
the EOS problem by integrating an auxiliary EOS loss into the training to
estimate if the model should emit EOS or other words. Our experiments show that
improving EOS estimation not only increases the performance of our proposed
look-ahead module but also the robustness of the beam search.
</summary>
    <author>
      <name>Yu-Siang Wang</name>
    </author>
    <author>
      <name>Yen-Ling Kuo</name>
    </author>
    <author>
      <name>Boris Katz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03667v1</id>
    <updated>2020-03-07T21:42:50Z</updated>
    <published>2020-03-07T21:42:50Z</published>
    <title>The growing echo chamber of social media: Measuring temporal and social
  contagion dynamics for over 150 languages on Twitter for 2009--2020</title>
    <summary>  Working from a dataset of 118 billion messages running from the start of 2009
to the end of 2019, we identify and explore the relative daily use of over 150
languages on Twitter. We find that eight languages comprise 80% of all tweets,
with English, Japanese, Spanish, and Portuguese being the most dominant. To
quantify each language's level of being a Twitter `echo chamber' over time, we
compute the `contagion ratio': the balance of retweets to organic messages. We
find that for the most common languages on Twitter there is a growing tendency,
though not universal, to retweet rather than share new content. By the end of
2019, the contagion ratios for half of the top 30 languages, including English
and Spanish, had reached above 1---the naive contagion threshold. In 2019, the
top 5 languages with the highest average daily ratios were, in order, Thai
(7.3), Hindi, Tamil, Urdu, and Catalan, while the bottom 5 were Russian,
Swedish, Esperanto, Cebuano, and Finnish (0.26). Further, we show that over
time, the contagion ratios for most common languages are growing more strongly
than those of rare languages.
</summary>
    <author>
      <name>Thayer Alshaabi</name>
    </author>
    <author>
      <name>David R. Dewhurst</name>
    </author>
    <author>
      <name>Joshua R. Minot</name>
    </author>
    <author>
      <name>Michael V. Arnold</name>
    </author>
    <author>
      <name>Jane L. Adams</name>
    </author>
    <author>
      <name>Christopher M. Danforth</name>
    </author>
    <author>
      <name>Peter Sheridan Dodds</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages (11 main, 22 appendix), 26 figures (6 main, 20 appendix), 4
  online appendices available \&lt;here
  http://compstorylab.org/share/papers/alshaabi2020a/&gt; , our source code along
  with our documentation is publicly available online on a Gitlab \&lt;repository
  https://gitlab.com/compstorylab/storywrangler&gt;</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03666v1</id>
    <updated>2020-03-07T21:21:29Z</updated>
    <published>2020-03-07T21:21:29Z</published>
    <title>Multi-task Learning Based Neural Bridging Reference Resolution</title>
    <summary>  We propose a multi task learning-based neural model for bridging reference
resolution tackling two key challenges faced by bridging reference resolution.
The first challenge is the lack of large corpora annotated with bridging
references. To address this, we use multi-task learning to help bridging
reference resolution with coreference resolution. We show that substantial
improvements of up to 8 p.p. can be achieved on full bridging resolution with
this architecture. The second challenge is the different definitions of
bridging used in different corpora, meaning that hand-coded systems or systems
using special features designed for one corpus do not work well with other
corpora. Our neural model only uses a small number of corpus independent
features, thus can be applied easily to different corpora. Evaluations with
very different bridging corpora (ARRAU, ISNOTES, BASHI and SCICORP) suggest
that our architecture works equally well on all corpora, and achieves the SoTA
results on full bridging resolution for all corpora, outperforming the best
reported results by up to 34.9 percentage points.
</summary>
    <author>
      <name>Juntao Yu</name>
    </author>
    <author>
      <name>Massimo Poesio</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03654v1</id>
    <updated>2020-03-07T20:21:50Z</updated>
    <published>2020-03-07T20:21:50Z</published>
    <title>Discovering linguistic (ir)regularities in word embeddings through
  max-margin separating hyperplanes</title>
    <summary>  We experiment with new methods for learning how related words are positioned
relative to each other in word embedding spaces. Previous approaches learned
constant vector offsets: vectors that point from source tokens to target tokens
with an assumption that these offsets were parallel to each other. We show that
the offsets between related tokens are closer to orthogonal than parallel, and
that they have low cosine similarities. We proceed by making a different
assumption; target tokens are linearly separable from source and un-labeled
tokens. We show that a max-margin hyperplane can separate target tokens and
that vectors orthogonal to this hyperplane represent the relationship between
source and targets. We find that this representation of the relationship
obtains the best results in dis-covering linguistic regularities. We experiment
with vector space models trained by a variety of algorithms (Word2vec:
CBOW/skip-gram, fastText, or GloVe), and various word context choices such as
linear word-order, syntax dependency grammars, and with and without knowledge
of word position. These experiments show that our model, SVMCos, is robust to a
range of experimental choices when training word embeddings.
</summary>
    <author>
      <name>Noel Kennedy</name>
    </author>
    <author>
      <name>Imogen Schofield</name>
    </author>
    <author>
      <name>Dave C. Brodbelt</name>
    </author>
    <author>
      <name>David B. Church</name>
    </author>
    <author>
      <name>Dan G. O'Neill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03645v1</id>
    <updated>2020-03-07T19:31:08Z</updated>
    <published>2020-03-07T19:31:08Z</published>
    <title>Generating Emotionally Aligned Responses in Dialogues using Affect
  Control Theory</title>
    <summary>  State-of-the-art neural dialogue systems excel at syntactic and semantic
modelling of language, but often have a hard time establishing emotional
alignment with the human interactant during a conversation. In this work, we
bring Affect Control Theory (ACT), a socio-mathematical model of emotions for
human-human interactions, to the neural dialogue generation setting. ACT makes
predictions about how humans respond to emotional stimuli in social situations.
Due to this property, ACT and its derivative probabilistic models have been
successfully deployed in several applications of Human-Computer Interaction,
including empathetic tutoring systems, assistive healthcare devices and
two-person social dilemma games. We investigate how ACT can be used to develop
affect-aware conversational agents, which produce emotionally aligned responses
to prompts and take into consideration the affective identities of the
interactants.
</summary>
    <author>
      <name>Nabiha Asghar</name>
    </author>
    <author>
      <name>Ivan Kobyzev</name>
    </author>
    <author>
      <name>Jesse Hoey</name>
    </author>
    <author>
      <name>Pascal Poupart</name>
    </author>
    <author>
      <name>Muhammad Bilal Sheikh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03612v1</id>
    <updated>2020-03-07T17:22:52Z</updated>
    <published>2020-03-07T17:22:52Z</published>
    <title>Frozen Binomials on the Web: Word Ordering and Language Conventions in
  Online Text</title>
    <summary>  There is inherent information captured in the order in which we write words
in a list. The orderings of binomials --- lists of two words separated by `and'
or `or' --- has been studied for more than a century. These binomials are
common across many areas of speech, in both formal and informal text. In the
last century, numerous explanations have been given to describe what order
people use for these binomials, from differences in semantics to differences in
phonology. These rules describe primarily `frozen' binomials that exist in
exactly one ordering and have lacked large-scale trials to determine efficacy.
  Online text provides a unique opportunity to study these lists in the context
of informal text at a very large scale. In this work, we expand the view of
binomials to include a large-scale analysis of both frozen and non-frozen
binomials in a quantitative way. Using this data, we then demonstrate that most
previously proposed rules are ineffective at predicting binomial ordering. By
tracking the order of these binomials across time and communities we are able
to establish additional, unexplored dimensions central to these predictions.
  Expanding beyond the question of individual binomials, we also explore the
global structure of binomials in various communities, establishing a new model
for these lists and analyzing this structure for non-frozen and frozen
binomials. Additionally, novel analysis of trinomials --- lists of length three
--- suggests that none of the binomials analysis applies in these cases.
Finally, we demonstrate how large data sets gleaned from the web can be used in
conjunction with older theories to expand and improve on old questions.
</summary>
    <author>
      <name>Katherine Van Koevering</name>
    </author>
    <author>
      <name>Austin R. Benson</name>
    </author>
    <author>
      <name>Jon Kleinberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03556v1</id>
    <updated>2020-03-07T11:21:03Z</updated>
    <published>2020-03-07T11:21:03Z</published>
    <title>General-Purpose Communicative Function Recognition using a Hierarchical
  Network with Cascading Outputs and Maximum a Posteriori Path Estimation</title>
    <summary>  ISO 24617-2, the standard for dialog act annotation, defines a hierarchically
organized set of general-purpose communicative functions. The automatic
recognition of these functions, although practically unexplored, is relevant
for a dialog system, since they provide cues regarding the intention behind the
segments and how they should be interpreted. In this paper, we explore the
recognition of general-purpose communicative functions in the DialogBank, which
is a reference set of dialogs annotated according to the standard. To do so, we
adapt a state-of-the-art approach on flat dialog act recognition to deal with
the hierarchical classification problem. More specifically, we propose the use
of a hierarchical network with cascading outputs and maximum a posteriori path
estimation to predict the communicative function at each level of the
hierarchy, preserve the dependencies between the functions in the path, and
decide at which level to stop. Furthermore, since the amount of dialogs in the
DialogBank is reduced, we rely both on additional dialogs annotated using
mapping processes and on transfer learning to improve performance. The results
of our experiments show that the hierarchical approach outperforms a flat one
and that maximum a posteriori estimation outperforms an iterative prediction
approach based on masking.
</summary>
    <author>
      <name>Eugénio Ribeiro</name>
    </author>
    <author>
      <name>Ricardo Ribeiro</name>
    </author>
    <author>
      <name>David Martins de Matos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.3.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03507v1</id>
    <updated>2020-03-07T03:36:47Z</updated>
    <published>2020-03-07T03:36:47Z</published>
    <title>ECSP: A New Task for Emotion-Cause Span-Pair Extraction and
  Classification</title>
    <summary>  Emotion cause analysis such as emotion cause extraction (ECE) and
emotion-cause pair extraction (ECPE) have gradually attracted the attention of
many researchers. However, there are still two shortcomings in the existing
research: 1) In most cases, emotion expression and cause are not the whole
clause, but the span in the clause, so extracting the clause-pair rather than
the span-pair greatly limits its applications in real-world scenarios; 2) It is
not enough to extract the emotion expression clause without identifying the
emotion categories, the presence of emotion clause does not necessarily convey
emotional information explicitly due to different possible causes. In this
paper, we propose a new task: Emotion-Cause Span-Pair extraction and
classification (ECSP), which aims to extract the potential span-pair of emotion
and corresponding causes in a document, and make emotion classification for
each pair. In the new ECSP task, ECE and ECPE can be regarded as two special
cases at the clause-level. We propose a span-based extract-then-classify (ETC)
model, where emotion and cause are directly extracted and paired from the
document under the supervision of target span boundaries, and corresponding
categories are then classified using their pair representations and localized
context. Experiments show that our proposed ETC model outperforms the SOTA
model of ECE and ECPE task respectively and gets a fair-enough results on ECSP
task.
</summary>
    <author>
      <name>Hongliang Bi</name>
    </author>
    <author>
      <name>Pengyuan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03504v1</id>
    <updated>2020-03-07T03:29:01Z</updated>
    <published>2020-03-07T03:29:01Z</published>
    <title>A Post-processing Method for Detecting Unknown Intent of Dialogue System
  via Pre-trained Deep Neural Network Classifier</title>
    <summary>  With the maturity and popularity of dialogue systems, detecting user's
unknown intent in dialogue systems has become an important task. It is also one
of the most challenging tasks since we can hardly get examples, prior knowledge
or the exact numbers of unknown intents. In this paper, we propose SofterMax
and deep novelty detection (SMDN), a simple yet effective post-processing
method for detecting unknown intent in dialogue systems based on pre-trained
deep neural network classifiers. Our method can be flexibly applied on top of
any classifiers trained in deep neural networks without changing the model
architecture. We calibrate the confidence of the softmax outputs to compute the
calibrated confidence score (i.e., SofterMax) and use it to calculate the
decision boundary for unknown intent detection. Furthermore, we feed the
feature representations learned by the deep neural networks into traditional
novelty detection algorithm to detect unknown intents from different
perspectives. Finally, we combine the methods above to perform the joint
prediction. Our method classifies examples that differ from known intents as
unknown and does not require any examples or prior knowledge of it. We have
conducted extensive experiments on three benchmark dialogue datasets. The
results show that our method can yield significant improvements compared with
the state-of-the-art baselines
</summary>
    <author>
      <name>Ting-En Lin</name>
    </author>
    <author>
      <name>Hua Xu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.knosys.2019.104979</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.knosys.2019.104979" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Knowledge-Based Systems 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03504v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03504v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03484v1</id>
    <updated>2020-03-07T01:52:19Z</updated>
    <published>2020-03-07T01:52:19Z</published>
    <title>Synthetic Error Dataset Generation Mimicking Bengali Writing Pattern</title>
    <summary>  While writing Bengali using English keyboard, users often make spelling
mistakes. The accuracy of any Bengali spell checker or paragraph correction
module largely depends on the kind of error dataset it is based on. Manual
generation of such error dataset is a cumbersome process. In this research, We
present an algorithm for automatic misspelled Bengali word generation from
correct word through analyzing Bengali writing pattern using QWERTY layout
English keyboard. As part of our analysis, we have formed a list of most
commonly used Bengali words, phonetically similar replaceable clusters,
frequently mispressed replaceable clusters, frequently mispressed insertion
prone clusters and some rules for Juktakkhar (constant letter clusters)
handling while generating errors.
</summary>
    <author>
      <name>Md. Habibur Rahman Sifat</name>
    </author>
    <author>
      <name>Chowdhury Rafeed Rahman</name>
    </author>
    <author>
      <name>Mohammad Rafsan</name>
    </author>
    <author>
      <name>Md. Hasibur Rahman</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03446v1</id>
    <updated>2020-03-06T21:28:44Z</updated>
    <published>2020-03-06T21:28:44Z</published>
    <title>Natural Language QA Approaches using Reasoning with External Knowledge</title>
    <summary>  Question answering (QA) in natural language (NL) has been an important aspect
of AI from its early days. Winograd's ``councilmen'' example in his 1972 paper
and McCarthy's Mr. Hug example of 1976 highlights the role of external
knowledge in NL understanding. While Machine Learning has been the go-to
approach in NL processing as well as NL question answering (NLQA) for the last
30 years, recently there has been an increasingly emphasized thread on NLQA
where external knowledge plays an important role. The challenges inspired by
Winograd's councilmen example, and recent developments such as the Rebooting AI
book, various NLQA datasets, research on knowledge acquisition in the NLQA
context, and their use in various NLQA models have brought the issue of NLQA
using ``reasoning'' with external knowledge to the forefront. In this paper, we
present a survey of the recent work on them. We believe our survey will help
establish a bridge between multiple fields of AI, especially between (a) the
traditional fields of knowledge representation and reasoning and (b) the field
of NL understanding and NLQA.
</summary>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Pratyay Banerjee</name>
    </author>
    <author>
      <name>Kuntal Kumar Pal</name>
    </author>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, Work in Progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03444v1</id>
    <updated>2020-03-06T21:19:44Z</updated>
    <published>2020-03-06T21:19:44Z</published>
    <title>NYTWIT: A Dataset of Novel Words in the New York Times</title>
    <summary>  We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance.
</summary>
    <author>
      <name>Yuval Pinter</name>
    </author>
    <author>
      <name>Cassandra L. Jacobs</name>
    </author>
    <author>
      <name>Max Bittker</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03350v1</id>
    <updated>2020-03-06T18:27:39Z</updated>
    <published>2020-03-06T18:27:39Z</published>
    <title>Distributional semantic modeling: a revised technique to train term/word
  vector space models applying the ontology-related approach</title>
    <summary>  We design a new technique for the distributional semantic modeling with a
neural network-based approach to learn distributed term representations (or
term embeddings) - term vector space models as a result, inspired by the recent
ontology-related approach (using different types of contextual knowledge such
as syntactic knowledge, terminological knowledge, semantic knowledge, etc.) to
the identification of terms (term extraction) and relations between them
(relation extraction) called semantic pre-processing technology - SPT. Our
method relies on automatic term extraction from the natural language texts and
subsequent formation of the problem-oriented or application-oriented (also
deeply annotated) text corpora where the fundamental entity is the term
(includes non-compositional and compositional terms). This gives us an
opportunity to changeover from distributed word representations (or word
embeddings) to distributed term representations (or term embeddings). This
transition will allow to generate more accurate semantic maps of different
subject domains (also, of relations between input terms - it is useful to
explore clusters and oppositions, or to test your hypotheses about them). The
semantic map can be represented as a graph using Vec2graph - a Python library
for visualizing word embeddings (term embeddings in our case) as dynamic and
interactive graphs. The Vec2graph library coupled with term embeddings will not
only improve accuracy in solving standard NLP tasks, but also update the
conventional concept of automated ontology development. The main practical
result of our work is the development kit (set of toolkits represented as web
service APIs and web application), which provides all necessary routines for
the basic linguistic pre-processing and the semantic pre-processing of the
natural language texts in Ukrainian for future training of term vector space
models.
</summary>
    <author>
      <name>Oleksandr Palagin</name>
    </author>
    <author>
      <name>Vitalii Velychko</name>
    </author>
    <author>
      <name>Kyrylo Malakhov</name>
    </author>
    <author>
      <name>Oleksandr Shchurov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In English, 9 pages, 2 figures. Not published yet. Prepared for
  special issue (UkrPROG 2020 conference) of the scientific journal "Problems
  in programming" (Founder: National Academy of Sciences of Ukraine, Institute
  of Software Systems of NAS Ukraine)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03264v1</id>
    <updated>2020-03-06T15:03:08Z</updated>
    <published>2020-03-06T15:03:08Z</published>
    <title>Quality of Word Embeddings on Sentiment Analysis Tasks</title>
    <summary>  Word embeddings or distributed representations of words are being used in
various applications like machine translation, sentiment analysis, topic
identification etc. Quality of word embeddings and performance of their
applications depends on several factors like training method, corpus size and
relevance etc. In this study we compare performance of a dozen of pretrained
word embedding models on lyrics sentiment analysis and movie review polarity
tasks. According to our results, Twitter Tweets is the best on lyrics sentiment
analysis, whereas Google News and Common Crawl are the top performers on movie
polarity analysis. Glove trained models slightly outrun those trained with
Skipgram. Also, factors like topic relevance and size of corpus significantly
impact the quality of the models. When medium or large-sized text sets are
available, obtaining word embeddings from same training dataset is usually the
best choice.
</summary>
    <author>
      <name>Erion Çano</name>
    </author>
    <author>
      <name>Maurizio Morisio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-59569-6_42</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-59569-6_42" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, 2 tables. Published in proceedings of NLDB 2017,
  the 22nd Conference of Natural Language Processing and Information Systems,
  Liege, Belgium</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03239v1</id>
    <updated>2020-03-06T14:35:20Z</updated>
    <published>2020-03-06T14:35:20Z</published>
    <title>On the Role of Conceptualization in Commonsense Knowledge Graph
  Construction</title>
    <summary>  Commonsense knowledge graphs (CKG) like Atomic and ASER are substantially
different from conventional KG as they consist of much larger number of nodes
formed by loosely-structured texts, which, though, enable them to handle highly
diverse queries in natural language regarding commonsense, lead to unique
challenges to automatic KG construction methods. Besides identifying relations
absent from the KG between nodes, the methods are also expected to explore
absent nodes represented by texts, in which different real-world things or
entities may appear. To deal with innumerable entities involved with
commonsense in real world, we introduce to CKG construction methods
conceptualization, i.e., to view entities mentioned in texts as instances of
specific concepts or vice versa. We build synthetic triples by
conceptualization, and further formulate the task as triple classification,
handled by a discriminatory model with knowledge transferred from pretrained
language models and fine-tuned by negative sampling. Experiments demonstrate
that our methods could effectively identify plausible triples and expand the KG
by triples of both new nodes and edges in high diversity and novelty.
</summary>
    <author>
      <name>Mutian He</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <author>
      <name>Kun Xu</name>
    </author>
    <author>
      <name>Yu Dong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03235v1</id>
    <updated>2020-03-06T14:25:50Z</updated>
    <published>2020-03-06T14:25:50Z</published>
    <title>Practical Annotation Strategies for Question Answering Datasets</title>
    <summary>  Annotating datasets for question answering (QA) tasks is very costly, as it
requires intensive manual labor and often domain-specific knowledge. Yet
strategies for annotating QA datasets in a cost-effective manner are scarce. To
provide a remedy for practitioners, our objective is to develop heuristic rules
for annotating a subset of questions, so that the annotation cost is reduced
while maintaining both in- and out-of-domain performance. For this, we conduct
a large-scale analysis in order to derive practical recommendations. First, we
demonstrate experimentally that more training samples contribute often only to
a higher in-domain test-set performance, but do not help the model in
generalizing to unseen datasets. Second, we develop a model-guided annotation
strategy: it makes a recommendation with regard to which subset of samples
should be annotated. Its effectiveness is demonstrated in a case study based on
domain customization of QA to a clinical setting. Here, remarkably, annotating
a stratified subset with only 1.2% of the original training set achieves 97.7%
of the performance as if the complete dataset was annotated. Hence, the
labeling effort can be reduced immensely. Altogether, our work fulfills a
demand in practice when labeling budgets are limited and where thus
recommendations are needed for annotating QA datasets more cost-effectively.
</summary>
    <author>
      <name>Bernhard Kratzwald</name>
    </author>
    <author>
      <name>Xiang Yue</name>
    </author>
    <author>
      <name>Huan Sun</name>
    </author>
    <author>
      <name>Stefan Feuerriegel</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03204v1</id>
    <updated>2020-03-06T13:47:30Z</updated>
    <published>2020-03-06T13:47:30Z</published>
    <title>Is POS Tagging Necessary or Even Helpful for Neural Dependency Parsing?</title>
    <summary>  In the pre deep learning era, part-of-speech tags have been considered as
indispensable ingredients for feature engineering in dependency parsing due to
their important role in alleviating data sparseness of purely lexical features,
and quite a few works focus on joint tagging and parsing models to avoid error
propagation. In contrast, recent studies suggest that POS tagging becomes much
less important or even useless for neural parsing, especially when using
character-based word representations such as CharLSTM. Yet there still lacks a
full and systematic investigation on this interesting issue, both empirically
and linguistically. To answer this, we design four typical multi-task learning
frameworks (i.e., Share-Loose, Share-Tight, Stack-Discrete, Stack-Hidden), for
joint tagging and parsing based on the state-of-the-art biaffine parser.
Considering that it is much cheaper to annotate POS tags than parse trees, we
also investigate the utilization of large-scale heterogeneous POS-tag data. We
conduct experiments on both English and Chinese datasets, and the results
clearly show that POS tagging (both homogeneous and heterogeneous) can still
significantly improve parsing performance when using the Stack-Hidden joint
framework. We conduct detailed analysis and gain more insights from the
linguistic aspect.
</summary>
    <author>
      <name>Yu Zhang</name>
    </author>
    <author>
      <name>Zhenghua Li</name>
    </author>
    <author>
      <name>Houquan Zhou</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03131v1</id>
    <updated>2020-03-06T10:58:59Z</updated>
    <published>2020-03-06T10:58:59Z</published>
    <title>Morfessor EM+Prune: Improved Subword Segmentation with Expectation
  Maximization and Pruning</title>
    <summary>  Data-driven segmentation of words into subword units has been used in various
natural language processing applications such as automatic speech recognition
and statistical machine translation for almost 20 years. Recently it has became
more widely adopted, as models based on deep neural networks often benefit from
subword units even for morphologically simpler languages. In this paper, we
discuss and compare training algorithms for a unigram subword model, based on
the Expectation Maximization algorithm and lexicon pruning. Using English,
Finnish, North Sami, and Turkish data sets, we show that this approach is able
to find better solutions to the optimization problem defined by the Morfessor
Baseline model than its original recursive training algorithm. The improved
optimization also leads to higher morphological segmentation accuracy when
compared to a linguistic gold standard. We publish implementations of the new
algorithms in the widely-used Morfessor software package.
</summary>
    <author>
      <name>Stig-Arne Grönroos</name>
    </author>
    <author>
      <name>Sami Virpioja</name>
    </author>
    <author>
      <name>Mikko Kurimo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03106v1</id>
    <updated>2020-03-06T09:46:51Z</updated>
    <published>2020-03-06T09:46:51Z</published>
    <title>Sensitive Data Detection and Classification in Spanish Clinical Text:
  Experiments with BERT</title>
    <summary>  Massive digital data processing provides a wide range of opportunities and
benefits, but at the cost of endangering personal data privacy. Anonymisation
consists in removing or replacing sensitive information from data, enabling its
exploitation for different purposes while preserving the privacy of
individuals. Over the years, a lot of automatic anonymisation systems have been
proposed; however, depending on the type of data, the target language or the
availability of training documents, the task remains challenging still. The
emergence of novel deep-learning models during the last two years has brought
large improvements to the state of the art in the field of Natural Language
Processing. These advancements have been most noticeably led by BERT, a model
proposed by Google in 2018, and the shared language models pre-trained on
millions of documents. In this paper, we use a BERT-based sequence labelling
model to conduct a series of anonymisation experiments on several clinical
datasets in Spanish. We also compare BERT to other algorithms. The experiments
show that a simple BERT-based model with general-domain pre-training obtains
highly competitive results without any domain specific feature engineering.
</summary>
    <author>
      <name>Aitor García-Pablos</name>
    </author>
    <author>
      <name>Naiara Perez</name>
    </author>
    <author>
      <name>Montse Cuadros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at 12th Edition of Language Resources and Evaluation
  Conference (LREC2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03072v1</id>
    <updated>2020-03-06T08:29:37Z</updated>
    <published>2020-03-06T08:29:37Z</published>
    <title>Improving Neural Named Entity Recognition with Gazetteers</title>
    <summary>  The goal of this work is to improve the performance of a neural named entity
recognition system by adding input features that indicate a word is part of a
name included in a gazetteer. This article describes how to generate gazetteers
from the Wikidata knowledge graph as well as how to integrate the information
into a neural NER system. Experiments reveal that the approach yields
performance gains in two distinct languages: a high-resource, word-based
language, English and a high-resource, character-based language, Chinese.
Experiments were also performed in a low-resource language, Russian on a newly
annotated Russian NER corpus from Reddit tagged with four core types and twelve
extended types. This article reports a baseline score. It is a longer version
of a paper in the 33rd FLAIRS conference (Song et al. 2020).
</summary>
    <author>
      <name>Chan Hee Song</name>
    </author>
    <author>
      <name>Dawn Lawrie</name>
    </author>
    <author>
      <name>Tim Finin</name>
    </author>
    <author>
      <name>James Mayfield</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Short version accepted to the 33rd FLAIRS conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03069v1</id>
    <updated>2020-03-06T08:18:13Z</updated>
    <published>2020-03-06T08:18:13Z</published>
    <title>Parsing Thai Social Data: A New Challenge for Thai NLP</title>
    <summary>  Dependency parsing (DP) is a task that analyzes text for syntactic structure
and relationship between words. DP is widely used to improve natural language
processing (NLP) applications in many languages such as English. Previous works
on DP are generally applicable to formally written languages. However, they do
not apply to informal languages such as the ones used in social networks.
Therefore, DP has to be researched and explored with such social network data.
In this paper, we explore and identify a DP model that is suitable for Thai
social network data. After that, we will identify the appropriate linguistic
unit as an input. The result showed that, the transition based model called,
improve Elkared dependency parser outperform the others at UAS of 81.42%.
</summary>
    <author>
      <name>Sattaya Singkul</name>
    </author>
    <author>
      <name>Borirat Khampingyot</name>
    </author>
    <author>
      <name>Nattasit Maharattamalai</name>
    </author>
    <author>
      <name>Supawat Taerungruang</name>
    </author>
    <author>
      <name>Tawunrat Chalothorn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 8 figures, to be published in The 14th International Joint
  Symposium on Artificial Intelligence and Natural Language Processing
  (iSAI-NLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03064v1</id>
    <updated>2020-03-06T08:08:20Z</updated>
    <published>2020-03-06T08:08:20Z</published>
    <title>Transfer Learning for Information Extraction with Limited Data</title>
    <summary>  This paper presents a practical approach to fine-grained information
extraction. Through plenty of experiences of authors in practically applying
information extraction to business process automation, there can be found a
couple of fundamental technical challenges: (i) the availability of labeled
data is usually limited and (ii) highly detailed classification is required.
The main idea of our proposal is to leverage the concept of transfer learning,
which is to reuse the pre-trained model of deep neural networks, with a
combination of common statistical classifiers to determine the class of each
extracted term. To do that, we first exploit BERT to deal with the limitation
of training data in real scenarios, then stack BERT with Convolutional Neural
Networks to learn hidden representation for classification. To validate our
approach, we applied our model to an actual case of document processing, which
is a process of competitive bids for government projects in Japan. We used 100
documents for training and testing and confirmed that the model enables to
extract fine-grained named entities with a detailed level of information
preciseness specialized in the targeted business process, such as a department
name of application receivers.
</summary>
    <author>
      <name>Minh-Tien Nguyen</name>
    </author>
    <author>
      <name>Viet-Anh Phan</name>
    </author>
    <author>
      <name>Le Thai Linh</name>
    </author>
    <author>
      <name>Nguyen Hong Son</name>
    </author>
    <author>
      <name>Le Tien Dung</name>
    </author>
    <author>
      <name>Miku Hirano</name>
    </author>
    <author>
      <name>Hajime Hotta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, PACLING conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03044v1</id>
    <updated>2020-03-06T05:56:49Z</updated>
    <published>2020-03-06T05:56:49Z</published>
    <title>A Corpus for Detecting High-Context Medical Conditions in Intensive Care
  Patient Notes Focusing on Frequently Readmitted Patients</title>
    <summary>  A crucial step within secondary analysis of electronic health records (EHRs)
is to identify the patient cohort under investigation. While EHRs contain
medical billing codes that aim to represent the conditions and treatments
patients may have, much of the information is only present in the patient
notes. Therefore, it is critical to develop robust algorithms to infer
patients' conditions and treatments from their written notes. In this paper, we
introduce a dataset for patient phenotyping, a task that is defined as the
identification of whether a patient has a given medical condition (also
referred to as clinical indication or phenotype) based on their patient note.
Nursing Progress Notes and Discharge Summaries from the Intensive Care Unit of
a large tertiary care hospital were manually annotated for the presence of
several high-context phenotypes relevant to treatment and risk of
re-hospitalization. This dataset contains 1102 Discharge Summaries and 1000
Nursing Progress Notes. Each Discharge Summary and Progress Note has been
annotated by at least two expert human annotators (one clinical researcher and
one resident physician). Annotated phenotypes include treatment non-adherence,
chronic pain, advanced/metastatic cancer, as well as 10 other phenotypes. This
dataset can be utilized for academic and industrial research in medicine and
computer science, particularly within the field of medical natural language
processing.
</summary>
    <author>
      <name>Edward T. Moseley</name>
    </author>
    <author>
      <name>Joy T. Wu</name>
    </author>
    <author>
      <name>Jonathan Welt</name>
    </author>
    <author>
      <name>John Foote</name>
    </author>
    <author>
      <name>Patrick D. Tyler</name>
    </author>
    <author>
      <name>David W. Grant</name>
    </author>
    <author>
      <name>Eric T. Carlson</name>
    </author>
    <author>
      <name>Sebastian Gehrmann</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Leo Anthony Celi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03014v1</id>
    <updated>2020-03-06T03:02:12Z</updated>
    <published>2020-03-06T03:02:12Z</published>
    <title>A Framework for the Computational Linguistic Analysis of Dehumanization</title>
    <summary>  Dehumanization is a pernicious psychological process that often leads to
extreme intergroup bias, hate speech, and violence aimed at targeted social
groups. Despite these serious consequences and the wealth of available data,
dehumanization has not yet been computationally studied on a large scale.
Drawing upon social psychology research, we create a computational linguistic
framework for analyzing dehumanizing language by identifying linguistic
correlates of salient components of dehumanization. We then apply this
framework to analyze discussions of LGBTQ people in the New York Times from
1986 to 2015. Overall, we find increasingly humanizing descriptions of LGBTQ
people over time. However, we find that the label homosexual has emerged to be
much more strongly associated with dehumanizing attitudes than other labels,
such as gay. Our proposed techniques highlight processes of linguistic
variation and change in discourses surrounding marginalized groups.
Furthermore, the ability to analyze dehumanizing language at a large scale has
implications for automatically detecting and understanding media bias as well
as abusive language online.
</summary>
    <author>
      <name>Julia Mendelsohn</name>
    </author>
    <author>
      <name>Yulia Tsvetkov</name>
    </author>
    <author>
      <name>Dan Jurafsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 8 figures (Appendix is 3 pages, 2 figures). Submitted to
  Frontiers in Artificial Intelligence (Language and Computation)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02973v1</id>
    <updated>2020-03-06T00:18:50Z</updated>
    <published>2020-03-06T00:18:50Z</published>
    <title>S-APIR: News-based Business Sentiment Index</title>
    <summary>  This paper describes our work on developing a new business sentiment index
using daily newspaper articles. We adopt a recurrent neural network (RNN) with
Gated Recurrent Units to predict the business sentiment of a given text. An RNN
is initially trained on Economy Watchers Survey and then fine-tuned on news
texts for domain adaptation. Also, a one-class support vector machine is
applied to filter out texts deemed irrelevant to business sentiment. Moreover,
we propose a simple approach to temporally analyzing how much and when any
given factor influences the predicted business sentiment. The validity and
utility of the proposed approaches are empirically demonstrated through a
series of experiments on Nikkei Newspaper articles published from 2013 to 2018.
</summary>
    <author>
      <name>Kazuhiro Seki</name>
    </author>
    <author>
      <name>Yusuke Ikuta</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02958v1</id>
    <updated>2020-03-05T23:09:24Z</updated>
    <published>2020-03-05T23:09:24Z</published>
    <title>EmpTransfo: A Multi-head Transformer Architecture for Creating
  Empathetic Dialog Systems</title>
    <summary>  Understanding emotions and responding accordingly is one of the biggest
challenges of dialog systems. This paper presents EmpTransfo, a multi-head
Transformer architecture for creating an empathetic dialog system. EmpTransfo
utilizes state-of-the-art pre-trained models (e.g., OpenAI-GPT) for language
generation, though models with different sizes can be used. We show that
utilizing the history of emotions and other metadata can improve the quality of
generated conversations by the dialog system. Our experimental results using a
challenging language corpus show that the proposed approach outperforms other
models in terms of Hit@1 and PPL (Perplexity).
</summary>
    <author>
      <name>Rohola Zandie</name>
    </author>
    <author>
      <name>Mohammad H. Mahoor</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02955v1</id>
    <updated>2020-03-05T22:55:45Z</updated>
    <published>2020-03-05T22:55:45Z</published>
    <title>Automatic Compilation of Resources for Academic Writing and Evaluating
  with Informal Word Identification and Paraphrasing System</title>
    <summary>  We present the first approach to automatically building resources for
academic writing. The aim is to build a writing aid system that automatically
edits a text so that it better adheres to the academic style of writing. On top
of existing academic resources, such as the Corpus of Contemporary American
English (COCA) academic Word List, the New Academic Word List, and the Academic
Collocation List, we also explore how to dynamically build such resources that
would be used to automatically identify informal or non-academic words or
phrases. The resources are compiled using different generic approaches that can
be extended for different domains and languages. We describe the evaluation of
resources with a system implementation. The system consists of an informal word
identification (IWI), academic candidate paraphrase generation, and paraphrase
ranking components. To generate candidates and rank them in context, we have
used the PPDB and WordNet paraphrase resources. We use the Concepts in Context
(CoInCO) "All-Words" lexical substitution dataset both for the informal word
identification and paraphrase generation experiments. Our informal word
identification component achieves an F-1 score of 82%, significantly
outperforming a stratified classifier baseline. The main contribution of this
work is a domain-independent methodology to build targeted resources for
writing aids.
</summary>
    <author>
      <name>Seid Muhie Yimam</name>
    </author>
    <author>
      <name>Gopalakrishnan Venkatesh</name>
    </author>
    <author>
      <name>John Sie Yuen Lee</name>
    </author>
    <author>
      <name>Chris Biemann</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02931v1</id>
    <updated>2020-03-05T21:25:00Z</updated>
    <published>2020-03-05T21:25:00Z</published>
    <title>Neural Cross-Lingual Transfer and Limited Annotated Data for Named
  Entity Recognition in Danish</title>
    <summary>  Named Entity Recognition (NER) has greatly advanced by the introduction of
deep neural architectures. However, the success of these methods depends on
large amounts of training data. The scarcity of publicly-available
human-labeled datasets has resulted in limited evaluation of existing NER
systems, as is the case for Danish. This paper studies the effectiveness of
cross-lingual transfer for Danish, evaluates its complementarity to limited
gold data, and sheds light on performance of Danish NER.
</summary>
    <author>
      <name>Barbara Plank</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at NoDaLiDa 2019; updated (system, data and repository
  details)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NoDaLiDa, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.02931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02912v1</id>
    <updated>2020-03-05T20:42:51Z</updated>
    <published>2020-03-05T20:42:51Z</published>
    <title>What the [MASK]? Making Sense of Language-Specific BERT Models</title>
    <summary>  Recently, Natural Language Processing (NLP) has witnessed an impressive
progress in many areas, due to the advent of novel, pretrained contextual
representation models. In particular, Devlin et al. (2019) proposed a model,
called BERT (Bidirectional Encoder Representations from Transformers), which
enables researchers to obtain state-of-the art performance on numerous NLP
tasks by fine-tuning the representations on their data set and task, without
the need for developing and training highly-specific architectures. The authors
also released multilingual BERT (mBERT), a model trained on a corpus of 104
languages, which can serve as a universal language model. This model obtained
impressive results on a zero-shot cross-lingual natural inference task. Driven
by the potential of BERT models, the NLP community has started to investigate
and generate an abundant number of BERT models that are trained on a particular
language, and tested on a specific data domain and task. This allows us to
evaluate the true potential of mBERT as a universal language model, by
comparing it to the performance of these more specific models. This paper
presents the current state of the art in language-specific BERT models,
providing an overall picture with respect to different dimensions (i.e.
architectures, data domains, and tasks). Our aim is to provide an immediate and
straightforward overview of the commonalities and differences between
Language-Specific (language-specific) BERT models and mBERT. We also provide an
interactive and constantly updated website that can be used to explore the
information we have collected, at https://bertlang.unibocconi.it.
</summary>
    <author>
      <name>Debora Nozza</name>
    </author>
    <author>
      <name>Federico Bianchi</name>
    </author>
    <author>
      <name>Dirk Hovy</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02877v1</id>
    <updated>2020-03-05T19:14:33Z</updated>
    <published>2020-03-05T19:14:33Z</published>
    <title>Distill, Adapt, Distill: Training Small, In-Domain Models for Neural
  Machine Translation</title>
    <summary>  We explore best practices for training small, memory efficient machine
translation models with sequence-level knowledge distillation in the domain
adaptation setting. While both domain adaptation and knowledge distillation are
widely-used, their interaction remains little understood. Our large-scale
empirical results in machine translation (on three language pairs with three
domains each) suggest distilling twice for best performance: once using
general-domain data and again using in-domain data with an adapted teacher.
</summary>
    <author>
      <name>Mitchell A. Gordon</name>
    </author>
    <author>
      <name>Kevin Duh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02817v1</id>
    <updated>2020-03-05T18:40:44Z</updated>
    <published>2020-03-05T18:40:44Z</published>
    <title>An Empirical Accuracy Law for Sequential Machine Translation: the Case
  of Google Translate</title>
    <summary>  We have established, through empirical testing, a law that relates the number
of translating hops to translation accuracy in sequential machine translation
in Google Translate. Both accuracy and size decrease with the number of hops;
the former displays a decrease closely following a power law. Such a law allows
one to predict the behavior of translation chains that may be built as society
increasingly depends on automated devices.
</summary>
    <author>
      <name>Lucas Nunes Sequeira</name>
    </author>
    <author>
      <name>Bruno Moreschi</name>
    </author>
    <author>
      <name>Fabio Gagliardi Cozman</name>
    </author>
    <author>
      <name>Bernardo Fontes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures (mostly graphs), a few mathematical functions and
  samples of the experiment</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02756v1</id>
    <updated>2020-03-05T16:46:35Z</updated>
    <published>2020-03-05T16:46:35Z</published>
    <title>HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in
  Natural Language Inference</title>
    <summary>  Many recent studies have shown that for models trained on datasets for
natural language inference (NLI), it is possible to make correct predictions by
merely looking at the hypothesis while completely ignoring the premise. In this
work, we manage to derive adversarial examples in terms of the hypothesis-only
bias and explore eligible ways to mitigate such bias. Specifically, we extract
various phrases from the hypotheses (artificial patterns) in the training sets,
and show that they have been strong indicators to the specific labels. We then
figure out `hard' and `easy' instances from the original test sets whose labels
are opposite to or consistent with those indications. We also set up baselines
including both pretrained models (BERT, RoBERTa, XLNet) and competitive
non-pretrained models (InferSent, DAM, ESIM). Apart from the benchmark and
baselines, we also investigate two debiasing approaches which exploit the
artificial pattern modeling to mitigate such hypothesis-only bias:
down-sampling and adversarial training. We believe those methods can be treated
as competitive baselines in NLI debiasing tasks.
</summary>
    <author>
      <name>Tianyu Liu</name>
    </author>
    <author>
      <name>Xin Zheng</name>
    </author>
    <author>
      <name>Baobao Chang</name>
    </author>
    <author>
      <name>Zhifang Sui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02739v1</id>
    <updated>2020-03-05T16:07:32Z</updated>
    <published>2020-03-05T16:07:32Z</published>
    <title>Zero-Shot Cross-Lingual Transfer with Meta Learning</title>
    <summary>  Learning what to share between tasks has been a topic of high importance
recently, as strategic sharing of knowledge has been shown to improve the
performance of downstream tasks. The same applies to sharing between languages,
and is especially important when considering the fact that most languages in
the world suffer from being under-resourced. In this paper, we consider the
setting of training models on multiple different languages at the same time,
when little or no data is available for languages other than English. We show
that this challenging setup can be approached using meta-learning, where, in
addition to training a source language model, another model learns to select
which training instances are the most beneficial. We experiment using standard
supervised, zero-shot cross-lingual, as well as few-shot cross-lingual settings
for different natural language understanding tasks (natural language inference,
question answering). Our extensive experimental setup demonstrates the
consistent effectiveness of meta-learning, on a total 16 languages. We improve
upon state-of-the-art on zero-shot and few-shot NLI and QA tasks on the XNLI
and X-WikiRe datasets, respectively. We further conduct a comprehensive
analysis which indicates that correlation of typological features between
languages can further explain when parameter sharing learned via meta learning
is beneficial.
</summary>
    <author>
      <name>Farhad Nooralahzadeh</name>
    </author>
    <author>
      <name>Giannis Bekoulis</name>
    </author>
    <author>
      <name>Johannes Bjerva</name>
    </author>
    <author>
      <name>Isabelle Augenstein</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02738v1</id>
    <updated>2020-03-05T16:06:37Z</updated>
    <published>2020-03-05T16:06:37Z</published>
    <title>BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward</title>
    <summary>  Measuring the quality of a generated sequence against a set of references is
a central problem in many learning frameworks, be it to compute a score, to
assign a reward, or to perform discrimination. Despite great advances in model
architectures, metrics that scale independently of the number of references are
still based on n-gram estimates. We show that the underlying operations,
counting words and comparing counts, can be lifted to embedding words and
comparing embeddings. An in-depth analysis of BERT embeddings shows empirically
that contextual embeddings can be employed to capture the required dependencies
while maintaining the necessary scalability through appropriate pruning and
smoothing techniques. We cast unconditional generation as a reinforcement
learning problem and show that our reward function indeed provides a more
effective learning signal than n-gram reward in this challenging setting.
</summary>
    <author>
      <name>Florian Schmidt</name>
    </author>
    <author>
      <name>Thomas Hofmann</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02736v1</id>
    <updated>2020-03-05T16:06:07Z</updated>
    <published>2020-03-05T16:06:07Z</published>
    <title>Fact Check-Worthiness Detection as Positive Unlabelled Learning</title>
    <summary>  A critical component of automatically combating misinformation is the
detection of fact check-worthiness, i.e. determining if a piece of information
should be checked for veracity. There are multiple isolated lines of research
which address this core issue: check-worthiness detection from political
speeches and debates, rumour detection on Twitter, and citation needed
detection from Wikipedia. What is still lacking is a structured comparison of
these variants of check-worthiness, as well as a unified approach to them. We
find that check-worthiness detection is a very challenging task in any domain,
because it both hinges upon detecting how factual a sentence is, and how likely
a sentence is to be believed without verification. As such, annotators often
only mark those instances they judge to be clear-cut check-worthy. Our
best-performing method automatically corrects for this, using a variant of
positive unlabelled learning, which learns when an instance annotated as not
check-worthy should in fact have been annotated as being check-worthy. In
applying this, we outperform the state of the art in two of the three domains
studied for check-worthiness detection in English.
</summary>
    <author>
      <name>Dustin Wright</name>
    </author>
    <author>
      <name>Isabelle Augenstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02599v2</id>
    <updated>2020-03-06T10:33:23Z</updated>
    <published>2020-03-05T13:22:23Z</published>
    <title>An Incremental Explanation of Inference in Hybrid Bayesian Networks for
  Increasing Model Trustworthiness and Supporting Clinical Decision Making</title>
    <summary>  Various AI models are increasingly being considered as part of clinical
decision-support tools. However, the trustworthiness of such models is rarely
considered. Clinicians are more likely to use a model if they can understand
and trust its predictions. Key to this is if its underlying reasoning can be
explained. A Bayesian network (BN) model has the advantage that it is not a
black-box and its reasoning can be explained. In this paper, we propose an
incremental explanation of inference that can be applied to hybrid BNs, i.e.
those that contain both discrete and continuous nodes. The key questions that
we answer are: (1) which important evidence supports or contradicts the
prediction, and (2) through which intermediate variables does the information
flow. The explanation is illustrated using a real clinical case study. A small
evaluation study is also conducted.
</summary>
    <author>
      <name>Evangelia Kyrimi</name>
    </author>
    <author>
      <name>Somayyeh Mossadegh</name>
    </author>
    <author>
      <name>Nigel Tai</name>
    </author>
    <author>
      <name>William Marsh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02599v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02599v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02498v1</id>
    <updated>2020-03-05T09:25:30Z</updated>
    <published>2020-03-05T09:25:30Z</published>
    <title>RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and
  Evaluation System</title>
    <summary>  Interests in the automatic generation of cooking recipes have been growing
steadily over the past few years thanks to a large amount of online cooking
recipes. We present RecipeGPT, a novel online recipe generation and evaluation
system. The system provides two modes of text generations: (1) instruction
generation from given recipe title and ingredients; and (2) ingredient
generation from recipe title and cooking instructions. Its back-end text
generation module comprises a generative pre-trained language model GPT-2
fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation
module allows the users to conveniently inspect the quality of the generated
recipe contents and store the results for future reference. RecipeGPT can be
accessed online at https://recipegpt.org/.
</summary>
    <author>
      <name>Helena H. Lee</name>
    </author>
    <author>
      <name>Ke Shu</name>
    </author>
    <author>
      <name>Palakorn Achananuparp</name>
    </author>
    <author>
      <name>Philips Kokoh Prasetyo</name>
    </author>
    <author>
      <name>Yue Liu</name>
    </author>
    <author>
      <name>Ee-Peng Lim</name>
    </author>
    <author>
      <name>Lav R. Varshney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to WWW 2020. Demo track paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02356v2</id>
    <updated>2020-03-06T18:51:54Z</updated>
    <published>2020-03-04T22:45:22Z</published>
    <title>Kleister: A novel task for Information Extraction involving Long
  Documents with Complex Layout</title>
    <summary>  State-of-the-art solutions for Natural Language Processing (NLP) are able to
capture a broad range of contexts, like the sentence-level context or
document-level context for short documents. But these solutions are still
struggling when it comes to longer, real-world documents with the information
encoded in the spatial structure of the document, such as page elements like
tables, forms, headers, openings or footers; complex page layout or presence of
multiple pages.
  To encourage progress on deeper and more complex Information Extraction (IE)
we introduce a new task (named Kleister) with two new datasets. Utilizing both
textual and structural layout features, an NLP system must find the most
important information, about various types of entities, in long formal
documents. We propose Pipeline method as a text-only baseline with different
Named Entity Recognition architectures (Flair, BERT, RoBERTa). Moreover, we
checked the most popular PDF processing tools for text extraction (pdf2djvu,
Tesseract and Textract) in order to analyze behavior of IE system in presence
of errors introduced by these tools.
</summary>
    <author>
      <name>Filip Graliński</name>
    </author>
    <author>
      <name>Tomasz Stanisławek</name>
    </author>
    <author>
      <name>Anna Wróblewska</name>
    </author>
    <author>
      <name>Dawid Lipiński</name>
    </author>
    <author>
      <name>Agnieszka Kaliska</name>
    </author>
    <author>
      <name>Paulina Rosalska</name>
    </author>
    <author>
      <name>Bartosz Topolski</name>
    </author>
    <author>
      <name>Przemysław Biecek</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02356v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02356v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02349v1</id>
    <updated>2020-03-04T22:12:18Z</updated>
    <published>2020-03-04T22:12:18Z</published>
    <title>A Study on Efficiency, Accuracy and Document Structure for Answer
  Sentence Selection</title>
    <summary>  An essential task of most Question Answering (QA) systems is to re-rank the
set of answer candidates, i.e., Answer Sentence Selection (A2S). These
candidates are typically sentences either extracted from one or more documents
preserving their natural order or retrieved by a search engine. Most
state-of-the-art approaches to the task use huge neural models, such as BERT,
or complex attentive architectures. In this paper, we argue that by exploiting
the intrinsic structure of the original rank together with an effective
word-relatedness encoder, we can achieve competitive results with respect to
the state of the art while retaining high efficiency. Our model takes 9.5
seconds to train on the WikiQA dataset, i.e., very fast in comparison with the
$\sim 18$ minutes required by a standard BERT-base fine-tuning.
</summary>
    <author>
      <name>Daniele Bonadiman</name>
    </author>
    <author>
      <name>Alessandro Moschitti</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02301v1</id>
    <updated>2020-03-04T19:30:15Z</updated>
    <published>2020-03-04T19:30:15Z</published>
    <title>Real-time, Universal, and Robust Adversarial Attacks Against Speaker
  Recognition Systems</title>
    <summary>  As the popularity of voice user interface (VUI) exploded in recent years,
speaker recognition system has emerged as an important medium of identifying a
speaker in many security-required applications and services. In this paper, we
propose the first real-time, universal, and robust adversarial attack against
the state-of-the-art deep neural network (DNN) based speaker recognition
system. Through adding an audio-agnostic universal perturbation on arbitrary
enrolled speaker's voice input, the DNN-based speaker recognition system would
identify the speaker as any target (i.e., adversary-desired) speaker label. In
addition, we improve the robustness of our attack by modeling the sound
distortions caused by the physical over-the-air propagation through estimating
room impulse response (RIR). Experiment using a public dataset of $109$ English
speakers demonstrates the effectiveness and robustness of our proposed attack
with a high attack success rate of over 90%. The attack launching time also
achieves a 100X speedup over contemporary non-universal attacks.
</summary>
    <author>
      <name>Yi Xie</name>
    </author>
    <author>
      <name>Cong Shi</name>
    </author>
    <author>
      <name>Zhuohang Li</name>
    </author>
    <author>
      <name>Jian Liu</name>
    </author>
    <author>
      <name>Yingying Chen</name>
    </author>
    <author>
      <name>Bo Yuan</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02249v1</id>
    <updated>2020-03-04T18:41:10Z</updated>
    <published>2020-03-04T18:41:10Z</published>
    <title>jiant: A Software Toolkit for Research on General-Purpose Text
  Understanding Models</title>
    <summary>  We introduce jiant, an open source toolkit for conducting multitask and
transfer learning experiments on English NLU tasks. jiant enables modular and
configuration-driven experimentation with state-of-the-art models and
implements a broad set of tasks for probing, transfer learning, and multitask
training experiments. jiant implements over 50 NLU tasks, including all GLUE
and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published
performance on a variety of tasks and models, including BERT and RoBERTa. jiant
is available at https://jiant.info.
</summary>
    <author>
      <name>Yada Pruksachatkun</name>
    </author>
    <author>
      <name>Phil Yeres</name>
    </author>
    <author>
      <name>Haokun Liu</name>
    </author>
    <author>
      <name>Jason Phang</name>
    </author>
    <author>
      <name>Phu Mon Htut</name>
    </author>
    <author>
      <name>Alex Wang</name>
    </author>
    <author>
      <name>Ian Tenney</name>
    </author>
    <author>
      <name>Samuel R. Bowman</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02245v1</id>
    <updated>2020-03-04T18:35:19Z</updated>
    <published>2020-03-04T18:35:19Z</published>
    <title>Data Augmentation using Pre-trained Transformer Models</title>
    <summary>  Language model based pre-trained models such as BERT have provided
significant gains across different NLP tasks. In this paper, we study different
types of pre-trained transformer based models such as auto-regressive models
(GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional
data augmentation. We show that prepending the class labels to text sequences
provides a simple yet effective way to condition the pre-trained models for
data augmentation. On three classification benchmarks, pre-trained Seq2Seq
model outperforms other models. Further, we explore how different pre-trained
model based data augmentation differs in-terms of data diversity, and how well
such methods preserve the class-label information.
</summary>
    <author>
      <name>Varun Kumar</name>
    </author>
    <author>
      <name>Ashutosh Choudhary</name>
    </author>
    <author>
      <name>Eunah Cho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02244v1</id>
    <updated>2020-03-04T18:31:32Z</updated>
    <published>2020-03-04T18:31:32Z</published>
    <title>Unsupervised Adversarial Domain Adaptation for Implicit Discourse
  Relation Classification</title>
    <summary>  Implicit discourse relations are not only more challenging to classify, but
also to annotate, than their explicit counterparts. We tackle situations where
training data for implicit relations are lacking, and exploit domain adaptation
from explicit relations (Ji et al., 2015). We present an unsupervised
adversarial domain adaptive network equipped with a reconstruction component.
Our system outperforms prior works and other adversarial benchmarks for
unsupervised domain adaptation. Additionally, we extend our system to take
advantage of labeled data if some are available.
</summary>
    <author>
      <name>Hsin-Ping Huang</name>
    </author>
    <author>
      <name>Junyi Jessy Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CoNLL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02197v2</id>
    <updated>2020-03-06T04:09:27Z</updated>
    <published>2020-03-04T17:10:10Z</published>
    <title>Evaluating Low-Resource Machine Translation between Chinese and
  Vietnamese with Back-Translation</title>
    <summary>  Back translation (BT) has been widely used and become one of standard
techniques for data augmentation in Neural Machine Translation (NMT), BT has
proven to be helpful for improving the performance of translation effectively,
especially for low-resource scenarios. While most works related to BT mainly
focus on European languages, few of them study languages in other areas around
the world. In this paper, we investigate the impacts of BT on Asia language
translations between the extremely low-resource Chinese and Vietnamese language
pair. We evaluate and compare the effects of different sizes of synthetic data
on both NMT and Statistical Machine Translation (SMT) models for Chinese to
Vietnamese and Vietnamese to Chinese, with character-based and word-based
settings. Some conclusions from previous works are partially confirmed and we
also draw some other interesting findings and conclusions, which are beneficial
to understand BT further.
</summary>
    <author>
      <name>Hongzheng Li</name>
    </author>
    <author>
      <name>Heyan Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02197v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02197v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02639v1</id>
    <updated>2020-03-04T15:07:03Z</updated>
    <published>2020-03-04T15:07:03Z</published>
    <title>Phase transitions in a decentralized graph-based approach to human
  language</title>
    <summary>  Zipf's law establishes a scaling behavior for word-frequencies in large text
corpora. The appearance of Zipfian properties in human language has been
previously explained as an optimization problem for the interests of speakers
and hearers. On the other hand, human-like vocabularies can be viewed as
bipartite graphs. The aim here is double: within a bipartite-graph approach to
human vocabularies, to propose a decentralized language game model for the
formation of Zipfian properties. To do this, we define a language game, in
which a population of artificial agents is involved in idealized linguistic
interactions. Numerical simulations show the appearance of a phase transition
from an initially disordered state to three possible phases for language
formation. Our results suggest that Zipfian properties in language seem to
arise partly from decentralized linguistic interactions between agents endowed
with bipartite word-meaning mappings.
</summary>
    <author>
      <name>Javier Vera</name>
    </author>
    <author>
      <name>Felipe Urbina</name>
    </author>
    <author>
      <name>Wenceslao Palma</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02020v1</id>
    <updated>2020-03-04T11:57:53Z</updated>
    <published>2020-03-04T11:57:53Z</published>
    <title>Posterior-GAN: Towards Informative and Coherent Response Generation with
  Posterior Generative Adversarial Network</title>
    <summary>  Neural conversational models learn to generate responses by taking into
account the dialog history. These models are typically optimized over the
query-response pairs with a maximum likelihood estimation objective. However,
the query-response tuples are naturally loosely coupled, and there exist
multiple responses that can respond to a given query, which leads the
conversational model learning burdensome. Besides, the general dull response
problem is even worsened when the model is confronted with meaningless response
training instances. Intuitively, a high-quality response not only responds to
the given query but also links up to the future conversations, in this paper,
we leverage the query-response-future turn triples to induce the generated
responses that consider both the given context and the future conversations. To
facilitate the modeling of these triples, we further propose a novel
encoder-decoder based generative adversarial learning framework, Posterior
Generative Adversarial Network (Posterior-GAN), which consists of a forward and
a backward generative discriminator to cooperatively encourage the generated
response to be informative and coherent by two complementary assessment
perspectives. Experimental results demonstrate that our method effectively
boosts the informativeness and coherence of the generated response on both
automatic and human evaluation, which verifies the advantages of considering
two assessment perspectives.
</summary>
    <author>
      <name>Shaoxiong Feng</name>
    </author>
    <author>
      <name>Hongshen Chen</name>
    </author>
    <author>
      <name>Kan Li</name>
    </author>
    <author>
      <name>Dawei Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01950v1</id>
    <updated>2020-03-04T08:44:32Z</updated>
    <published>2020-03-04T08:44:32Z</published>
    <title>AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit
  Alignment</title>
    <summary>  Targeting at both high efficiency and performance, we propose AlignTTS to
predict the mel-spectrum in parallel. AlignTTS is based on a Feed-Forward
Transformer which generates mel-spectrum from a sequence of characters, and the
duration of each character is determined by a duration predictor.Instead of
adopting the attention mechanism in Transformer TTS to align text to
mel-spectrum, the alignment loss is presented to consider all possible
alignments in training by use of dynamic programming. Experiments on the
LJSpeech dataset show that our model achieves not only state-of-the-art
performance which outperforms Transformer TTS by 0.03 in mean option score
(MOS), but also a high efficiency which is more than 50 times faster than
real-time.
</summary>
    <author>
      <name>Zhen Zeng</name>
    </author>
    <author>
      <name>Jianzong Wang</name>
    </author>
    <author>
      <name>Ning Cheng</name>
    </author>
    <author>
      <name>Tian Xia</name>
    </author>
    <author>
      <name>Jing Xiao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">will be presented in ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01924v1</id>
    <updated>2020-03-04T07:44:55Z</updated>
    <published>2020-03-04T07:44:55Z</published>
    <title>GraphTTS: graph-to-sequence modelling in neural text-to-speech</title>
    <summary>  This paper leverages the graph-to-sequence method in neural text-to-speech
(GraphTTS), which maps the graph embedding of the input sequence to
spectrograms. The graphical inputs consist of node and edge representations
constructed from input texts. The encoding of these graphical inputs
incorporates syntax information by a GNN encoder module. Besides, applying the
encoder of GraphTTS as a graph auxiliary encoder (GAE) can analyse prosody
information from the semantic structure of texts. This can remove the manual
selection of reference audios process and makes prosody modelling an end-to-end
procedure. Experimental analysis shows that GraphTTS outperforms the
state-of-the-art sequence-to-sequence models by 0.24 in Mean Opinion Score
(MOS). GAE can adjust the pause, ventilation and tones of synthesised audios
automatically. This experimental conclusion may give some inspiration to
researchers working on improving speech synthesis prosody.
</summary>
    <author>
      <name>Aolan Sun</name>
    </author>
    <author>
      <name>Jianzong Wang</name>
    </author>
    <author>
      <name>Ning Cheng</name>
    </author>
    <author>
      <name>Huayi Peng</name>
    </author>
    <author>
      <name>Zhen Zeng</name>
    </author>
    <author>
      <name>Jing Xiao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01912v1</id>
    <updated>2020-03-04T06:36:50Z</updated>
    <published>2020-03-04T06:36:50Z</published>
    <title>Restoration of Fragmentary Babylonian Texts Using Recurrent Neural
  Networks</title>
    <summary>  The main source of information regarding ancient Mesopotamian history and
culture are clay cuneiform tablets. Despite being an invaluable resource, many
tablets are fragmented leading to missing information. Currently these missing
parts are manually completed by experts. In this work we investigate the
possibility of assisting scholars and even automatically completing the breaks
in ancient Akkadian texts from Achaemenid period Babylonia by modelling the
language using recurrent neural networks.
</summary>
    <author>
      <name>Ethan Fetaya</name>
    </author>
    <author>
      <name>Yonatan Lifshitz</name>
    </author>
    <author>
      <name>Elad Aaron</name>
    </author>
    <author>
      <name>Shai Gordin</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01857v1</id>
    <updated>2020-03-04T02:00:57Z</updated>
    <published>2020-03-04T02:00:57Z</published>
    <title>SeMemNN: A Semantic Matrix-Based Memory Neural Network for Text
  Classification</title>
    <summary>  Text categorization is the task of assigning labels to documents written in a
natural language, and it has numerous real-world applications including
sentiment analysis as well as traditional topic assignment tasks. In this
paper, we propose 5 different configurations for the semantic matrix-based
memory neural network with end-to-end learning manner and evaluate our proposed
method on two corpora of news articles (AG news, Sogou news). The best
performance of our proposed method outperforms the baseline VDCNN models on the
text classification task and gives a faster speed for learning semantics.
Moreover, we also evaluate our model on small scale datasets. The results show
that our proposed method can still achieve better results in comparison to
VDCNN on the small scale dataset. This paper is to appear in the Proceedings of
the 2020 IEEE 14th International Conference on Semantic Computing (ICSC 2020),
San Diego, California, 2020.
</summary>
    <author>
      <name>Changzeng Fu</name>
    </author>
    <author>
      <name>Chaoran Liu</name>
    </author>
    <author>
      <name>Carlos Toshinori Ishi</name>
    </author>
    <author>
      <name>Yuichiro Yoshikawa</name>
    </author>
    <author>
      <name>Hiroshi Ishiguro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICSC.2020.00076</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICSC.2020.00076" rel="related"/>
    <link href="http://arxiv.org/abs/2003.01857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01848v1</id>
    <updated>2020-03-04T01:14:27Z</updated>
    <published>2020-03-04T01:14:27Z</published>
    <title>On Emergent Communication in Competitive Multi-Agent Teams</title>
    <summary>  Several recent works have found the emergence of grounded compositional
language in the communication protocols developed by mostly cooperative
multi-agent systems when learned end-to-end to maximize performance on a
downstream task. However, human populations learn to solve complex tasks
involving communicative behaviors not only in fully cooperative settings but
also in scenarios where competition acts as an additional external pressure for
improvement. In this work, we investigate whether competition for performance
from an external, similar agent team could act as a social influence that
encourages multi-agent populations to develop better communication protocols
for improved performance, compositionality, and convergence speed. We start
from Task &amp; Talk, a previously proposed referential game between two
cooperative agents as our testbed and extend it into Task, Talk &amp; Compete, a
game involving two competitive teams each consisting of two aforementioned
cooperative agents. Using this new setting, we provide an empirical study
demonstrating the impact of competitive influence on multi-agent teams. Our
results show that an external competitive influence leads to improved accuracy
and generalization, as well as faster emergence of communicative languages that
are more informative and compositional.
</summary>
    <author>
      <name>Paul Pu Liang</name>
    </author>
    <author>
      <name>Jeffrey Chen</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Louis-Philippe Morency</name>
    </author>
    <author>
      <name>Satwik Kottur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAMAS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01821v1</id>
    <updated>2020-03-03T22:44:10Z</updated>
    <published>2020-03-03T22:44:10Z</published>
    <title>HyperEmbed: Tradeoffs Between Resources and Performance in NLP Tasks
  with Hyperdimensional Computing enabled Embedding of n-gram Statistics</title>
    <summary>  Recent advances in Deep Learning have led to a significant performance
increase on several NLP tasks, however, the models become more and more
computationally demanding. Therefore, this paper tackles the domain of
computationally efficient algorithms for NLP tasks. In particular, it
investigates distributed representations of n-gram statistics of texts. The
representations are formed using hyperdimensional computing enabled embedding.
These representations then serve as features, which are used as input to
standard classifiers. We investigate the applicability of the embedding on one
large and three small standard datasets for classification tasks using nine
classifiers. The embedding achieved on par F1 scores while decreasing the time
and memory requirements by several times compared to the conventional n-gram
statistics, e.g., for one of the classifiers on a small dataset, the memory
reduction was 6.18 times; while train and test speed-ups were 4.62 and 3.84
times, respectively. For many classifiers on the large dataset, the memory
reduction was about 100 times and train and test speed-ups were over 100 times.
More importantly, the usage of distributed representations formed via
hyperdimensional computing allows dissecting the strict dependency between the
dimensionality of the representation and the parameters of n-gram statistics,
thus, opening a room for tradeoffs.
</summary>
    <author>
      <name>Pedro Alonso</name>
    </author>
    <author>
      <name>Kumar Shridhar</name>
    </author>
    <author>
      <name>Denis Kleyko</name>
    </author>
    <author>
      <name>Evgeny Osipov</name>
    </author>
    <author>
      <name>Marcus Liwicki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 1 figure, 12 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01797v1</id>
    <updated>2020-03-03T21:13:12Z</updated>
    <published>2020-03-03T21:13:12Z</published>
    <title>Discover Your Social Identity from What You Tweet: a Content Based
  Approach</title>
    <summary>  An identity denotes the role an individual or a group plays in highly
differentiated contemporary societies. In this paper, our goal is to classify
Twitter users based on their role identities. We first collect a coarse-grained
public figure dataset automatically, then manually label a more fine-grained
identity dataset. We propose a hierarchical self-attention neural network for
Twitter user role identity classification. Our experiments demonstrate that the
proposed model significantly outperforms multiple baselines. We further propose
a transfer learning scheme that improves our model's performance by a large
margin. Such transfer learning also greatly reduces the need for a large amount
of human labeled data.
</summary>
    <author>
      <name>Binxuan Huang</name>
    </author>
    <author>
      <name>Kathleen M. Carley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-42699-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-42699-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a preprint of a chapter published in Disinformation,
  Misinformation, and Fake News in Social Media: Emerging Research Challenges
  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,
  Springer reproduced with permission of Springer Nature Switzerland AG. The
  final authenticated version is available online at:
  http://dx.doi.org/10.1007/978-3-030-42699-6</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01787v1</id>
    <updated>2020-03-03T20:48:43Z</updated>
    <published>2020-03-03T20:48:43Z</published>
    <title>Untangling in Invariant Speech Recognition</title>
    <summary>  Encouraged by the success of deep neural networks on a variety of visual
tasks, much theoretical and experimental work has been aimed at understanding
and interpreting how vision networks operate. Meanwhile, deep neural networks
have also achieved impressive performance in audio processing applications,
both as sub-components of larger systems and as complete end-to-end systems by
themselves. Despite their empirical successes, comparatively little is
understood about how these audio models accomplish these tasks. In this work,
we employ a recently developed statistical mechanical theory that connects
geometric properties of network representations and the separability of classes
to probe how information is untangled within neural networks trained to
recognize speech. We observe that speaker-specific nuisance variations are
discarded by the network's hierarchy, whereas task-relevant properties such as
words and phonemes are untangled in later layers. Higher level concepts such as
parts-of-speech and context dependence also emerge in the later layers of the
network. Finally, we find that the deep representations carry out significant
temporal untangling by efficiently extracting task-relevant features at each
time step of the computation. Taken together, these findings shed light on how
deep auditory models process time dependent input signals to achieve invariant
speech recognition, and show how different concepts emerge through the layers
of the network.
</summary>
    <author>
      <name>Cory Stephenson</name>
    </author>
    <author>
      <name>Jenelle Feather</name>
    </author>
    <author>
      <name>Suchismita Padhy</name>
    </author>
    <author>
      <name>Oguz Elibol</name>
    </author>
    <author>
      <name>Hanlin Tang</name>
    </author>
    <author>
      <name>Josh McDermott</name>
    </author>
    <author>
      <name>SueYeon Chung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Neural Information Processing Systems. 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04360v1</id>
    <updated>2020-03-03T20:35:36Z</updated>
    <published>2020-03-03T20:35:36Z</published>
    <title>GenNet : Reading Comprehension with Multiple Choice Questions using
  Generation and Selection model</title>
    <summary>  Multiple-choice machine reading comprehension is difficult task as its
required machines to select the correct option from a set of candidate or
possible options using the given passage and question.Reading Comprehension
with Multiple Choice Questions task,required a human (or machine) to read a
given passage, question pair and select the best one option from n given
options. There are two different ways to select the correct answer from the
given passage. Either by selecting the best match answer to by eliminating the
worst match answer. Here we proposed GenNet model, a neural network-based
model. In this model first we will generate the answer of the question from the
passage and then will matched the generated answer with given answer, the best
matched option will be our answer. For answer generation we used S-net (Tan et
al., 2017) model trained on SQuAD and to evaluate our model we used Large-scale
RACE (ReAding Comprehension Dataset From Examinations) (Lai et al.,2017).
</summary>
    <author>
      <name>Vaishali Ingale</name>
    </author>
    <author>
      <name>Pushpender Singh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01769v1</id>
    <updated>2020-03-03T20:06:24Z</updated>
    <published>2020-03-03T20:06:24Z</published>
    <title>Phonetic Feedback for Speech Enhancement With and Without Parallel
  Speech Data</title>
    <summary>  While deep learning systems have gained significant ground in speech
enhancement research, these systems have yet to make use of the full potential
of deep learning systems to provide high-level feedback. In particular,
phonetic feedback is rare in speech enhancement research even though it
includes valuable top-down information. We use the technique of mimic loss to
provide phonetic feedback to an off-the-shelf enhancement system, and find
gains in objective intelligibility scores on CHiME-4 data. This technique takes
a frozen acoustic model trained on clean speech to provide valuable feedback to
the enhancement model, even in the case where no parallel speech data is
available. Our work is one of the first to show intelligibility improvement for
neural enhancement systems without parallel speech data, and we show phonetic
feedback can improve a state-of-the-art neural enhancement system trained with
parallel speech data.
</summary>
    <author>
      <name>Peter Plantinga</name>
    </author>
    <author>
      <name>Deblin Bagchi</name>
    </author>
    <author>
      <name>Eric Fosler-Lussier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages + 1 page for references, accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01765v1</id>
    <updated>2020-03-03T19:58:43Z</updated>
    <published>2020-03-03T19:58:43Z</published>
    <title>Towards Real-time Mispronunciation Detection in Kids' Speech</title>
    <summary>  Modern mispronunciation detection and diagnosis systems have seen significant
gains in accuracy due to the introduction of deep learning. However, these
systems have not been evaluated for the ability to be run in real-time, an
important factor in applications that provide rapid feedback. In particular,
the state-of-the-art uses bi-directional recurrent networks, where a
uni-directional network may be more appropriate. Teacher-student learning is a
natural approach to use to improve a uni-directional model, but when using a
CTC objective, this is limited by poor alignment of outputs to evidence. We
address this limitation by trying two loss terms for improving the alignments
of our models. One loss is an "alignment loss" term that encourages outputs
only when features do not resemble silence. The other loss term uses a
uni-directional model as teacher model to align the bi-directional model. Our
proposed model uses these aligned bi-directional models as teacher models.
Experiments on the CSLU kids' corpus show that these changes decrease the
latency of the outputs, and improve the detection rates, with a trade-off
between these goals.
</summary>
    <author>
      <name>Peter Plantinga</name>
    </author>
    <author>
      <name>Eric Fosler-Lussier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages + 1 page for references, accepted at ASRU 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01680v2</id>
    <updated>2020-03-06T16:01:31Z</updated>
    <published>2020-03-03T18:07:42Z</published>
    <title>Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation</title>
    <summary>  Domain adaptation has recently become a key problem in dialogue systems
research. Deep learning, while being the preferred technique for modeling such
systems, works best given massive training data. However, in the real-world
scenario, such resources aren't available for every new domain, so the ability
to train with a few dialogue examples can be considered essential. Pre-training
on large data sources and adapting to the target data has become the standard
method for few-shot problems within the deep learning framework. In this paper,
we present the winning entry at the fast domain adaptation task of DSTC8, a
hybrid generative-retrieval model based on GPT-2 fine-tuned to the multi-domain
MetaLWOz dataset. Robust and diverse in response generation, our model uses
retrieval logic as a fallback, being SoTA on MetaLWOz in human evaluation (&gt;4%
improvement over the 2nd place system) and attaining competitive generalization
performance in adaptation to the unseen MultiWOZ dataset.
</summary>
    <author>
      <name>Igor Shalyminov</name>
    </author>
    <author>
      <name>Alessandro Sordoni</name>
    </author>
    <author>
      <name>Adam Atkinson</name>
    </author>
    <author>
      <name>Hannes Schulz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at DSTC8@AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01680v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01680v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01509v2</id>
    <updated>2020-03-04T06:53:00Z</updated>
    <published>2020-03-03T14:11:45Z</published>
    <title>Improving Uyghur ASR systems with decoders using morpheme-based language
  models</title>
    <summary>  Uyghur is a minority language, and its resources for Automatic Speech
Recognition (ASR) research are always insufficient. THUYG-20 is currently the
only open-sourced dataset of Uyghur speeches. State-of-the-art results of its
clean and noiseless speech test task haven't been updated since the first
release, which shows a big gap in the development of ASR between mainstream
languages and Uyghur. In this paper, we try to bridge the gap by ultimately
optimizing the ASR systems, and by developing a morpheme-based decoder,
MLDG-Decoder (Morpheme Lattice Dynamically Generating Decoder for Uyghur
DNN-HMM systems), which has long been missing. We have open-sourced the
decoder. The MLDG-Decoder employs an algorithm, named as "on-the-fly
composition with FEBABOS", to allow the back-off states and transitions to play
the role of a relay station in on-the-fly composition. The algorithm empowers
the dynamically generated graph to constrain the morpheme sequences in the
lattices as effectively as the static and fully composed graph does when a
4-Gram morpheme-based Language Model (LM) is used. We have trained deeper and
wider neural network acoustic models, and experimented with three kinds of
decoding schemes. The experimental results show that the decoding based on the
static and fully composed graph reduces state-of-the-art Word Error Rate (WER)
on the clean and noiseless speech test task in THUYG-20 to 14.24%. The
MLDG-Decoder reduces the WER to 14.54% while keeping the memory consumption
reasonable. Based on the open-sourced MLDG-Decoder, readers can easily
reproduce the experimental results in this paper.
</summary>
    <author>
      <name>Zicheng Qiu</name>
    </author>
    <author>
      <name>Wei Jiang</name>
    </author>
    <author>
      <name>Turghunjan Mamut</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01509v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01509v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01478v2</id>
    <updated>2020-03-05T01:35:36Z</updated>
    <published>2020-03-03T12:25:03Z</published>
    <title>Multi-Task Learning with Auxiliary Speaker Identification for
  Conversational Emotion Recognition</title>
    <summary>  Conversational emotion recognition (CER) has attracted increasing interests
in the natural language processing (NLP) community. Different from the vanilla
emotion recognition, effective speaker-sensitive utterance representation is
one major challenge for CER. In this paper, we exploit speaker identification
(SI) as an auxiliary task to enhance the utterance representation in
conversations. By this method, we can learn better speaker-aware contextual
representations from the additional SI corpus. Experiments on two benchmark
datasets demonstrate that the proposed architecture is highly effective for
CER, obtaining new state-of-the-art results on two datasets.
</summary>
    <author>
      <name>Jingye Li</name>
    </author>
    <author>
      <name>Meishan Zhang</name>
    </author>
    <author>
      <name>Donghong Ji</name>
    </author>
    <author>
      <name>Yijiang Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01478v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01478v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01473v2</id>
    <updated>2020-03-04T07:56:09Z</updated>
    <published>2020-03-03T12:13:06Z</published>
    <title>XGPT: Cross-modal Generative Pre-Training for Image Captioning</title>
    <summary>  While many BERT-based cross-modal pre-trained models produce excellent
results on downstream understanding tasks like image-text retrieval and VQA,
they cannot be applied to generation tasks directly. In this paper, we propose
XGPT, a new method of Cross-modal Generative Pre-Training for Image Captioning
that is designed to pre-train text-to-image caption generators through three
novel generation tasks, including Image-conditioned Masked Language Modeling
(IMLM), Image-conditioned Denoising Autoencoding (IDA), and Text-conditioned
Image Feature Generation (TIFG). As a result, the pre-trained XGPT can be
fine-tuned without any task-specific architecture modifications to create
state-of-the-art models for image captioning. Experiments show that XGPT
obtains new state-of-the-art results on the benchmark datasets, including COCO
Captions and Flickr30k Captions. We also use XGPT to generate new image
captions as data augmentation for the image retrieval task and achieve
significant improvement on all recall metrics.
</summary>
    <author>
      <name>Qiaolin Xia</name>
    </author>
    <author>
      <name>Haoyang Huang</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Dongdong Zhang</name>
    </author>
    <author>
      <name>Lei Ji</name>
    </author>
    <author>
      <name>Zhifang Sui</name>
    </author>
    <author>
      <name>Edward Cui</name>
    </author>
    <author>
      <name>Taroon Bharti</name>
    </author>
    <author>
      <name>Xin Liu</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01473v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01473v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01472v1</id>
    <updated>2020-03-03T12:11:12Z</updated>
    <published>2020-03-03T12:11:12Z</published>
    <title>Seshat: A tool for managing and verifying annotation campaigns of audio
  data</title>
    <summary>  We introduce Seshat, a new, simple and open-source software to efficiently
manage annotations of speech corpora. The Seshat software allows users to
easily customise and manage annotations of large audio corpora while ensuring
compliance with the formatting and naming conventions of the annotated output
files. In addition, it includes procedures for checking the content of
annotations following specific rules are implemented in personalised parsers.
Finally, we propose a double-annotation mode, for which Seshat computes
automatically an associated inter-annotator agreement with the $\gamma$ measure
taking into account the categorisation and segmentation discrepancies.
</summary>
    <author>
      <name>Hadrien Titeux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Rachid Riad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Xuan-Nga Cao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Hamilakis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Kris Madden</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Alejandrina Cristia</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Anne-Catherine Bachoud-Lévi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSCP, CoML</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LREC, May 2020, Marseilles, France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.01472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01425v1</id>
    <updated>2020-03-03T10:25:50Z</updated>
    <published>2020-03-03T10:25:50Z</published>
    <title>Understanding the Prediction Mechanism of Sentiments by XAI
  Visualization</title>
    <summary>  People often rely on online reviews to make purchase decisions. The present
work aimed to gain an understanding of a machine learning model's prediction
mechanism by visualizing the effect of sentiments extracted from online hotel
reviews with explainable AI (XAI) methodology. Study 1 used the extracted
sentiments as features to predict the review ratings by five machine learning
algorithms (knn, CART decision trees, support vector machines, random forests,
gradient boosting machines) and identified random forests as best algorithm.
Study 2 analyzed the random forests model by feature importance and revealed
the sentiments joy, disgust, positive and negative as the most predictive
features. Furthermore, the visualization of additive variable attributions and
their prediction distribution showed correct prediction in direction and effect
size for the 5-star rating but partially wrong direction and insufficient
effect size for the 1-star rating. These prediction details were corroborated
by a what-if analysis for the four top features. In conclusion, the prediction
mechanism of a machine learning model can be uncovered by visualization of
particular observations. Comparing instances of contrasting ground truth values
can draw a differential picture of the prediction mechanism and inform
decisions for model improvement.
</summary>
    <author>
      <name>Chaehan So</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the author's prefinal version be published in conference
  proceedings: 4th International Conference on Natural Language Processing and
  Information Retrieval, Sejong, South Korea, 26-28 June, 2020, ACM</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01371v1</id>
    <updated>2020-03-03T07:34:24Z</updated>
    <published>2020-03-03T07:34:24Z</published>
    <title>Meta-Embeddings Based On Self-Attention</title>
    <summary>  Creating meta-embeddings for better performance in language modelling has
received attention lately, and methods based on concatenation or merely
calculating the arithmetic mean of more than one separately trained embeddings
to perform meta-embeddings have shown to be beneficial. In this paper, we
devise a new meta-embedding model based on the self-attention mechanism, namely
the Duo. With less than 0.4M parameters, the Duo mechanism achieves
state-of-the-art accuracy in text classification tasks such as 20NG.
Additionally, we propose a new meta-embedding sequece-to-sequence model for
machine translation, which to the best of our knowledge, is the first machine
translation model based on more than one word-embedding. Furthermore, it has
turned out that our model outperform the Transformer not only in terms of
achieving a better result, but also a faster convergence on recognized
benchmarks, such as the WMT 2014 English-to-French translation task.
</summary>
    <author>
      <name>Qichen Li</name>
    </author>
    <author>
      <name>Xiaoke Jiang</name>
    </author>
    <author>
      <name>Jun Xia</name>
    </author>
    <author>
      <name>Jian Li</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01355v2</id>
    <updated>2020-03-05T03:20:33Z</updated>
    <published>2020-03-03T06:39:27Z</published>
    <title>CLUECorpus2020: A Large-scale Chinese Corpus for Pre-training Language
  Model</title>
    <summary>  In this paper, we introduce the Chinese corpus from CLUE organization,
CLUECorpus2020, a large-scale corpus that can be used directly for
self-supervised learning such as pre-training of a language model, or language
generation. It has 100G raw corpus with 35 billion Chinese characters, which is
retrieved from Common Crawl. To better understand this corpus, we conduct
language understanding experiments on both small and large scale, and results
show that the models trained on this corpus can achieve excellent performance
on Chinese. We release a new Chinese vocabulary with a size of 8K, which is
only one-third of the vocabulary size used in Chinese Bert released by Google.
It saves computational cost and memory while works as good as original
vocabulary. We also release both large and tiny versions of the pre-trained
model on this corpus. The former achieves the state-of-the-art result, and the
latter retains most precision while accelerating training and prediction speed
for eight times compared to Bert-base. To facilitate future work on
self-supervised learning on Chinese, we release our dataset, new vocabulary,
codes, and pre-trained models on Github.
</summary>
    <author>
      <name>Liang Xu</name>
    </author>
    <author>
      <name>Xuanwei Zhang</name>
    </author>
    <author>
      <name>Qianqian Dong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01355v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01355v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01345v1</id>
    <updated>2020-03-03T05:49:55Z</updated>
    <published>2020-03-03T05:49:55Z</published>
    <title>Benchmark Performance of Machine And Deep Learning Based Methodologies
  for Urdu Text Document Classification</title>
    <summary>  In order to provide benchmark performance for Urdu text document
classification, the contribution of this paper is manifold. First, it pro-vides
a publicly available benchmark dataset manually tagged against 6 classes.
Second, it investigates the performance impact of traditional machine learning
based Urdu text document classification methodologies by embedding 10
filter-based feature selection algorithms which have been widely used for other
languages. Third, for the very first time, it as-sesses the performance of
various deep learning based methodologies for Urdu text document
classification. In this regard, for experimentation, we adapt 10 deep learning
classification methodologies which have pro-duced best performance figures for
English text classification. Fourth, it also investigates the performance
impact of transfer learning by utiliz-ing Bidirectional Encoder Representations
from Transformers approach for Urdu language. Fifth, it evaluates the integrity
of a hybrid approach which combines traditional machine learning based feature
engineering and deep learning based automated feature engineering. Experimental
results show that feature selection approach named as Normalised Dif-ference
Measure along with Support Vector Machine outshines state-of-the-art
performance on two closed source benchmark datasets CLE Urdu Digest 1000k, and
CLE Urdu Digest 1Million with a significant margin of 32%, and 13%
respectively. Across all three datasets, Normalised Differ-ence Measure
outperforms other filter based feature selection algorithms as it significantly
uplifts the performance of all adopted machine learning, deep learning, and
hybrid approaches. The source code and presented dataset are available at
Github repository.
</summary>
    <author>
      <name>Muhammad Nabeel Asim</name>
    </author>
    <author>
      <name>Muhammad Usman Ghani</name>
    </author>
    <author>
      <name>Muhammad Ali Ibrahim</name>
    </author>
    <author>
      <name>Sheraz Ahmad</name>
    </author>
    <author>
      <name>Waqar Mahmood</name>
    </author>
    <author>
      <name>Andreas Dengel</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01343v1</id>
    <updated>2020-03-03T05:32:09Z</updated>
    <published>2020-03-03T05:32:09Z</published>
    <title>Improving Candidate Generation for Low-resource Cross-lingual Entity
  Linking</title>
    <summary>  Cross-lingual entity linking (XEL) is the task of finding referents in a
target-language knowledge base (KB) for mentions extracted from source-language
texts. The first step of (X)EL is candidate generation, which retrieves a list
of plausible candidate entities from the target-language KB for each mention.
Approaches based on resources from Wikipedia have proven successful in the
realm of relatively high-resource languages (HRL), but these do not extend well
to low-resource languages (LRL) with few, if any, Wikipedia pages. Recently,
transfer learning methods have been shown to reduce the demand for resources in
the LRL by utilizing resources in closely-related languages, but the
performance still lags far behind their high-resource counterparts. In this
paper, we first assess the problems faced by current entity candidate
generation methods for low-resource XEL, then propose three improvements that
(1) reduce the disconnect between entity mentions and KB entries, and (2)
improve the robustness of the model to low-resource scenarios. The methods are
simple, but effective: we experiment with our approach on seven XEL datasets
and find that they yield an average gain of 16.9% in Top-30 gold candidate
recall, compared to state-of-the-art baselines. Our improved model also yields
an average gain of 7.9% in in-KB accuracy of end-to-end XEL.
</summary>
    <author>
      <name>Shuyan Zhou</name>
    </author>
    <author>
      <name>Shruti Rijhwani</name>
    </author>
    <author>
      <name>John Wieting</name>
    </author>
    <author>
      <name>Jaime Carbonell</name>
    </author>
    <author>
      <name>Graham Neubig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to TACL 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01338v1</id>
    <updated>2020-03-03T05:10:13Z</updated>
    <published>2020-03-03T05:10:13Z</published>
    <title>Hierarchical Context Enhanced Multi-Domain Dialogue System for
  Multi-domain Task Completion</title>
    <summary>  Task 1 of the DSTC8-track1 challenge aims to develop an end-to-end
multi-domain dialogue system to accomplish complex users' goals under tourist
information desk settings. This paper describes our submitted solution,
Hierarchical Context Enhanced Dialogue System (HCEDS), for this task. The main
motivation of our system is to comprehensively explore the potential of
hierarchical context for sufficiently understanding complex dialogues. More
specifically, we apply BERT to capture token-level information and employ the
attention mechanism to capture sentence-level information. The results listed
in the leaderboard show that our system achieves first place in automatic
evaluation and the second place in human evaluation.
</summary>
    <author>
      <name>Jingyuan Yang</name>
    </author>
    <author>
      <name>Guang Liu</name>
    </author>
    <author>
      <name>Yuzhao Mao</name>
    </author>
    <author>
      <name>Zhiwei Zhao</name>
    </author>
    <author>
      <name>Weiguo Gao</name>
    </author>
    <author>
      <name>Xuan Li</name>
    </author>
    <author>
      <name>Haiqin Yang</name>
    </author>
    <author>
      <name>Jianping Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at DSTC workshop, AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02126v1</id>
    <updated>2020-03-03T04:36:33Z</updated>
    <published>2020-03-03T04:36:33Z</published>
    <title>Sequential Neural Networks for Noetic End-to-End Response Selection</title>
    <summary>  The noetic end-to-end response selection challenge as one track in the 7th
Dialog System Technology Challenges (DSTC7) aims to push the state of the art
of utterance classification for real world goal-oriented dialog systems, for
which participants need to select the correct next utterances from a set of
candidates for the multi-turn context. This paper presents our systems that are
ranked top 1 on both datasets under this challenge, one focused and small
(Advising) and the other more diverse and large (Ubuntu). Previous
state-of-the-art models use hierarchy-based (utterance-level and token-level)
neural networks to explicitly model the interactions among different turns'
utterances for context modeling. In this paper, we investigate a sequential
matching model based only on chain sequence for multi-turn response selection.
Our results demonstrate that the potentials of sequential matching approaches
have not yet been fully exploited in the past for multi-turn response
selection. In addition to ranking top 1 in the challenge, the proposed model
outperforms all previous models, including state-of-the-art hierarchy-based
models, on two large-scale public multi-turn response selection benchmark
datasets.
</summary>
    <author>
      <name>Qian Chen</name>
    </author>
    <author>
      <name>Wen Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.csl.2020.101072</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.csl.2020.101072" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 3 figures, Computer Speech &amp; Language. arXiv admin note:
  substantial text overlap with arXiv:1901.02609</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Speech &amp; Language, Volume 62, July 2020, 101072</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.02126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01309v1</id>
    <updated>2020-03-03T03:17:29Z</updated>
    <published>2020-03-03T03:17:29Z</published>
    <title>Controllable Time-Delay Transformer for Real-Time Punctuation Prediction
  and Disfluency Detection</title>
    <summary>  With the increased applications of automatic speech recognition (ASR) in
recent years, it is essential to automatically insert punctuation marks and
remove disfluencies in transcripts, to improve the readability of the
transcripts as well as the performance of subsequent applications, such as
machine translation, dialogue systems, and so forth. In this paper, we propose
a Controllable Time-delay Transformer (CT-Transformer) model that jointly
completes the punctuation prediction and disfluency detection tasks in real
time. The CT-Transformer model facilitates freezing partial outputs with
controllable time delay to fulfill the real-time constraints in partial
decoding required by subsequent applications. We further propose a fast
decoding strategy to minimize latency while maintaining competitive
performance. Experimental results on the IWSLT2011 benchmark dataset and an
in-house Chinese annotated dataset demonstrate that the proposed approach
outperforms the previous state-of-the-art models on F-scores and achieves a
competitive inference speed.
</summary>
    <author>
      <name>Qian Chen</name>
    </author>
    <author>
      <name>Mengzhe Chen</name>
    </author>
    <author>
      <name>Bo Li</name>
    </author>
    <author>
      <name>Wen Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, accepted by ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01305v1</id>
    <updated>2020-03-03T02:56:36Z</updated>
    <published>2020-03-03T02:56:36Z</published>
    <title>Transfer Learning for Context-Aware Spoken Language Understanding</title>
    <summary>  Spoken language understanding (SLU) is a key component of task-oriented
dialogue systems. SLU parses natural language user utterances into semantic
frames. Previous work has shown that incorporating context information
significantly improves SLU performance for multi-turn dialogues. However,
collecting a large-scale human-labeled multi-turn dialogue corpus for the
target domains is complex and costly. To reduce dependency on the collection
and annotation effort, we propose a Context Encoding Language Transformer
(CELT) model facilitating exploiting various context information for SLU. We
explore different transfer learning approaches to reduce dependency on data
collection and annotation. In addition to unsupervised pre-training using
large-scale general purpose unlabeled corpora, such as Wikipedia, we explore
unsupervised and supervised adaptive training approaches for transfer learning
to benefit from other in-domain and out-of-domain dialogue corpora.
Experimental results demonstrate that the proposed model with the proposed
transfer learning approaches achieves significant improvement on the SLU
performance over state-of-the-art models on two large-scale single-turn
dialogue benchmarks and one large-scale multi-turn dialogue benchmark.
</summary>
    <author>
      <name>Qian Chen</name>
    </author>
    <author>
      <name>Zhu Zhuo</name>
    </author>
    <author>
      <name>Wen Wang</name>
    </author>
    <author>
      <name>Qiuyun Xu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ASRU46091.2019.9003902</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ASRU46091.2019.9003902" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, ASRU2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU), SG, Singapore, 2019, pp. 779-786</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.01305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01271v1</id>
    <updated>2020-03-03T00:55:43Z</updated>
    <published>2020-03-03T00:55:43Z</published>
    <title>Med7: a transferable clinical natural language processing model for
  electronic health records</title>
    <summary>  The field of clinical natural language processing has been advanced
significantly since the introduction of deep learning models. The
self-supervised representation learning and the transfer learning paradigm
became the methods of choice in many natural language processing application,
in particular in the settings with the dearth of high quality manually
annotated data. Electronic health record systems are ubiquitous and the
majority of patients' data are now being collected electronically and in
particular in the form of free text. Identification of medical concepts and
information extraction is a challenging task, yet important ingredient for
parsing unstructured data into structured and tabulated format for downstream
analytical tasks. In this work we introduced a named-entity recognition model
for clinical natural language processing. The model is trained to recognise
seven categories: drug names, route, frequency, dosage, strength, form,
duration. The model was first self-supervisedly pre-trained by predicting the
next word, using a collection of 2 million free-text patients' records from
MIMIC-III corpora and then fine-tuned on the named-entity recognition task. The
model achieved a lenient (strict) micro-averaged F1 score of 0.957 (0.893)
across all seven categories. Additionally, we evaluated the transferability of
the developed model using the data from the Intensive Care Unit in the US to
secondary care mental health records (CRIS) in the UK. A direct application of
the trained NER model to CRIS data resulted in reduced performance of F1=0.762,
however after fine-tuning on a small sample from CRIS, the model achieved a
reasonable performance of F1=0.944. This demonstrated that despite a close
similarity between the data sets and the NER tasks, it is essential to
fine-tune on the target domain data in order to achieve more accurate results.
</summary>
    <author>
      <name>Andrey Kormilitzin</name>
    </author>
    <author>
      <name>Nemanja Vaci</name>
    </author>
    <author>
      <name>Qiang Liu</name>
    </author>
    <author>
      <name>Alejo Nevado-Holgado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 1 figure, 15 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01200v2</id>
    <updated>2020-03-04T19:15:30Z</updated>
    <published>2020-03-02T21:32:05Z</published>
    <title>Natural Language Processing Advancements By Deep Learning: A Survey</title>
    <summary>  Natural Language Processing (NLP) helps empower intelligent machines by
enhancing a better understanding of the human language for linguistic-based
human-computer communication. Recent developments in computational power and
the advent of large amounts of linguistic data have heightened the need and
demand for automating semantic analysis using data-driven approaches. The
utilization of data-driven strategies is pervasive now due to the significant
improvements demonstrated through the usage of deep learning methods in areas
such as Computer Vision, Automatic Speech Recognition, and in particular, NLP.
This survey categorizes and addresses the different aspects and applications of
NLP that have benefited from deep learning. It covers core NLP tasks and
applications and describes how deep learning methods and models advance these
areas. We further analyze and compare different approaches and state-of-the-art
models.
</summary>
    <author>
      <name>Amirsina Torfi</name>
    </author>
    <author>
      <name>Rouzbeh A. Shirvani</name>
    </author>
    <author>
      <name>Yaser Keneshloo</name>
    </author>
    <author>
      <name>Nader Tavvaf</name>
    </author>
    <author>
      <name>Edward A. Fox</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01200v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01200v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01018v1</id>
    <updated>2020-03-02T16:50:33Z</updated>
    <published>2020-03-02T16:50:33Z</published>
    <title>Identification of primary and collateral tracks in stuttered speech</title>
    <summary>  Disfluent speech has been previously addressed from two main perspectives:
the clinical perspective focusing on diagnostic, and the Natural Language
Processing (NLP) perspective aiming at modeling these events and detect them
for downstream tasks. In addition, previous works often used different metrics
depending on whether the input features are text or speech, making it difficult
to compare the different contributions. Here, we introduce a new evaluation
framework for disfluency detection inspired by the clinical and NLP perspective
together with the theory of performance from \cite{clark1996using} which
distinguishes between primary and collateral tracks. We introduce a novel
forced-aligned disfluency dataset from a corpus of semi-directed interviews,
and present baseline results directly comparing the performance of text-based
features (word and span information) and speech-based (acoustic-prosodic
information). Finally, we introduce new audio features inspired by the
word-based span features. We show experimentally that using these features
outperformed the baselines for speech-based predictions on the present dataset.
</summary>
    <author>
      <name>Rachid Riad</name>
    </author>
    <author>
      <name>Anne-Catherine Bachoud-Lévi</name>
    </author>
    <author>
      <name>Frank Rudzicz</name>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01006v3</id>
    <updated>2020-03-06T08:58:48Z</updated>
    <published>2020-03-02T16:35:17Z</published>
    <title>The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources</title>
    <summary>  We introduce the STEM (Science, Technology, Engineering, and Medicine)
Dataset for Scientific Entity Extraction, Classification, and Resolution,
version 1.0 (STEM-ECR v1.0). The STEM-ECR v1.0 dataset has been developed to
provide a benchmark for the evaluation of scientific entity extraction,
classification, and resolution tasks in a domain-independent fashion. It
comprises abstracts in 10 STEM disciplines that were found to be the most
prolific ones on a major publishing platform. We describe the creation of such
a multidisciplinary corpus and highlight the obtained findings in terms of the
following features: 1) a generic conceptual formalism for scientific entities
in a multidisciplinary scientific context; 2) the feasibility of the
domain-independent human annotation of scientific entities under such a generic
formalism; 3) a performance benchmark obtainable for automatic extraction of
multidisciplinary scientific entities using BERT-based neural models; 4) a
delineated 3-step entity resolution procedure for human annotation of the
scientific entities via encyclopedic entity linking and lexicographic word
sense disambiguation; and 5) human evaluations of Babelfy returned encyclopedic
links and lexicographic senses for our entities. Our findings cumulatively
indicate that human annotation and automatic learning of multidisciplinary
scientific concepts as well as their semantic disambiguation in a wide-ranging
setting as STEM is reasonable.
</summary>
    <author>
      <name>Jennifer D'Souza</name>
    </author>
    <author>
      <name>Anett Hoppe</name>
    </author>
    <author>
      <name>Arthur Brack</name>
    </author>
    <author>
      <name>Mohamad Yaser Jaradeh</name>
    </author>
    <author>
      <name>Sören Auer</name>
    </author>
    <author>
      <name>Ralph Ewerth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in LREC 2020 proceedings. 10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01006v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01006v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00864v2</id>
    <updated>2020-03-03T16:38:15Z</updated>
    <published>2020-03-02T13:10:18Z</published>
    <title>Pathological speech detection using x-vector embeddings</title>
    <summary>  The potential of speech as a non-invasive biomarker to assess a speaker's
health has been repeatedly supported by the results of multiple works, for both
physical and psychological conditions. Traditional systems for speech-based
disease classification have focused on carefully designed knowledge-based
features. However, these features may not represent the disease's full
symptomatology, and may even overlook its more subtle manifestations. This has
prompted researchers to move in the direction of general speaker
representations that inherently model symptoms, such as Gaussian Supervectors,
i-vectors and, x-vectors. In this work, we focus on the latter, to assess their
applicability as a general feature extraction method to the detection of
Parkinson's disease (PD) and obstructive sleep apnea (OSA). We test our
approach against knowledge-based features and i-vectors, and report results for
two European Portuguese corpora, for OSA and PD, as well as for an additional
Spanish corpus for PD. Both x-vector and i-vector models were trained with an
out-of-domain European Portuguese corpus. Our results show that x-vectors are
able to perform better than knowledge-based features in same-language corpora.
Moreover, while x-vectors performed similarly to i-vectors in matched
conditions, they significantly outperform them when domain-mismatch occurs.
</summary>
    <author>
      <name>Catarina Botelho</name>
    </author>
    <author>
      <name>Francisco Teixeira</name>
    </author>
    <author>
      <name>Thomas Rolland</name>
    </author>
    <author>
      <name>Alberto Abad</name>
    </author>
    <author>
      <name>Isabel Trancoso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to EUSIPCO 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00864v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00864v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00857v3</id>
    <updated>2020-03-09T21:15:55Z</updated>
    <published>2020-03-02T13:07:46Z</published>
    <title>Multi-View Learning for Vision-and-Language Navigation</title>
    <summary>  Learning to navigate in a visual environment following natural language
instructions is a challenging task because natural language instructions are
highly variable, ambiguous, and under-specified. In this paper, we present a
novel training paradigm, Learn from EveryOne (LEO), which leverages multiple
instructions (as different views) for the same trajectory to resolve language
ambiguity and improve generalization. By sharing parameters across
instructions, our approach learns more effectively from limited training data
and generalizes better in unseen environments. On the recent Room-to-Room (R2R)
benchmark dataset, LEO achieves 16% improvement (absolute) over a greedy agent
as the base agent (25.3% $\rightarrow$ 41.4%) in Success Rate weighted by Path
Length (SPL). Further, LEO is complementary to most existing models for
vision-and-language navigation, allowing for easy integration with the existing
techniques, leading to LEO+, which creates the new state of the art, pushing
the R2R benchmark to 62% (9% absolute improvement).
</summary>
    <author>
      <name>Qiaolin Xia</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Chunyuan Li</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Zhifang Sui</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00857v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00857v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00744v1</id>
    <updated>2020-03-02T10:21:17Z</updated>
    <published>2020-03-02T10:21:17Z</published>
    <title>PhoBERT: Pre-trained language models for Vietnamese</title>
    <summary>  We present PhoBERT with two versions of "base" and "large"--the first public
large-scale monolingual language models pre-trained for Vietnamese. We show
that PhoBERT improves the state-of-the-art in multiple Vietnamese-specific NLP
tasks including Part-of-speech tagging, Named-entity recognition and Natural
language inference. We release PhoBERT to facilitate future research and
downstream applications for Vietnamese NLP. Our PhoBERT is released at:
https://github.com/VinAIResearch/PhoBERT
</summary>
    <author>
      <name>Dat Quoc Nguyen</name>
    </author>
    <author>
      <name>Anh Tuan Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00739v1</id>
    <updated>2020-03-02T10:03:14Z</updated>
    <published>2020-03-02T10:03:14Z</published>
    <title>Long Short-Term Sample Distillation</title>
    <summary>  In the past decade, there has been substantial progress at training
increasingly deep neural networks. Recent advances within the teacher--student
training paradigm have established that information about past training updates
show promise as a source of guidance during subsequent training steps. Based on
this notion, in this paper, we propose Long Short-Term Sample Distillation, a
novel training policy that simultaneously leverages multiple phases of the
previous training process to guide the later training updates to a neural
network, while efficiently proceeding in just one single generation pass. With
Long Short-Term Sample Distillation, the supervision signal for each sample is
decomposed into two parts: a long-term signal and a short-term one. The
long-term teacher draws on snapshots from several epochs ago in order to
provide steadfast guidance and to guarantee teacher--student differences, while
the short-term one yields more up-to-date cues with the goal of enabling
higher-quality updates. Moreover, the teachers for each sample are unique, such
that, overall, the model learns from a very diverse set of teachers.
Comprehensive experimental results across a range of vision and NLP tasks
demonstrate the effectiveness of this new training method.
</summary>
    <author>
      <name>Liang Jiang</name>
    </author>
    <author>
      <name>Zujie Wen</name>
    </author>
    <author>
      <name>Zhongping Liang</name>
    </author>
    <author>
      <name>Yafang Wang</name>
    </author>
    <author>
      <name>Gerard de Melo</name>
    </author>
    <author>
      <name>Zhe Li</name>
    </author>
    <author>
      <name>Liangzhuang Ma</name>
    </author>
    <author>
      <name>Jiaxing Zhang</name>
    </author>
    <author>
      <name>Xiaolong Li</name>
    </author>
    <author>
      <name>Yuan Qi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published as a conference paper at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00674v1</id>
    <updated>2020-03-02T05:40:57Z</updated>
    <published>2020-03-02T05:40:57Z</published>
    <title>Style Example-Guided Text Generation using Generative Adversarial
  Transformers</title>
    <summary>  We introduce a language generative model framework for generating a styled
paragraph based on a context sentence and a style reference example. The
framework consists of a style encoder and a texts decoder. The style encoder
extracts a style code from the reference example, and the text decoder
generates texts based on the style code and the context. We propose a novel
objective function to train our framework. We also investigate different
network design choices. We conduct extensive experimental validation with
comparison to strong baselines to validate the effectiveness of the proposed
framework using a newly collected dataset with diverse text styles. Both code
and dataset will be released upon publication.
</summary>
    <author>
      <name>Kuo-Hao Zeng</name>
    </author>
    <author>
      <name>Mohammad Shoeybi</name>
    </author>
    <author>
      <name>Ming-Yu Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00639v1</id>
    <updated>2020-03-02T03:09:28Z</updated>
    <published>2020-03-02T03:09:28Z</published>
    <title>Learning from Easy to Complex: Adaptive Multi-curricula Learning for
  Neural Dialogue Generation</title>
    <summary>  Current state-of-the-art neural dialogue systems are mainly data-driven and
are trained on human-generated responses. However, due to the subjectivity and
open-ended nature of human conversations, the complexity of training dialogues
varies greatly. The noise and uneven complexity of query-response pairs impede
the learning efficiency and effects of the neural dialogue generation models.
What is more, so far, there are no unified dialogue complexity measurements,
and the dialogue complexity embodies multiple aspects of
attributes---specificity, repetitiveness, relevance, etc. Inspired by human
behaviors of learning to converse, where children learn from easy dialogues to
complex ones and dynamically adjust their learning progress, in this paper, we
first analyze five dialogue attributes to measure the dialogue complexity in
multiple perspectives on three publicly available corpora. Then, we propose an
adaptive multi-curricula learning framework to schedule a committee of the
organized curricula. The framework is established upon the reinforcement
learning paradigm, which automatically chooses different curricula at the
evolving learning process according to the learning status of the neural
dialogue generation model. Extensive experiments conducted on five
state-of-the-art models demonstrate its learning efficiency and effectiveness
with respect to 13 automatic evaluation metrics and human judgments.
</summary>
    <author>
      <name>Hengyi Cai</name>
    </author>
    <author>
      <name>Hongshen Chen</name>
    </author>
    <author>
      <name>Cheng Zhang</name>
    </author>
    <author>
      <name>Yonghao Song</name>
    </author>
    <author>
      <name>Xiaofang Zhao</name>
    </author>
    <author>
      <name>Yangxi Li</name>
    </author>
    <author>
      <name>Dongsheng Duan</name>
    </author>
    <author>
      <name>Dawei Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00576v1</id>
    <updated>2020-03-01T20:32:51Z</updated>
    <published>2020-03-01T20:32:51Z</published>
    <title>StructSum: Incorporating Latent and Explicit Sentence Dependencies for
  Single Document Summarization</title>
    <summary>  Traditional preneural approaches to single document summarization relied on
modeling the intermediate structure of a document before generating the
summary. In contrast, the current state of the art neural summarization models
do not preserve any intermediate structure, resorting to encoding the document
as a sequence of tokens. The goal of this work is two-fold: to improve the
quality of generated summaries and to learn interpretable document
representations for summarization. To this end, we propose incorporating latent
and explicit sentence dependencies into single-document summarization models.
We use structure-aware encoders to induce latent sentence relations, and inject
explicit coreferring mention graph across sentences to incorporate explicit
structure. On the CNN/DM dataset, our model outperforms standard baselines and
provides intermediate latent structures for analysis. We present an extensive
analysis of our summaries and show that modeling document structure reduces
copying long sequences and incorporates richer content from the source document
while maintaining comparable summary lengths and an increased degree of
abstraction.
</summary>
    <author>
      <name>Vidhisha Balachandran</name>
    </author>
    <author>
      <name>Artidoro Pagnoni</name>
    </author>
    <author>
      <name>Jay Yoon Lee</name>
    </author>
    <author>
      <name>Dheeraj Rajagopal</name>
    </author>
    <author>
      <name>Jaime Carbonell</name>
    </author>
    <author>
      <name>Yulia Tsvetkov</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00443v2</id>
    <updated>2020-03-09T22:06:54Z</updated>
    <published>2020-03-01T09:06:31Z</published>
    <title>Environment-agnostic Multitask Learning for Natural Language Grounded
  Navigation</title>
    <summary>  Recent research efforts enable study for natural language grounded navigation
in photo-realistic environments, e.g., following natural language instructions
or dialog. However, existing methods tend to overfit training data in seen
environments and fail to generalize well in previously unseen environments. In
order to close the gap between seen and unseen environments, we aim at learning
a generalized navigation model from two novel perspectives: (1) we introduce a
multitask navigation model that can be seamlessly trained on both
Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH)
tasks, which benefits from richer natural language guidance and effectively
transfers knowledge across tasks; (2) we propose to learn environment-agnostic
representations for the navigation policy that are invariant among the
environments seen during training, thus generalizing better on unseen
environments. Extensive experiments show that training with
environment-agnostic multitask learning objective significantly reduces the
performance gap between seen and unseen environments and the navigation agent
so trained outperforms the baselines on unseen environments by 16% (relative
measure on success rate) on VLN and 120% (goal progress) on NDH. Our submission
to the CVDN leaderboard establishes a new state-of-the-art for the NDH task
outperforming the existing best model by more than 66% (goal progress) on the
holdout test set. The code for training the navigation model using
environment-agnostic multitask learning is available at
https://github.com/google-research/valan.
</summary>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Vihan Jain</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <author>
      <name>Sujith Ravi</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00443v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00443v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00353v1</id>
    <updated>2020-02-29T22:15:15Z</updated>
    <published>2020-02-29T22:15:15Z</published>
    <title>Clinical Text Summarization with Syntax-Based Negation and Semantic
  Concept Identification</title>
    <summary>  In the era of clinical information explosion, a good strategy for clinical
text summarization is helpful to improve the clinical workflow. The ideal
summarization strategy can preserve important information in the informative
but less organized, ill-structured clinical narrative texts. Instead of using
pure statistical learning approaches, which are difficult to interpret and
explain, we utilized knowledge of computational linguistics with human
experts-curated biomedical knowledge base to achieve the interpretable and
meaningful clinical text summarization. Our research objective is to use the
biomedical ontology with semantic information, and take the advantage from the
language hierarchical structure, the constituency tree, in order to identify
the correct clinical concepts and the corresponding negation information, which
is critical for summarizing clinical concepts from narrative text. We achieved
the clinically acceptable performance for both negation detection and concept
identification, and the clinical concepts with common negated patterns can be
identified and negated by the proposed method.
</summary>
    <author>
      <name>Wei-Hung Weng</name>
    </author>
    <author>
      <name>Yu-An Chung</name>
    </author>
    <author>
      <name>Schrasing Tong</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00330v3</id>
    <updated>2020-03-06T12:14:42Z</updated>
    <published>2020-02-29T18:55:13Z</published>
    <title>Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and
  Perspective</title>
    <summary>  Neural-symbolic computing has now become the subject of interest of both
academic and industry research laboratories. Graph Neural Networks (GNN) have
been widely used in relational and symbolic domains, with widespread
application of GNNs in combinatorial optimization, constraint satisfaction,
relational reasoning and other scientific domains. The need for improved
explainability, interpretability and trust of AI systems in general demands
principled methodologies, as suggested by neural-symbolic computing. In this
paper, we review the state-of-the-art on the use of GNNs as a model of
neural-symbolic computing. This includes the application of GNNs in several
domains as well as its relationship to current developments in neural-symbolic
computing.
</summary>
    <author>
      <name>Luis Lamb</name>
    </author>
    <author>
      <name>Artur Garcez</name>
    </author>
    <author>
      <name>Marco Gori</name>
    </author>
    <author>
      <name>Marcelo Prates</name>
    </author>
    <author>
      <name>Pedro Avelar</name>
    </author>
    <author>
      <name>Moshe Vardi</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00330v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00330v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00304v1</id>
    <updated>2020-02-29T17:02:41Z</updated>
    <published>2020-02-29T17:02:41Z</published>
    <title>Voice trigger detection from LVCSR hypothesis lattices using
  bidirectional lattice recurrent neural networks</title>
    <summary>  We propose a method to reduce false voice triggers of a speech-enabled
personal assistant by post-processing the hypothesis lattice of a server-side
large-vocabulary continuous speech recognizer (LVCSR) via a neural network. We
first discuss how an estimate of the posterior probability of the trigger
phrase can be obtained from the hypothesis lattice using known techniques to
perform detection, then investigate a statistical model that processes the
lattice in a more explicitly data-driven, discriminative manner. We propose
using a Bidirectional Lattice Recurrent Neural Network (LatticeRNN) for the
task, and show that it can significantly improve detection accuracy over using
the 1-best result or the posterior.
</summary>
    <author>
      <name>Woojay Jeon</name>
    </author>
    <author>
      <name>Leo Liu</name>
    </author>
    <author>
      <name>Henry Mason</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICASSP.2019.8682617</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICASSP.2019.8682617" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at IEEE ICASSP, May 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2019 - 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019, pp.
  6356-6360</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.00304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00201v1</id>
    <updated>2020-02-29T07:39:35Z</updated>
    <published>2020-02-29T07:39:35Z</published>
    <title>What Emotions Make One or Five Stars? Understanding Ratings of Online
  Product Reviews by Sentiment Analysis and XAI</title>
    <summary>  When people buy products online, they primarily base their decisions on the
recommendations of others given in online reviews. The current work analyzed
these online reviews by sentiment analysis and used the extracted sentiments as
features to predict the product ratings by several machine learning algorithms.
These predictions were disentangled by various meth-ods of explainable AI (XAI)
to understand whether the model showed any bias during prediction. Study 1
benchmarked these algorithms (knn, support vector machines, random forests,
gradient boosting machines, XGBoost) and identified random forests and XGBoost
as best algorithms for predicting the product ratings. In Study 2, the analysis
of global feature importance identified the sentiment joy and the emotional
valence negative as most predictive features. Two XAI visualization methods,
local feature attributions and partial dependency plots, revealed several
incorrect prediction mechanisms on the instance-level. Performing the
benchmarking as classification, Study 3 identified a high no-information rate
of 64.4% that indicated high class imbalance as underlying reason for the
identified problems. In conclusion, good performance by machine learning
algorithms must be taken with caution because the dataset, as encountered in
this work, could be biased towards certain predictions. This work demonstrates
how XAI methods reveal such prediction bias.
</summary>
    <author>
      <name>Chaehan So</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in: Lecture Notes in Artificial Intelligence, 1st
  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as
  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00166v1</id>
    <updated>2020-02-29T03:09:55Z</updated>
    <published>2020-02-29T03:09:55Z</published>
    <title>Depth-Adaptive Graph Recurrent Network for Text Classification</title>
    <summary>  The Sentence-State LSTM (S-LSTM) is a powerful and high efficient graph
recurrent network, which views words as nodes and performs layer-wise recurrent
steps between them simultaneously. Despite its successes on text
representations, the S-LSTM still suffers from two drawbacks. Firstly, given a
sentence, certain words are usually more ambiguous than others, and thus more
computation steps need to be taken for these difficult words and vice versa.
However, the S-LSTM takes fixed computation steps for all words, irrespective
of their hardness. The secondary one comes from the lack of sequential
information (e.g., word order) that is inherently important for natural
language. In this paper, we try to address these issues and propose a
depth-adaptive mechanism for the S-LSTM, which allows the model to learn how
many computational steps to conduct for different words as required. In
addition, we integrate an extra RNN layer to inject sequential information,
which also serves as an input feature for the decision of adaptive depths.
Results on the classic text classification task (24 datasets in various sizes
and domains) show that our model brings significant improvements against the
conventional S-LSTM and other high-performance models (e.g., the Transformer),
meanwhile achieving a good accuracy-speed trade off.
</summary>
    <author>
      <name>Yijin Liu</name>
    </author>
    <author>
      <name>Fandong Meng</name>
    </author>
    <author>
      <name>Yufeng Chen</name>
    </author>
    <author>
      <name>Jinan Xu</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code at: https://github.com/Adaxry/Depth-Adaptive-GRN</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00104v1</id>
    <updated>2020-02-28T22:59:24Z</updated>
    <published>2020-02-28T22:59:24Z</published>
    <title>AraBERT: Transformer-based Model for Arabic Language Understanding</title>
    <summary>  The Arabic language is a morphologically rich and complex language with
relatively little resources and a less explored syntax compared to English.
Given these limitations, tasks like Sentiment Analysis (SA), Named Entity
Recognition (NER), and Question Answering (QA), have proven to be very
challenging to tackle. Recently, with the surge of transformers based models,
language-specific BERT based models proved to have a very efficient
understanding of languages, provided they are pre-trained on a very large
corpus. Such models were able to set new standards and achieve state-of-the-art
results for most NLP tasks. In this paper, we pre-trained BERT specifically for
the Arabic language in the pursuit of achieving the same success that BERT did
for the English language. We then compare the performance of AraBERT with
multilingual BERT provided by Google and other state-of-the-art approaches. The
results of the conducted experiments show that the newly developed AraBERT
achieved state-of-the-art results on most tested tasks. The pretrained araBERT
models are publicly available on hoping to encourage research and applications
for Arabic NLP.
</summary>
    <author>
      <name>Wissam Antoun</name>
    </author>
    <author>
      <name>Fady Baly</name>
    </author>
    <author>
      <name>Hazem Hajj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 tables, this paper will be submitted to The 4th Workshop
  on Open-Source Arabic Corpora and Processing Tools co-located with LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12867v1</id>
    <updated>2020-02-28T17:05:55Z</updated>
    <published>2020-02-28T17:05:55Z</published>
    <title>Do all Roads Lead to Rome? Understanding the Role of Initialization in
  Iterative Back-Translation</title>
    <summary>  Back-translation provides a simple yet effective approach to exploit
monolingual corpora in Neural Machine Translation (NMT). Its iterative variant,
where two opposite NMT models are jointly trained by alternately using a
synthetic parallel corpus generated by the reverse model, plays a central role
in unsupervised machine translation. In order to start producing sound
translations and provide a meaningful training signal to each other, existing
approaches rely on either a separate machine translation system to warm up the
iterative procedure, or some form of pre-training to initialize the weights of
the model. In this paper, we analyze the role that such initialization plays in
iterative back-translation. Is the behavior of the final system heavily
dependent on it? Or does iterative back-translation converge to a similar
solution given any reasonable initialization? Through a series of empirical
experiments over a diverse set of warmup systems, we show that, although the
quality of the initial system does affect final performance, its effect is
relatively small, as iterative back-translation has a strong tendency to
convergence to a similar solution. As such, the margin of improvement left for
the initialization method is narrow, suggesting that future research should
focus more on improving the iterative mechanism itself.
</summary>
    <author>
      <name>Mikel Artetxe</name>
    </author>
    <author>
      <name>Gorka Labaka</name>
    </author>
    <author>
      <name>Noe Casas</name>
    </author>
    <author>
      <name>Eneko Agirre</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12854v1</id>
    <updated>2020-02-28T16:30:33Z</updated>
    <published>2020-02-28T16:30:33Z</published>
    <title>Metaphoric Paraphrase Generation</title>
    <summary>  This work describes the task of metaphoric paraphrase generation, in which we
are given a literal sentence and are charged with generating a metaphoric
paraphrase. We propose two different models for this task: a lexical
replacement baseline and a novel sequence to sequence model, 'metaphor
masking', that generates free metaphoric paraphrases. We use crowdsourcing to
evaluate our results, as well as developing an automatic metric for evaluating
metaphoric paraphrases. We show that while the lexical replacement baseline is
capable of producing accurate paraphrases, they often lack metaphoricity, while
our metaphor masking model excels in generating metaphoric sentences while
performing nearly as well with regard to fluency and paraphrase quality.
</summary>
    <author>
      <name>Kevin Stowe</name>
    </author>
    <author>
      <name>Leonardo Ribeiro</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12804v1</id>
    <updated>2020-02-28T15:28:49Z</updated>
    <published>2020-02-28T15:28:49Z</published>
    <title>UniLMv2: Pseudo-Masked Language Models for Unified Language Model
  Pre-Training</title>
    <summary>  We propose to pre-train a unified language model for both autoencoding and
partially autoregressive language modeling tasks using a novel training
procedure, referred to as a pseudo-masked language model (PMLM). Given an input
text with masked tokens, we rely on conventional masks to learn inter-relations
between corrupted tokens and context via autoencoding, and pseudo masks to
learn intra-relations between masked spans via partially autoregressive
modeling. With well-designed position embeddings and self-attention masks, the
context encodings are reused to avoid redundant computation. Moreover,
conventional masks used for autoencoding provide global masking information, so
that all the position embeddings are accessible in partially autoregressive
language modeling. In addition, the two tasks pre-train a unified language
model as a bidirectional encoder and a sequence-to-sequence decoder,
respectively. Our experiments show that the unified language models pre-trained
using PMLM achieve new state-of-the-art results on a wide range of natural
language understanding and generation tasks across several widely used
benchmarks.
</summary>
    <author>
      <name>Hangbo Bao</name>
    </author>
    <author>
      <name>Li Dong</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Wenhui Wang</name>
    </author>
    <author>
      <name>Nan Yang</name>
    </author>
    <author>
      <name>Xiaodong Liu</name>
    </author>
    <author>
      <name>Yu Wang</name>
    </author>
    <author>
      <name>Songhao Piao</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <author>
      <name>Hsiao-Wuen Hon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12699v1</id>
    <updated>2020-02-28T13:20:09Z</updated>
    <published>2020-02-28T13:20:09Z</published>
    <title>Automatic Section Recognition in Obituaries</title>
    <summary>  Obituaries contain information about people's values across times and
cultures, which makes them a useful resource for exploring cultural history.
They are typically structured similarly, with sections corresponding to
Personal Information, Biographical Sketch, Characteristics, Family, Gratitude,
Tribute, Funeral Information and Other aspects of the person. To make this
information available for further studies, we propose a statistical model which
recognizes these sections. To achieve that, we collect a corpus of 20058
English obituaries from TheDaily Item, Remembering.CA and The London Free
Press. The evaluation of our annotation guidelines with three annotators on
1008 obituaries shows a substantial agreement of Fleiss k = 0.87. Formulated as
an automatic segmentation task, a convolutional neural network outperforms
bag-of-words and embedding-based BiLSTMs and BiLSTM-CRFs with a micro F1 =
0.81.
</summary>
    <author>
      <name>Valentino Sabbatino</name>
    </author>
    <author>
      <name>Laura Bostan</name>
    </author>
    <author>
      <name>Roman Klinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure, accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12683v2</id>
    <updated>2020-03-02T10:47:53Z</updated>
    <published>2020-02-28T12:44:34Z</published>
    <title>RP-DNN: A Tweet level propagation context based deep neural networks for
  early rumor detection in Social Media</title>
    <summary>  Early rumor detection (ERD) on social media platform is very challenging when
limited, incomplete and noisy information is available. Most of the existing
methods have largely worked on event-level detection that requires the
collection of posts relevant to a specific event and relied only on
user-generated content. They are not appropriate to detect rumor sources in the
very early stages, before an event unfolds and becomes widespread. In this
paper, we address the task of ERD at the message level. We present a novel
hybrid neural network architecture, which combines a task-specific
character-based bidirectional language model and stacked Long Short-Term Memory
(LSTM) networks to represent textual contents and social-temporal contexts of
input source tweets, for modelling propagation patterns of rumors in the early
stages of their development. We apply multi-layered attention models to jointly
learn attentive context embeddings over multiple context inputs. Our
experiments employ a stringent leave-one-out cross-validation (LOO-CV)
evaluation setup on seven publicly available real-life rumor event data sets.
Our models achieve state-of-the-art(SoA) performance for detecting unseen
rumors on large augmented data which covers more than 12 events and 2,967
rumors. An ablation study is conducted to understand the relative contribution
of each component of our proposed model.
</summary>
    <author>
      <name>Jie Gao</name>
    </author>
    <author>
      <name>Sooji Han</name>
    </author>
    <author>
      <name>Xingyi Song</name>
    </author>
    <author>
      <name>Fabio Ciravegna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Manuscript accepted for publication at The LREC 2020 Proceedings. The
  International Conference on Language Resources and Evaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12683v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12683v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12645v1</id>
    <updated>2020-02-28T10:44:32Z</updated>
    <published>2020-02-28T10:44:32Z</published>
    <title>Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis</title>
    <summary>  We aim to characterize how different speakers contribute to the perceived
output quality of multi-speaker Text-to-Speech (TTS) synthesis. We
automatically rate the quality of TTS using a neural network (NN) trained on
human mean opinion score (MOS) ratings. First, we train and evaluate our NN
model on 13 different TTS and voice conversion (VC) systems from the ASVSpoof
2019 Logical Access (LA) Dataset. Since it is not known how best to represent
speech for this task, we compare 8 different representations alongside MOSNet
frame-based features. Our representations include image-based spectrogram
features and x-vector embeddings that explicitly model different types of noise
such as T60 reverberation time. Our NN predicts MOS with a high correlation to
human judgments. We report prediction correlation and error. A key finding is
the quality achieved for certain speakers seems consistent, regardless of the
TTS or VC system. It is widely accepted that some speakers give higher quality
than others for building a TTS system: our method provides an automatic way to
identify such speakers. Finally, to see if our quality prediction models
generalize, we predict quality scores for synthetic speech using a separate
multi-speaker TTS system that was trained on LibriTTS data, and conduct our own
MOS listening test to compare human ratings with our NN predictions.
</summary>
    <author>
      <name>Jennifer Williams</name>
    </author>
    <author>
      <name>Joanna Rownicka</name>
    </author>
    <author>
      <name>Pilar Oplustil</name>
    </author>
    <author>
      <name>Simon King</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Odyssey 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12620v1</id>
    <updated>2020-02-28T09:44:07Z</updated>
    <published>2020-02-28T09:44:07Z</published>
    <title>TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural
  Language Processing</title>
    <summary>  In this paper, we introduce TextBrewer, an open-source knowledge distillation
toolkit designed for natural language processing. It works with different
neural network models and supports various kinds of tasks, such as text
classification, reading comprehension, sequence labeling. TextBrewer provides a
simple and uniform workflow that enables quick setup of distillation
experiments with highly flexible configurations. It offers a set of predefined
distillation methods and can be extended with custom code. As a case study, we
use TextBrewer to distill BERT on several typical NLP tasks. With simple
configuration, we achieve results that are comparable with or even higher than
the state-of-the-art performance. Our toolkit is available through:
http://textbrewer.hfl-rc.com
</summary>
    <author>
      <name>Ziqing Yang</name>
    </author>
    <author>
      <name>Yiming Cui</name>
    </author>
    <author>
      <name>Zhipeng Chen</name>
    </author>
    <author>
      <name>Wanxiang Che</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Shijin Wang</name>
    </author>
    <author>
      <name>Guoping Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12620v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12620v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12612v1</id>
    <updated>2020-02-28T09:25:53Z</updated>
    <published>2020-02-28T09:25:53Z</published>
    <title>A multi-layer approach to disinformation detection on Twitter</title>
    <summary>  We tackle the problem of classifying news articles pertaining to
disinformation vs mainstream news by solely inspecting their diffusion
mechanisms on Twitter. Our technique is inherently simple compared to existing
text-based approaches, as it allows to by-pass the multiple levels of
complexity which are found in news content (e.g. grammar, syntax, style). We
employ a multi-layer representation of Twitter diffusion networks, and we
compute for each layer a set of global network features which quantify
different aspects of the sharing process. Experimental results with two
large-scale datasets, corresponding to diffusion cascades of news shared
respectively in the United States and Italy, show that a simple Logistic
Regression model is able to classify disinformation vs mainstream networks with
high accuracy (AUROC up to 94%), also when considering the political bias of
different sources in the classification task. We also highlight differences in
the sharing patterns of the two news domains which appear to be
country-independent. We believe that our network-based approach provides useful
insights which pave the way to the future development of a system to detect
misleading and harmful information spreading on social media.
</summary>
    <author>
      <name>Francesco Pierri</name>
    </author>
    <author>
      <name>Carlo Piccardi</name>
    </author>
    <author>
      <name>Stefano Ceri</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12591v1</id>
    <updated>2020-02-28T08:18:37Z</updated>
    <published>2020-02-28T08:18:37Z</published>
    <title>DC-BERT: Decoupling Question and Document for Efficient Contextual
  Encoding</title>
    <summary>  Recent studies on open-domain question answering have achieved prominent
performance improvement using pre-trained language models such as BERT.
State-of-the-art approaches typically follow the "retrieve and read" pipeline
and employ BERT-based reranker to filter retrieved documents before feeding
them into the reader module. The BERT retriever takes as input the
concatenation of question and each retrieved document. Despite the success of
these approaches in terms of QA accuracy, due to the concatenation, they can
barely handle high-throughput of incoming questions each with a large
collection of retrieved documents. To address the efficiency problem, we
propose DC-BERT, a decoupled contextual encoding framework that has dual BERT
models: an online BERT which encodes the question only once, and an offline
BERT which pre-encodes all the documents and caches their encodings. On SQuAD
Open and Natural Questions Open datasets, DC-BERT achieves 10x speedup on
document retrieval, while retaining most (about 98%) of the QA performance
compared to state-of-the-art approaches for open-domain question answering.
</summary>
    <author>
      <name>Yuyu Zhang</name>
    </author>
    <author>
      <name>Ping Nie</name>
    </author>
    <author>
      <name>Xiubo Geng</name>
    </author>
    <author>
      <name>Arun Ramamurthy</name>
    </author>
    <author>
      <name>Le Song</name>
    </author>
    <author>
      <name>Daxin Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12585v1</id>
    <updated>2020-02-28T07:46:48Z</updated>
    <published>2020-02-28T07:46:48Z</published>
    <title>Exploring and Distilling Cross-Modal Information for Image Captioning</title>
    <summary>  Recently, attention-based encoder-decoder models have been used extensively
in image captioning. Yet there is still great difficulty for the current
methods to achieve deep image understanding. In this work, we argue that such
understanding requires visual attention to correlated image regions and
semantic attention to coherent attributes of interest. To perform effective
attention, we explore image captioning from a cross-modal perspective and
propose the Global-and-Local Information Exploring-and-Distilling approach that
explores and distills the source information in vision and language. It
globally provides the aspect vector, a spatial and relational representation of
images based on caption contexts, through the extraction of salient region
groupings and attribute collocations, and locally extracts the fine-grained
regions and attributes in reference to the aspect vector for word selection.
Our fully-attentive model achieves a CIDEr score of 129.3 in offline COCO
evaluation on the COCO testing set with remarkable efficiency in terms of
accuracy, speed, and parameter budget.
</summary>
    <author>
      <name>Fenglin Liu</name>
    </author>
    <author>
      <name>Xuancheng Ren</name>
    </author>
    <author>
      <name>Yuanxin Liu</name>
    </author>
    <author>
      <name>Kai Lei</name>
    </author>
    <author>
      <name>Xu Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IJCAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12570v1</id>
    <updated>2020-02-28T06:51:40Z</updated>
    <published>2020-02-28T06:51:40Z</published>
    <title>Learning Directly from Grammar Compressed Text</title>
    <summary>  Neural networks using numerous text data have been successfully applied to a
variety of tasks. While massive text data is usually compressed using
techniques such as grammar compression, almost all of the previous machine
learning methods assume already decompressed sequence data as their input. In
this paper, we propose a method to directly apply neural sequence models to
text data compressed with grammar compression algorithms without decompression.
To encode the unique symbols that appear in compression rules, we introduce
composer modules to incrementally encode the symbols into vector
representations. Through experiments on real datasets, we empirically showed
that the proposal model can achieve both memory and computational efficiency
while maintaining moderate performance.
</summary>
    <author>
      <name>Yoichi Sasaki</name>
    </author>
    <author>
      <name>Kosuke Akimoto</name>
    </author>
    <author>
      <name>Takanori Maehara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 Postscript figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12558v1</id>
    <updated>2020-02-28T05:37:06Z</updated>
    <published>2020-02-28T05:37:06Z</published>
    <title>Modeling Future Cost for Neural Machine Translation</title>
    <summary>  Existing neural machine translation (NMT) systems utilize
sequence-to-sequence neural networks to generate target translation word by
word, and then make the generated word at each time-step and the counterpart in
the references as consistent as possible. However, the trained translation
model tends to focus on ensuring the accuracy of the generated target word at
the current time-step and does not consider its future cost which means the
expected cost of generating the subsequent target translation (i.e., the next
target word). To respond to this issue, we propose a simple and effective
method to model the future cost of each target word for NMT systems. In detail,
a time-dependent future cost is estimated based on the current generated target
word and its contextual information to boost the training of the NMT model.
Furthermore, the learned future context representation at the current time-step
is used to help the generation of the next target word in the decoding.
Experimental results on three widely-used translation datasets, including the
WMT14 German-to-English, WMT14 English-to-French, and WMT17 Chinese-to-English,
show that the proposed approach achieves significant improvements over strong
Transformer-based NMT baseline.
</summary>
    <author>
      <name>Chaoqun Duan</name>
    </author>
    <author>
      <name>Kehai Chen</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
    <author>
      <name>Masao Utiyama</name>
    </author>
    <author>
      <name>Eiichiro Sumita</name>
    </author>
    <author>
      <name>Conghui Zhu</name>
    </author>
    <author>
      <name>Tiejun Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12549v1</id>
    <updated>2020-02-28T05:17:55Z</updated>
    <published>2020-02-28T05:17:55Z</published>
    <title>Robust Unsupervised Neural Machine Translation with Adversarial Training</title>
    <summary>  Unsupervised neural machine translation (UNMT) has recently attracted great
interest in the machine translation community, achieving only slightly worse
results than supervised neural machine translation. However, in real-world
scenarios, there usually exists minor noise in the input sentence and the
neural translation system is sensitive to the small perturbations in the input,
leading to poor performance. In this paper, we first define two types of noises
and empirically show the effect of these noisy data on UNMT performance.
Moreover, we propose adversarial training methods to improve the robustness of
UNMT in the noisy scenario. To the best of our knowledge, this paper is the
first work to explore the robustness of UNMT. Experimental results on several
language pairs show that our proposed methods substantially outperform
conventional UNMT systems in the noisy scenario.
</summary>
    <author>
      <name>Haipeng Sun</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
    <author>
      <name>Kehai Chen</name>
    </author>
    <author>
      <name>Masao Utiyama</name>
    </author>
    <author>
      <name>Eiichiro Sumita</name>
    </author>
    <author>
      <name>Tiejun Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12540v1</id>
    <updated>2020-02-28T04:32:16Z</updated>
    <published>2020-02-28T04:32:16Z</published>
    <title>UKARA 1.0 Challenge Track 1: Automatic Short-Answer Scoring in Bahasa
  Indonesia</title>
    <summary>  We describe our third-place solution to the UKARA 1.0 challenge on automated
essay scoring. The task consists of a binary classification problem on two
datasets | answers from two different questions. We ended up using two
different models for the two datasets. For task A, we applied a random forest
algorithm on features extracted using unigram with latent semantic analysis
(LSA). On the other hand, for task B, we only used logistic regression on
TF-IDF features. Our model results in F1 score of 0.812.
</summary>
    <author>
      <name>Ali Akbar Septiandri</name>
    </author>
    <author>
      <name>Yosef Ardhito Winatmoko</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12530v2</id>
    <updated>2020-03-05T00:16:05Z</updated>
    <published>2020-02-28T03:53:31Z</published>
    <title>Temporal Convolutional Attention-based Network For Sequence Modeling</title>
    <summary>  With the development of feed-forward models, the default model for sequence
modeling has gradually evolved to replace recurrent networks. Many powerful
feed-forward models based on convolutional networks and attention mechanism
were proposed and show more potential to handle sequence modeling tasks. We
wonder that is there an architecture that can not only achieve an approximate
substitution of recurrent network, but also absorb the advantages of
feed-forward models. So we propose an exploratory architecture referred to
Temporal Convolutional Attention-based Network (TCAN) which combines temporal
convolutional network and attention mechanism. TCAN includes two parts, one is
Temporal Attention (TA) which captures relevant features inside the sequence,
the other is Enhanced Residual (ER) which extracts shallow layer's important
information and transfers to deep layers. We improve the state-of-the-art
results of bpc/perplexity to 26.92 on word-level PTB, 1.043 on character-level
PTB, and 6.66 on WikiText-2.
</summary>
    <author>
      <name>Hongyan Hao</name>
    </author>
    <author>
      <name>Yan Wang</name>
    </author>
    <author>
      <name>Yudi Xia</name>
    </author>
    <author>
      <name>Jian Zhao</name>
    </author>
    <author>
      <name>Furao Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12530v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12530v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12457v1</id>
    <updated>2020-02-27T21:44:41Z</updated>
    <published>2020-02-27T21:44:41Z</published>
    <title>Comment Ranking Diversification in Forum Discussions</title>
    <summary>  Viewing consumption of discussion forums with hundreds or more comments
depends on ranking because most users only view top-ranked comments. When
comments are ranked by an ordered score (e.g. number of replies or up-votes)
without adjusting for semantic similarity of near-ranked comments, top-ranked
comments are more likely to emphasize the majority opinion and incur
redundancy. In this paper, we propose a top K comment diversification
re-ranking model using Maximal Marginal Relevance (MMR) and evaluate its impact
in three categories: (1) semantic diversity, (2) inclusion of the semantics of
lower-ranked comments, and (3) redundancy, within the context of a HarvardX
course discussion forum. We conducted a double-blind, small-scale evaluation
experiment requiring subjects to select between the top 5 comments of a
diversified ranking and a baseline ranking ordered by score. For three
subjects, across 100 trials, subjects selected the diversified (75% score, 25%
diversification) ranking as significantly (1) more diverse, (2) more inclusive,
and (3) less redundant. Within each category, inter-rater reliability showed
moderate consistency, with typical Cohen-Kappa scores near 0.2. Our findings
suggest that our model improves (1) diversification, (2) inclusion, and (3)
redundancy, among top K ranked comments in online discussion forums.
</summary>
    <author>
      <name>Curtis G. Northcutt</name>
    </author>
    <author>
      <name>Kimberly A. Leon</name>
    </author>
    <author>
      <name>Naichun Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3051457.3054016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3051457.3054016" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 figures, published in Learning @ Scale, 2017</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Sixth {ACM} Conference on Learning @ Scale, L@S
  2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.12457v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12457v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12344v1</id>
    <updated>2020-02-27T18:58:15Z</updated>
    <published>2020-02-27T18:58:15Z</published>
    <title>Generating Followup Questions for Interpretable Multi-hop Question
  Answering</title>
    <summary>  We propose a framework for answering open domain multi-hop questions in which
partial information is read and used to generate followup questions, to finally
be answered by a pretrained single-hop answer extractor. This framework makes
each hop interpretable, and makes the retrieval associated with later hops as
flexible and specific as for the first hop. As a first instantiation of this
framework, we train a pointer-generator network to predict followup questions
based on the question and partial information. This provides a novel
application of a neural question generation network, which is applied to give
weak ground truth single-hop followup questions based on the final answers and
their supporting facts. Learning to generate followup questions that select the
relevant answer spans against downstream supporting facts, while avoiding
distracting premises, poses an exciting semantic challenge for text generation.
We present an evaluation using the two-hop bridge questions of HotpotQA.
</summary>
    <author>
      <name>Christopher Malon</name>
    </author>
    <author>
      <name>Bing Bai</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12328v1</id>
    <updated>2020-02-27T18:48:33Z</updated>
    <published>2020-02-27T18:48:33Z</published>
    <title>Few-shot Natural Language Generation for Task-Oriented Dialog</title>
    <summary>  As a crucial component in task-oriented dialog systems, the Natural Language
Generation (NLG) module converts a dialog act represented in a semantic form
into a response in natural language. The success of traditional template-based
or statistical models typically relies on heavily annotated data, which is
infeasible for new domains. Therefore, it is pivotal for an NLG system to
generalize well with limited labelled data in real applications. To this end,
we present FewShotWoz, the first NLG benchmark to simulate the few-shot
learning setting in task-oriented dialog systems. Further, we develop the
SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to
acquire the controllable generation ability, and fine-tuned with only a few
domain-specific labels to adapt to new domains. Experiments on FewShotWoz and
the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly
outperforms existing methods, measured by various automatic metrics and human
evaluations.
</summary>
    <author>
      <name>Baolin Peng</name>
    </author>
    <author>
      <name>Chenguang Zhu</name>
    </author>
    <author>
      <name>Chunyuan Li</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Jinchao Li</name>
    </author>
    <author>
      <name>Michael Zeng</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project website: https://aka.ms/scgpt ; Code and data:
  https://github.com/pengbaolin/SC-GPT</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12327v1</id>
    <updated>2020-02-27T18:46:42Z</updated>
    <published>2020-02-27T18:46:42Z</published>
    <title>A Primer in BERTology: What we know about how BERT works</title>
    <summary>  Transformer-based models are now widely used in NLP, but we still do not
understand a lot about their inner workings. This paper describes what is known
to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40
analysis studies. We also provide an overview of the proposed modifications to
the model and its training regime. We then outline the directions for further
research.
</summary>
    <author>
      <name>Anna Rogers</name>
    </author>
    <author>
      <name>Olga Kovaleva</name>
    </author>
    <author>
      <name>Anna Rumshisky</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12327v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12327v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12231v1</id>
    <updated>2020-02-27T16:22:42Z</updated>
    <published>2020-02-27T16:22:42Z</published>
    <title>SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation</title>
    <summary>  We propose autoencoding speaker conversion for training data augmentation in
automatic speech translation. This technique directly transforms an audio
sequence, resulting in audio synthesized to resemble another speaker's voice.
Our method compares favorably to SpecAugment on English$\to$French and
English$\to$Romanian automatic speech translation (AST) tasks as well as on a
low-resource English automatic speech recognition (ASR) task. Further, in
ablations, we show the benefits of both quantity and diversity in augmented
data. Finally, we show that we can combine our approach with augmentation by
machine-translated transcripts to obtain a competitive end-to-end AST model
that outperforms a very strong cascade model on an English$\to$French AST task.
Our method is sufficiently general that it can be applied to other speech
generation and analysis tasks.
</summary>
    <author>
      <name>Arya D. McCarthy</name>
    </author>
    <author>
      <name>Liezl Puzon</name>
    </author>
    <author>
      <name>Juan Pino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12196v2</id>
    <updated>2020-02-28T10:11:09Z</updated>
    <published>2020-02-27T15:42:39Z</published>
    <title>Annotation of Emotion Carriers in Personal Narratives</title>
    <summary>  We are interested in the problem of understanding personal narratives (PN) -
spoken or written - recollections of facts, events, and thoughts. In PN,
emotion carriers are the speech or text segments that best explain the
emotional state of the user. Such segments may include entities, verb or noun
phrases. Advanced automatic understanding of PNs requires not only the
prediction of the user emotional state but also to identify which events (e.g.
"the loss of relative" or "the visit of grandpa") or people ( e.g. "the old
group of high school mates") carry the emotion manifested during the personal
recollection. This work proposes and evaluates an annotation model for
identifying emotion carriers in spoken personal narratives. Compared to other
text genres such as news and microblogs, spoken PNs are particularly
challenging because a narrative is usually unstructured, involving multiple
sub-events and characters as well as thoughts and associated emotions perceived
by the narrator. In this work, we experiment with annotating emotion carriers
from speech transcriptions in the Ulm State-of-Mind in Speech (USoMS) corpus, a
dataset of German PNs. We believe this resource could be used for experiments
in the automatic extraction of emotion carriers from PN, a task that could
provide further advancements in narrative understanding.
</summary>
    <author>
      <name>Aniruddha Tammewar</name>
    </author>
    <author>
      <name>Alessandra Cervone</name>
    </author>
    <author>
      <name>Eva-Maria Messner</name>
    </author>
    <author>
      <name>Giuseppe Riccardi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12196v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12196v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12097v1</id>
    <updated>2020-02-27T14:02:31Z</updated>
    <published>2020-02-27T14:02:31Z</published>
    <title>Improving cross-lingual model transfer by chunking</title>
    <summary>  We present a shallow parser guided cross-lingual model transfer approach in
order to address the syntactic differences between source and target languages
more effectively. In this work, we assume the chunks or phrases in a sentence
as transfer units in order to address the syntactic differences between the
source and target languages arising due to the differences in ordering of words
in the phrases and the ordering of phrases in a sentence separately.
</summary>
    <author>
      <name>Ayan Das</name>
    </author>
    <author>
      <name>Sudeshna Sarkar</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12005v1</id>
    <updated>2020-02-27T09:50:41Z</updated>
    <published>2020-02-27T09:50:41Z</published>
    <title>Binarized PMI Matrix: Bridging Word Embeddings and Hyperbolic Spaces</title>
    <summary>  We show analytically that removing sigmoid transformation in the SGNS
objective does not harm the quality of word vectors significantly and at the
same time is related to factorizing a binarized PMI matrix which, in turn, can
be treated as an adjacency matrix of a certain graph. Empirically, such graph
is a complex network, i.e. it has strong clustering and scale-free degree
distribution, and is tightly connected with hyperbolic spaces. In short, we
show the connection between static word embeddings and hyperbolic spaces
through the binarized PMI matrix using analytical and empirical methods.
</summary>
    <author>
      <name>Zhenisbek Assylbekov</name>
    </author>
    <author>
      <name>Alibi Jangeldin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.12005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12798v1</id>
    <updated>2020-02-27T05:06:19Z</updated>
    <published>2020-02-27T05:06:19Z</published>
    <title>Optimizing Memory-Access Patterns for Deep Learning Accelerators</title>
    <summary>  Deep learning (DL) workloads are moving towards accelerators for faster
processing and lower cost. Modern DL accelerators are good at handling the
large-scale multiply-accumulate operations that dominate DL workloads; however,
it is challenging to make full use of the compute power of an accelerator since
the data must be properly staged in a software-managed scratchpad memory.
Failing to do so can result in significant performance loss. This paper
proposes a systematic approach which leverages the polyhedral model to analyze
all operators of a DL model together to minimize the number of memory accesses.
Experiments show that our approach can substantially reduce the impact of
memory accesses required by common neural-network models on a homegrown AWS
machine-learning inference chip named Inferentia, which is available through
Amazon EC2 Inf1 instances.
</summary>
    <author>
      <name>Hongbin Zheng</name>
    </author>
    <author>
      <name>Sejong Oh</name>
    </author>
    <author>
      <name>Huiqing Wang</name>
    </author>
    <author>
      <name>Preston Briggs</name>
    </author>
    <author>
      <name>Jiading Gai</name>
    </author>
    <author>
      <name>Animesh Jain</name>
    </author>
    <author>
      <name>Yizhi Liu</name>
    </author>
    <author>
      <name>Rich Heaton</name>
    </author>
    <author>
      <name>Randy Huang</name>
    </author>
    <author>
      <name>Yida Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended abstract for a poster presented at C4ML workshop 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11910v1</id>
    <updated>2020-02-27T04:29:13Z</updated>
    <published>2020-02-27T04:29:13Z</published>
    <title>Integrating Boundary Assembling into a DNN Framework for Named Entity
  Recognition in Chinese Social Media Text</title>
    <summary>  Named entity recognition is a challenging task in Natural Language
Processing, especially for informal and noisy social media text. Chinese word
boundaries are also entity boundaries, therefore, named entity recognition for
Chinese text can benefit from word boundary detection, outputted by Chinese
word segmentation. Yet Chinese word segmentation poses its own difficulty
because it is influenced by several factors, e.g., segmentation criteria,
employed algorithm, etc. Dealt improperly, it may generate a cascading failure
to the quality of named entity recognition followed. In this paper we integrate
a boundary assembling method with the state-of-the-art deep neural network
model, and incorporate the updated word boundary information into a conditional
random field model for named entity recognition. Our method shows a 2% absolute
improvement over previous state-of-the-art results.
</summary>
    <author>
      <name>Zhaoheng Gong</name>
    </author>
    <author>
      <name>Ping Chen</name>
    </author>
    <author>
      <name>Jiang Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11893v2</id>
    <updated>2020-02-28T06:04:14Z</updated>
    <published>2020-02-27T03:06:35Z</published>
    <title>CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue
  Dataset</title>
    <summary>  To advance multi-domain (cross-domain) dialogue modeling as well as alleviate
the shortage of Chinese task-oriented datasets, we propose CrossWOZ, the first
large-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It
contains 6K dialogue sessions and 102K utterances for 5 domains, including
hotel, restaurant, attraction, metro, and taxi. Moreover, the corpus contains
rich annotation of dialogue states and dialogue acts at both user and system
sides. About 60% of the dialogues have cross-domain user goals that favor
inter-domain dependency and encourage natural transition across domains in
conversation. We also provide a user simulator and several benchmark models for
pipelined task-oriented dialogue systems, which will facilitate researchers to
compare and evaluate their models on this corpus. The large size and rich
annotation of CrossWOZ make it suitable to investigate a variety of tasks in
cross-domain dialogue modeling, such as dialogue state tracking, policy
learning, user simulation, etc.
</summary>
    <author>
      <name>Qi Zhu</name>
    </author>
    <author>
      <name>Kaili Huang</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by TACL</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11893v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11893v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11848v1</id>
    <updated>2020-02-27T00:09:25Z</updated>
    <published>2020-02-27T00:09:25Z</published>
    <title>Analysis of diversity-accuracy tradeoff in image captioning</title>
    <summary>  We investigate the effect of different model architectures, training
objectives, hyperparameter settings and decoding procedures on the diversity of
automatically generated image captions. Our results show that 1) simple
decoding by naive sampling, coupled with low temperature is a competitive and
fast method to produce diverse and accurate caption sets; 2) training with
CIDEr-based reward using Reinforcement learning harms the diversity properties
of the resulting generator, which cannot be mitigated by manipulating decoding
parameters. In addition, we propose a new metric AllSPICE for evaluating both
accuracy and diversity of a set of captions by a single value.
</summary>
    <author>
      <name>Ruotian Luo</name>
    </author>
    <author>
      <name>Gregory Shakhnarovich</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11847v1</id>
    <updated>2020-02-27T00:08:45Z</updated>
    <published>2020-02-27T00:08:45Z</published>
    <title>Echo State Neural Machine Translation</title>
    <summary>  We present neural machine translation (NMT) models inspired by echo state
network (ESN), named Echo State NMT (ESNMT), in which the encoder and decoder
layer weights are randomly generated then fixed throughout training. We show
that even with this extremely simple model construction and training procedure,
ESNMT can already reach 70-80% quality of fully trainable baselines. We examine
how spectral radius of the reservoir, a key quantity that characterizes the
model, determines the model behavior. Our findings indicate that randomized
networks can work well even for complicated sequence-to-sequence prediction NLP
tasks.
</summary>
    <author>
      <name>Ankush Garg</name>
    </author>
    <author>
      <name>Yuan Cao</name>
    </author>
    <author>
      <name>Qi Ge</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11800v1</id>
    <updated>2020-02-26T21:28:57Z</updated>
    <published>2020-02-26T21:28:57Z</published>
    <title>Universal Phone Recognition with a Multilingual Allophone System</title>
    <summary>  Multilingual models can improve language processing, particularly for low
resource situations, by sharing parameters across languages. Multilingual
acoustic models, however, generally ignore the difference between phonemes
(sounds that can support lexical contrasts in a particular language) and their
corresponding phones (the sounds that are actually spoken, which are language
independent). This can lead to performance degradation when combining a variety
of training languages, as identically annotated phonemes can actually
correspond to several different underlying phonetic realizations. In this work,
we propose a joint model of both language-independent phone and
language-dependent phoneme distributions. In multilingual ASR experiments over
11 languages, we find that this model improves testing performance by 2%
phoneme error rate absolute in low-resource conditions. Additionally, because
we are explicitly modeling language-independent phones, we can build a
(nearly-)universal phone recognizer that, when combined with the PHOIBLE large,
manually curated database of phone inventories, can be customized into 2,000
language dependent recognizers. Experiments on two low-resourced indigenous
languages, Inuktitut and Tusom, show that our recognizer achieves phone
accuracy improvements of more than 17%, moving a step closer to speech
recognition for all languages in the world.
</summary>
    <author>
      <name>Xinjian Li</name>
    </author>
    <author>
      <name>Siddharth Dalmia</name>
    </author>
    <author>
      <name>Juncheng Li</name>
    </author>
    <author>
      <name>Matthew Lee</name>
    </author>
    <author>
      <name>Patrick Littell</name>
    </author>
    <author>
      <name>Jiali Yao</name>
    </author>
    <author>
      <name>Antonios Anastasopoulos</name>
    </author>
    <author>
      <name>David R. Mortensen</name>
    </author>
    <author>
      <name>Graham Neubig</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <author>
      <name>Florian Metze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11794v1</id>
    <updated>2020-02-26T21:17:13Z</updated>
    <published>2020-02-26T21:17:13Z</published>
    <title>Train Large, Then Compress: Rethinking Model Size for Efficient Training
  and Inference of Transformers</title>
    <summary>  Since hardware resources are limited, the objective of training deep learning
models is typically to maximize accuracy subject to the time and memory
constraints of training and inference. We study the impact of model size in
this setting, focusing on Transformer models for NLP tasks that are limited by
compute: self-supervised pretraining and high-resource machine translation. We
first show that even though smaller Transformer models execute faster per
iteration, wider and deeper models converge in significantly fewer steps.
Moreover, this acceleration in convergence typically outpaces the additional
computational overhead of using larger models. Therefore, the most
compute-efficient training strategy is to counterintuitively train extremely
large models but stop after a small number of iterations.
  This leads to an apparent trade-off between the training efficiency of large
Transformer models and the inference efficiency of small Transformer models.
However, we show that large models are more robust to compression techniques
such as quantization and pruning than small models. Consequently, one can get
the best of both worlds: heavily compressed, large models achieve higher
accuracy than lightly compressed, small models.
</summary>
    <author>
      <name>Zhuohan Li</name>
    </author>
    <author>
      <name>Eric Wallace</name>
    </author>
    <author>
      <name>Sheng Shen</name>
    </author>
    <author>
      <name>Kevin Lin</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <author>
      <name>Dan Klein</name>
    </author>
    <author>
      <name>Joseph E. Gonzalez</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11781v1</id>
    <updated>2020-02-26T20:38:42Z</updated>
    <published>2020-02-26T20:38:42Z</published>
    <title>Towards Zero-shot Learning for Automatic Phonemic Transcription</title>
    <summary>  Automatic phonemic transcription tools are useful for low-resource language
documentation. However, due to the lack of training sets, only a tiny fraction
of languages have phonemic transcription tools. Fortunately, multilingual
acoustic modeling provides a solution given limited audio training data. A more
challenging problem is to build phonemic transcribers for languages with zero
training data. The difficulty of this task is that phoneme inventories often
differ between the training languages and the target language, making it
infeasible to recognize unseen phonemes. In this work, we address this problem
by adopting the idea of zero-shot learning. Our model is able to recognize
unseen phonemes in the target language without any training data. In our model,
we decompose phonemes into corresponding articulatory attributes such as vowel
and consonant. Instead of predicting phonemes directly, we first predict
distributions over articulatory attributes, and then compute phoneme
distributions with a customized acoustic model. We evaluate our model by
training it using 13 languages and testing it using 7 unseen languages. We find
that it achieves 7.7% better phoneme error rate on average over a standard
multilingual model.
</summary>
    <author>
      <name>Xinjian Li</name>
    </author>
    <author>
      <name>Siddharth Dalmia</name>
    </author>
    <author>
      <name>David R. Mortensen</name>
    </author>
    <author>
      <name>Juncheng Li</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <author>
      <name>Florian Metze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11643v1</id>
    <updated>2020-02-26T17:18:49Z</updated>
    <published>2020-02-26T17:18:49Z</published>
    <title>Marathi To English Neural Machine Translation With Near Perfect Corpus
  And Transformers</title>
    <summary>  There have been very few attempts to benchmark performances of
state-of-the-art algorithms for Neural Machine Translation task on Indian
Languages. Google, Bing, Facebook and Yandex are some of the very few companies
which have built translation systems for few of the Indian Languages. Among
them, translation results from Google are supposed to be better, based on
general inspection. Bing-Translator do not even support Marathi language which
has around 95 million speakers and ranks 15th in the world in terms of combined
primary and secondary speakers. In this exercise, we trained and compared
variety of Neural Machine Marathi to English Translators trained with
BERT-tokenizer by huggingface and various Transformer based architectures using
Facebook's Fairseq platform with limited but almost correct parallel corpus to
achieve better BLEU scores than Google on Tatoeba and Wikimedia open datasets.
</summary>
    <author>
      <name>Swapnil Ashok Jadhav</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 tables. This report is based on applied research work done
  at Dailyhunt</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11643v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11643v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11566v1</id>
    <updated>2020-02-26T15:34:52Z</updated>
    <published>2020-02-26T15:34:52Z</published>
    <title>Object Relational Graph with Teacher-Recommended Learning for Video
  Captioning</title>
    <summary>  Taking full advantage of the information from both vision and language is
critical for the video captioning task. Existing models lack adequate visual
representation due to the neglect of interaction between object, and sufficient
training for content-related words due to long-tailed problems. In this paper,
we propose a complete video captioning system including both a novel model and
an effective training strategy. Specifically, we propose an object relational
graph (ORG) based encoder, which captures more detailed interaction features to
enrich visual representation. Meanwhile, we design a teacher-recommended
learning (TRL) method to make full use of the successful external language
model (ELM) to integrate the abundant linguistic knowledge into the caption
model. The ELM generates more semantically similar word proposals which extend
the ground-truth words used for training to deal with the long-tailed problem.
Experimental evaluations on three benchmarks: MSVD, MSR-VTT and VATEX show the
proposed ORG-TRL system achieves state-of-the-art performance. Extensive
ablation studies and visualizations illustrate the effectiveness of our system.
</summary>
    <author>
      <name>Ziqi Zhang</name>
    </author>
    <author>
      <name>Yaya Shi</name>
    </author>
    <author>
      <name>Chunfeng Yuan</name>
    </author>
    <author>
      <name>Bing Li</name>
    </author>
    <author>
      <name>Peijin Wang</name>
    </author>
    <author>
      <name>Weiming Hu</name>
    </author>
    <author>
      <name>Zhengjun Zha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by CVPR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11566v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11566v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11402v2</id>
    <updated>2020-02-28T18:44:07Z</updated>
    <published>2020-02-26T10:48:53Z</published>
    <title>Detecting Potential Topics In News Using BERT, CRF and Wikipedia</title>
    <summary>  For a news content distribution platform like Dailyhunt, Named Entity
Recognition is a pivotal task for building better user recommendation and
notification algorithms. Apart from identifying names, locations, organisations
from the news for 13+ Indian languages and use them in algorithms, we also need
to identify n-grams which do not necessarily fit in the definition of
Named-Entity, yet they are important. For example, "me too movement", "beef
ban", "alwar mob lynching". In this exercise, given an English language text,
we are trying to detect case-less n-grams which convey important information
and can be used as topics and/or hashtags for a news. Model is built using
Wikipedia titles data, private English news corpus and BERT-Multilingual
pre-trained model, Bi-GRU and CRF architecture. It shows promising results when
compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of
F1 and especially Recall.
</summary>
    <author>
      <name>Swapnil Ashok Jadhav</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 tables, 1 figure, 2 examples. This is a report based on
  applied research work conducted at Dailyhunt</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11402v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11402v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11296v1</id>
    <updated>2020-02-26T04:18:01Z</updated>
    <published>2020-02-26T04:18:01Z</published>
    <title>Sparse Sinkhorn Attention</title>
    <summary>  We propose Sparse Sinkhorn Attention, a new efficient and sparse method for
learning to attend. Our method is based on differentiable sorting of internal
representations. Concretely, we introduce a meta sorting network that learns to
generate latent permutations over sequences. Given sorted sequences, we are
then able to compute quasi-global attention with only local windows, improving
the memory efficiency of the attention module. To this end, we propose new
algorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a
dynamic sequence truncation method for tailoring Sinkhorn Attention for
encoding and/or decoding purposes. Via extensive experiments on algorithmic
seq2seq sorting, language modeling, pixel-wise image generation, document
classification and natural language inference, we demonstrate that our memory
efficient Sinkhorn Attention method is competitive with vanilla attention and
consistently outperforms recently proposed efficient Transformer models such as
Sparse Transformers.
</summary>
    <author>
      <name>Yi Tay</name>
    </author>
    <author>
      <name>Dara Bahri</name>
    </author>
    <author>
      <name>Liu Yang</name>
    </author>
    <author>
      <name>Donald Metzler</name>
    </author>
    <author>
      <name>Da-Cheng Juan</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11268v3</id>
    <updated>2020-02-28T01:40:54Z</updated>
    <published>2020-02-26T02:53:42Z</published>
    <title>A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition</title>
    <summary>  This article describes a density ratio approach to integrating external
Language Models (LMs) into end-to-end models for Automatic Speech Recognition
(ASR). Applied to a Recurrent Neural Network Transducer (RNN-T) ASR model
trained on a given domain, a matched in-domain RNN-LM, and a target domain
RNN-LM, the proposed method uses Bayes' Rule to define RNN-T posteriors for the
target domain, in a manner directly analogous to the classic hybrid model for
ASR based on Deep Neural Networks (DNNs) or LSTMs in the Hidden Markov Model
(HMM) framework (Bourlard &amp; Morgan, 1994). The proposed approach is evaluated
in cross-domain and limited-data scenarios, for which a significant amount of
target domain text data is used for LM training, but only limited (or no)
{audio, transcript} training data pairs are used to train the RNN-T.
Specifically, an RNN-T model trained on paired audio &amp; transcript data from
YouTube is evaluated for its ability to generalize to Voice Search data. The
Density Ratio method was found to consistently outperform the dominant approach
to LM and end-to-end ASR integration, Shallow Fusion.
</summary>
    <author>
      <name>Erik McDermott</name>
    </author>
    <author>
      <name>Hasim Sak</name>
    </author>
    <author>
      <name>Ehsan Variani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, presented at 2019 IEEE Automatic Speech
  Recognition and Understanding Workshop (ASRU 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11268v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11268v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11213v1</id>
    <updated>2020-02-25T22:59:36Z</updated>
    <published>2020-02-25T22:59:36Z</published>
    <title>Speech2Phone: A Multilingual and Text Independent Speaker Identification
  Model</title>
    <summary>  Voice recognition is an area with a wide application potential. Speaker
identification is useful in several voice recognition tasks, as seen in
voice-based authentication, transcription systems and intelligent personal
assistants. Some tasks benefit from open-set models which can handle new
speakers without the need of retraining. Audio embeddings for speaker
identification is a proposal to solve this issue. However, choosing a suitable
model is a difficult task, especially when the training resources are scarce.
Besides, it is not always clear whether embeddings are as good as more
traditional methods. In this work, we propose the Speech2Phone and compare
several embedding models for open-set speaker identification, as well as
traditional closed-set models. The models were investigated in the scenario of
small datasets, which makes them more applicable to languages in which data
scarceness is an issue. The results show that embeddings generated by
artificial neural networks are competitive when compared to classical
approaches for the task. Considering a testing dataset composed of 20 speakers,
the best models reach accuracies of 100% and 76.96% for closed an open set
scenarios, respectively. Results suggest that the models can perform language
independent speaker identification. Among the tested models, a fully connected
one, here presented as Speech2Phone, led to the higher accuracy. Furthermore,
the models were tested for different languages showing that the knowledge
learned was successfully transferred for close and distant languages to
Portuguese (in terms of vocabulary). Finally, the models can scale and can
handle more speakers than they were trained for, identifying 150% more speakers
while still maintaining 55% accuracy.
</summary>
    <author>
      <name>Edresson Casanova</name>
    </author>
    <author>
      <name>Arnaldo Candido Junior</name>
    </author>
    <author>
      <name>Christopher Shulby</name>
    </author>
    <author>
      <name>Hamilton Pereira da Silva</name>
    </author>
    <author>
      <name>Pedro Luiz de Paula Filho</name>
    </author>
    <author>
      <name>Alessandro Ferreira Cordeiro</name>
    </author>
    <author>
      <name>Victor de Oliveira Guedes</name>
    </author>
    <author>
      <name>Sandra Maria Aluisio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is under consideration at Expert Systems With Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11213v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11213v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11143v1</id>
    <updated>2020-02-25T19:07:54Z</updated>
    <published>2020-02-25T19:07:54Z</published>
    <title>End-to-End Entity Linking and Disambiguation leveraging Word and
  Knowledge Graph Embeddings</title>
    <summary>  Entity linking - connecting entity mentions in a natural language utterance
to knowledge graph (KG) entities is a crucial step for question answering over
KGs. It is often based on measuring the string similarity between the entity
label and its mention in the question. The relation referred to in the question
can help to disambiguate between entities with the same label. This can be
misleading if an incorrect relation has been identified in the relation linking
step. However, an incorrect relation may still be semantically similar to the
relation in which the correct entity forms a triple within the KG; which could
be captured by the similarity of their KG embeddings. Based on this idea, we
propose the first end-to-end neural network approach that employs KG as well as
word embeddings to perform joint relation and entity classification of simple
questions while implicitly performing entity disambiguation with the help of a
novel gating mechanism. An empirical evaluation shows that the proposed
approach achieves a performance comparable to state-of-the-art entity linking
while requiring less post-processing.
</summary>
    <author>
      <name>Rostislav Nedelchev</name>
    </author>
    <author>
      <name>Debanjan Chaudhuri</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <author>
      <name>Asja Fischer</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11143v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11143v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11102v2</id>
    <updated>2020-03-06T18:59:02Z</updated>
    <published>2020-02-25T18:59:05Z</published>
    <title>On Feature Normalization and Data Augmentation</title>
    <summary>  Modern neural network training relies heavily on data augmentation for
improved generalization. After the initial success of label-preserving
augmentations, there has been a recent surge of interest in label-perturbing
approaches, which combine features and labels across training samples to smooth
the learned decision surface. In this paper, we propose a new augmentation
method that leverages the first and second moments extracted and re-injected by
feature normalization. We replace the moments of the learned features of one
training image by those of another, and also interpolate the target labels. As
our approach is fast, operates entirely in feature space, and mixes different
signals than prior methods, one can effectively combine it with existing
augmentation methods. We demonstrate its efficacy across benchmark data sets in
computer vision, speech, and natural language processing, where it consistently
improves the generalization performance of highly competitive baseline
networks.
</summary>
    <author>
      <name>Boyi Li</name>
    </author>
    <author>
      <name>Felix Wu</name>
    </author>
    <author>
      <name>Ser-Nam Lim</name>
    </author>
    <author>
      <name>Serge Belongie</name>
    </author>
    <author>
      <name>Kilian Q. Weinberger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code is available at https://github.com/Boyiliee/MoEx</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11102v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11102v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11023v1</id>
    <updated>2020-02-25T16:44:50Z</updated>
    <published>2020-02-25T16:44:50Z</published>
    <title>Semantic Relatedness for Keyword Disambiguation: Exploiting Different
  Embeddings</title>
    <summary>  Understanding the meaning of words is crucial for many tasks that involve
human-machine interaction. This has been tackled by research in Word Sense
Disambiguation (WSD) in the Natural Language Processing (NLP) field. Recently,
WSD and many other NLP tasks have taken advantage of embeddings-based
representation of words, sentences, and documents. However, when it comes to
WSD, most embeddings models suffer from ambiguity as they do not capture the
different possible meanings of the words. Even when they do, the list of
possible meanings for a word (sense inventory) has to be known in advance at
training time to be included in the embeddings space. Unfortunately, there are
situations in which such a sense inventory is not known in advance (e.g., an
ontology selected at run-time), or it evolves with time and its status diverges
from the one at training time. This hampers the use of embeddings models for
WSD. Furthermore, traditional WSD techniques do not perform well in situations
in which the available linguistic information is very scarce, such as the case
of keyword-based queries. In this paper, we propose an approach to keyword
disambiguation which grounds on a semantic relatedness between words and senses
provided by an external inventory (ontology) that is not known at training
time. Building on previous works, we present a semantic relatedness measure
that uses word embeddings, and explore different disambiguation algorithms to
also exploit both word and sentence representations. Experimental results show
that this approach achieves results comparable with the state of the art when
applied for WSD, without training for a particular domain.
</summary>
    <author>
      <name>María G. Buey</name>
    </author>
    <author>
      <name>Carlos Bobed</name>
    </author>
    <author>
      <name>Jorge Gracia</name>
    </author>
    <author>
      <name>Eduardo Mena</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11004v1</id>
    <updated>2020-02-25T16:24:42Z</updated>
    <published>2020-02-25T16:24:42Z</published>
    <title>Language-Independent Tokenisation Rivals Language-Specific Tokenisation
  for Word Similarity Prediction</title>
    <summary>  Language-independent tokenisation (LIT) methods that do not require labelled
language resources or lexicons have recently gained popularity because of their
applicability in resource-poor languages. Moreover, they compactly represent a
language using a fixed size vocabulary and can efficiently handle unseen or
rare words. On the other hand, language-specific tokenisation (LST) methods
have a long and established history, and are developed using carefully created
lexicons and training resources. Unlike subtokens produced by LIT methods, LST
methods produce valid morphological subwords. Despite the contrasting
trade-offs between LIT vs. LST methods, their performance on downstream NLP
tasks remain unclear. In this paper, we empirically compare the two approaches
using semantic similarity measurement as an evaluation task across a diverse
set of languages. Our experimental results covering eight languages show that
LST consistently outperforms LIT when the vocabulary size is large, but LIT can
produce comparable or better results than LST in many languages with
comparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging
the use of LIT when language-specific resources are unavailable, incomplete or
a smaller model is required. Moreover, we find that smoothed inverse frequency
(SIF) to be an accurate method to create word embeddings from subword
embeddings for multilingual semantic similarity prediction tasks. Further
analysis of the nearest neighbours of tokens show that semantically and
syntactically related tokens are closely embedded in subword embedding spaces
</summary>
    <author>
      <name>Danushka Bollegala</name>
    </author>
    <author>
      <name>Ryuichi Kiryo</name>
    </author>
    <author>
      <name>Kosuke Tsujino</name>
    </author>
    <author>
      <name>Haruki Yukawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the 12th Language Resources and Evaluation (LREC 2020)
  Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10959v1</id>
    <updated>2020-02-25T15:22:23Z</updated>
    <published>2020-02-25T15:22:23Z</published>
    <title>A more abstractive summarization model</title>
    <summary>  Pointer-generator network is an extremely popular method of text
summarization. More recent works in this domain still build on top of the
baseline pointer generator by augmenting a content selection phase, or by
decomposing the decoder into a contextual network and a language model.
However, all such models that are based on the pointer-generator base
architecture cannot generate novel words in the summary and mostly copy words
from the source text. In our work, we first thoroughly investigate why the
pointer-generator network is unable to generate novel words, and then address
that by adding an Out-of-vocabulary (OOV) penalty. This enables us to improve
the amount of novelty/abstraction significantly. We use normalized n-gram
novelty scores as a metric for determining the level of abstraction. Moreover,
we also report rouge scores of our model since most summarization models are
evaluated with R-1, R-2, R-L scores.
</summary>
    <author>
      <name>Satyaki Chakraborty</name>
    </author>
    <author>
      <name>Xinya Li</name>
    </author>
    <author>
      <name>Sayak Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10957v1</id>
    <updated>2020-02-25T15:21:10Z</updated>
    <published>2020-02-25T15:21:10Z</published>
    <title>MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression
  of Pre-Trained Transformers</title>
    <summary>  Pre-trained language models (e.g., BERT (Devlin et al., 2018) and its
variants) have achieved remarkable success in varieties of NLP tasks. However,
these models usually consist of hundreds of millions of parameters which brings
challenges for fine-tuning and online serving in real-life applications due to
latency and capacity constraints. In this work, we present a simple and
effective approach to compress large Transformer (Vaswani et al., 2017) based
pre-trained models, termed as deep self-attention distillation. The small model
(student) is trained by deeply mimicking the self-attention module, which plays
a vital role in Transformer networks, of the large model (teacher).
Specifically, we propose distilling the self-attention module of the last
Transformer layer of the teacher, which is effective and flexible for the
student. Furthermore, we introduce the scaled dot-product between values in the
self-attention module as the new deep self-attention knowledge, in addition to
the attention distributions (i.e., the scaled dot-product of queries and keys)
that have been used in existing works. Moreover, we show that introducing a
teacher assistant (Mirzadeh et al., 2019) also helps the distillation of large
pre-trained Transformer models. Experimental results demonstrate that our model
outperforms state-of-the-art baselines in different parameter size of student
models. In particular, it retains more than 99% accuracy on SQuAD 2.0 and
several GLUE benchmark tasks using 50% of the Transformer parameters and
computations of the teacher model. The code and models are publicly available
at https://github.com/microsoft/unilm/tree/master/minilm
</summary>
    <author>
      <name>Wenhui Wang</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Li Dong</name>
    </author>
    <author>
      <name>Hangbo Bao</name>
    </author>
    <author>
      <name>Nan Yang</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code and models:
  https://github.com/microsoft/unilm/tree/master/minilm</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10937v1</id>
    <updated>2020-02-25T15:11:02Z</updated>
    <published>2020-02-25T15:11:02Z</published>
    <title>Diversity-Based Generalization for Neural Unsupervised Text
  Classification under Domain Shift</title>
    <summary>  Domain adaptation approaches seek to learn from a source domain and
generalize it to an unseen target domain. At present, the state-of-the-art
domain adaptation approaches for subjective text classification problems are
semi-supervised; and use unlabeled target data along with labeled source data.
In this paper, we propose a novel method for domain adaptation of single-task
text classification problems based on a simple but effective idea of
diversity-based generalization that does not require unlabeled target data.
Diversity plays the role of promoting the model to better generalize and be
indiscriminate towards domain shift by forcing the model not to rely on same
features for prediction. We apply this concept on the most explainable
component of neural networks, the attention layer. To generate sufficient
diversity, we create a multi-head attention model and infuse a diversity
constraint between the attention heads such that each head will learn
differently. We further expand upon our model by tri-training and designing a
procedure with an additional diversity constraint between the attention heads
of the tri-trained classifiers. Extensive evaluation using the standard
benchmark dataset of Amazon reviews and a newly constructed dataset of Crisis
events shows that our fully unsupervised method matches with the competing
semi-supervised baselines. Our results demonstrate that machine learning
architectures that ensure sufficient diversity can generalize better;
encouraging future research to design ubiquitously usable learning models
without using unlabeled target data.
</summary>
    <author>
      <name>Jitin Krishnan</name>
    </author>
    <author>
      <name>Hemant Purohit</name>
    </author>
    <author>
      <name>Huzefa Rangwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures, Source Code Available</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10931v1</id>
    <updated>2020-02-25T15:05:06Z</updated>
    <published>2020-02-25T15:05:06Z</published>
    <title>Detecting Asks in SE attacks: Impact of Linguistic and Structural
  Knowledge</title>
    <summary>  Social engineers attempt to manipulate users into undertaking actions such as
downloading malware by clicking links or providing access to money or sensitive
information. Natural language processing, computational sociolinguistics, and
media-specific structural clues provide a means for detecting both the ask
(e.g., buy gift card) and the risk/reward implied by the ask, which we call
framing (e.g., lose your job, get a raise). We apply linguistic resources such
as Lexical Conceptual Structure to tackle ask detection and also leverage
structural clues such as links and their proximity to identified asks to
improve confidence in our results. Our experiments indicate that the
performance of ask detection, framing detection, and identification of the top
ask is improved by linguistically motivated classes coupled with structural
clues such as links. Our approach is implemented in a system that informs users
about social engineering risk situations.
</summary>
    <author>
      <name>Bonnie J. Dorr</name>
    </author>
    <author>
      <name>Archna Bhatia</name>
    </author>
    <author>
      <name>Adam Dalton</name>
    </author>
    <author>
      <name>Brodie Mather</name>
    </author>
    <author>
      <name>Bryanna Hebenstreit</name>
    </author>
    <author>
      <name>Sashank Santhanam</name>
    </author>
    <author>
      <name>Zhuo Cheng</name>
    </author>
    <author>
      <name>Samira Shaikh</name>
    </author>
    <author>
      <name>Alan Zemel</name>
    </author>
    <author>
      <name>Tomek Strzalkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10903v1</id>
    <updated>2020-02-25T14:43:56Z</updated>
    <published>2020-02-25T14:43:56Z</published>
    <title>KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation
  Classification</title>
    <summary>  Lexical relations describe how concepts are semantically related, in the form
of relation triples. The accurate prediction of lexical relations between
concepts is challenging, due to the sparsity of patterns indicating the
existence of such relations. We propose the Knowledge-Enriched Meta-Learning
(KEML) framework to address the task of lexical relation classification. In
KEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is presented to learn
concept representations from massive text corpora, with rich lexical knowledge
injected by distant supervision. A probabilistic distribution of auxiliary
tasks is defined to increase the model's ability to recognize different types
of lexical relations. We further combine a meta-learning process over the
auxiliary task distribution and supervised learning to train the neural lexical
relation classifier. Experiments over multiple datasets show that KEML
outperforms state-of-the-art methods.
</summary>
    <author>
      <name>Chengyu Wang</name>
    </author>
    <author>
      <name>Minghui Qiu</name>
    </author>
    <author>
      <name>Jun Huang</name>
    </author>
    <author>
      <name>Xiaofeng He</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10903v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10903v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10851v1</id>
    <updated>2020-02-25T13:27:31Z</updated>
    <published>2020-02-25T13:27:31Z</published>
    <title>Small-Footprint Open-Vocabulary Keyword Spotting with Quantized LSTM
  Networks</title>
    <summary>  We explore a keyword-based spoken language understanding system, in which the
intent of the user can directly be derived from the detection of a sequence of
keywords in the query. In this paper, we focus on an open-vocabulary keyword
spotting method, allowing the user to define their own keywords without having
to retrain the whole model. We describe the different design choices leading to
a fast and small-footprint system, able to run on tiny devices, for any
arbitrary set of user-defined keywords, without training data specific to those
keywords. The model, based on a quantized long short-term memory (LSTM) neural
network, trained with connectionist temporal classification (CTC), weighs less
than 500KB. Our approach takes advantage of some properties of the predictions
of CTC-trained networks to calibrate the confidence scores and implement a fast
detection algorithm. The proposed system outperforms a standard keyword-filler
model approach.
</summary>
    <author>
      <name>Théodore Bluche</name>
    </author>
    <author>
      <name>Maël Primet</name>
    </author>
    <author>
      <name>Thibault Gisselbrecht</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10832v1</id>
    <updated>2020-02-25T12:44:36Z</updated>
    <published>2020-02-25T12:44:36Z</published>
    <title>BERT Can See Out of the Box: On the Cross-modal Transferability of Text
  Representations</title>
    <summary>  Pre-trained language models such as BERT have recently contributed to
significant advances in Natural Language Processing tasks. Interestingly, while
multilingual BERT models have demonstrated impressive results, recent works
have shown how monolingual BERT can also be competitive in zero-shot
cross-lingual settings. This suggests that the abstractions learned by these
models can transfer across languages, even when trained on monolingual data. In
this paper, we investigate whether such generalization potential applies to
other modalities, such as vision: does BERT contain abstractions that
generalize beyond text? We introduce BERT-gen, an architecture for text
generation based on BERT, able to leverage on either mono- or multi- modal
representations. The results reported under different configurations indicate a
positive answer to our research question, and the proposed model obtains
substantial improvements over the state-of-the-art on two established Visual
Question Generation datasets.
</summary>
    <author>
      <name>Thomas Scialom</name>
    </author>
    <author>
      <name>Patrick Bordes</name>
    </author>
    <author>
      <name>Paul-Alexis Dray</name>
    </author>
    <author>
      <name>Jacopo Staiano</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10829v1</id>
    <updated>2020-02-25T12:40:06Z</updated>
    <published>2020-02-25T12:40:06Z</published>
    <title>MuST-Cinema: a Speech-to-Subtitles corpus</title>
    <summary>  Growing needs in localising audiovisual content in multiple languages through
subtitles call for the development of automatic solutions for human subtitling.
Neural Machine Translation (NMT) can contribute to the automatisation of
subtitling, facilitating the work of human subtitlers and reducing turn-around
times and related costs. NMT requires high-quality, large, task-specific
training data. The existing subtitling corpora, however, are missing both
alignments to the source language audio and important information about
subtitle breaks. This poses a significant limitation for developing efficient
automatic approaches for subtitling, since the length and form of a subtitle
directly depends on the duration of the utterance. In this work, we present
MuST-Cinema, a multilingual speech translation corpus built from TED subtitles.
The corpus is comprised of (audio, transcription, translation) triplets.
Subtitle breaks are preserved by inserting special symbols. We show that the
corpus can be used to build models that efficiently segment sentences into
subtitles and propose a method for annotating existing subtitling corpora with
subtitle breaks, conforming to the constraint of length.
</summary>
    <author>
      <name>Alina Karakanta</name>
    </author>
    <author>
      <name>Matteo Negri</name>
    </author>
    <author>
      <name>Marco Turchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10782v1</id>
    <updated>2020-02-25T10:36:17Z</updated>
    <published>2020-02-25T10:36:17Z</published>
    <title>Abstractive Snippet Generation</title>
    <summary>  An abstractive snippet is an originally created piece of text to summarize a
web page on a search engine results page. Compared to the conventional
extractive snippets, which are generated by extracting phrases and sentences
verbatim from a web page, abstractive snippets circumvent copyright issues;
even more interesting is the fact that they open the door for personalization.
Abstractive snippets have been evaluated as equally powerful in terms of user
acceptance and expressiveness---but the key question remains: Can abstractive
snippets be automatically generated with sufficient quality?
  This paper introduces a new approach to abstractive snippet generation: We
identify the first two large-scale sources for distant supervision, namely
anchor contexts and web directories. By mining the entire ClueWeb09 and
ClueWeb12 for anchor contexts and by utilizing the DMOZ Open Directory Project,
we compile the Webis Abstractive Snippet Corpus 2020, comprising more than 3.5
million triples of the form $\langle$query, snippet, document$\rangle$ as
training examples, where the snippet is either an anchor context or a web
directory description in lieu of a genuine query-biased abstractive snippet of
the web document. We propose a bidirectional abstractive snippet generation
model and assess the quality of both our corpus and the generated abstractive
snippets with standard measures, crowdsourcing, and in comparison to the state
of the art. The evaluation shows that our novel data sources along with the
proposed model allow for producing usable query-biased abstractive snippets
while minimizing text reuse.
</summary>
    <author>
      <name>Wei-Fan Chen</name>
    </author>
    <author>
      <name>Shahbaz Syed</name>
    </author>
    <author>
      <name>Benno Stein</name>
    </author>
    <author>
      <name>Matthias Hagen</name>
    </author>
    <author>
      <name>Martin Potthast</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380206</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380206" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by WWW 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10772v1</id>
    <updated>2020-02-25T10:05:56Z</updated>
    <published>2020-02-25T10:05:56Z</published>
    <title>Label-guided Learning for Text Classification</title>
    <summary>  Text classification is one of the most important and fundamental tasks in
natural language processing. Performance of this task mainly dependents on text
representation learning. Currently, most existing learning frameworks mainly
focus on encoding local contextual information between words. These methods
always neglect to exploit global clues, such as label information, for encoding
text information. In this study, we propose a label-guided learning framework
LguidedLearn for text representation and classification. Our method is novel
but simple that we only insert a label-guided encoding layer into the commonly
used text representation learning schemas. That label-guided layer performs
label-based attentive encoding to map the universal text embedding (encoded by
a contextual information learner) into different label spaces, resulting in
label-wise embeddings. In our proposed framework, the label-guided layer can be
easily and directly applied with a contextual encoding method to perform
jointly learning. Text information is encoded based on both the local
contextual information and the global label clues. Therefore, the obtained text
embeddings are more robust and discriminative for text classification.
Extensive experiments are conducted on benchmark datasets to illustrate the
effectiveness of our proposed method.
</summary>
    <author>
      <name>Xien Liu</name>
    </author>
    <author>
      <name>Song Wang</name>
    </author>
    <author>
      <name>Xiao Zhang</name>
    </author>
    <author>
      <name>Xinxin You</name>
    </author>
    <author>
      <name>Ji Wu</name>
    </author>
    <author>
      <name>Dejing Dou</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10757v1</id>
    <updated>2020-02-25T09:18:26Z</updated>
    <published>2020-02-25T09:18:26Z</published>
    <title>Event Detection with Relation-Aware Graph Convolutional Neural Networks</title>
    <summary>  Event detection (ED), a key subtask of information extraction, aims to
recognize instances of specific types of events in text. Recently, graph
convolutional networks (GCNs) over dependency trees have been widely used to
capture syntactic structure information and get convincing performances in
event detection. However, these works ignore the syntactic relation labels on
the tree, which convey rich and useful linguistic knowledge for event
detection. In this paper, we investigate a novel architecture named
Relation-Aware GCN (RA-GCN), which efficiently exploits syntactic relation
labels and models the relation between words specifically. We first propose a
relation-aware aggregation module to produce expressive word representation by
aggregating syntactically connected words through specific relation.
Furthermore, a context-aware relation update module is designed to explicitly
update the relation representation between words, and these two modules work in
the mutual promotion way. Experimental results on the ACE2005 dataset show that
our model achieves a new state-of-the-art performance for event detection.
</summary>
    <author>
      <name>Shiyao Cui</name>
    </author>
    <author>
      <name>Bowen Yu</name>
    </author>
    <author>
      <name>Tingwen Liu</name>
    </author>
    <author>
      <name>Zhenyu Zhang</name>
    </author>
    <author>
      <name>Xuebin Wang</name>
    </author>
    <author>
      <name>Jinqiao Shi</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10710v1</id>
    <updated>2020-02-25T07:49:12Z</updated>
    <published>2020-02-25T07:49:12Z</published>
    <title>End-to-end Emotion-Cause Pair Extraction via Learning to Link</title>
    <summary>  Emotion-cause pair extraction (ECPE), as an emergent natural language
processing task, aims at jointly investigating emotions and their underlying
causes in documents. It extends the previous emotion cause extraction (ECE)
task, yet without requiring a set of pre-given emotion clauses as in ECE.
Existing approaches to ECPE generally adopt a two-stage method, i.e., (1)
emotion and cause detection, and then (2) pairing the detected emotions and
causes. Such pipeline method, while intuitive, suffers from two critical
issues, including error propagation across stages that may hinder the
effectiveness, and high computational cost that would limit the practical
application of the method. To tackle these issues, we propose a multi-task
learning model that can extract emotions, causes and emotion-cause pairs
simultaneously in an end-to-end manner. Specifically, our model regards pair
extraction as a link prediction task, and learns to link from emotion clauses
to cause clauses, i.e., the links are directional. Emotion extraction and cause
extraction are incorporated into the model as auxiliary tasks, which further
boost the pair extraction. Experiments are conducted on an ECPE benchmarking
dataset. The results show that our proposed model outperforms a range of
state-of-the-art approaches in terms of both effectiveness and efficiency.
</summary>
    <author>
      <name>Haolin Song</name>
    </author>
    <author>
      <name>Chen Zhang</name>
    </author>
    <author>
      <name>Qiuchi Li</name>
    </author>
    <author>
      <name>Dawei Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10695v1</id>
    <updated>2020-02-25T06:41:07Z</updated>
    <published>2020-02-25T06:41:07Z</published>
    <title>Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge</title>
    <summary>  Audio-Visual Scene-Aware Dialog (AVSD) is an extension from Video Question
Answering (QA) whereby the dialogue agent is required to generate natural
language responses to address user queries and carry on conversations. This is
a challenging task as it consists of video features of multiple modalities,
including text, visual, and audio features. The agent also needs to learn
semantic dependencies among user utterances and system responses to make
coherent conversations with humans. In this work, we describe our submission to
the AVSD track of the 8th Dialogue System Technology Challenge. We adopt
dot-product attention to combine text and non-text features of input video. We
further enhance the generation capability of the dialogue agent by adopting
pointer networks to point to tokens from multiple source sequences in each
generation step. Our systems achieve high performance in automatic metrics and
obtain 5th and 6th place in human evaluation among all submissions.
</summary>
    <author>
      <name>Hung Le</name>
    </author>
    <author>
      <name>Nancy F. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at DSTC Workshop at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10670v2</id>
    <updated>2020-03-03T05:16:37Z</updated>
    <published>2020-02-25T05:09:48Z</published>
    <title>Exploring BERT Parameter Efficiency on the Stanford Question Answering
  Dataset v2.0</title>
    <summary>  In this paper we explore the parameter efficiency of BERT arXiv:1810.04805 on
version 2.0 of the Stanford Question Answering dataset (SQuAD2.0). We evaluate
the parameter efficiency of BERT while freezing a varying number of final
transformer layers as well as including the adapter layers proposed in
arXiv:1902.00751. Additionally, we experiment with the use of context-aware
convolutional (CACNN) filters, as described in arXiv:1709.08294v3, as a final
augmentation layer for the SQuAD2.0 tasks.
  This exploration is motivated in part by arXiv:1907.10597, which made a
compelling case for broadening the evaluation criteria of artificial
intelligence models to include various measures of resource efficiency. While
we do not evaluate these models based on their floating point operation
efficiency as proposed in arXiv:1907.10597, we examine efficiency with respect
to training time, inference time, and total number of model parameters. Our
results largely corroborate those of arXiv:1902.00751 for adapter modules,
while also demonstrating that gains in F1 score from adding context-aware
convolutional filters are not practical due to the increase in training and
inference time.
</summary>
    <author>
      <name>Eric Hulburd</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10670v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10670v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10665v1</id>
    <updated>2020-02-25T04:56:47Z</updated>
    <published>2020-02-25T04:56:47Z</published>
    <title>Declarative Memory-based Structure for the Representation of Text Data</title>
    <summary>  In the era of intelligent computing, computational progress in text
processing is an essential consideration. Many systems have been developed to
process text over different languages. Though, there is considerable
development, they still lack in understanding of the text, i.e., instead of
keeping text as knowledge, many treat text as a data. In this work we introduce
a text representation scheme which is influenced by human memory
infrastructure. Since texts are declarative in nature, a structural
organization would foster efficient computation over text. We exploit long term
episodic memory to keep text information observed over time. This not only keep
fragments of text in an organized fashion but also reduces redundancy and
stores the temporal relation among them. Wordnet has been used to imitate
semantic memory, which works at word level to facilitate the understanding
about individual words within text. Experimental results of various operation
performed over episodic memory and growth of knowledge infrastructure over time
is reported.
</summary>
    <author>
      <name>Sumant Pushp</name>
    </author>
    <author>
      <name>Pragya Kashmira</name>
    </author>
    <author>
      <name>Shyamanta M Hazarika</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10640v1</id>
    <updated>2020-02-25T03:13:32Z</updated>
    <published>2020-02-25T03:13:32Z</published>
    <title>Differentiable Reasoning over a Virtual Knowledge Base</title>
    <summary>  We consider the task of answering complex multi-hop questions using a corpus
as a virtual knowledge base (KB). In particular, we describe a neural module,
DrKIT, that traverses textual data like a KB, softly following paths of
relations between mentions of entities in the corpus. At each step the module
uses a combination of sparse-matrix TFIDF indices and a maximum inner product
search (MIPS) on a special index of contextual representations of the mentions.
This module is differentiable, so the full system can be trained end-to-end
using gradient based methods, starting from natural language inputs. We also
describe a pretraining scheme for the contextual representation encoder by
generating hard negative examples using existing knowledge bases. We show that
DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,
cutting the gap between text-based and KB-based state-of-the-art by 70%. On
HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking
approach to retrieving the relevant passages required to answer a question.
DrKIT is also very efficient, processing 10-100x more queries per second than
existing multi-hop systems.
</summary>
    <author>
      <name>Bhuwan Dhingra</name>
    </author>
    <author>
      <name>Manzil Zaheer</name>
    </author>
    <author>
      <name>Vidhisha Balachandran</name>
    </author>
    <author>
      <name>Graham Neubig</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>William W. Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10638v1</id>
    <updated>2020-02-25T03:08:12Z</updated>
    <published>2020-02-25T03:08:12Z</published>
    <title>Towards Learning a Generic Agent for Vision-and-Language Navigation via
  Pre-training</title>
    <summary>  Learning to navigate in a visual environment following natural-language
instructions is a challenging task, because the multimodal inputs to the agent
are highly variable, and the training data on a new task is often limited. In
this paper, we present the first pre-training and fine-tuning paradigm for
vision-and-language navigation (VLN) tasks. By training on a large amount of
image-text-action triplets in a self-supervised learning manner, the
pre-trained model provides generic representations of visual environments and
language instructions. It can be easily used as a drop-in for existing VLN
frameworks, leading to the proposed agent called Prevalent. It learns more
effectively in new tasks and generalizes better in a previously unseen
environment. The performance is validated on three VLN tasks. On the
Room-to-Room benchmark, our model improves the state-of-the-art from 47% to 51%
on success rate weighted by path length. Further, the learned representation is
transferable to other VLN tasks. On two recent tasks, vision-and-dialog
navigation and ``Help, Anna!'' the proposed Prevalent leads to significant
improvement over existing methods, achieving a new state of the art.
</summary>
    <author>
      <name>Weituo Hao</name>
    </author>
    <author>
      <name>Chunyuan Li</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at CVPR 2020. The first two authors contributed equally to
  this manuscript. Code: https://github.com/weituo12321/PREVALENT</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10582v1</id>
    <updated>2020-02-24T23:07:38Z</updated>
    <published>2020-02-24T23:07:38Z</published>
    <title>Automating Discovery of Dominance in Synchronous Computer-Mediated
  Communication</title>
    <summary>  With the advent of electronic interaction, dominance (or the assertion of
control over others) has acquired new dimensions. This study investigates the
dynamics and characteristics of dominance in virtual interaction by analyzing
electronic chat transcripts of groups solving a hidden profile task. We
investigate computer-mediated communication behavior patterns that demonstrate
dominance and identify a number of relevant variables. These indicators are
calculated with automatic and manual coding of text transcripts. A comparison
of both sets of variables indicates that automatic text analysis methods yield
similar conclusions than manual coding. These findings are encouraging to
advance research in text analysis methods in general, and in the study of
virtual team dominance in particular.
</summary>
    <author>
      <name>Jim Samuel</name>
    </author>
    <author>
      <name>Richard Holowczak</name>
    </author>
    <author>
      <name>Raquel Benbunan-Fich</name>
    </author>
    <author>
      <name>Ilan Levine</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HICSS.2014.636</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HICSS.2014.636" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">47th Hawaii International Conference on System Sciences, 2014, pp.
  1804-1812</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.10582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10546v1</id>
    <updated>2020-02-24T21:04:51Z</updated>
    <published>2020-02-24T21:04:51Z</published>
    <title>Parsing Early Modern English for Linguistic Search</title>
    <summary>  We investigate the question of whether advances in NLP over the last few
years make it possible to vastly increase the size of data usable for research
in historical syntax. This brings together many of the usual tools in NLP -
word embeddings, tagging, and parsing - in the service of linguistic queries
over automatically annotated corpora. We train a part-of-speech (POS) tagger
and parser on a corpus of historical English, using ELMo embeddings trained
over a billion words of similar text. The evaluation is based on the standard
metrics, as well as on the accuracy of the query searches using the parsed
data.
</summary>
    <author>
      <name>Seth Kulick</name>
    </author>
    <author>
      <name>Neville Ryant</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11506v1</id>
    <updated>2020-02-24T20:11:35Z</updated>
    <published>2020-02-24T20:11:35Z</published>
    <title>Using Distributional Thesaurus Embedding for Co-hyponymy Detection</title>
    <summary>  Discriminating lexical relations among distributionally similar words has
always been a challenge for natural language processing (NLP) community. In
this paper, we investigate whether the network embedding of distributional
thesaurus can be effectively utilized to detect co-hyponymy relations. By
extensive experiments over three benchmark datasets, we show that the vector
representation obtained by applying node2vec on distributional thesaurus
outperforms the state-of-the-art models for binary classification of
co-hyponymy vs. hypernymy, as well as co-hyponymy vs. meronymy, by huge
margins.
</summary>
    <author>
      <name>Abhik Jana</name>
    </author>
    <author>
      <name>Nikhil Reddy Varimalla</name>
    </author>
    <author>
      <name>Pawan Goyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in LREC 2020. arXiv admin note: text overlap with
  arXiv:1802.04609</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10416v1</id>
    <updated>2020-02-24T17:59:11Z</updated>
    <published>2020-02-24T17:59:11Z</published>
    <title>Resources for Turkish Dependency Parsing: Introducing the BOUN Treebank
  and the BoAT Annotation Tool</title>
    <summary>  In this paper, we describe our contributions and efforts to develop Turkish
resources, which include a new treebank (BOUN Treebank) with novel sentences,
along with the guidelines we adopted and a new annotation tool we developed
(BoAT). The manual annotation process we employed was shaped and implemented by
a team of four linguists and five NLP specialists. Decisions regarding the
annotation of the BOUN Treebank were made in line with the Universal
Dependencies framework, which originated from the works of De Marneffe et al.
(2014) and Nivre et al. (2016). We took into account the recent unifying
efforts based on the re-annotation of other Turkish treebanks in the UD
framework (T\"urk et al., 2019). Through the BOUN Treebank, we introduced a
total of 9,757 sentences from various topics including biographical texts,
national newspapers, instructional texts, popular culture articles, and essays.
In addition, we report the parsing results of a graph-based dependency parser
obtained over each text type, the total of the BOUN Treebank, and all Turkish
treebanks that we either re-annotated or introduced. We show that a
state-of-the-art dependency parser has improved scores for identifying the
proper head and the syntactic relationships between the heads and the
dependents. In light of these results, we have observed that the unification of
the Turkish annotation scheme and introducing a more comprehensive treebank
improves performance with regards to dependency parsing
</summary>
    <author>
      <name>Utku Türk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Linguistics Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Furkan Atmaca</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Linguistics Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Şaziye Betül Özateş</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Gözde Berk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Seyyit Talha Bedir</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Linguistics Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Abdullatif Köksal</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Balkız Öztürk Başaran</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Linguistics Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Tunga Güngör</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Arzucan Özgür</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering Boğaziçi University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 5 figures, 10 tables, submitted to Language Resources and
  Evaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10375v1</id>
    <updated>2020-02-24T17:07:32Z</updated>
    <published>2020-02-24T17:07:32Z</published>
    <title>Discriminative Adversarial Search for Abstractive Summarization</title>
    <summary>  We introduce a novel approach for sequence decoding, Discriminative
Adversarial Search (DAS), which has the desirable properties of alleviating the
effects of exposure bias without requiring external metrics. Inspired by
Generative Adversarial Networks (GANs), wherein a discriminator is used to
improve the generator, our method differs from GANs in that the generator
parameters are not updated at training time and the discriminator is only used
to drive sequence generation at inference time.
  We investigate the effectiveness of the proposed approach on the task of
Abstractive Summarization: the results obtained show that a naive application
of DAS improves over the state-of-the-art methods, with further gains obtained
via discriminator retraining. Moreover, we show how DAS can be effective for
cross-domain adaptation. Finally, all results reported are obtained without
additional rule-based filtering strategies, commonly used by the best
performing systems available: this indicates that DAS can effectively be
deployed without relying on post-hoc modifications of the generated outputs.
</summary>
    <author>
      <name>Thomas Scialom</name>
    </author>
    <author>
      <name>Paul-Alexis Dray</name>
    </author>
    <author>
      <name>Sylvain Lamprier</name>
    </author>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <author>
      <name>Jacopo Staiano</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10361v2</id>
    <updated>2020-03-03T13:34:59Z</updated>
    <published>2020-02-24T16:45:59Z</published>
    <title>Multilingual Twitter Corpus and Baselines for Evaluating Demographic
  Bias in Hate Speech Recognition</title>
    <summary>  Existing research on fairness evaluation of document classification models
mainly uses synthetic monolingual data without ground truth for author
demographic attributes. In this work, we assemble and publish a multilingual
Twitter corpus for the task of hate speech detection with inferred four author
demographic factors: age, country, gender and race/ethnicity. The corpus covers
five languages: English, Italian, Polish, Portuguese and Spanish. We evaluate
the inferred demographic labels with a crowdsourcing platform, Figure Eight. To
examine factors that can cause biases, we take an empirical analysis of
demographic predictability on the English corpus. We measure the performance of
four popular document classifiers and evaluate the fairness and bias of the
baseline classifiers on the author-level demographic attributes.
</summary>
    <author>
      <name>Xiaolei Huang</name>
    </author>
    <author>
      <name>Linzi Xing</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Michael J. Paul</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10361v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10361v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10348v1</id>
    <updated>2020-02-24T16:20:32Z</updated>
    <published>2020-02-24T16:20:32Z</published>
    <title>Low-Resource Knowledge-Grounded Dialogue Generation</title>
    <summary>  Responding with knowledge has been recognized as an important capability for
an intelligent conversational agent. Yet knowledge-grounded dialogues, as
training data for learning such a response generation model, are difficult to
obtain. Motivated by the challenge in practice, we consider knowledge-grounded
dialogue generation under a natural assumption that only limited training
examples are available. In such a low-resource setting, we devise a
disentangled response decoder in order to isolate parameters that depend on
knowledge-grounded dialogues from the entire generation model. By this means,
the major part of the model can be learned from a large number of ungrounded
dialogues and unstructured documents, while the remaining small parameters can
be well fitted using the limited training examples. Evaluation results on two
benchmarks indicate that with only 1/8 training data, our model can achieve the
state-of-the-art performance and generalize well on out-of-domain knowledge.
</summary>
    <author>
      <name>Xueliang Zhao</name>
    </author>
    <author>
      <name>Wei Wu</name>
    </author>
    <author>
      <name>Chongyang Tao</name>
    </author>
    <author>
      <name>Can Xu</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Rui Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10345v1</id>
    <updated>2020-02-24T16:17:12Z</updated>
    <published>2020-02-24T16:17:12Z</published>
    <title>Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation</title>
    <summary>  Fine-tuning pre-trained language models like BERT has become an effective way
in NLP and yields state-of-the-art results on many downstream tasks. Recent
studies on adapting BERT to new tasks mainly focus on modifying the model
structure, re-designing the pre-train tasks, and leveraging external data and
knowledge. The fine-tuning strategy itself has yet to be fully explored. In
this paper, we improve the fine-tuning of BERT with two effective mechanisms:
self-ensemble and self-distillation. The experiments on text classification and
natural language inference tasks show our proposed methods can significantly
improve the adaption of BERT without any external data or knowledge.
</summary>
    <author>
      <name>Yige Xu</name>
    </author>
    <author>
      <name>Xipeng Qiu</name>
    </author>
    <author>
      <name>Ligao Zhou</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10336v1</id>
    <updated>2020-02-24T16:07:11Z</updated>
    <published>2020-02-24T16:07:11Z</published>
    <title>Semi-Supervised Speech Recognition via Local Prior Matching</title>
    <summary>  For sequence transduction tasks like speech recognition, a strong structured
prior model encodes rich information about the target space, implicitly ruling
out invalid sequences by assigning them low probability. In this work, we
propose local prior matching (LPM), a semi-supervised objective that distills
knowledge from a strong prior (e.g. a language model) to provide learning
signal to a discriminative model trained on unlabeled speech. We demonstrate
that LPM is theoretically well-motivated, simple to implement, and superior to
existing knowledge distillation techniques under comparable settings. Starting
from a baseline trained on 100 hours of labeled speech, with an additional 360
hours of unlabeled data, LPM recovers 54% and 73% of the word error rate on
clean and noisy test sets relative to a fully supervised model on the same
data.
</summary>
    <author>
      <name>Wei-Ning Hsu</name>
    </author>
    <author>
      <name>Ann Lee</name>
    </author>
    <author>
      <name>Gabriel Synnaeve</name>
    </author>
    <author>
      <name>Awni Hannun</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10329v1</id>
    <updated>2020-02-24T15:57:41Z</updated>
    <published>2020-02-24T15:57:41Z</published>
    <title>KBSET -- Knowledge-Based Support for Scholarly Editing and Text
  Processing with Declarative LaTeX Markup and a Core Written in SWI-Prolog</title>
    <summary>  KBSET is an environment that provides support for scholarly editing in two
flavors: First, as a practical tool KBSET/Letters that accompanies the
development of editions of correspondences (in particular from the 18th and
19th century), completely from source documents to PDF and HTML presentations.
Second, as a prototypical tool KBSET/NER for experimentally investigating novel
forms of working on editions that are centered around automated named entity
recognition. KBSET can process declarative application-specific markup that is
expressed in LaTeX notation and incorporate large external fact bases that are
typically provided in RDF. KBSET includes specially developed LaTeX styles and
a core system that is written in SWI-Prolog, which is used there in many roles,
utilizing that it realizes the potential of Prolog as a unifying language.
</summary>
    <author>
      <name>Jana Kittelmann</name>
    </author>
    <author>
      <name>Christoph Wernhard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in DECLARE 2019 Revised Selected Papers</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02966v1</id>
    <updated>2020-02-24T14:53:32Z</updated>
    <published>2020-02-24T14:53:32Z</published>
    <title>End-to-End Neural Diarization: Reformulating Speaker Diarization as
  Simple Multi-label Classification</title>
    <summary>  The most common approach to speaker diarization is clustering of speaker
embeddings. However, the clustering-based approach has a number of problems;
i.e., (i) it is not optimized to minimize diarization errors directly, (ii) it
cannot handle speaker overlaps correctly, and (iii) it has trouble adapting
their speaker embedding models to real audio recordings with speaker overlaps.
To solve these problems, we propose the End-to-End Neural Diarization (EEND),
in which a neural network directly outputs speaker diarization results given a
multi-speaker recording. To realize such an end-to-end model, we formulate the
speaker diarization problem as a multi-label classification problem and
introduce a permutation-free objective function to directly minimize
diarization errors. Besides its end-to-end simplicity, the EEND method can
explicitly handle speaker overlaps during training and inference. Just by
feeding multi-speaker recordings with corresponding speaker segment labels, our
model can be easily adapted to real conversations. We evaluated our method on
simulated speech mixtures and real conversation datasets. The results showed
that the EEND method outperformed the state-of-the-art x-vector
clustering-based method, while it correctly handled speaker overlaps. We
explored the neural network architecture for the EEND method, and found that
the self-attention-based neural network was the key to achieving excellent
performance. In contrast to conditioning the network only on its previous and
next hidden states, as is done using bidirectional long short-term memory
(BLSTM), self-attention is directly conditioned on all the frames. By
visualizing the attention weights, we show that self-attention captures global
speaker characteristics in addition to local speech activity dynamics, making
it especially suitable for dealing with the speaker diarization problem.
</summary>
    <author>
      <name>Yusuke Fujita</name>
    </author>
    <author>
      <name>Shinji Watanabe</name>
    </author>
    <author>
      <name>Shota Horiguchi</name>
    </author>
    <author>
      <name>Yawen Xue</name>
    </author>
    <author>
      <name>Kenji Nagamatsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submission to IEEE TASLP. This article draws from our previous
  conference papers: arxiv:1909.06247 and arxiv:1909.05952</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10260v1</id>
    <updated>2020-02-24T13:53:06Z</updated>
    <published>2020-02-24T13:53:06Z</published>
    <title>Fixed Encoder Self-Attention Patterns in Transformer-Based Machine
  Translation</title>
    <summary>  Transformer-based models have brought a radical change to neural machine
translation. A key feature of the Transformer architecture is the so-called
multi-head attention mechanism, which allows the model to focus simultaneously
on different parts of the input. However, recent works have shown that
attention heads learn simple positional patterns which are often redundant. In
this paper, we propose to replace all but one attention head of each encoder
layer with fixed -- non-learnable -- attentive patterns that are solely based
on position and do not require any external knowledge. Our experiments show
that fixing the attention heads on the encoder side of the Transformer at
training time does not impact the translation quality and even increases BLEU
scores by up to 3 points in low-resource scenarios.
</summary>
    <author>
      <name>Alessandro Raganato</name>
    </author>
    <author>
      <name>Yves Scherrer</name>
    </author>
    <author>
      <name>Jörg Tiedemann</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10210v1</id>
    <updated>2020-02-24T12:52:10Z</updated>
    <published>2020-02-24T12:52:10Z</published>
    <title>Learning to Select Bi-Aspect Information for Document-Scale Text Content
  Manipulation</title>
    <summary>  In this paper, we focus on a new practical task, document-scale text content
manipulation, which is the opposite of text style transfer and aims to preserve
text styles while altering the content. In detail, the input is a set of
structured records and a reference text for describing another recordset. The
output is a summary that accurately describes the partial content in the source
recordset with the same writing style of the reference. The task is
unsupervised due to lack of parallel data, and is challenging to select
suitable records and style words from bi-aspect inputs respectively and
generate a high-fidelity long document. To tackle those problems, we first
build a dataset based on a basketball game report corpus as our testbed, and
present an unsupervised neural model with interactive attention mechanism,
which is used for learning the semantic relationship between records and
reference texts to achieve better content transfer and better style
preservation. In addition, we also explore the effectiveness of the
back-translation in our task for constructing some pseudo-training pairs.
Empirical results show superiority of our approaches over competitive methods,
and the models also yield a new state-of-the-art result on a sentence-level
dataset.
</summary>
    <author>
      <name>Xiaocheng Feng</name>
    </author>
    <author>
      <name>Yawei Sun</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Heng Gong</name>
    </author>
    <author>
      <name>Yibo Sun</name>
    </author>
    <author>
      <name>Wei Bi</name>
    </author>
    <author>
      <name>Xiaojiang Liu</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by AAAI2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10210v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10210v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10198v2</id>
    <updated>2020-02-25T08:49:11Z</updated>
    <published>2020-02-24T12:26:11Z</published>
    <title>Leveraging Code Generation to Improve Code Retrieval and Summarization
  via Dual Learning</title>
    <summary>  Code summarization generates brief natural language description given a
source code snippet, while code retrieval fetches relevant source code given a
natural language query. Since both tasks aim to model the association between
natural language and programming language, recent studies have combined these
two tasks to improve their performance. However, researchers have yet been able
to effectively leverage the intrinsic connection between the two tasks as they
train these tasks in a separate or pipeline manner, which means their
performance can not be well balanced. In this paper, we propose a novel
end-to-end model for the two tasks by introducing an additional code generation
task. More specifically, we explicitly exploit the probabilistic correlation
between code summarization and code generation with dual learning, and utilize
the two encoders for code summarization and code generation to train the code
retrieval task via multi-task learning. We have carried out extensive
experiments on an existing dataset of SQL and Python, and results show that our
model can significantly improve the results of the code retrieval task over
the-state-of-art models, as well as achieve competitive performance in terms of
BLEU score for the code summarization task.
</summary>
    <author>
      <name>Wei Ye</name>
    </author>
    <author>
      <name>Rui Xie</name>
    </author>
    <author>
      <name>Jinglei Zhang</name>
    </author>
    <author>
      <name>Tianxiang Hu</name>
    </author>
    <author>
      <name>Xiaoyin Wang</name>
    </author>
    <author>
      <name>Shikun Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380295</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380295" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at The Web Conference (WWW) 2020, full paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10198v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10198v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10127v1</id>
    <updated>2020-02-24T09:34:18Z</updated>
    <published>2020-02-24T09:34:18Z</published>
    <title>FONDUE: A Framework for Node Disambiguation Using Network Embeddings</title>
    <summary>  Real-world data often presents itself in the form of a network. Examples
include social networks, citation networks, biological networks, and knowledge
graphs. In their simplest form, networks represent real-life entities (e.g.
people, papers, proteins, concepts) as nodes, and describe them in terms of
their relations with other entities by means of edges between these nodes. This
can be valuable for a range of purposes from the study of information diffusion
to bibliographic analysis, bioinformatics research, and question-answering.
  The quality of networks is often problematic though, affecting downstream
tasks. This paper focuses on the common problem where a node in the network in
fact corresponds to multiple real-life entities. In particular, we introduce
FONDUE, an algorithm based on network embedding for node disambiguation. Given
a network, FONDUE identifies nodes that correspond to multiple entities, for
subsequent splitting. Extensive experiments on twelve benchmark datasets
demonstrate that FONDUE is substantially and uniformly more accurate for
ambiguous node identification compared to the existing state-of-the-art, at a
comparable computational cost, while less optimal for determining the best way
to split ambiguous nodes.
</summary>
    <author>
      <name>Ahmad Mel</name>
    </author>
    <author>
      <name>Bo Kang</name>
    </author>
    <author>
      <name>Jefrey Lijffijt</name>
    </author>
    <author>
      <name>Tijl De Bie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10116v1</id>
    <updated>2020-02-24T08:34:33Z</updated>
    <published>2020-02-24T08:34:33Z</published>
    <title>A Hybrid Approach to Dependency Parsing: Combining Rules and Morphology
  with Deep Learning</title>
    <summary>  Fully data-driven, deep learning-based models are usually designed as
language-independent and have been shown to be successful for many natural
language processing tasks. However, when the studied language is low-resourced
and the amount of training data is insufficient, these models can benefit from
the integration of natural language grammar-based information. We propose two
approaches to dependency parsing especially for languages with restricted
amount of training data. Our first approach combines a state-of-the-art deep
learning-based parser with a rule-based approach and the second one
incorporates morphological information into the parser. In the rule-based
approach, the parsing decisions made by the rules are encoded and concatenated
with the vector representations of the input words as additional information to
the deep network. The morphology-based approach proposes different methods to
include the morphological structure of words into the parser network.
Experiments are conducted on the IMST-UD Treebank and the results suggest that
integration of explicit knowledge about the target language to a neural parser
through a rule-based parsing system and morphological analysis leads to more
accurate annotations and hence, increases the parsing performance in terms of
attachment scores. The proposed methods are developed for Turkish, but can be
adapted to other languages as well.
</summary>
    <author>
      <name>Şaziye Betül Özateş</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering, Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Arzucan Özgür</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering, Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Tunga Güngör</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering, Boğaziçi University</arxiv:affiliation>
    </author>
    <author>
      <name>Balkız Öztürk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Linguistics, Boğaziçi University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10107v1</id>
    <updated>2020-02-24T07:56:02Z</updated>
    <published>2020-02-24T07:56:02Z</published>
    <title>Predicting Subjective Features from Questions on QA Websites using BERT</title>
    <summary>  Modern Question-Answering websites, such as StackOverflow and Quora, have
specific user rules to maintain their content quality. These systems rely on
user reports for accessing new contents, which has serious problems including
the slow handling of violations, the loss of normal and experienced users'
time, the low quality of some reports, and discouraging feedback to new users.
Therefore, with the overall goal of providing solutions for automating
moderation actions in Q&amp;A websites, we aim to provide a model to predict 20
quality or subjective aspects of questions in QA websites. To this end, we used
data gathered by the CrowdSource team at Google Research in 2019 and fine-tuned
pre-trained BERT model on our problem. Model achieves 95.4% accuracy after 2
epochs of training and did not improve substantially in the next ones. Results
confirm that by simple fine-tuning, we can achieve accurate models, in little
time, and on less amount of data.
</summary>
    <author>
      <name>Issa Annamoradnejad</name>
    </author>
    <author>
      <name>Mohammadamin Fazli</name>
    </author>
    <author>
      <name>Jafar Habibi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7; I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10101v1</id>
    <updated>2020-02-24T07:37:17Z</updated>
    <published>2020-02-24T07:37:17Z</published>
    <title>GRET: Global Representation Enhanced Transformer</title>
    <summary>  Transformer, based on the encoder-decoder framework, has achieved
state-of-the-art performance on several natural language generation tasks. The
encoder maps the words in the input sentence into a sequence of hidden states,
which are then fed into the decoder to generate the output sentence. These
hidden states usually correspond to the input words and focus on capturing
local information. However, the global (sentence level) information is seldom
explored, leaving room for the improvement of generation quality. In this
paper, we propose a novel global representation enhanced Transformer (GRET) to
explicitly model global representation in the Transformer network.
Specifically, in the proposed model, an external state is generated for the
global representation from the encoder. The global representation is then fused
into the decoder during the decoding process to improve generation quality. We
conduct experiments in two text generation tasks: machine translation and text
summarization. Experimental results on four WMT machine translation tasks and
LCSTS text summarization task demonstrate the effectiveness of the proposed
approach on natural language generation.
</summary>
    <author>
      <name>Rongxiang Weng</name>
    </author>
    <author>
      <name>Haoran Wei</name>
    </author>
    <author>
      <name>Shujian Huang</name>
    </author>
    <author>
      <name>Heng Yu</name>
    </author>
    <author>
      <name>Lidong Bing</name>
    </author>
    <author>
      <name>Weihua Luo</name>
    </author>
    <author>
      <name>Jiajun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10096v1</id>
    <updated>2020-02-24T07:25:01Z</updated>
    <published>2020-02-24T07:25:01Z</published>
    <title>Emosaic: Visualizing Affective Content of Text at Varying Granularity</title>
    <summary>  This paper presents Emosaic, a tool for visualizing the emotional tone of
text documents, considering multiple dimensions of emotion and varying levels
of semantic granularity. Emosaic is grounded in psychological research on the
relationship between language, affect, and color perception. We capitalize on
an established three-dimensional model of human emotion: valence (good, nice
vs. bad, awful), arousal (calm, passive vs. exciting, active) and dominance
(weak, controlled vs. strong, in control). Previously, multi-dimensional models
of emotion have been used rarely in visualizations of textual data, due to the
perceptual challenges involved. Furthermore, until recently most text
visualizations remained at a high level, precluding closer engagement with the
deep semantic content of the text. Informed by empirical studies, we introduce
a color mapping that translates any point in three-dimensional affective space
into a unique color. Emosaic uses affective dictionaries of words annotated
with the three emotional parameters of the valence-arousal-dominance model to
extract emotional meanings from texts and then assigns to them corresponding
color parameters of the hue-saturation-brightness color space. This approach of
mapping emotion to color is aimed at helping readers to more easily grasp the
emotional tone of the text. Several features of Emosaic allow readers to
interactively explore the affective content of the text in more detail; e.g.,
in aggregated form as histograms, in sequential form following the order of
text, and in detail embedded into the text display itself. Interaction
techniques have been included to allow for filtering and navigating of text and
visualizations.
</summary>
    <author>
      <name>Philipp Geuder</name>
    </author>
    <author>
      <name>Marie Claire Leidinger</name>
    </author>
    <author>
      <name>Martin von Lupin</name>
    </author>
    <author>
      <name>Marian Dörk</name>
    </author>
    <author>
      <name>Tobias Schröder</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10016v1</id>
    <updated>2020-02-23T23:58:04Z</updated>
    <published>2020-02-23T23:58:04Z</published>
    <title>Deep Multimodal Image-Text Embeddings for Automatic Cross-Media
  Retrieval</title>
    <summary>  This paper considers the task of matching images and sentences by learning a
visual-textual embedding space for cross-modal retrieval. Finding such a space
is a challenging task since the features and representations of text and image
are not comparable. In this work, we introduce an end-to-end deep multimodal
convolutional-recurrent network for learning both vision and language
representations simultaneously to infer image-text similarity. The model learns
which pairs are a match (positive) and which ones are a mismatch (negative)
using a hinge-based triplet ranking. To learn about the joint representations,
we leverage our newly extracted collection of tweets from Twitter. The main
characteristic of our dataset is that the images and tweets are not
standardized the same as the benchmarks. Furthermore, there can be a higher
semantic correlation between the pictures and tweets contrary to benchmarks in
which the descriptions are well-organized. Experimental results on MS-COCO
benchmark dataset show that our model outperforms certain methods presented
previously and has competitive performance compared to the state-of-the-art.
The code and dataset have been made available publicly.
</summary>
    <author>
      <name>Hadi Abdi Khojasteh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Ebrahim Ansari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics, Charles University, Czechia</arxiv:affiliation>
    </author>
    <author>
      <name>Parvin Razzaghi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Research in Fundamental Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Akbar Karimi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMP Lab, Department of Engineering and Architecture, University of Parma, Parma, Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages and 2 figures, Learn more about this project at
  https://iasbs.ac.ir/~ansari/deeptwitter</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.0; H.3.3; I.2.0; I.2.6; I.2.7; I.2.10; I.5.0; I.4.0; I.4.10; I.7.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09919v1</id>
    <updated>2020-02-23T15:16:43Z</updated>
    <published>2020-02-23T15:16:43Z</published>
    <title>Do Multi-Hop Question Answering Systems Know How to Answer the
  Single-Hop Sub-Questions?</title>
    <summary>  Multi-hop question answering (QA) requires a model to retrieve and integrate
information from different parts of a long text to answer a question. Humans
answer this kind of complex questions via a divide-and-conquer approach. In
this paper, we investigate whether top-performing models for multi-hop
questions understand the underlying sub-questions like humans. We adopt a
neural decomposition model to generate sub-questions for a multi-hop complex
question, followed by extracting the corresponding sub-answers. We show that
multiple state-of-the-art multi-hop QA models fail to correctly answer a large
portion of sub-questions, although their corresponding multi-hop questions are
correctly answered. This indicates that these models manage to answer the
multi-hop questions using some partial clues, instead of truly understanding
the reasoning paths. We also propose a new model which significantly improves
the performance on answering the sub-questions. Our work takes a step forward
towards building a more explainable multi-hop QA system.
</summary>
    <author>
      <name>Yixuan Tang</name>
    </author>
    <author>
      <name>Hwee Tou Ng</name>
    </author>
    <author>
      <name>Anthony K. H. Tung</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09901v1</id>
    <updated>2020-02-23T13:33:04Z</updated>
    <published>2020-02-23T13:33:04Z</published>
    <title>A Nepali Rule Based Stemmer and its performance on different NLP
  applications</title>
    <summary>  Stemming is an integral part of Natural Language Processing (NLP). It's a
preprocessing step in almost every NLP application. Arguably, the most
important usage of stemming is in Information Retrieval (IR). While there are
lots of work done on stemming in languages like English, Nepali stemming has
only a few works. This study focuses on creating a Rule Based stemmer for
Nepali text. Specifically, it is an affix stripping system that identifies two
different class of suffixes in Nepali grammar and strips them separately. Only
a single negativity prefix (Na) is identified and stripped. This study focuses
on a number of techniques like exception word identification, morphological
normalization and word transformation to increase stemming performance. The
stemmer is tested intrinsically using Paice's method and extrinsically on a
basic tf-idf based IR system and an elementary news topic classifier using
Multinomial Naive Bayes Classifier. The difference in performance of these
systems with and without using the stemmer is analysed.
</summary>
    <author>
      <name>Pravesh Koirala</name>
    </author>
    <author>
      <name>Aman Shakya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 4th International IT Conference on ICT with
  Smart Computing and 9th National Students' Conference on Information
  Technology, (NaSCoIT 2018), Kathmandu, Nepal, ISSN No 2505-1075, pp. 16
  (December 2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.09901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09877v1</id>
    <updated>2020-02-23T09:52:20Z</updated>
    <published>2020-02-23T09:52:20Z</published>
    <title>Automata for Hyperlanguages</title>
    <summary>  Hyperproperties lift conventional trace properties from a set of execution
traces to a set of sets of execution traces. Hyperproperties have been shown to
be a powerful formalism for expressing and reasoning about information-flow
security policies and important properties of cyber-physical systems such as
sensitivity and robustness, as well as consistency conditions in distributed
computing such as linearizability. Although there is an extensive body of work
on automata-based representation of trace properties, we currently lack such
characterization for hyperproperties. We introduce hyperautomata for em
hyperlanguages, which are languages over sets of words. Essentially,
hyperautomata allow running multiple quantified words over an automaton. We
propose a specific type of hyperautomata called nondeterministic finite
hyperautomata (NFH), which accept regular hyperlanguages. We demonstrate the
ability of regular hyperlanguages to express hyperproperties for finite traces.
We then explore the fundamental properties of NFH and show their closure under
the Boolean operations. We show that while nonemptiness is undecidable in
general, it is decidable for several fragments of NFH. We further show the
decidability of the membership problem for finite sets and regular languages
for NFH, as well as the containment problem for several fragments of NFH.
Finally, we introduce learning algorithms based on Angluin's L-star algorithm
for the fragments NFH in which the quantification is either strictly universal
or strictly existential.
</summary>
    <author>
      <name>Borzoo Bonakdarpour</name>
    </author>
    <author>
      <name>Sarai Sheinvald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages of main paper and another 10 pages appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10943v1</id>
    <updated>2020-02-23T07:39:55Z</updated>
    <published>2020-02-23T07:39:55Z</published>
    <title>Data Augmentation for Personal Knowledge Graph Population</title>
    <summary>  A personal knowledge graph comprising people as nodes, their personal data as
node attributes, and their relationships as edges has a number of applications
in de-identification, master data management, and fraud prevention. While
artificial neural networks have led to significant improvements in different
tasks in cold start knowledge graph population, the overall F1 of the system
remains quite low. This problem is more acute in personal knowledge graph
population which presents additional challenges with regard to data protection,
fairness and privacy. In this work, we present a system that uses rule based
annotators to augment training data for neural models, and for slot filling to
increase the diversity of the populated knowledge graph. We also propose a
representative set sampling method to use the populated knowledge graph data
for downstream applications. We introduce new resources and discuss our
results.
</summary>
    <author>
      <name>Lingraj S Vannur</name>
    </author>
    <author>
      <name>Lokesh Nagalapatti</name>
    </author>
    <author>
      <name>Balaji Ganesan</name>
    </author>
    <author>
      <name>Hima Patel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures, under review. arXiv admin note: substantial text
  overlap with arXiv:2001.08013</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09836v1</id>
    <updated>2020-02-23T06:21:43Z</updated>
    <published>2020-02-23T06:21:43Z</published>
    <title>Fill in the BLANC: Human-free quality estimation of document summaries</title>
    <summary>  We present BLANC, a new approach to the automatic estimation of document
summary quality. Our goal is to measure the functional performance of a summary
with an objective, reproducible, and fully automated method. Our approach
achieves this by measuring the performance boost gained by a pre-trained
language model with access to a document summary while carrying out its
language understanding task on the document's text. We present evidence that
BLANC scores have at least as good correlation with human evaluations as do the
ROUGE family of summary quality measurements. And unlike ROUGE, the BLANC
method does not require human-written reference summaries, allowing for fully
human-free summary quality estimation.
</summary>
    <author>
      <name>Oleg Vasilyev</name>
    </author>
    <author>
      <name>Vedant Dharnidharka</name>
    </author>
    <author>
      <name>John Bohannon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09812v1</id>
    <updated>2020-02-23T03:07:31Z</updated>
    <published>2020-02-23T03:07:31Z</published>
    <title>Sketching Transformed Matrices with Applications to Natural Language
  Processing</title>
    <summary>  Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in
memory but is in a disk or is presented in a data stream. However, we need to
compute a matrix decomposition of the entry-wisely transformed matrix,
$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space
efficient way? Many machine learning applications indeed need to deal with such
large transformed matrices, for example word embedding method in NLP needs to
work with the pointwise mutual information (PMI) matrix, while the entrywise
transformation makes it difficult to apply known linear algebraic tools.
Existing approaches for this problem either need to store the whole matrix and
perform the entry-wise transformation afterwards, which is space consuming or
infeasible, or need to redesign the learning method, which is application
specific and requires substantial remodeling.
  In this paper, we first propose a space-efficient sketching algorithm for
computing the product of a given small matrix with the transformed matrix. It
works for a general family of transformations with provable small error bounds
and thus can be used as a primitive in downstream learning tasks. We then apply
this primitive to a concrete application: low-rank approximation. We show that
our approach obtains small error and is efficient in both space and time. We
complement our theoretical results with experiments on synthetic and real data.
</summary>
    <author>
      <name>Yingyu Liang</name>
    </author>
    <author>
      <name>Zhao Song</name>
    </author>
    <author>
      <name>Mengdi Wang</name>
    </author>
    <author>
      <name>Lin F. Yang</name>
    </author>
    <author>
      <name>Xin Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AISTATS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09758v1</id>
    <updated>2020-02-22T19:40:35Z</updated>
    <published>2020-02-22T19:40:35Z</published>
    <title>Unsupervised Question Decomposition for Question Answering</title>
    <summary>  We aim to improve question answering (QA) by decomposing hard questions into
easier sub-questions that existing QA systems can answer. Since collecting
labeled decompositions is cumbersome, we propose an unsupervised approach to
produce sub-questions. Specifically, by leveraging &gt;10M questions from Common
Crawl, we learn to map from the distribution of multi-hop questions to the
distribution of single-hop sub-questions. We answer sub-questions with an
off-the-shelf QA model and incorporate the resulting answers in a downstream,
multi-hop QA system. On a popular multi-hop QA dataset, HotpotQA, we show large
improvements over a strong baseline, especially on adversarial and
out-of-domain questions. Our method is generally applicable and automatically
learns to decompose questions of different classes, while matching the
performance of decomposition methods that rely heavily on hand-engineering and
annotation.
</summary>
    <author>
      <name>Ethan Perez</name>
    </author>
    <author>
      <name>Patrick Lewis</name>
    </author>
    <author>
      <name>Wen-tau Yih</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09685v1</id>
    <updated>2020-02-22T11:17:16Z</updated>
    <published>2020-02-22T11:17:16Z</published>
    <title>Exploiting Typed Syntactic Dependencies for Targeted Sentiment
  Classification Using Graph Attention Neural Network</title>
    <summary>  Targeted sentiment classification predicts the sentiment polarity on given
target mentions in input texts. Dominant methods employ neural networks for
encoding the input sentence and extracting relations between target mentions
and their contexts. Recently, graph neural network has been investigated for
integrating dependency syntax for the task, achieving the state-of-the-art
results. However, existing methods do not consider dependency label
information, which can be intuitively useful. To solve the problem, we
investigate a novel relational graph attention network that integrates typed
syntactic dependency information. Results on standard benchmarks show that our
method can effectively leverage label information for improving targeted
sentiment classification performances. Our final model significantly
outperforms state-of-the-art syntax-based approaches.
</summary>
    <author>
      <name>Xuefeng Bai</name>
    </author>
    <author>
      <name>Pengbo Liu</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09673v1</id>
    <updated>2020-02-22T10:06:37Z</updated>
    <published>2020-02-22T10:06:37Z</published>
    <title>Incorporating Effective Global Information via Adaptive Gate Attention
  for Text Classification</title>
    <summary>  The dominant text classification studies focus on training classifiers using
textual instances only or introducing external knowledge (e.g., hand-craft
features and domain expert knowledge). In contrast, some corpus-level
statistical features, like word frequency and distribution, are not well
exploited. Our work shows that such simple statistical information can enhance
classification performance both efficiently and significantly compared with
several baseline models. In this paper, we propose a classifier with gate
mechanism named Adaptive Gate Attention model with Global Information (AGA+GI),
in which the adaptive gate mechanism incorporates global statistical features
into latent semantic features and the attention layer captures dependency
relationship within the sentence. To alleviate the overfitting issue, we
propose a novel Leaky Dropout mechanism to improve generalization ability and
performance stability. Our experiments show that the proposed method can
achieve better accuracy than CNN-based and RNN-based approaches without global
information on several benchmarks.
</summary>
    <author>
      <name>Xianming Li</name>
    </author>
    <author>
      <name>Zongxi Li</name>
    </author>
    <author>
      <name>Yingbin Zhao</name>
    </author>
    <author>
      <name>Haoran Xie</name>
    </author>
    <author>
      <name>Qing Li</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09646v1</id>
    <updated>2020-02-22T06:54:04Z</updated>
    <published>2020-02-22T06:54:04Z</published>
    <title>Machine Translation System Selection from Bandit Feedback</title>
    <summary>  Adapting machine translation systems in the real world is a difficult
problem. In contrast to offline training, users cannot provide the type of
fine-grained feedback typically used for improving the system. Moreover, users
have different translation needs, and even a single user's needs may change
over time.
  In this work we take a different approach, treating the problem of adapting
as one of selection. Instead of adapting a single system, we train many
translation systems using different architectures and data partitions. Using
bandit learning techniques on simulated user feedback, we learn a policy to
choose which system to use for a particular translation task. We show that our
approach can (1) quickly adapt to address domain changes in translation tasks,
(2) outperform the single best system in mixed-domain translation tasks, and
(3) make effective instance-specific decisions when using contextual bandit
strategies.
</summary>
    <author>
      <name>Jason Naradowsky</name>
    </author>
    <author>
      <name>Xuan Zhang</name>
    </author>
    <author>
      <name>Kevin Duh</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09637v1</id>
    <updated>2020-02-22T06:01:52Z</updated>
    <published>2020-02-22T06:01:52Z</published>
    <title>Markov Chain Monte-Carlo Phylogenetic Inference Construction in
  Computational Historical Linguistics</title>
    <summary>  More and more languages in the world are under study nowadays, as a result,
the traditional way of historical linguistics study is facing some challenges.
For example, the linguistic comparative research among languages needs manual
annotation, which becomes more and more impossible with the increasing amount
of language data coming out all around the world. Although it could hardly
replace linguists work, the automatic computational methods have been taken
into consideration and it can help people reduce their workload. One of the
most important work in historical linguistics is word comparison from different
languages and find the cognate words for them, which means people try to figure
out if the two languages are related to each other or not. In this paper, I am
going to use computational method to cluster the languages and use Markov Chain
Monte Carlo (MCMC) method to build the language typology relationship tree
based on the clusters.
</summary>
    <author>
      <name>Tianyi Ni</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09634v1</id>
    <updated>2020-02-22T05:40:32Z</updated>
    <published>2020-02-22T05:40:32Z</published>
    <title>Data Augmentation for Copy-Mechanism in Dialogue State Tracking</title>
    <summary>  While several state-of-the-art approaches to dialogue state tracking (DST)
have shown promising performances on several benchmarks, there is still a
significant performance gap between seen slot values (i.e., values that occur
in both training set and test set) and unseen ones (values that occur in
training set but not in test set). Recently, the copy-mechanism has been widely
used in DST models to handle unseen slot values, which copies slot values from
user utterance directly. In this paper, we aim to find out the factors that
influence the generalization ability of a common copy-mechanism model for DST.
Our key observations include: 1) the copy-mechanism tends to memorize values
rather than infer them from contexts, which is the primary reason for
unsatisfactory generalization performance; 2) greater diversity of slot values
in the training set increase the performance on unseen values but slightly
decrease the performance on seen values. Moreover, we propose a simple but
effective algorithm of data augmentation to train copy-mechanism models, which
augments the input dataset by copying user utterances and replacing the real
slot values with randomly generated strings. Users could use two
hyper-parameters to realize a trade-off between the performances on seen values
and unseen ones, as well as a trade-off between overall performance and
computational cost. Experimental results on three widely used datasets (WoZ
2.0, DSTC2, and Multi-WoZ 2.0) show the effectiveness of our approach.
</summary>
    <author>
      <name>Xiaohui Song</name>
    </author>
    <author>
      <name>Liangjun Zang</name>
    </author>
    <author>
      <name>Yipeng Su</name>
    </author>
    <author>
      <name>Xing Wu</name>
    </author>
    <author>
      <name>Jizhong Han</name>
    </author>
    <author>
      <name>Songlin Hu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09620v2</id>
    <updated>2020-03-04T04:49:45Z</updated>
    <published>2020-02-22T04:12:37Z</published>
    <title>Efficient Sentence Embedding via Semantic Subspace Analysis</title>
    <summary>  A novel sentence embedding method built upon semantic subspace analysis,
called semantic subspace sentence embedding (S3E), is proposed in this work.
Given the fact that word embeddings can capture semantic relationship while
semantically similar words tend to form semantic groups in a high-dimensional
embedding space, we develop a sentence representation scheme by analyzing
semantic subspaces of its constituent words. Specifically, we construct a
sentence model from two aspects. First, we represent words that lie in the same
semantic group using the intra-group descriptor. Second, we characterize the
interaction between multiple semantic groups with the inter-group descriptor.
The proposed S3E method is evaluated on both textual similarity tasks and
supervised tasks. Experimental results show that it offers comparable or better
performance than the state-of-the-art. The complexity of our S3E method is also
much lower than other parameterized models.
</summary>
    <author>
      <name>Bin Wang</name>
    </author>
    <author>
      <name>Fenxiao Chen</name>
    </author>
    <author>
      <name>Yuncheng Wang</name>
    </author>
    <author>
      <name>C. -C. Jay Kuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09620v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09620v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09616v1</id>
    <updated>2020-02-22T04:05:41Z</updated>
    <published>2020-02-22T04:05:41Z</published>
    <title>"Wait, I'm Still Talking!" Predicting the Dialogue Interaction Behavior
  Using Imagine-Then-Arbitrate Model</title>
    <summary>  Producing natural and accurate responses like human beings is the ultimate
goal of intelligent dialogue agents. So far, most of the past works concentrate
on selecting or generating one pertinent and fluent response according to
current query and its context. These models work on a one-to-one environment,
making one response to one utterance each round. However, in real human-human
conversations, human often sequentially sends several short messages for
readability instead of a long message in one turn. Thus messages will not end
with an explicit ending signal, which is crucial for agents to decide when to
reply. So the first step for an intelligent dialogue agent is not replying but
deciding if it should reply at the moment. To address this issue, in this
paper, we propose a novel Imagine-then-Arbitrate (ITA) neural dialogue model to
help the agent decide whether to wait or to make a response directly. Our
method has two imaginator modules and an arbitrator module. The two imaginators
will learn the agent's and user's speaking style respectively, generate
possible utterances as the input of the arbitrator, combining with dialogue
history. And the arbitrator decides whether to wait or to make a response to
the user directly. To verify the performance and effectiveness of our method,
we prepared two dialogue datasets and compared our approach with several
popular models. Experimental results show that our model performs well on
addressing ending prediction issue and outperforms baseline models.
</summary>
    <author>
      <name>Zehao Lin</name>
    </author>
    <author>
      <name>Xiaoming Kang</name>
    </author>
    <author>
      <name>Guodun Li</name>
    </author>
    <author>
      <name>Feng Ji</name>
    </author>
    <author>
      <name>Haiqing Chen</name>
    </author>
    <author>
      <name>Yin Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09604v1</id>
    <updated>2020-02-22T02:34:51Z</updated>
    <published>2020-02-22T02:34:51Z</published>
    <title>Emergent Communication with World Models</title>
    <summary>  We introduce Language World Models, a class of language-conditional
generative model which interpret natural language messages by predicting latent
codes of future observations. This provides a visual grounding of the message,
similar to an enhanced observation of the world, which may include objects
outside of the listening agent's field-of-view. We incorporate this
"observation" into a persistent memory state, and allow the listening agent's
policy to condition on it, akin to the relationship between memory and
controller in a World Model. We show this improves effective communication and
task success in 2D gridworld speaker-listener navigation tasks. In addition, we
develop two losses framed specifically for our model-based formulation to
promote positive signalling and positive listening. Finally, because messages
are interpreted in a generative model, we can visualize the model beliefs to
gain insight into how the communication channel is utilized.
</summary>
    <author>
      <name>Alexander I. Cowen-Rivers</name>
    </author>
    <author>
      <name>Jason Naradowsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS Workshop on Emergent Communication</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09599v1</id>
    <updated>2020-02-22T01:49:27Z</updated>
    <published>2020-02-22T01:49:27Z</published>
    <title>Training Question Answering Models From Synthetic Data</title>
    <summary>  Question and answer generation is a data augmentation method that aims to
improve question answering (QA) models given the limited amount of human
labeled data. However, a considerable gap remains between synthetic and
human-generated question-answer pairs. This work aims to narrow this gap by
taking advantage of large language models and explores several factors such as
model size, quality of pretrained models, scale of data synthesized, and
algorithmic choices. On the SQuAD1.1 question answering task, we achieve higher
accuracy using solely synthetic questions and answers than when using the
SQuAD1.1 training set questions alone. Removing access to real Wikipedia data,
we synthesize questions and answers from a synthetic corpus generated by an 8.3
billion parameter GPT-2 model. With no access to human supervision and only
access to other models, we are able to train state of the art question
answering networks on entirely model-generated data that achieve 88.4 Exact
Match (EM) and 93.9 F1 score on the SQuAD1.1 dev set. We further apply our
methodology to SQuAD2.0 and show a 2.8 absolute gain on EM score compared to
prior work using synthetic data.
</summary>
    <author>
      <name>Raul Puri</name>
    </author>
    <author>
      <name>Ryan Spring</name>
    </author>
    <author>
      <name>Mostofa Patwary</name>
    </author>
    <author>
      <name>Mohammad Shoeybi</name>
    </author>
    <author>
      <name>Bryan Catanzaro</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09581v1</id>
    <updated>2020-02-22T00:35:26Z</updated>
    <published>2020-02-22T00:35:26Z</published>
    <title>Extracting and Validating Explanatory Word Archipelagoes using Dual
  Entropy</title>
    <summary>  The logical connectivity of text is represented by the connectivity of words
that form archipelagoes. Here, each archipelago is a sequence of islands of the
occurrences of a certain word. An island here means the local sequence of
sentences where the word is emphasized, and an archipelago of a length
comparable to the target text is extracted using the co-variation of entropy A
(the window-based entropy) on the distribution of the word's occurrences with
the width of each time window. Then, the logical connectivity of text is
evaluated on entropy B (the graph-based entropy) computed on the distribution
of sentences to connected word-clusters obtained on the co-occurrence of words.
The results show the parts of the target text with words forming archipelagoes
extracted on entropy A, without learned or prepared knowledge, form an
explanatory part of the text that is of smaller entropy B than the parts
extracted by the baseline methods.
</summary>
    <author>
      <name>Yukio Ohsawa</name>
    </author>
    <author>
      <name>Teruaki Hayashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 2 columns</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W32 (Primary) 68T50, 91F20 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09543v1</id>
    <updated>2020-02-21T20:39:09Z</updated>
    <published>2020-02-21T20:39:09Z</published>
    <title>Modelling Latent Skills for Multitask Language Generation</title>
    <summary>  We present a generative model for multitask conditional language generation.
Our guiding hypothesis is that a shared set of latent skills underlies many
disparate language generation tasks, and that explicitly modelling these skills
in a task embedding space can help with both positive transfer across tasks and
with efficient adaptation to new tasks. We instantiate this task embedding
space as a latent variable in a latent variable sequence-to-sequence model. We
evaluate this hypothesis by curating a series of monolingual text-to-text
language generation datasets - covering a broad range of tasks and domains -
and comparing the performance of models both in the multitask and few-shot
regimes. We show that our latent task variable model outperforms other
sequence-to-sequence baselines on average across tasks in the multitask
setting. In the few-shot learning setting on an unseen test dataset (i.e., a
new task), we demonstrate that model adaptation based on inference in the
latent task space is more robust than standard fine-tuning based parameter
adaptation and performs comparably in terms of overall performance. Finally, we
examine the latent task representations learnt by our model and show that they
cluster tasks in a natural way.
</summary>
    <author>
      <name>Kris Cao</name>
    </author>
    <author>
      <name>Dani Yogatama</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09419v2</id>
    <updated>2020-02-26T07:30:23Z</updated>
    <published>2020-02-21T17:09:19Z</published>
    <title>Guider l'attention dans les modeles de sequence a sequence pour la
  prediction des actes de dialogue</title>
    <summary>  The task of predicting dialog acts (DA) based on conversational dialog is a
key component in the development of conversational agents. Accurately
predicting DAs requires a precise modeling of both the conversation and the
global tag dependencies. We leverage seq2seq approaches widely adopted in
Neural Machine Translation (NMT) to improve the modelling of tag sequentiality.
Seq2seq models are known to learn complex global dependencies while currently
proposed approaches using linear conditional random fields (CRF) only model
local tag dependencies. In this work, we introduce a seq2seq model tailored for
DA classification using: a hierarchical encoder, a novel guided attention
mechanism and beam search applied to both training and inference. Compared to
the state of the art our model does not require handcrafted features and is
trained end-to-end. Furthermore, the proposed approach achieves an unmatched
accuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on
MRDA.
</summary>
    <author>
      <name>Pierre Colombo</name>
    </author>
    <author>
      <name>Emile Chapuis</name>
    </author>
    <author>
      <name>Matteo Manica</name>
    </author>
    <author>
      <name>Emmanuel Vignon</name>
    </author>
    <author>
      <name>Giovanna Varni</name>
    </author>
    <author>
      <name>Chloe Clavel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WACAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.09419v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09419v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09402v2</id>
    <updated>2020-03-09T09:21:14Z</updated>
    <published>2020-02-21T16:37:57Z</published>
    <title>Accessing Higher-level Representations in Sequential Transformers with
  Feedback Memory</title>
    <summary>  Transformers are feedforward networks that can process input tokens in
parallel. While this parallelization makes them computationally efficient, it
restricts the model from fully exploiting the sequential nature of the input -
the representation at a given layer can only access representations from lower
layers, rather than the higher level representations already built in previous
time steps. In this work, we propose the Feedback Transformer architecture that
exposes all previous representations to all future representations, meaning the
lowest representation of the current timestep is formed from the highest-level
abstract representation of the past. We demonstrate on a variety of benchmarks
in language modeling, neural machine translation, summarization, and
reinforcement learning that the increased representation capacity can improve
over Transformer baselines.
</summary>
    <author>
      <name>Angela Fan</name>
    </author>
    <author>
      <name>Thibaut Lavril</name>
    </author>
    <author>
      <name>Edouard Grave</name>
    </author>
    <author>
      <name>Armand Joulin</name>
    </author>
    <author>
      <name>Sainbayar Sukhbaatar</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09402v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09402v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09361v1</id>
    <updated>2020-02-21T15:33:53Z</updated>
    <published>2020-02-21T15:33:53Z</published>
    <title>Crowdsourced Collective Entity Resolution with Relational Match
  Propagation</title>
    <summary>  Knowledge bases (KBs) store rich yet heterogeneous entities and facts. Entity
resolution (ER) aims to identify entities in KBs which refer to the same
real-world object. Recent studies have shown significant benefits of involving
humans in the loop of ER. They often resolve entities with pairwise similarity
measures over attribute values and resort to the crowds to label uncertain
ones. However, existing methods still suffer from high labor costs and
insufficient labeling to some extent. In this paper, we propose a novel
approach called crowdsourced collective ER, which leverages the relationships
between entities to infer matches jointly rather than independently.
Specifically, it iteratively asks human workers to label picked entity pairs
and propagates the labeling information to their neighbors in distance. During
this process, we address the problems of candidate entity pruning,
probabilistic propagation, optimal question selection and error-tolerant truth
inference. Our experiments on real-world datasets demonstrate that, compared
with state-of-the-art methods, our approach achieves superior accuracy with
much less labeling.
</summary>
    <author>
      <name>Jiacheng Huang</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <author>
      <name>Zhifeng Bao</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 36th IEEE International Conference on Data
  Engineering (ICDE 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09253v1</id>
    <updated>2020-02-21T12:59:57Z</updated>
    <published>2020-02-21T12:59:57Z</published>
    <title>Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration</title>
    <summary>  Autonomous reinforcement learning agents must be intrinsically motivated to
explore their environment, discover potential goals, represent them and learn
how to achieve them. As children do the same, they benefit from exposure to
language, using it to formulate goals and imagine new ones as they learn their
meaning. In our proposed learning architecture (IMAGINE), the agent freely
explores its environment and turns natural language descriptions of interesting
interactions from a social partner into potential goals. IMAGINE learns to
represent goals by jointly learning a language model and a goal-conditioned
reward function. Just like humans, our agent uses language compositionality to
generate new goals by composing known ones. Leveraging modular model
architectures based on Deep Sets and gated-attention mechanisms, IMAGINE
autonomously builds a repertoire of behaviors and shows good zero-shot
generalization properties for various types of generalization. When imagining
its own goals, the agent leverages zero-shot generalization of the reward
function to further train on imagined goals and refine its behavior. We present
experiments in a simulated domain where the agent interacts with procedurally
generated scenes containing objects of various types and colors, discovers
goals, imagines others and learns to achieve them.
</summary>
    <author>
      <name>Cédric Colas</name>
    </author>
    <author>
      <name>Tristan Karch</name>
    </author>
    <author>
      <name>Nicolas Lair</name>
    </author>
    <author>
      <name>Jean-Michel Dussoux</name>
    </author>
    <author>
      <name>Clément Moulin-Frier</name>
    </author>
    <author>
      <name>Peter Ford Dominey</name>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contains main article and supplementaries</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09253v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09253v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09247v1</id>
    <updated>2020-02-21T12:37:12Z</updated>
    <published>2020-02-21T12:37:12Z</published>
    <title>Is Aligning Embedding Spaces a Challenging Task? An Analysis of the
  Existing Methods</title>
    <summary>  Representation Learning of words and Knowledge Graphs (KG) into low
dimensional vector spaces along with its applications to many real-world
scenarios have recently gained momentum. In order to make use of multiple KG
embeddings for knowledge-driven applications such as question answering, named
entity disambiguation, knowledge graph completion, etc., alignment of different
KG embedding spaces is necessary. In addition to multilinguality and
domain-specific information, different KGs pose the problem of structural
differences making the alignment of the KG embeddings more challenging. This
paper provides a theoretical analysis and comparison of the state-of-the-art
alignment methods between two embedding spaces representing entity-entity and
entity-word. This paper also aims at assessing the capability and short-comings
of the existing alignment methods on the pretext of different applications.
</summary>
    <author>
      <name>Russa Biswas</name>
    </author>
    <author>
      <name>Mehwish Alam</name>
    </author>
    <author>
      <name>Harald Sack</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09213v1</id>
    <updated>2020-02-21T10:39:53Z</updated>
    <published>2020-02-21T10:39:53Z</published>
    <title>Refinement of Unsupervised Cross-Lingual Word Embeddings</title>
    <summary>  Cross-lingual word embeddings aim to bridge the gap between high-resource and
low-resource languages by allowing to learn multilingual word representations
even without using any direct bilingual signal. The lion's share of the methods
are projection-based approaches that map pre-trained embeddings into a shared
latent space. These methods are mostly based on the orthogonal transformation,
which assumes language vector spaces to be isomorphic. However, this criterion
does not necessarily hold, especially for morphologically-rich languages. In
this paper, we propose a self-supervised method to refine the alignment of
unsupervised bilingual word embeddings. The proposed model moves vectors of
words and their corresponding translations closer to each other as well as
enforces length- and center-invariance, thus allowing to better align
cross-lingual embeddings. The experimental results demonstrate the
effectiveness of our approach, as in most cases it outperforms state-of-the-art
methods in a bilingual lexicon induction task.
</summary>
    <author>
      <name>Magdalena Biesialska</name>
    </author>
    <author>
      <name>Marta R. Costa-jussà</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 24th European Conference on Artificial Intelligence
  (ECAI 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09213v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09213v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10266v1</id>
    <updated>2020-02-21T09:36:24Z</updated>
    <published>2020-02-21T09:36:24Z</published>
    <title>Rhythm, Chord and Melody Generation for Lead Sheets using Recurrent
  Neural Networks</title>
    <summary>  Music that is generated by recurrent neural networks often lacks a sense of
direction and coherence. We therefore propose a two-stage LSTM-based model for
lead sheet generation, in which the harmonic and rhythmic templates of the song
are produced first, after which, in a second stage, a sequence of melody notes
is generated conditioned on these templates. A subjective listening test shows
that our approach outperforms the baselines and increases perceived musical
coherence.
</summary>
    <author>
      <name>Cedric De Boom</name>
    </author>
    <author>
      <name>Stephanie Van Laere</name>
    </author>
    <author>
      <name>Tim Verbelen</name>
    </author>
    <author>
      <name>Bart Dhoedt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, 3 tables, 2 appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01043v1</id>
    <updated>2020-02-21T06:58:03Z</updated>
    <published>2020-02-21T06:58:03Z</published>
    <title>Gated Mechanism for Attention Based Multimodal Sentiment Analysis</title>
    <summary>  Multimodal sentiment analysis has recently gained popularity because of its
relevance to social media posts, customer service calls and video blogs. In
this paper, we address three aspects of multimodal sentiment analysis; 1. Cross
modal interaction learning, i.e. how multiple modalities contribute to the
sentiment, 2. Learning long-term dependencies in multimodal interactions and 3.
Fusion of unimodal and cross modal cues. Out of these three, we find that
learning cross modal interactions is beneficial for this problem. We perform
experiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment
Intensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity
(CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9%
and 81.1% respectively, which is 1.6% and 1.34% absolute improvement over
current state-of-the-art.
</summary>
    <author>
      <name>Ayush Kumar</name>
    </author>
    <author>
      <name>Jithendra Vepa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to appear in ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09127v1</id>
    <updated>2020-02-21T04:38:37Z</updated>
    <published>2020-02-21T04:38:37Z</published>
    <title>Learning Dynamic Knowledge Graphs to Generalize on Text-Based Games</title>
    <summary>  Playing text-based games requires skill in processing natural language and in
planning. Although a key goal for agents solving this task is to generalize
across multiple games, most previous work has either focused on solving a
single game or has tackled generalization with rule-based heuristics. In this
work, we investigate how structured information in the form of a knowledge
graph (KG) can facilitate effective planning and generalization. We introduce a
novel transformer-based sequence-to-sequence model that constructs a "belief"
KG from raw text observations of the environment, dynamically updating this
belief graph at every game step as it receives new observations. To train this
model to build useful graph representations, we introduce and analyze a set of
graph-related pre-training tasks. We demonstrate empirically that KG-based
representations from our model help agents to converge faster to better
policies for multiple text-based games, and further, enable stronger zero-shot
performance on unseen games. Experiments on unseen games show that our best
agent outperforms text-based baselines by 21.6%.
</summary>
    <author>
      <name>Ashutosh Adhikari</name>
    </author>
    <author>
      <name>Xingdi Yuan</name>
    </author>
    <author>
      <name>Marc-Alexandre Côté</name>
    </author>
    <author>
      <name>Mikuláš Zelinka</name>
    </author>
    <author>
      <name>Marc-Antoine Rondeau</name>
    </author>
    <author>
      <name>Romain Laroche</name>
    </author>
    <author>
      <name>Pascal Poupart</name>
    </author>
    <author>
      <name>Jian Tang</name>
    </author>
    <author>
      <name>Adam Trischler</name>
    </author>
    <author>
      <name>William L. Hamilton</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09084v1</id>
    <updated>2020-02-21T01:47:09Z</updated>
    <published>2020-02-21T01:47:09Z</published>
    <title>On the impressive performance of randomly weighted encoders in
  summarization tasks</title>
    <summary>  In this work, we investigate the performance of untrained randomly
initialized encoders in a general class of sequence to sequence models and
compare their performance with that of fully-trained encoders on the task of
abstractive summarization. We hypothesize that random projections of an input
text have enough representational power to encode the hierarchical structure of
sentences and semantics of documents. Using a trained decoder to produce
abstractive text summaries, we empirically demonstrate that architectures with
untrained randomly initialized encoders perform competitively with respect to
the equivalent architectures with fully-trained encoders. We further find that
the capacity of the encoder not only improves overall model generalization but
also closes the performance gap between untrained randomly initialized and
full-trained encoders. To our knowledge, it is the first time that general
sequence to sequence models with attention are assessed for trained and
randomly projected representations on abstractive summarization.
</summary>
    <author>
      <name>Jonathan Pilault</name>
    </author>
    <author>
      <name>Jaehong Park</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019 SRW. First two authors contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08933v1</id>
    <updated>2020-02-20T18:30:36Z</updated>
    <published>2020-02-20T18:30:36Z</published>
    <title>Wavesplit: End-to-End Speech Separation by Speaker Clustering</title>
    <summary>  We introduce Wavesplit, an end-to-end speech separation system. From a single
recording of mixed speech, the model infers and clusters representations of
each speaker and then estimates each source signal conditioned on the inferred
representations. The model is trained on the raw waveform to jointly perform
the two tasks. Our model infers a set of speaker representations through
clustering, which addresses the fundamental permutation problem of speech
separation. Moreover, the sequence-wide speaker representations provide a more
robust separation of long, challenging sequences, compared to previous
approaches. We show that Wavesplit outperforms the previous state-of-the-art on
clean mixtures of 2 or 3 speakers (WSJ0-2mix, WSJ0-3mix), as well as in noisy
(WHAM!) and reverberated (WHAMR!) conditions. As an additional contribution, we
further improve our model by introducing online data augmentation for
separation.
</summary>
    <author>
      <name>Neil Zeghidour</name>
    </author>
    <author>
      <name>David Grangier</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08926v1</id>
    <updated>2020-02-20T18:21:30Z</updated>
    <published>2020-02-20T18:21:30Z</published>
    <title>Imputer: Sequence Modelling via Imputation and Dynamic Programming</title>
    <summary>  This paper presents the Imputer, a neural sequence model that generates
output sequences iteratively via imputations. The Imputer is an iterative
generative model, requiring only a constant number of generation steps
independent of the number of input or output tokens. The Imputer can be trained
to approximately marginalize over all possible alignments between the input and
output sequences, and all possible generation orders. We present a tractable
dynamic programming training algorithm, which yields a lower bound on the log
marginal likelihood. When applied to end-to-end speech recognition, the Imputer
outperforms prior non-autoregressive models and achieves competitive results to
autoregressive models. On LibriSpeech test-other, the Imputer achieves 11.1
WER, outperforming CTC at 13.0 WER and seq2seq at 12.5 WER.
</summary>
    <author>
      <name>William Chan</name>
    </author>
    <author>
      <name>Chitwan Saharia</name>
    </author>
    <author>
      <name>Geoffrey Hinton</name>
    </author>
    <author>
      <name>Mohammad Norouzi</name>
    </author>
    <author>
      <name>Navdeep Jaitly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08911v1</id>
    <updated>2020-02-20T17:54:46Z</updated>
    <published>2020-02-20T17:54:46Z</published>
    <title>Measuring Social Biases in Grounded Vision and Language Embeddings</title>
    <summary>  We generalize the notion of social biases from language embeddings to
grounded vision and language embeddings. Biases are present in grounded
embeddings, and indeed seem to be equally or more significant than for
ungrounded embeddings. This is despite the fact that vision and language can
suffer from different biases, which one might hope could attenuate the biases
in both. Multiple ways exist to generalize metrics measuring bias in word
embeddings to this new setting. We introduce the space of generalizations
(Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations
answer different yet important questions about how biases, language, and vision
interact. These metrics are used on a new dataset, the first for grounded bias,
created by augmenting extending standard linguistic bias benchmarks with 10,228
images from COCO, Conceptual Captions, and Google Images. Dataset construction
is challenging because vision datasets are themselves very biased. The presence
of these biases in systems will begin to have real-world consequences as they
are deployed, making carefully measuring bias and then mitigating it critical
to building a fair society.
</summary>
    <author>
      <name>Candace Ross</name>
    </author>
    <author>
      <name>Boris Katz</name>
    </author>
    <author>
      <name>Andrei Barbu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08880v1</id>
    <updated>2020-02-20T17:31:04Z</updated>
    <published>2020-02-20T17:31:04Z</published>
    <title>The Fluidity of Concept Representations in Human Brain Signals</title>
    <summary>  Cognitive theories of human language processing often distinguish between
concrete and abstract concepts. In this work, we analyze the discriminability
of concrete and abstract concepts in fMRI data using a range of analysis
methods. We find that the distinction can be decoded from the signal with an
accuracy significantly above chance, but it is not found to be a relevant
structuring factor in clustering and relational analyses. From our detailed
comparison, we obtain the impression that human concept representations are
more fluid than dichotomous categories can capture. We argue that fluid concept
representations lead to more realistic models of human language processing
because they better capture the ambiguity and underspecification present in
natural language use.
</summary>
    <author>
      <name>Eva Hendrikx</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Amsterdam</arxiv:affiliation>
    </author>
    <author>
      <name>Lisa Beinborn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Amsterdam</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08878v1</id>
    <updated>2020-02-20T17:26:46Z</updated>
    <published>2020-02-20T17:26:46Z</published>
    <title>Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges</title>
    <summary>  Computational models of emergent communication in agent populations are
currently gaining interest in the machine learning community due to recent
advances in Multi-Agent Reinforcement Learning (MARL). Current contributions
are however still relatively disconnected from the earlier theoretical and
computational literature aiming at understanding how language might have
emerged from a prelinguistic substance. The goal of this paper is to position
recent MARL contributions within the historical context of language evolution
research, as well as to extract from this theoretical and computational
background a few challenges for future research.
</summary>
    <author>
      <name>Clément Moulin-Frier</name>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Challenges and Opportunities for Multi-Agent Reinforcement
  Learning (COMARL AAAI 2020), AAAI Spring Symposium Series, Stanford
  University, Palo Alto, California, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.08878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08866v1</id>
    <updated>2020-02-20T17:06:27Z</updated>
    <published>2020-02-20T17:06:27Z</published>
    <title>Contextual Lensing of Universal Sentence Representations</title>
    <summary>  What makes a universal sentence encoder universal? The notion of a generic
encoder of text appears to be at odds with the inherent contextualization and
non-permanence of language use in a dynamic world. However, mapping sentences
into generic fixed-length vectors for downstream similarity and retrieval tasks
has been fruitful, particularly for multilingual applications. How do we manage
this dilemma? In this work we propose Contextual Lensing, a methodology for
inducing context-oriented universal sentence vectors. We break the construction
of universal sentence vectors into a core, variable length, sentence matrix
representation equipped with an adaptable `lens' from which fixed-length
vectors can be induced as a function of the lens context. We show that it is
possible to focus notions of language similarity into a small number of lens
parameters given a core universal matrix representation. For example, we
demonstrate the ability to encode translation similarity of sentences across
several languages into a single weight matrix, even when the core encoder has
not seen parallel data.
</summary>
    <author>
      <name>Jamie Kiros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08801v2</id>
    <updated>2020-02-26T07:25:05Z</updated>
    <published>2020-02-20T15:25:20Z</published>
    <title>Guiding attention in Sequence-to-sequence models for Dialogue Act
  prediction</title>
    <summary>  The task of predicting dialog acts (DA) based on conversational dialog is a
key component in the development of conversational agents. Accurately
predicting DAs requires a precise modeling of both the conversation and the
global tag dependencies. We leverage seq2seq approaches widely adopted in
Neural Machine Translation (NMT) to improve the modelling of tag sequentiality.
Seq2seq models are known to learn complex global dependencies while currently
proposed approaches using linear conditional random fields (CRF) only model
local tag dependencies. In this work, we introduce a seq2seq model tailored for
DA classification using: a hierarchical encoder, a novel guided attention
mechanism and beam search applied to both training and inference. Compared to
the state of the art our model does not require handcrafted features and is
trained end-to-end. Furthermore, the proposed approach achieves an unmatched
accuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on
MRDA.
</summary>
    <author>
      <name>Pierre Colombo</name>
    </author>
    <author>
      <name>Emile Chapuis</name>
    </author>
    <author>
      <name>Matteo Manica</name>
    </author>
    <author>
      <name>Emmanuel Vignon</name>
    </author>
    <author>
      <name>Giovanna Varni</name>
    </author>
    <author>
      <name>Chloe Clavel</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.08801v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08801v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08614v1</id>
    <updated>2020-02-20T08:20:52Z</updated>
    <published>2020-02-20T08:20:52Z</published>
    <title>Balancing Cost and Benefit with Tied-Multi Transformers</title>
    <summary>  We propose and evaluate a novel procedure for training multiple Transformers
with tied parameters which compresses multiple models into one enabling the
dynamic choice of the number of encoder and decoder layers during decoding. In
sequence-to-sequence modeling, typically, the output of the last layer of the
N-layer encoder is fed to the M-layer decoder, and the output of the last
decoder layer is used to compute loss. Instead, our method computes a single
loss consisting of NxM losses, where each loss is computed from the output of
one of the M decoder layers connected to one of the N encoder layers. Such a
model subsumes NxM models with different number of encoder and decoder layers,
and can be used for decoding with fewer than the maximum number of encoder and
decoder layers. We then propose a mechanism to choose a priori the number of
encoder and decoder layers for faster decoding, and also explore recurrent
stacking of layers and knowledge distillation for model compression. We present
a cost-benefit analysis of applying the proposed approaches for neural machine
translation and show that they reduce decoding costs while preserving
translation quality.
</summary>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Raphael Rubino</name>
    </author>
    <author>
      <name>Atsushi Fujita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of our previous manuscript available at
  arXiv:1908.10118</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08608v2</id>
    <updated>2020-02-22T02:21:21Z</updated>
    <published>2020-02-20T08:01:28Z</published>
    <title>FrameAxis: Characterizing Framing Bias and Intensity with Word Embedding</title>
    <summary>  We propose FrameAxis, a method of characterizing the framing of a given text
by identifying the most relevant semantic axes ("microframes") defined by
antonym word pairs. In contrast to the traditional framing analysis, which has
been constrained by a small number of manually annotated general frames, our
unsupervised approach provides much more detailed insights, by considering a
host of semantic axes. Our method is capable of quantitatively teasing out
framing bias -- how biased a text is in each microframe -- and framing
intensity -- how much each microframe is used -- from the text, offering a
nuanced characterization of framing. We evaluate our approach using SemEval
datasets as well as three other datasets and human evaluations, demonstrating
that FrameAxis can reliably characterize documents with relevant microframes.
Our method may allow scalable and nuanced computational analyses of framing
across disciplines.
</summary>
    <author>
      <name>Haewoon Kwak</name>
    </author>
    <author>
      <name>Jisun An</name>
    </author>
    <author>
      <name>Yong-Yeol Ahn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; typos corrected (email address)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08608v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08608v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08562v1</id>
    <updated>2020-02-20T04:14:35Z</updated>
    <published>2020-02-20T04:14:35Z</published>
    <title>Federated pretraining and fine tuning of BERT using clinical notes from
  multiple silos</title>
    <summary>  Large scale contextual representation models, such as BERT, have
significantly advanced natural language processing (NLP) in recently years.
However, in certain area like healthcare, accessing diverse large scale text
data from multiple institutions is extremely challenging due to privacy and
regulatory reasons. In this article, we show that it is possible to both
pretrain and fine tune BERT models in a federated manner using clinical texts
from different silos without moving the data.
</summary>
    <author>
      <name>Dianbo Liu</name>
    </author>
    <author>
      <name>Tim Miller</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08434v1</id>
    <updated>2020-02-19T20:42:19Z</updated>
    <published>2020-02-19T20:42:19Z</published>
    <title>Interactive Natural Language-based Person Search</title>
    <summary>  In this work, we consider the problem of searching people in an unconstrained
environment, with natural language descriptions. Specifically, we study how to
systematically design an algorithm to effectively acquire descriptions from
humans. An algorithm is proposed by adapting models, used for visual and
language understanding, to search a person of interest (POI) in a principled
way, achieving promising results without the need to re-design another
complicated model. We then investigate an iterative question-answering (QA)
strategy that enable robots to request additional information about the POI's
appearance from the user. To this end, we introduce a greedy algorithm to rank
questions in terms of their significance, and equip the algorithm with the
capability to dynamically adjust the length of human-robot interaction
according to model's uncertainty. Our approach is validated not only on
benchmark datasets but on a mobile robot, moving in a dynamic and crowded
environment.
</summary>
    <author>
      <name>Vikram Shree</name>
    </author>
    <author>
      <name>Wei-Lun Chao</name>
    </author>
    <author>
      <name>Mark Campbell</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LRA.2020.2969921</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LRA.2020.2969921" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures, Published in IEEE Robotics and Automation
  Letters (RA-L), "Dataset at:
  https://github.com/vikshree/QA_PersonSearchLanguageData" , Video attachment
  at: https://www.youtube.com/watch?v=Yyxu8uVUREE&amp;feature=youtu.be</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in IEEE Robotics and Automation Letters, vol. 5, no. 2, pp.
  1851-1858, April 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.08434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08325v1</id>
    <updated>2020-02-19T17:57:46Z</updated>
    <published>2020-02-19T17:57:46Z</published>
    <title>VQA-LOL: Visual Question Answering under the Lens of Logic</title>
    <summary>  Logical connectives and their implications on the meaning of a natural
language sentence are a fundamental aspect of understanding. In this paper, we
investigate visual question answering (VQA) through the lens of logical
transformation and posit that systems that seek to answer questions about
images must be robust to these transformations of the question. If a VQA system
is able to answer a question, it should also be able to answer the logical
composition of questions. We analyze the performance of state-of-the-art models
on the VQA task under these logical operations and show that they have
difficulty in correctly answering such questions. We then construct an
augmentation of the VQA dataset with questions containing logical operations
and retrain the same models to establish a baseline. We further propose a novel
methodology to train models to learn negation, conjunction, and disjunction and
show improvement in learning logical composition and retaining performance on
VQA. We suggest this work as a move towards embedding logical connectives in
visual understanding, along with the benefits of robustness and
generalizability. Our code and dataset is available online at
https://www.public.asu.edu/~tgokhale/vqa_lol.html
</summary>
    <author>
      <name>Tejas Gokhale</name>
    </author>
    <author>
      <name>Pratyay Banerjee</name>
    </author>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Yezhou Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08307v1</id>
    <updated>2020-02-19T17:40:57Z</updated>
    <published>2020-02-19T17:40:57Z</published>
    <title>Compressing BERT: Studying the Effects of Weight Pruning on Transfer
  Learning</title>
    <summary>  Universal feature extractors, such as BERT for natural language processing
and VGG for computer vision, have become effective methods for improving deep
learning models without requiring more labeled data. A common paradigm is to
pre-train a feature extractor on large amounts of data then fine-tune it as
part of a deep learning model on some downstream task (i.e. transfer learning).
While effective, feature extractors like BERT may be prohibitively large for
some deployment scenarios. We explore weight pruning for BERT and ask: how does
compression during pre-training affect transfer learning? We find that pruning
affects transfer learning in three broad regimes. Low levels of pruning
(30-40\%) do not affect pre-training loss or transfer to downstream tasks at
all. Medium levels of pruning increase the pre-training loss and prevent useful
pre-training information from being transferred to downstream tasks. High
levels of pruning additionally prevent models from fitting downstream datasets,
leading to further degradation. Finally, we observe that fine-tuning BERT on a
specific task does not improve its prunability. We conclude that BERT can be
pruned once during pre-training rather than separately for each task without
affecting performance.
</summary>
    <author>
      <name>Mitchell A. Gordon</name>
    </author>
    <author>
      <name>Kevin Duh</name>
    </author>
    <author>
      <name>Nicholas Andrews</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08795v1</id>
    <updated>2020-02-19T17:18:20Z</updated>
    <published>2020-02-19T17:18:20Z</published>
    <title>How To Avoid Being Eaten By a Grue: Exploration Strategies for
  Text-Adventure Agents</title>
    <summary>  Text-based games -- in which an agent interacts with the world through
textual natural language -- present us with the problem of
combinatorially-sized action-spaces. Most current reinforcement learning
algorithms are not capable of effectively handling such a large number of
possible actions per turn. Poor sample efficiency, consequently, results in
agents that are unable to pass bottleneck states, where they are unable to
proceed because they do not see the right action sequence to pass the
bottleneck enough times to be sufficiently reinforced. Building on prior work
using knowledge graphs in reinforcement learning, we introduce two new game
state exploration strategies. We compare our exploration strategies against
strong baselines on the classic text-adventure game, Zork1, where prior agent
have been unable to get past a bottleneck where the agent is eaten by a Grue.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Ethan Tien</name>
    </author>
    <author>
      <name>Zhaochen Luo</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08267v2</id>
    <updated>2020-02-20T04:43:19Z</updated>
    <published>2020-02-19T16:21:00Z</published>
    <title>Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation</title>
    <summary>  Sentiment Analysis and Emotion Detection in conversation is key in a number
of real-world applications, with different applications leveraging different
kinds of data to be able to achieve reasonably accurate predictions. Multimodal
Emotion Detection and Sentiment Analysis can be particularly useful as
applications will be able to use specific subsets of the available modalities,
as per their available data, to be able to produce relevant predictions.
Current systems dealing with Multimodal functionality fail to leverage and
capture the context of the conversation through all modalities, the current
speaker and listener(s) in the conversation, and the relevance and relationship
between the available modalities through an adequate fusion mechanism. In this
paper, we propose a recurrent neural network architecture that attempts to take
into account all the mentioned drawbacks, and keeps track of the context of the
conversation, interlocutor states, and the emotions conveyed by the speakers in
the conversation. Our proposed model out performs the state of the art on two
benchmark datasets on a variety of accuracy and regression metrics.
</summary>
    <author>
      <name>Aman Shenoy</name>
    </author>
    <author>
      <name>Ashish Sardana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08267v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08267v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08241v1</id>
    <updated>2020-02-19T15:38:03Z</updated>
    <published>2020-02-19T15:38:03Z</published>
    <title>A Differential-form Pullback Programming Language for Higher-order
  Reverse-mode Automatic Differentiation</title>
    <summary>  Building on the observation that reverse-mode automatic differentiation (AD)
-- a generalisation of backpropagation -- can naturally be expressed as
pullbacks of differential 1-forms, we design a simple higher-order programming
language with a first-class differential operator, and present a reduction
strategy which exactly simulates reverse-mode AD. We justify our reduction
strategy by interpreting our language in any differential $\lambda$-category
that satisfies the Hahn-Banach Separation Theorem, and show that the reduction
strategy precisely captures reverse-mode AD in a truly higher-order setting.
</summary>
    <author>
      <name>Carol Mak</name>
    </author>
    <author>
      <name>Luke Ong</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08155v1</id>
    <updated>2020-02-19T13:09:07Z</updated>
    <published>2020-02-19T13:09:07Z</published>
    <title>CodeBERT: A Pre-Trained Model for Programming and Natural Languages</title>
    <summary>  We present CodeBERT, a bimodal pre-trained model for programming language
(PL) and nat-ural language (NL). CodeBERT learns general-purpose
representations that support downstream NL-PL applications such as natural
language codesearch, code documentation generation, etc. We develop CodeBERT
with Transformer-based neural architecture, and train it with a hybrid
objective function that incorporates the pre-training task of replaced token
detection, which is to detect plausible alternatives sampled from generators.
This enables us to utilize both bimodal data of NL-PL pairs and unimodal data,
where the former provides input tokens for model training while the latter
helps to learn better generators. We evaluate CodeBERT on two NL-PL
applications by fine-tuning model parameters. Results show that CodeBERT
achieves state-of-the-art performance on both natural language code search and
code documentation generation tasks. Furthermore, to investigate what type of
knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and
evaluate in a zero-shot setting where parameters of pre-trained models are
fixed. Results show that CodeBERT performs better than previous pre-trained
models on NL-PL probing.
</summary>
    <author>
      <name>Zhangyin Feng</name>
    </author>
    <author>
      <name>Daya Guo</name>
    </author>
    <author>
      <name>Duyu Tang</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Xiaocheng Feng</name>
    </author>
    <author>
      <name>Ming Gong</name>
    </author>
    <author>
      <name>Linjun Shou</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Daxin Jiang</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08155v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08155v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08131v1</id>
    <updated>2020-02-19T12:22:46Z</updated>
    <published>2020-02-19T12:22:46Z</published>
    <title>Hierarchical models vs. transfer learning for document-level sentiment
  classification</title>
    <summary>  Documents are composed of smaller pieces - paragraphs, sentences, and tokens
- that have complex relationships between one another. Sentiment classification
models that take into account the structure inherent in these documents have a
theoretical advantage over those that do not. At the same time, transfer
learning models based on language model pretraining have shown promise for
document classification. However, these two paradigms have not been
systematically compared and it is not clear under which circumstances one
approach is better than the other. In this work we empirically compare
hierarchical models and transfer learning for document-level sentiment
classification. We show that non-trivial hierarchical models outperform
previous baselines and transfer learning on document-level sentiment
classification in five languages.
</summary>
    <author>
      <name>Jeremy Barnes</name>
    </author>
    <author>
      <name>Vinit Ravishankar</name>
    </author>
    <author>
      <name>Lilja Øvrelid</name>
    </author>
    <author>
      <name>Erik Velldal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08126v1</id>
    <updated>2020-02-19T12:01:33Z</updated>
    <published>2020-02-19T12:01:33Z</published>
    <title>Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition</title>
    <summary>  Recently, language identity information has been utilized to improve the
performance of end-to-end code-switching (CS) speech recognition. However,
previous works use an additional language identification (LID) model as an
auxiliary module, which causes the system complex. In this work, we propose an
improved recurrent neural network transducer (RNN-T) model with language bias
to alleviate the problem. We use the language identities to bias the model to
predict the CS points. This promotes the model to learn the language identity
information directly from transcription, and no additional LID model is needed.
We evaluate the approach on a Mandarin-English CS corpus SEAME. Compared to our
RNN-T baseline, the proposed method can achieve 16.2% and 12.9% relative error
reduction on two test sets, respectively.
</summary>
    <author>
      <name>Shuai Zhang</name>
    </author>
    <author>
      <name>Jiangyan Yi</name>
    </author>
    <author>
      <name>Zhengkun Tian</name>
    </author>
    <author>
      <name>Jianhua Tao</name>
    </author>
    <author>
      <name>Ye Bai</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08087v2</id>
    <updated>2020-03-06T15:29:34Z</updated>
    <published>2020-02-19T09:48:39Z</published>
    <title>LAMBERT: Layout-Aware language Modeling using BERT for information
  extraction</title>
    <summary>  In this paper we introduce a novel approach to the problem of understanding
documents where the local semantics is influenced by non-trivial layout.
Namely, we modify the Transformer architecture in a way that allows it to use
the graphical features defined by the layout, without the need to re-learn the
language semantics from scratch, thanks to starting the training process from a
model pretrained on classical language modeling tasks.
</summary>
    <author>
      <name>Łukasz Garncarek</name>
    </author>
    <author>
      <name>Rafał Powalski</name>
    </author>
    <author>
      <name>Tomasz Stanisławek</name>
    </author>
    <author>
      <name>Bartosz Topolski</name>
    </author>
    <author>
      <name>Piotr Halama</name>
    </author>
    <author>
      <name>Filip Graliński</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v1: 9 pages; work in progress; this version of the paper was
  submitted to review on Dec 10, 2019, and subsequently withdrawn on Feb 17,
  2020 v2: 17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08087v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08087v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08046v1</id>
    <updated>2020-02-19T08:17:00Z</updated>
    <published>2020-02-19T08:17:00Z</published>
    <title>Tree-structured Attention with Hierarchical Accumulation</title>
    <summary>  Incorporating hierarchical structures like constituency trees has been shown
to be effective for various natural language processing (NLP) tasks. However,
it is evident that state-of-the-art (SOTA) sequence-based models like the
Transformer struggle to encode such structures inherently. On the other hand,
dedicated models like the Tree-LSTM, while explicitly modeling hierarchical
structures, do not perform as efficiently as the Transformer. In this paper, we
attempt to bridge this gap with "Hierarchical Accumulation" to encode parse
tree structures into self-attention at constant time complexity. Our approach
outperforms SOTA methods in four IWSLT translation tasks and the WMT'14
English-German translation task. It also yields improvements over Transformer
and Tree-LSTM on three text classification tasks. We further demonstrate that
using hierarchical priors can compensate for data shortage, and that our model
prefers phrase-level attentions over token-level attentions.
</summary>
    <author>
      <name>Xuan-Phi Nguyen</name>
    </author>
    <author>
      <name>Shafiq Joty</name>
    </author>
    <author>
      <name>Steven C. H. Hoi</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08024v1</id>
    <updated>2020-02-19T06:39:26Z</updated>
    <published>2020-02-19T06:39:26Z</published>
    <title>Non-Autoregressive Dialog State Tracking</title>
    <summary>  Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues
have progressed toward open-vocabulary or generation-based approaches where the
models can generate slot value candidates from the dialogue history itself.
These approaches have shown good performance gain, especially in complicated
dialogue domains with dynamic slot values. However, they fall short in two
aspects: (1) they do not allow models to explicitly learn signals across
domains and slots to detect potential dependencies among (domain, slot) pairs;
and (2) existing models follow auto-regressive approaches which incur high time
cost when the dialogue evolves over multiple domains and multiple turns. In
this paper, we propose a novel framework of Non-Autoregressive Dialog State
Tracking (NADST) which can factor in potential dependencies among domains and
slots to optimize the models towards better prediction of dialogue states as a
complete set rather than separate slots. In particular, the non-autoregressive
nature of our method not only enables decoding in parallel to significantly
reduce the latency of DST for real-time dialogue response generation, but also
detect dependencies among slots at token level in addition to slot and domain
level. Our empirical results show that our model achieves the state-of-the-art
joint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency
of our model is an order of magnitude lower than the previous state of the art
as the dialogue history extends over time.
</summary>
    <author>
      <name>Hung Le</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Steven C. H. Hoi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICLR 2020. International Conference on Learning
  Representations (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11768v1</id>
    <updated>2020-02-19T04:18:45Z</updated>
    <published>2020-02-19T04:18:45Z</published>
    <title>Attacking Neural Text Detectors</title>
    <summary>  Machine learning based language models have recently made significant
progress, which introduces a danger to spread misinformation. To combat this
potential danger, several methods have been proposed for detecting text written
by these language models. This paper presents two classes of black-box attacks
on these detectors, one which randomly replaces characters with homoglyphs, and
the other a simple scheme to purposefully misspell words. The homoglyph and
misspelling attacks decrease a popular neural text detector's recall on neural
text from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that
the attacks are transferable to other neural text detectors.
</summary>
    <author>
      <name>Max Wolff</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07982v1</id>
    <updated>2020-02-19T03:30:00Z</updated>
    <published>2020-02-19T03:30:00Z</published>
    <title>Toward Making the Most of Context in Neural Machine Translation</title>
    <summary>  Document-level machine translation manages to outperform sentence level
models by a small margin, but have failed to be widely adopted. We argue that
previous research did not make a clear use of the global context, and propose a
new document-level NMT framework that deliberately models the local context of
each sentence with the awareness of the global context of the document in both
source and target languages. We specifically design the model to be able to
deal with documents containing any number of sentences, including single
sentences. This unified approach allows our model to be trained elegantly on
standard datasets without needing to train on sentence and document level data
separately. Experimental results demonstrate that our model outperforms
Transformer baselines and previous document-level NMT models with substantial
margins of up to 2.1 BLEU on state-of-the-art baselines. We also provide
analyses which show the benefit of context far beyond the neighboring two or
three sentences, which previous studies have typically incorporated.
</summary>
    <author>
      <name>Zaixiang Zheng</name>
    </author>
    <author>
      <name>Xiang Yue</name>
    </author>
    <author>
      <name>Shujian Huang</name>
    </author>
    <author>
      <name>Jiajun Chen</name>
    </author>
    <author>
      <name>Alexandra Birch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to a conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07972v1</id>
    <updated>2020-02-19T03:05:28Z</updated>
    <published>2020-02-19T03:05:28Z</published>
    <title>The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural
  Language Understanding</title>
    <summary>  We present MT-DNN, an open-source natural language understanding (NLU)
toolkit that makes it easy for researchers and developers to train customized
deep learning models. Built upon PyTorch and Transformers, MT-DNN is designed
to facilitate rapid customization for a broad spectrum of NLU tasks, using a
variety of objectives (classification, regression, structured prediction) and
text encoders (e.g., RNNs, BERT, RoBERTa, UniLM). A unique feature of MT-DNN is
its built-in support for robust and transferable learning using the adversarial
multi-task learning paradigm. To enable efficient production deployment, MT-DNN
supports multi-task knowledge distillation, which can substantially compress a
deep neural model without significant performance drop. We demonstrate the
effectiveness of MT-DNN on a wide range of NLU applications across general and
biomedical domains. The software and pre-trained models will be publicly
available at https://github.com/namisan/mt-dnn.
</summary>
    <author>
      <name>Xiaodong Liu</name>
    </author>
    <author>
      <name>Yu Wang</name>
    </author>
    <author>
      <name>Jianshu Ji</name>
    </author>
    <author>
      <name>Hao Cheng</name>
    </author>
    <author>
      <name>Xueyun Zhu</name>
    </author>
    <author>
      <name>Emmanuel Awa</name>
    </author>
    <author>
      <name>Pengcheng He</name>
    </author>
    <author>
      <name>Weizhu Chen</name>
    </author>
    <author>
      <name>Hoifung Poon</name>
    </author>
    <author>
      <name>Guihong Cao</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures and 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07927v2</id>
    <updated>2020-02-26T16:27:37Z</updated>
    <published>2020-02-18T23:52:39Z</published>
    <title>Studying the Effects of Cognitive Biases in Evaluation of Conversational
  Agents</title>
    <summary>  Humans quite frequently interact with conversational agents. The rapid
advancement in generative language modeling through neural networks has helped
advance the creation of intelligent conversational agents. Researchers
typically evaluate the output of their models through crowdsourced judgments,
but there are no established best practices for conducting such studies.
Moreover, it is unclear if cognitive biases in decision-making are affecting
crowdsourced workers' judgments when they undertake these tasks. To
investigate, we conducted a between-subjects study with 77 crowdsourced workers
to understand the role of cognitive biases, specifically anchoring bias, when
humans are asked to evaluate the output of conversational agents. Our results
provide insight into how best to evaluate conversational agents. We find
increased consistency in ratings across two experimental conditions may be a
result of anchoring bias. We also determine that external factors such as time
and prior experience in similar tasks have effects on inter-rater consistency.
</summary>
    <author>
      <name>Sashank Santhanam</name>
    </author>
    <author>
      <name>Alireza Karduni</name>
    </author>
    <author>
      <name>Samira Shaikh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at CHI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07927v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07927v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07845v1</id>
    <updated>2020-02-18T19:40:20Z</updated>
    <published>2020-02-18T19:40:20Z</published>
    <title>Transfer Learning for Abstractive Summarization at Controllable Budgets</title>
    <summary>  Summarizing a document within an allocated budget while maintaining its major
concepts is a challenging task. If the budget can take any arbitrary value and
not known beforehand, it becomes even more difficult. Most of the existing
methods for abstractive summarization, including state-of-the-art neural
networks are data intensive. If the number of available training samples
becomes limited, they fail to construct high-quality summaries. We propose MLS,
an end-to-end framework to generate abstractive summaries with limited training
data at arbitrary compression budgets. MLS employs a pair of supervised
sequence-to-sequence networks. The first network called the \textit{MFS-Net}
constructs a minimal feasible summary by identifying the key concepts of the
input document. The second network called the Pointer-Magnifier then generates
the final summary from the minimal feasible summary by leveraging an
interpretable multi-headed attention model. Experiments on two cross-domain
datasets show that MLS outperforms baseline methods over a range of success
metrics including ROUGE and METEOR. We observed an improvement of approximately
4% in both metrics over the state-of-art convolutional network at lower
budgets. Results from a human evaluation study also establish the effectiveness
of MLS in generating complete coherent summaries at arbitrary compression
budgets.
</summary>
    <author>
      <name>Ritesh Sarkhel</name>
    </author>
    <author>
      <name>Moniba Keymanesh</name>
    </author>
    <author>
      <name>Arnab Nandi</name>
    </author>
    <author>
      <name>Srinivasan Parthasarathy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07775v1</id>
    <updated>2020-02-18T18:10:03Z</updated>
    <published>2020-02-18T18:10:03Z</published>
    <title>An enhanced Tree-LSTM architecture for sentence semantic modeling using
  typed dependencies</title>
    <summary>  Tree-based Long short term memory (LSTM) network has become state-of-the-art
for modeling the meaning of language texts as they can effectively exploit the
grammatical syntax and thereby non-linear dependencies among words of the
sentence. However, most of these models cannot recognize the difference in
meaning caused by a change in semantic roles of words or phrases because they
do not acknowledge the type of grammatical relations, also known as typed
dependencies, in sentence structure. This paper proposes an enhanced LSTM
architecture, called relation gated LSTM, which can model the relationship
between two inputs of a sequence using a control input. We also introduce a
Tree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence
dependency parse structure as well as the dependency type to embed sentence
meaning into a dense vector. The proposed model outperformed its type-unaware
counterpart in two typical NLP tasks - Semantic Relatedness Scoring and
Sentiment Analysis, in a lesser number of training epochs. The results were
comparable or competitive with other state-of-the-art models. Qualitative
analysis showed that changes in the voice of sentences had little effect on the
model's predicted scores, while changes in nominal (noun) words had a more
significant impact. The model recognized subtle semantic relationships in
sentence pairs. The magnitudes of learned typed dependencies embeddings were
also in agreement with human intuitions. The research findings imply the
significance of grammatical relations in sentence modeling. The proposed models
would serve as a base for future researches in this direction.
</summary>
    <author>
      <name>Jeena Kleenankandy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science and Engineering, National Institute of Technology Calicut, Kerala, India</arxiv:affiliation>
    </author>
    <author>
      <name>K. A. Abdul Nazeer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science and Engineering, National Institute of Technology Calicut, Kerala, India</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a preprint submitted to Journal of Information Processing and
  Management ( Elsevier ) on December 29, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07767v1</id>
    <updated>2020-02-18T17:59:02Z</updated>
    <published>2020-02-18T17:59:02Z</published>
    <title>Learning by Semantic Similarity Makes Abstractive Summarization Better</title>
    <summary>  One of the obstacles of abstractive summarization is the presence of various
potentially correct predictions. Widely used objective functions for supervised
learning, such as cross-entropy loss, cannot handle alternative answers
effectively. Rather, they act as a training noise. In this paper, we propose
Semantic Similarity strategy that can consider semantic meanings of generated
summaries while training. Our training objective includes maximizing semantic
similarity score which is calculated by an additional layer that estimates
semantic similarity between generated summary and reference summary. By
leveraging pre-trained language models, our model achieves a new
state-of-the-art performance, ROUGE-L score of 41.5 on CNN/DM dataset. To
support automatic evaluation, we also conducted human evaluation and received
higher scores relative to both baseline and reference summaries.
</summary>
    <author>
      <name>Wonjin Yoon</name>
    </author>
    <author>
      <name>Yoon Sun Yeo</name>
    </author>
    <author>
      <name>Minbyul Jeong</name>
    </author>
    <author>
      <name>Bong-Jun Yi</name>
    </author>
    <author>
      <name>Jaewoo Kang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07725v1</id>
    <updated>2020-02-18T16:51:05Z</updated>
    <published>2020-02-18T16:51:05Z</published>
    <title>Gradient-Based Adversarial Training on Transformer Networks for
  Detecting Check-Worthy Factual Claims</title>
    <summary>  We present a study on the efficacy of adversarial training on transformer
neural network models, with respect to the task of detecting check-worthy
claims. In this work, we introduce the first adversarially-regularized,
transformer-based claim spotter model that achieves state-of-the-art results on
multiple challenging benchmarks. We obtain a 4.31 point F1-score improvement
and a 1.09 point mAP score improvement over current state-of-the-art models on
the ClaimBuster Dataset and CLEF2019 Dataset, respectively. In the process, we
propose a method to apply adversarial training to transformer models, which has
the potential to be generalized to many similar text classification tasks.
Along with our results, we are releasing our codebase and manually labeled
datasets. We also showcase our models' real world usage via a live public API.
</summary>
    <author>
      <name>Kevin Meng</name>
    </author>
    <author>
      <name>Damian Jimenez</name>
    </author>
    <author>
      <name>Fatma Arslan</name>
    </author>
    <author>
      <name>Jacob Daniel Devasier</name>
    </author>
    <author>
      <name>Daniel Obembe</name>
    </author>
    <author>
      <name>Chengkai Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07715v1</id>
    <updated>2020-02-18T16:41:24Z</updated>
    <published>2020-02-18T16:41:24Z</published>
    <title>Neural Relation Prediction for Simple Question Answering over Knowledge
  Graph</title>
    <summary>  Relation extraction from simple questions aims to capture the relation of a
factoid question with one underlying relation from a set of predefined ones ina
knowledge base. Most recent methods take advantage of neural networks for
matching a question with all relations in order to find the best relation that
is expressed by that question. In this paper, we propose an instance-based
method to find similar questions of a new question, in the sense of their
relations, to predict its mentioned relation. The motivation roots in the fact
that a relation can be expressed with different forms of question and these
forms mostly share similar terms or concepts. Our experiments on the
SimpleQuestions dataset show that the proposed model achieved better accuracy
compared to the state-of-the-art relation extraction models.
</summary>
    <author>
      <name>Amin Abolghasemi</name>
    </author>
    <author>
      <name>Saeedeh Momtazi</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07660v1</id>
    <updated>2020-02-18T15:47:14Z</updated>
    <published>2020-02-18T15:47:14Z</published>
    <title>Decidability of cutpoint isolation for letter-monotonic probabilistic
  finite automata</title>
    <summary>  We show the surprising result that the cutpoint isolation problem is
decidable for probabilistic finite automata where input words are taken from a
letter-monotonic context-free language. A context-free language $L$ is
letter-monotonic when $L \subseteq a_1^*a_2^* \cdots a_\ell^*$ for some finite
$\ell &gt; 0$ where each letter is distinct. A cutpoint is isolated when it cannot
be approached arbitrarily closely. The decidability of this problem is in
marked contrast to the situation for the (strict) emptiness problem for PFA
which is undecidable under the even more severe restrictions of PFA with
polynomial ambiguity, commutative matrices and input over a letter-monotonic
language as well as the injectivity problem which is undecidable for PFA over
letter-monotonic languages. We provide a constructive nondeterministic
algorithm to solve the cutpoint isolation problem, even for exponentially
ambiguous PFA, and we also show that the problem is at least NP-hard.
</summary>
    <author>
      <name>Paul C. Bell</name>
    </author>
    <author>
      <name>Pavel Semukhin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q45" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1; F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02645v2</id>
    <updated>2020-03-06T02:41:29Z</updated>
    <published>2020-02-18T15:34:29Z</published>
    <title>SentenceMIM: A Latent Variable Language Model</title>
    <summary>  We introduce sentenceMIM, a probabilistic auto-encoder for language
modelling, trained with Mutual Information Machine (MIM) learning. Previous
attempts to learn variational auto-encoders for language data have had mixed
success, with empirical performance well below state-of-the-art auto-regressive
models, a key barrier being the occurrence of posterior collapse with VAEs. The
recently proposed MIM framework encourages high mutual information between
observations and latent variables, and is more robust against posterior
collapse. This paper formulates a MIM model for text data, along with a
corresponding learning algorithm. We demonstrate excellent perplexity (PPL)
results on several datasets, and show that the framework learns a rich latent
space, allowing for interpolation between sentences of different lengths with a
fixed-dimensional latent representation. We also demonstrate the versatility of
sentenceMIM by utilizing a trained model for question-answering, a transfer
learning task, without fine-tuning. To the best of our knowledge, this is the
first latent variable model (LVM) for text modelling that achieves competitive
performance with non-LVM models.
</summary>
    <author>
      <name>Micha Livne</name>
    </author>
    <author>
      <name>Kevin Swersky</name>
    </author>
    <author>
      <name>David J. Fleet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02645v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02645v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07591v1</id>
    <updated>2020-02-18T14:40:20Z</updated>
    <published>2020-02-18T14:40:20Z</published>
    <title>Text Classification with Lexicon from PreAttention Mechanism</title>
    <summary>  A comprehensive and high-quality lexicon plays a crucial role in traditional
text classification approaches. And it improves the utilization of the
linguistic knowledge. Although it is helpful for the task, the lexicon has got
little attention in recent neural network models. Firstly, getting a
high-quality lexicon is not easy. We lack an effective automated lexicon
extraction method, and most lexicons are hand crafted, which is very
inefficient for big data. What's more, there is no an effective way to use a
lexicon in a neural network. To address those limitations, we propose a
Pre-Attention mechanism for text classification in this paper, which can learn
attention of different words according to their effects in the classification
tasks. The words with different attention can form a domain lexicon.
Experiments on three benchmark text classification tasks show that our models
get competitive result comparing with the state-of-the-art methods. We get
90.5% accuracy on Stanford Large Movie Review dataset, 82.3% on Subjectivity
dataset, 93.7% on Movie Reviews. And compared with the text classification
model without Pre-Attention mechanism, those with Pre-Attention mechanism
improve by 0.9%-2.4% accuracy, which proves the validity of the Pre-Attention
mechanism. In addition, the Pre-Attention mechanism performs well followed by
different types of neural networks (e.g., convolutional neural networks and
Long Short-Term Memory networks). For the same dataset, when we use
Pre-Attention mechanism to get attention value followed by different neural
networks, those words with high attention values have a high degree of
coincidence, which proves the versatility and portability of the Pre-Attention
mechanism. we can get stable lexicons by attention values, which is an
inspiring method of information extraction.
</summary>
    <author>
      <name>QingBiao LI</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <author>
      <name>Chunhua Wu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <author>
      <name>Kangfeng Zheng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07563v2</id>
    <updated>2020-02-27T16:40:59Z</updated>
    <published>2020-02-18T13:57:10Z</published>
    <title>A Model to Measure the Spread Power of Rumors</title>
    <summary>  Nowadays, a significant portion of daily interacted posts in social media are
infected by rumors. This study investigates the problem of rumor analysis in
different areas from other researches. It tackles the unaddressed problem
related to calculating the Spread Power of Rumor (SPR) for the first time and
seeks to examine the spread power as the function of multi-contextual features.
For this purpose, the theory of Allport and Postman will be adopted. In which
it claims that there are two key factors determinant to the spread power of
rumors, namely importance and ambiguity. The proposed Rumor Spread Power
Measurement Model (RSPMM) computes SPR by utilizing a textual-based approach,
which entails contextual features to compute the spread power of the rumors in
two categories: False Rumor (FR) and True Rumor (TR). Totally 51 contextual
features are introduced to measure SPR and their impact on classification are
investigated, then 42 features in two categories "importance" (28 features) and
"ambiguity" (14 features) are selected to compute SPR. The proposed RSPMM is
verified on two labelled datasets, which are collected from Twitter and
Telegram. The results show that (i) the proposed new features are effective and
efficient to discriminate between FRs and TRs. (ii) the proposed RSPMM approach
focused only on contextual features while existing techniques are based on
Structure and Content features, but RSPMM achieves considerably outstanding
results (F-measure=83%). (iii) The result of T-Test shows that SPR criteria can
significantly distinguish between FR and TR, besides it can be useful as a new
method to verify the trueness of rumors.
</summary>
    <author>
      <name>Zoleikha Jahanbakhsh-Nagadeh</name>
    </author>
    <author>
      <name>Mohammad-Reza Feizi-Derakhshi</name>
    </author>
    <author>
      <name>Majid Ramezani</name>
    </author>
    <author>
      <name>Taymaz Rahkar-Farshi</name>
    </author>
    <author>
      <name>Meysam Asgari-Chenaghlu</name>
    </author>
    <author>
      <name>Narjes Nikzad-Khasmakhi</name>
    </author>
    <author>
      <name>Ali-Reza Feizi-Derakhshi</name>
    </author>
    <author>
      <name>Mehrdad Ranjbar-Khadivi</name>
    </author>
    <author>
      <name>Elnaz Zafarani-Moattar</name>
    </author>
    <author>
      <name>Mohammad-Ali Balafar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 9 tables, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07563v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07563v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07551v1</id>
    <updated>2020-02-18T13:44:49Z</updated>
    <published>2020-02-18T13:44:49Z</published>
    <title>Hierarchical Transformer Network for Utterance-level Emotion Recognition</title>
    <summary>  While there have been significant advances in de-tecting emotions in text, in
the field of utter-ance-level emotion recognition (ULER), there are still many
problems to be solved. In this paper, we address some challenges in ULER in
dialog sys-tems. (1) The same utterance can deliver different emotions when it
is in different contexts or from different speakers. (2) Long-range contextual
in-formation is hard to effectively capture. (3) Unlike the traditional text
classification problem, this task is supported by a limited number of datasets,
among which most contain inadequate conversa-tions or speech. To address these
problems, we propose a hierarchical transformer framework (apart from the
description of other studies, the "transformer" in this paper usually refers to
the encoder part of the transformer) with a lower-level transformer to model
the word-level input and an upper-level transformer to capture the context of
utterance-level embeddings. We use a pretrained language model bidirectional
encoder representa-tions from transformers (BERT) as the lower-level
transformer, which is equivalent to introducing external data into the model
and solve the problem of data shortage to some extent. In addition, we add
speaker embeddings to the model for the first time, which enables our model to
capture the in-teraction between speakers. Experiments on three dialog emotion
datasets, Friends, EmotionPush, and EmoryNLP, demonstrate that our proposed
hierarchical transformer network models achieve 1.98%, 2.83%, and 3.94%
improvement, respec-tively, over the state-of-the-art methods on each dataset
in terms of macro-F1.
</summary>
    <author>
      <name>QingBiao Li</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <author>
      <name>ChunHua Wu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <author>
      <name>KangFeng Zheng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <author>
      <name>Zhe Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing University of Posts and Telecommunications</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07526v1</id>
    <updated>2020-02-18T12:49:14Z</updated>
    <published>2020-02-18T12:49:14Z</published>
    <title>A Survey of Deep Learning Techniques for Neural Machine Translation</title>
    <summary>  In recent years, natural language processing (NLP) has got great development
with deep learning techniques. In the sub-field of machine translation, a new
approach named Neural Machine Translation (NMT) has emerged and got massive
attention from both academia and industry. However, with a significant number
of researches proposed in the past several years, there is little work in
investigating the development process of this new technology trend. This
literature survey traces back the origin and principal development timeline of
NMT, investigates the important branches, categorizes different research
orientations, and discusses some future research trends in this field.
</summary>
    <author>
      <name>Shuoheng Yang</name>
    </author>
    <author>
      <name>Yuxin Wang</name>
    </author>
    <author>
      <name>Xiaowen Chu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07510v1</id>
    <updated>2020-02-18T11:59:59Z</updated>
    <published>2020-02-18T11:59:59Z</published>
    <title>Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue</title>
    <summary>  Knowledge-grounded dialogue is a task of generating an informative response
based on both discourse context and external knowledge. As we focus on better
modeling the knowledge selection in the multi-turn knowledge-grounded dialogue,
we propose a sequential latent variable model as the first approach to this
matter. The model named sequential knowledge transformer (SKT) can keep track
of the prior and posterior distribution over knowledge; as a result, it can not
only reduce the ambiguity caused from the diversity in knowledge selection of
conversation but also better leverage the response information for proper
choice of knowledge. Our experimental results show that the proposed model
improves the knowledge selection accuracy and subsequently the performance of
utterance generation. We achieve the new state-of-the-art performance on Wizard
of Wikipedia (Dinan et al., 2019) as one of the most large-scale and
challenging benchmarks. We further validate the effectiveness of our model over
existing conversation methods in another knowledge-based dialogue Holl-E
dataset (Moghe et al., 2018).
</summary>
    <author>
      <name>Byeongchang Kim</name>
    </author>
    <author>
      <name>Jaewoo Ahn</name>
    </author>
    <author>
      <name>Gunhee Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in ICLR 2020 (Spotlight)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07458v1</id>
    <updated>2020-02-18T09:58:59Z</updated>
    <published>2020-02-18T09:58:59Z</published>
    <title>A New Clustering neural network for Chinese word segmentation</title>
    <summary>  In this article I proposed a new model to achieve Chinese word
segmentation(CWS),which may have the potentiality to apply in other domains in
the future.It is a new thinking in CWS compared to previous works,to consider
it as a clustering problem instead of a labeling problem.In this model,LSTM and
self attention structures are used to collect context also sentence level
features in every layer,and after several layers,a clustering model is applied
to split characters into groups,which are the final segmentation results.I call
this model CLNN.This algorithm can reach 98 percent of F score (without OOV
words) and 85 percent to 95 percent F score (with OOV words) in training data
sets.Error analyses shows that OOV words will greatly reduce performances,which
needs a deeper research in the future.
</summary>
    <author>
      <name>Yuze Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07422v1</id>
    <updated>2020-02-18T08:07:23Z</updated>
    <published>2020-02-18T08:07:23Z</published>
    <title>Assessing the Memory Ability of Recurrent Neural Networks</title>
    <summary>  It is known that Recurrent Neural Networks (RNNs) can remember, in their
hidden layers, part of the semantic information expressed by a sequence (e.g.,
a sentence) that is being processed. Different types of recurrent units have
been designed to enable RNNs to remember information over longer time spans.
However, the memory abilities of different recurrent units are still
theoretically and empirically unclear, thus limiting the development of more
effective and explainable RNNs. To tackle the problem, in this paper, we
identify and analyze the internal and external factors that affect the memory
ability of RNNs, and propose a Semantic Euclidean Space to represent the
semantics expressed by a sequence. Based on the Semantic Euclidean Space, a
series of evaluation indicators are defined to measure the memory abilities of
different recurrent units and analyze their limitations. These evaluation
indicators also provide a useful guidance to select suitable sequence lengths
for different RNNs during training.
</summary>
    <author>
      <name>Cheng Zhang</name>
    </author>
    <author>
      <name>Qiuchi Li</name>
    </author>
    <author>
      <name>Lingyu Hua</name>
    </author>
    <author>
      <name>Dawei Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ECAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07397v1</id>
    <updated>2020-02-18T06:29:01Z</updated>
    <published>2020-02-18T06:29:01Z</published>
    <title>Improving Multi-Turn Response Selection Models with Complementary
  Last-Utterance Selection by Instance Weighting</title>
    <summary>  Open-domain retrieval-based dialogue systems require a considerable amount of
training data to learn their parameters. However, in practice, the negative
samples of training data are usually selected from an unannotated conversation
data set at random. The generated training data is likely to contain noise and
affect the performance of the response selection models. To address this
difficulty, we consider utilizing the underlying correlation in the data
resource itself to derive different kinds of supervision signals and reduce the
influence of noisy data. More specially, we consider a main-complementary task
pair. The main task (\ie our focus) selects the correct response given the last
utterance and context, and the complementary task selects the last utterance
given the response and context. The key point is that the output of the
complementary task is used to set instance weights for the main task. We
conduct extensive experiments in two public datasets and obtain significant
improvement in both datasets. We also investigate the variant of our approach
in multiple aspects, and the results have verified the effectiveness of our
approach.
</summary>
    <author>
      <name>Kun Zhou</name>
    </author>
    <author>
      <name>Wayne Xin Zhao</name>
    </author>
    <author>
      <name>Yutao Zhu</name>
    </author>
    <author>
      <name>Ji-Rong Wen</name>
    </author>
    <author>
      <name>Jingsong Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. Accepted by PAKDD 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07339v1</id>
    <updated>2020-02-18T02:30:03Z</updated>
    <published>2020-02-18T02:30:03Z</published>
    <title>Annotating and Extracting Synthesis Process of All-Solid-State Batteries
  from Scientific Literature</title>
    <summary>  The synthesis process is essential for achieving computational experiment
design in the field of inorganic materials chemistry. In this work, we present
a novel corpus of the synthesis process for all-solid-state batteries and an
automated machine reading system for extracting the synthesis processes buried
in the scientific literature. We define the representation of the synthesis
processes using flow graphs, and create a corpus from the experimental sections
of 243 papers. The automated machine-reading system is developed by a deep
learning-based sequence tagger and simple heuristic rule-based relation
extractor. Our experimental results demonstrate that the sequence tagger with
the optimal setting can detect the entities with a macro-averaged F1 score of
0.826, while the rule-based relation extractor can achieve high performance
with a macro-averaged F1 score of 0.887.
</summary>
    <author>
      <name>Fusataka Kuniyoshi</name>
    </author>
    <author>
      <name>Kohei Makino</name>
    </author>
    <author>
      <name>Jun Ozawa</name>
    </author>
    <author>
      <name>Makoto Miwa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th International Conference on Language
  Resources and Evaluation (LREC 2020), Marseille, France</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07338v1</id>
    <updated>2020-02-18T02:22:31Z</updated>
    <published>2020-02-18T02:22:31Z</published>
    <title>Conditional Self-Attention for Query-based Summarization</title>
    <summary>  Self-attention mechanisms have achieved great success on a variety of NLP
tasks due to its flexibility of capturing dependency between arbitrary
positions in a sequence. For problems such as query-based summarization (Qsumm)
and knowledge graph reasoning where each input sequence is associated with an
extra query, explicitly modeling such conditional contextual dependencies can
lead to a more accurate solution, which however cannot be captured by existing
self-attention mechanisms. In this paper, we propose \textit{conditional
self-attention} (CSA), a neural network module designed for conditional
dependency modeling. CSA works by adjusting the pairwise attention between
input tokens in a self-attention module with the matching score of the inputs
to the given query. Thereby, the contextual dependencies modeled by CSA will be
highly relevant to the query. We further studied variants of CSA defined by
different types of attention. Experiments on Debatepedia and HotpotQA benchmark
datasets show CSA consistently outperforms vanilla Transformer and previous
models for the Qsumm problem.
</summary>
    <author>
      <name>Yujia Xie</name>
    </author>
    <author>
      <name>Tianyi Zhou</name>
    </author>
    <author>
      <name>Yi Mao</name>
    </author>
    <author>
      <name>Weizhu Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07306v1</id>
    <updated>2020-02-18T00:22:54Z</updated>
    <published>2020-02-18T00:22:54Z</published>
    <title>From English To Foreign Languages: Transferring Pre-trained Language
  Models</title>
    <summary>  Pre-trained models have demonstrated their effectiveness in many downstream
natural language processing (NLP) tasks. The availability of multilingual
pre-trained models enables zero-shot transfer of NLP tasks from high resource
languages to low resource ones. However, recent research in improving
pre-trained models focuses heavily on English. While it is possible to train
the latest neural architectures for other languages from scratch, it is
undesirable due to the required amount of compute. In this work, we tackle the
problem of transferring an existing pre-trained model from English to other
languages under a limited computational budget. With a single GPU, our approach
can obtain a foreign BERT base model within a day and a foreign BERT large
within two days. Furthermore, evaluating our models on six languages, we
demonstrate that our models are better than multilingual BERT on two zero-shot
tasks: natural language inference and dependency parsing.
</summary>
    <author>
      <name>Ke Tran</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07106v1</id>
    <updated>2020-02-17T17:54:27Z</updated>
    <published>2020-02-17T17:54:27Z</published>
    <title>Controlling Computation versus Quality for Neural Sequence Models</title>
    <summary>  Most neural networks utilize the same amount of compute for every example
independent of the inherent complexity of the input. Further, methods that
adapt the amount of computation to the example focus on finding a fixed
inference-time computational graph per example, ignoring any external
computational budgets or varying inference time limitations. In this work, we
utilize conditional computation to make neural sequence models (Transformer)
more efficient and computation-aware during inference. We first modify the
Transformer architecture, making each set of operations conditionally
executable depending on the output of a learned control network. We then train
this model in a multi-task setting, where each task corresponds to a particular
computation budget. This allows us to train a single model that can be
controlled to operate on different points of the computation-quality trade-off
curve, depending on the available computation budget at inference time. We
evaluate our approach on two tasks: (i) WMT English-French Translation and (ii)
Unsupervised representation learning (BERT). Our experiments demonstrate that
the proposed Conditional Computation Transformer (CCT) is competitive with
vanilla Transformers when allowed to utilize its full computational budget,
while improving significantly over computationally equivalent baselines when
operating on smaller computational budgets.
</summary>
    <author>
      <name>Ankur Bapna</name>
    </author>
    <author>
      <name>Naveen Arivazhagan</name>
    </author>
    <author>
      <name>Orhan Firat</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06960v2</id>
    <updated>2020-03-04T12:18:40Z</updated>
    <published>2020-02-17T13:58:08Z</published>
    <title>Computing rank-revealing factorizations of matrices stored out-of-core</title>
    <summary>  This paper describes efficient algorithms for computing rank-revealing
factorizations of matrices that are too large to fit in RAM, and must instead
be stored on slow external memory devices such as solid-state or spinning disk
hard drives (out-of-core or out-of-memory). Traditional algorithms for
computing rank revealing factorizations, such as the column pivoted QR
factorization, or techniques for computing a full singular value decomposition
of a matrix, are very communication intensive. They are naturally expressed as
a sequence of matrix-vector operations, which become prohibitively expensive
when data is not available in main memory. Randomization allows these methods
to be reformulated so that large contiguous blocks of the matrix can be
processed in bulk. The paper describes two distinct methods. The first is a
blocked version of column pivoted Householder QR, organized as a "left-looking"
method to minimize the number of write operations (which are more expensive
than read operations on a spinning disk drive). The second method results in a
so called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where
$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an
algorithm-by-blocks, in which floating point operations overlap read and write
operations. The second method incorporates power iterations, and is
exceptionally good at revealing the numerical rank; it can often be used as a
substitute for a full singular value decomposition. Numerical experiments
demonstrate that the new algorithms are almost as fast when processing data
stored on a hard drive as traditional algorithms are for data stored in main
memory. To be precise, the computational time for fully factorizing an $n\times
n$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only
marginally larger when the matrix is stored out of core.
</summary>
    <author>
      <name>Nathan Heavner</name>
    </author>
    <author>
      <name>Per-Gunnar Martinsson</name>
    </author>
    <author>
      <name>Gregorio Quintana-Ortí</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 11 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06960v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06960v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.4; C.4; D.1.3; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06854v1</id>
    <updated>2020-02-17T09:30:52Z</updated>
    <published>2020-02-17T09:30:52Z</published>
    <title>HotelRec: a Novel Very Large-Scale Hotel Recommendation Dataset</title>
    <summary>  Today, recommender systems are an inevitable part of everyone's daily digital
routine and are present on most internet platforms. State-of-the-art deep
learning-based models require a large number of data to achieve their best
performance. Many datasets fulfilling this criterion have been proposed for
multiple domains, such as Amazon products, restaurants, or beers. However,
works and datasets in the hotel domain are limited: the largest hotel review
dataset is below the million samples. Additionally, the hotel domain suffers
from a higher data sparsity than traditional recommendation datasets and
therefore, traditional collaborative-filtering approaches cannot be applied to
such data. In this paper, we propose HotelRec, a very large-scale hotel
recommendation dataset, based on TripAdvisor, containing 50 million reviews. To
the best of our knowledge, HotelRec is the largest publicly available dataset
in the hotel domain (50M versus 0.9M) and additionally, the largest
recommendation dataset in a single domain and with textual reviews (50M versus
22M). We release HotelRec for further research:
https://github.com/Diego999/HotelRec.
</summary>
    <author>
      <name>Diego Antognini</name>
    </author>
    <author>
      <name>Boi Faltings</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figure, 5 tables. Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06851v1</id>
    <updated>2020-02-17T09:25:19Z</updated>
    <published>2020-02-17T09:25:19Z</published>
    <title>GameWikiSum: a Novel Large Multi-Document Summarization Dataset</title>
    <summary>  Today's research progress in the field of multi-document summarization is
obstructed by the small number of available datasets. Since the acquisition of
reference summaries is costly, existing datasets contain only hundreds of
samples at most, resulting in heavy reliance on hand-crafted features or
necessitating additional, manually annotated data. The lack of large corpora
therefore hinders the development of sophisticated models. Additionally, most
publicly available multi-document summarization corpora are in the news domain,
and no analogous dataset exists in the video game domain. In this paper, we
propose GameWikiSum, a new domain-specific dataset for multi-document
summarization, which is one hundred times larger than commonly used datasets,
and in another domain than news. Input documents consist of long professional
video game reviews as well as references of their gameplay sections in
Wikipedia pages. We analyze the proposed dataset and show that both abstractive
and extractive models can be trained on it. We release GameWikiSum for further
research: https://github.com/Diego999/GameWikiSum.
</summary>
    <author>
      <name>Diego Antognini</name>
    </author>
    <author>
      <name>Boi Faltings</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, 4 tables. Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06823v1</id>
    <updated>2020-02-17T08:13:36Z</updated>
    <published>2020-02-17T08:13:36Z</published>
    <title>Incorporating BERT into Neural Machine Translation</title>
    <summary>  The recently proposed BERT has shown great power on a variety of natural
language understanding tasks, such as text classification, reading
comprehension, etc. However, how to effectively apply BERT to neural machine
translation (NMT) lacks enough exploration. While BERT is more commonly used as
fine-tuning instead of contextual embedding for downstream language
understanding tasks, in NMT, our preliminary exploration of using BERT as
contextual embedding is better than using for fine-tuning. This motivates us to
think how to better leverage BERT for NMT along this direction. We propose a
new algorithm named BERT-fused model, in which we first use BERT to extract
representations for an input sequence, and then the representations are fused
with each layer of the encoder and decoder of the NMT model through attention
mechanisms. We conduct experiments on supervised (including sentence-level and
document-level translations), semi-supervised and unsupervised machine
translation, and achieve state-of-the-art results on seven benchmark datasets.
Our code is available at \url{https://github.com/bert-nmt/bert-nmt}.
</summary>
    <author>
      <name>Jinhua Zhu</name>
    </author>
    <author>
      <name>Yingce Xia</name>
    </author>
    <author>
      <name>Lijun Wu</name>
    </author>
    <author>
      <name>Di He</name>
    </author>
    <author>
      <name>Tao Qin</name>
    </author>
    <author>
      <name>Wengang Zhou</name>
    </author>
    <author>
      <name>Houqiang Li</name>
    </author>
    <author>
      <name>Tie-Yan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06714v1</id>
    <updated>2020-02-16T23:53:07Z</updated>
    <published>2020-02-16T23:53:07Z</published>
    <title>Multi-layer Representation Fusion for Neural Machine Translation</title>
    <summary>  Neural machine translation systems require a number of stacked layers for
deep models. But the prediction depends on the sentence representation of the
top-most layer with no access to low-level representations. This makes it more
difficult to train the model and poses a risk of information loss to
prediction. In this paper, we propose a multi-layer representation fusion
(MLRF) approach to fusing stacked layers. In particular, we design three fusion
functions to learn a better representation from the stack. Experimental results
show that our approach yields improvements of 0.92 and 0.56 BLEU points over
the strong Transformer baseline on IWSLT German-English and NIST
Chinese-English MT tasks respectively. The result is new state-of-the-art in
German-English translation.
</summary>
    <author>
      <name>Qiang Wang</name>
    </author>
    <author>
      <name>Fuxue Li</name>
    </author>
    <author>
      <name>Tong Xiao</name>
    </author>
    <author>
      <name>Yanyang Li</name>
    </author>
    <author>
      <name>Yinqiao Li</name>
    </author>
    <author>
      <name>Jingbo Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">COLING 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06701v1</id>
    <updated>2020-02-16T23:03:32Z</updated>
    <published>2020-02-16T23:03:32Z</published>
    <title>Gaussian Smoothen Semantic Features (GSSF) -- Exploring the Linguistic
  Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO
  Framework</title>
    <summary>  In this work, we have introduced Gaussian Smoothen Semantic Features (GSSF)
for Better Semantic Selection for Indian regional language-based image
captioning and introduced a procedure where we used the existing translation
and English crowd-sourced sentences for training. We have shown that this
architecture is a promising alternative source, where there is a crunch in
resources. Our main contribution of this work is the development of deep
learning architectures for the Bengali language (is the fifth widely spoken
language in the world) with a completely different grammar and language
attributes. We have shown that these are working well for complex applications
like language generation from image contexts and can diversify the
representation through introducing constraints, more extensive features, and
unique feature spaces. We also established that we could achieve absolute
precision and diversity when we use smoothened semantic tensor with the
traditional LSTM and feature decomposition networks. With better learning
architecture, we succeeded in establishing an automated algorithm and
assessment procedure that can help in the evaluation of competent applications
without the requirement for expertise and human intervention.
</summary>
    <author>
      <name>Chiranjib Sur</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06675v2</id>
    <updated>2020-02-19T15:35:10Z</updated>
    <published>2020-02-16T20:44:11Z</published>
    <title>Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language</title>
    <summary>  Ainu is an unwritten language that has been spoken by Ainu people who are one
of the ethnic groups in Japan. It is recognized as critically endangered by
UNESCO and archiving and documentation of its language heritage is of paramount
importance. Although a considerable amount of voice recordings of Ainu folklore
has been produced and accumulated to save their culture, only a quite limited
parts of them are transcribed so far. Thus, we started a project of automatic
speech recognition (ASR) for the Ainu language in order to contribute to the
development of annotated language archives. In this paper, we report speech
corpus development and the structure and performance of end-to-end ASR for
Ainu. We investigated four modeling units (phone, syllable, word piece, and
word) and found that the syllable-based model performed best in terms of both
word and phone recognition accuracy, which were about 60% and over 85%
respectively in speaker-open condition. Furthermore, word and phone accuracy of
80% and 90% has been achieved in a speaker-closed setting. We also found out
that a multilingual ASR training with additional speech corpora of English and
Japanese further improves the speaker-open test accuracy.
</summary>
    <author>
      <name>Kohei Matsuura</name>
    </author>
    <author>
      <name>Sei Ueno</name>
    </author>
    <author>
      <name>Masato Mimura</name>
    </author>
    <author>
      <name>Shinsuke Sakai</name>
    </author>
    <author>
      <name>Tatsuya Kawahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ver. 2</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06675v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06675v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06670v1</id>
    <updated>2020-02-16T20:20:38Z</updated>
    <published>2020-02-16T20:20:38Z</published>
    <title>The Utility of General Domain Transfer Learning for Medical Language
  Tasks</title>
    <summary>  The purpose of this study is to analyze the efficacy of transfer learning
techniques and transformer-based models as applied to medical natural language
processing (NLP) tasks, specifically radiological text classification. We used
1,977 labeled head CT reports, from a corpus of 96,303 total reports, to
evaluate the efficacy of pretraining using general domain corpora and a
combined general and medical domain corpus with a bidirectional representations
from transformers (BERT) model for the purpose of radiological text
classification. Model performance was benchmarked to a logistic regression
using bag-of-words vectorization and a long short-term memory (LSTM)
multi-label multi-class classification model, and compared to the published
literature in medical text classification. The BERT models using either set of
pretrained checkpoints outperformed the logistic regression model, achieving
sample-weighted average F1-scores of 0.87 and 0.87 for the general domain model
and the combined general and biomedical-domain model. General text transfer
learning may be a viable technique to generate state-of-the-art results within
medical NLP tasks on radiological corpora, outperforming other deep models such
as LSTMs. The efficacy of pretraining and transformer-based models could serve
to facilitate the creation of groundbreaking NLP models in the uniquely
challenging data environment of medical text.
</summary>
    <author>
      <name>Daniel Ranti</name>
    </author>
    <author>
      <name>Katie Hanss</name>
    </author>
    <author>
      <name>Shan Zhao</name>
    </author>
    <author>
      <name>Varun Arvind</name>
    </author>
    <author>
      <name>Joseph Titano</name>
    </author>
    <author>
      <name>Anthony Costa</name>
    </author>
    <author>
      <name>Eric Oermann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06652v1</id>
    <updated>2020-02-16T19:02:52Z</updated>
    <published>2020-02-16T19:02:52Z</published>
    <title>SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word
  Models</title>
    <summary>  Sentence embedding is an important research topic in natural language
processing (NLP) since it can transfer knowledge to downstream tasks.
Meanwhile, a contextualized word representation, called BERT, achieves the
state-of-the-art performance in quite a few NLP tasks. Yet, it is an open
problem to generate a high quality sentence representation from BERT-based word
models. It was shown in previous study that different layers of BERT capture
different linguistic properties. This allows us to fusion information across
layers to find better sentence representation. In this work, we study the
layer-wise pattern of the word representation of deep contextualized models.
Then, we propose a new sentence embedding method by dissecting BERT-based word
models through geometric analysis of the space spanned by the word
representation. It is called the SBERT-WK method. No further training is
required in SBERT-WK. We evaluate SBERT-WK on semantic textual similarity and
downstream supervised tasks. Furthermore, ten sentence-level probing tasks are
presented for detailed linguistic analysis. Experiments show that SBERT-WK
achieves the state-of-the-art performance. Our codes are publicly available.
</summary>
    <author>
      <name>Bin Wang</name>
    </author>
    <author>
      <name>C. -C. Jay Kuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figure, 8 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06644v1</id>
    <updated>2020-02-16T18:39:16Z</updated>
    <published>2020-02-16T18:39:16Z</published>
    <title>Towards Detection of Subjective Bias using Contextualized Word
  Embeddings</title>
    <summary>  Subjective bias detection is critical for applications like propaganda
detection, content recommendation, sentiment analysis, and bias neutralization.
This bias is introduced in natural language via inflammatory words and phrases,
casting doubt over facts, and presupposing the truth. In this work, we perform
comprehensive experiments for detecting subjective bias using BERT-based models
on the Wiki Neutrality Corpus(WNC). The dataset consists of $360k$ labeled
instances, from Wikipedia edits that remove various instances of the bias. We
further propose BERT-based ensembles that outperform state-of-the-art methods
like $BERT_{large}$ by a margin of $5.6$ F1 score.
</summary>
    <author>
      <name>Tanvi Dadu</name>
    </author>
    <author>
      <name>Kartikey Pant</name>
    </author>
    <author>
      <name>Radhika Mamidi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Companion Proceedings of the Web Conference 2020 (WWW
  '20 Companion)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06612v1</id>
    <updated>2020-02-16T16:24:39Z</updated>
    <published>2020-02-16T16:24:39Z</published>
    <title>Text-based Question Answering from Information Retrieval and Deep Neural
  Network Perspectives: A Survey</title>
    <summary>  Text-based Question Answering (QA) is a challenging task which aims at
finding short concrete answers for users' questions. This line of research has
been widely studied with information retrieval techniques and has received
increasing attention in recent years by considering deep neural network
approaches. Deep learning approaches, which are the main focus of this paper,
provide a powerful technique to learn multiple layers of representations and
interaction between questions and texts. In this paper, we provide a
comprehensive overview of different models proposed for the QA task, including
both traditional information retrieval perspective, and more recent deep neural
network perspective. We also introduce well-known datasets for the task and
present available results from the literature to have a comparison between
different techniques.
</summary>
    <author>
      <name>Zahra Abbasiyantaeb</name>
    </author>
    <author>
      <name>Saeedeh Momtazi</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06546v2</id>
    <updated>2020-02-18T01:59:03Z</updated>
    <published>2020-02-16T09:42:01Z</published>
    <title>Neural Machine Translation with Joint Representation</title>
    <summary>  Though early successes of Statistical Machine Translation (SMT) systems are
attributed in part to the explicit modelling of the interaction between any two
source and target units, e.g., alignment, the recent Neural Machine Translation
(NMT) systems resort to the attention which partially encodes the interaction
for efficiency. In this paper, we employ Joint Representation that fully
accounts for each possible interaction. We sidestep the inefficiency issue by
refining representations with the proposed efficient attention operation. The
resulting Reformer models offer a new Sequence-to- Sequence modelling paradigm
besides the Encoder-Decoder framework and outperform the Transformer baseline
in either the small scale IWSLT14 German-English, English-German and IWSLT15
Vietnamese-English or the large scale NIST12 Chinese-English translation tasks
by about 1 BLEU point.We also propose a systematic model scaling approach,
allowing the Reformer model to beat the state-of-the-art Transformer in IWSLT14
German-English and NIST12 Chinese-English with about 50% fewer parameters. The
code is publicly available at https://github.com/lyy1994/reformer.
</summary>
    <author>
      <name>Yanyang Li</name>
    </author>
    <author>
      <name>Qiang Wang</name>
    </author>
    <author>
      <name>Tong Xiao</name>
    </author>
    <author>
      <name>Tongran Liu</name>
    </author>
    <author>
      <name>Jingbo Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06546v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06546v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06544v1</id>
    <updated>2020-02-16T09:22:32Z</updated>
    <published>2020-02-16T09:22:32Z</published>
    <title>Exploring Neural Models for Parsing Natural Language into First-Order
  Logic</title>
    <summary>  Semantic parsing is the task of obtaining machine-interpretable
representations from natural language text. We consider one such formal
representation - First-Order Logic (FOL) and explore the capability of neural
models in parsing English sentences to FOL. We model FOL parsing as a sequence
to sequence mapping task where given a natural language sentence, it is encoded
into an intermediate representation using an LSTM followed by a decoder which
sequentially generates the predicates in the corresponding FOL formula. We
improve the standard encoder-decoder model by introducing a variable alignment
mechanism that enables it to align variables across predicates in the predicted
FOL. We further show the effectiveness of predicting the category of FOL entity
- Unary, Binary, Variables and Scoped Entities, at each decoder step as an
auxiliary task on improving the consistency of generated FOL. We perform
rigorous evaluations and extensive ablations. We also aim to release our code
as well as large scale FOL dataset along with models to aid further research in
logic-based parsing and inference in NLP.
</summary>
    <author>
      <name>Hrituraj Singh</name>
    </author>
    <author>
      <name>Milan Aggrawal</name>
    </author>
    <author>
      <name>Balaji Krishnamurthy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages, 2 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06525v1</id>
    <updated>2020-02-16T07:10:45Z</updated>
    <published>2020-02-16T07:10:45Z</published>
    <title>Learning to Generate Multiple Style Transfer Outputs for an Input
  Sentence</title>
    <summary>  Text style transfer refers to the task of rephrasing a given text in a
different style. While various methods have been proposed to advance the state
of the art, they often assume the transfer output follows a delta distribution,
and thus their models cannot generate different style transfer results for a
given input text. To address the limitation, we propose a one-to-many text
style transfer framework. In contrast to prior works that learn a one-to-one
mapping that converts an input sentence to one output sentence, our approach
learns a one-to-many mapping that can convert an input sentence to multiple
different output sentences, while preserving the input content. This is
achieved by applying adversarial training with a latent decomposition scheme.
Specifically, we decompose the latent representation of the input sentence to a
style code that captures the language style variation and a content code that
encodes the language style-independent content. We then combine the content
code with the style code for generating a style transfer output. By combining
the same content code with a different style code, we generate a different
style transfer output. Extensive experimental results with comparisons to
several text style transfer approaches on multiple public datasets using a
diverse set of performance metrics validate effectiveness of the proposed
approach.
</summary>
    <author>
      <name>Kevin Lin</name>
    </author>
    <author>
      <name>Ming-Yu Liu</name>
    </author>
    <author>
      <name>Ming-Ting Sun</name>
    </author>
    <author>
      <name>Jan Kautz</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06484v1</id>
    <updated>2020-02-16T01:09:41Z</updated>
    <published>2020-02-16T01:09:41Z</published>
    <title>A Multimodal Dialogue System for Conversational Image Editing</title>
    <summary>  In this paper, we present a multimodal dialogue system for Conversational
Image Editing. We formulate our multimodal dialogue system as a Partially
Observed Markov Decision Process (POMDP) and trained it with Deep Q-Network
(DQN) and a user simulator. Our evaluation shows that the DQN policy
outperforms a rule-based baseline policy, achieving 90\% success rate under
high error rates. We also conducted a real user study and analyzed real user
behavior.
</summary>
    <author>
      <name>Tzu-Hsiang Lin</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Doo Soon Kim</name>
    </author>
    <author>
      <name>Jean Oh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at 2nd Conversational AI Workshop at NeurIPS 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06450v1</id>
    <updated>2020-02-15T21:05:07Z</updated>
    <published>2020-02-15T21:05:07Z</published>
    <title>Supervised Phrase-boundary Embeddings</title>
    <summary>  We propose a new word embedding model, called SPhrase, that incorporates
supervised phrase information. Our method modifies traditional word embeddings
by ensuring that all target words in a phrase have exactly the same context. We
demonstrate that including this information within a context window produces
superior embeddings for both intrinsic evaluation tasks and downstream
extrinsic tasks.
</summary>
    <author>
      <name>Manni Singh</name>
    </author>
    <author>
      <name>David Weston</name>
    </author>
    <author>
      <name>Mark Levene</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04808v1</id>
    <updated>2020-02-15T19:03:36Z</updated>
    <published>2020-02-15T19:03:36Z</published>
    <title>Undersensitivity in Neural Reading Comprehension</title>
    <summary>  Current reading comprehension models generalise well to in-distribution test
sets, yet perform poorly on adversarially selected inputs. Most prior work on
adversarial inputs studies oversensitivity: semantically invariant text
perturbations that cause a model's prediction to change when it should not. In
this work we focus on the complementary problem: excessive prediction
undersensitivity, where input text is meaningfully changed but the model's
prediction does not, even though it should. We formulate a noisy adversarial
attack which searches among semantic variations of the question for which a
model erroneously predicts the same answer, and with even higher probability.
Despite comprising unanswerable questions, both SQuAD2.0 and NewsQA models are
vulnerable to this attack. This indicates that although accurate, models tend
to rely on spurious patterns and do not fully consider the information
specified in a question. We experiment with data augmentation and adversarial
training as defences, and find that both substantially decrease vulnerability
to attacks on held out data, as well as held out attack spaces. Addressing
undersensitivity also improves results on AddSent and AddOneSent, and models
furthermore generalise better when facing train/evaluation distribution
mismatch: they are less prone to overly rely on predictive cues present only in
the training set, and outperform a conventional model by as much as 10.9% F1.
</summary>
    <author>
      <name>Johannes Welbl</name>
    </author>
    <author>
      <name>Pasquale Minervini</name>
    </author>
    <author>
      <name>Max Bartolo</name>
    </author>
    <author>
      <name>Pontus Stenetorp</name>
    </author>
    <author>
      <name>Sebastian Riedel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06424v1</id>
    <updated>2020-02-15T18:34:52Z</updated>
    <published>2020-02-15T18:34:52Z</published>
    <title>Deeper Task-Specificity Improves Joint Entity and Relation Extraction</title>
    <summary>  Multi-task learning (MTL) is an effective method for learning related tasks,
but designing MTL models necessitates deciding which and how many parameters
should be task-specific, as opposed to shared between tasks. We investigate
this issue for the problem of jointly learning named entity recognition (NER)
and relation extraction (RE) and propose a novel neural architecture that
allows for deeper task-specificity than does prior work. In particular, we
introduce additional task-specific bidirectional RNN layers for both the NER
and RE tasks and tune the number of shared and task-specific layers separately
for different datasets. We achieve state-of-the-art (SOTA) results for both
tasks on the ADE dataset; on the CoNLL04 dataset, we achieve SOTA results on
the NER task and competitive results on the RE task while using an order of
magnitude fewer trainable parameters than the current SOTA architecture. An
ablation study confirms the importance of the additional task-specific layers
for achieving these results. Our work suggests that previous solutions to joint
NER and RE undervalue task-specificity and demonstrates the importance of
correctly balancing the number of shared and task-specific parameters for MTL
approaches in general.
</summary>
    <author>
      <name>Phil Crone</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06397v2</id>
    <updated>2020-02-19T14:42:41Z</updated>
    <published>2020-02-15T15:25:44Z</published>
    <title>Open Knowledge Enrichment for Long-tail Entities</title>
    <summary>  Knowledge bases (KBs) have gradually become a valuable asset for many AI
applications. While many current KBs are quite large, they are widely
acknowledged as incomplete, especially lacking facts of long-tail entities,
e.g., less famous persons. Existing approaches enrich KBs mainly on completing
missing links or filling missing values. However, they only tackle a part of
the enrichment problem and lack specific considerations regarding long-tail
entities. In this paper, we propose a full-fledged approach to knowledge
enrichment, which predicts missing properties and infers true facts of
long-tail entities from the open Web. Prior knowledge from popular entities is
leveraged to improve every enrichment step. Our experiments on the synthetic
and real-world datasets and comparison with related work demonstrate the
feasibility and superiority of the approach.
</summary>
    <author>
      <name>Ermei Cao</name>
    </author>
    <author>
      <name>Difeng Wang</name>
    </author>
    <author>
      <name>Jiacheng Huang</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 29th International World Wide Web Conference (WWW
  2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06397v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06397v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06353v1</id>
    <updated>2020-02-15T10:03:25Z</updated>
    <published>2020-02-15T10:03:25Z</published>
    <title>UniViLM: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation</title>
    <summary>  We propose UniViLM: a Unified Video and Language pre-training Model for
multimodal understanding and generation. Motivated by the recent success of
BERT based pre-training technique for NLP and image-language tasks, VideoBERT
and CBT are proposed to exploit BERT model for video and language pre-training
using narrated instructional videos. Different from their works which only
pre-train understanding task, we propose a unified video-language pre-training
model for both understanding and generation tasks. Our model comprises of 4
components including two single-modal encoders, a cross encoder and a decoder
with the Transformer backbone. We first pre-train our model to learn the
universal representation for both video and language on a large instructional
video dataset. Then we fine-tune the model on two multimodal tasks including
understanding task (text-based video retrieval) and generation task (multimodal
video captioning). Our extensive experiments show that our method can improve
the performance of both understanding and generation tasks and achieves the
state-of-the art results.
</summary>
    <author>
      <name>Huaishao Luo</name>
    </author>
    <author>
      <name>Lei Ji</name>
    </author>
    <author>
      <name>Botian Shi</name>
    </author>
    <author>
      <name>Haoyang Huang</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Tianrui Li</name>
    </author>
    <author>
      <name>Xilin Chen</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06305v1</id>
    <updated>2020-02-15T02:40:10Z</updated>
    <published>2020-02-15T02:40:10Z</published>
    <title>Fine-Tuning Pretrained Language Models: Weight Initializations, Data
  Orders, and Early Stopping</title>
    <summary>  Fine-tuning pretrained contextual word embedding models to supervised
downstream tasks has become commonplace in natural language processing. This
process, however, is often brittle: even with the same hyperparameter values,
distinct random seeds can lead to substantially different results. To better
understand this phenomenon, we experiment with four datasets from the GLUE
benchmark, fine-tuning BERT hundreds of times on each while varying only the
random seeds. We find substantial performance increases compared to previously
reported results, and we quantify how the performance of the best-found model
varies as a function of the number of fine-tuning trials. Further, we examine
two factors influenced by the choice of random seed: weight initialization and
training data order. We find that both contribute comparably to the variance of
out-of-sample performance, and that some weight initializations perform well
across all tasks explored. On small datasets, we observe that many fine-tuning
trials diverge part of the way through training, and we offer best practices
for practitioners to stop training less promising runs early. We publicly
release all of our experimental data, including training and validation scores
for 2,100 trials, to encourage further analysis of training dynamics during
fine-tuning.
</summary>
    <author>
      <name>Jesse Dodge</name>
    </author>
    <author>
      <name>Gabriel Ilharco</name>
    </author>
    <author>
      <name>Roy Schwartz</name>
    </author>
    <author>
      <name>Ali Farhadi</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <author>
      <name>Noah Smith</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06235v1</id>
    <updated>2020-02-14T20:02:11Z</updated>
    <published>2020-02-14T20:02:11Z</published>
    <title>Semantic Relatedness and Taxonomic Word Embeddings</title>
    <summary>  This paper connects a series of papers dealing with taxonomic word
embeddings. It begins by noting that there are different types of semantic
relatedness and that different lexical representations encode different forms
of relatedness. A particularly important distinction within semantic
relatedness is that of thematic versus taxonomic relatedness. Next, we present
a number of experiments that analyse taxonomic embeddings that have been
trained on a synthetic corpus that has been generated via a random walk over a
taxonomy. These experiments demonstrate how the properties of the synthetic
corpus, such as the percentage of rare words, are affected by the shape of the
knowledge graph the corpus is generated from. Finally, we explore the
interactions between the relative sizes of natural and synthetic corpora on the
performance of embeddings when taxonomic and thematic embeddings are combined.
</summary>
    <author>
      <name>Magdalena Kacmajor</name>
    </author>
    <author>
      <name>John D. Kelleher</name>
    </author>
    <author>
      <name>Filip Klubicka</name>
    </author>
    <author>
      <name>Alfredo Maldonado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06170v1</id>
    <updated>2020-02-14T18:41:58Z</updated>
    <published>2020-02-14T18:41:58Z</published>
    <title>Transformer on a Diet</title>
    <summary>  Transformer has been widely used thanks to its ability to capture sequence
information in an efficient way. However, recent developments, such as BERT and
GPT-2, deliver only heavy architectures with a focus on effectiveness. In this
paper, we explore three carefully-designed light Transformer architectures to
figure out whether the Transformer with less computations could produce
competitive results. Experimental results on language model benchmark datasets
hint that such trade-off is promising, and the light Transformer reduces 70%
parameters at best, while obtains competitive perplexity compared to standard
Transformer. The source code is publicly available.
</summary>
    <author>
      <name>Chenguang Wang</name>
    </author>
    <author>
      <name>Zihao Ye</name>
    </author>
    <author>
      <name>Aston Zhang</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Alexander J. Smola</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 tables, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06165v1</id>
    <updated>2020-02-14T18:31:31Z</updated>
    <published>2020-02-14T18:31:31Z</published>
    <title>Unsupervised Speaker Adaptation using Attention-based Speaker Memory for
  End-to-End ASR</title>
    <summary>  We propose an unsupervised speaker adaptation method inspired by the neural
Turing machine for end-to-end (E2E) automatic speech recognition (ASR). The
proposed model contains a memory block that holds speaker i-vectors extracted
from the training data and reads relevant i-vectors from the memory through an
attention mechanism. The resulting memory vector (M-vector) is concatenated to
the acoustic features or to the hidden layer activations of an E2E neural
network model. The E2E ASR system is based on the joint connectionist temporal
classification and attention-based encoder-decoder architecture. M-vector and
i-vector results are compared for inserting them at different layers of the
encoder neural network using the WSJ and TED-LIUM2 ASR benchmarks. We show that
M-vectors, which do not require an auxiliary speaker embedding extraction
system at test time, achieve similar word error rates (WERs) compared to
i-vectors for single speaker utterances and significantly lower WERs for
utterances in which there are speaker changes.
</summary>
    <author>
      <name>Leda Sarı</name>
    </author>
    <author>
      <name>Niko Moritz</name>
    </author>
    <author>
      <name>Takaaki Hori</name>
    </author>
    <author>
      <name>Jonathan Le Roux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proc. ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06144v1</id>
    <updated>2020-02-14T17:56:18Z</updated>
    <published>2020-02-14T17:56:18Z</published>
    <title>Combining Visual and Textual Features for Semantic Segmentation of
  Historical Newspapers</title>
    <summary>  The massive amounts of digitized historical documents acquired over the last
decades naturally lend themselves to automatic processing and exploration.
Research work seeking to automatically process facsimiles and extract
information thereby are multiplying with, as a first essential step, document
layout analysis. If the identification and categorization of segments of
interest in document images have seen significant progress over the last years
thanks to deep learning techniques, many challenges remain with, among others,
the use of finer-grained segmentation typologies and the consideration of
complex, heterogeneous documents such as historical newspapers. Besides, most
approaches consider visual features only, ignoring textual signal. In this
context, we introduce a multimodal approach for the semantic segmentation of
historical newspapers that combines visual and textual features. Based on a
series of experiments on diachronic Swiss and Luxembourgish newspapers, we
investigate, among others, the predictive power of visual and textual features
and their capacity to generalize across time and sources. Results show
consistent improvement of multimodal models in comparison to a strong visual
baseline, as well as better robustness to high material variance.
</summary>
    <author>
      <name>Raphaël Barman</name>
    </author>
    <author>
      <name>Maud Ehrmann</name>
    </author>
    <author>
      <name>Simon Clematide</name>
    </author>
    <author>
      <name>Sofia Ares Oliveira</name>
    </author>
    <author>
      <name>Frédéric Kaplan</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06115v1</id>
    <updated>2020-02-14T16:32:19Z</updated>
    <published>2020-02-14T16:32:19Z</published>
    <title>Scalable Neural Methods for Reasoning With a Symbolic Knowledge Base</title>
    <summary>  We describe a novel way of representing a symbolic knowledge base (KB) called
a sparse-matrix reified KB. This representation enables neural modules that are
fully differentiable, faithful to the original semantics of the KB, expressive
enough to model multi-hop inferences, and scalable enough to use with
realistically large KBs. The sparse-matrix reified KB can be distributed across
multiple GPUs, can scale to tens of millions of entities and facts, and is
orders of magnitude faster than naive sparse-matrix implementations. The
reified KB enables very simple end-to-end architectures to obtain competitive
performance on several benchmarks representing two families of tasks: KB
completion, and learning semantic parsers from denotations.
</summary>
    <author>
      <name>William W. Cohen</name>
    </author>
    <author>
      <name>Haitian Sun</name>
    </author>
    <author>
      <name>R. Alex Hofer</name>
    </author>
    <author>
      <name>Matthew Siegler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Also published in ICLR2020
  https://openreview.net/forum?id=BJlguT4YPr&amp;noteId=BJlguT4YPr</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06071v1</id>
    <updated>2020-02-14T15:23:38Z</updated>
    <published>2020-02-14T15:23:38Z</published>
    <title>FQuAD: French Question Answering Dataset</title>
    <summary>  Recent advances in the field of language modeling have improved
state-of-the-art results on many Natural Language Processing tasks. Among them,
the Machine Reading Comprehension task has made significant progress. However,
most of the results are reported in English since labeled resources available
in other languages, such as French, remain scarce. In the present work, we
introduce the French Question Answering Dataset (FQuAD). FQuAD is French Native
Reading Comprehension dataset that consists of 25,000+ questions on a set of
Wikipedia articles. A baseline model is trained which achieves an F1 score of
88.0% and an exact match ratio of 77.9% on the test set. The dataset is made
freely available at https://fquad.illuin.tech.
</summary>
    <author>
      <name>Martin d'Hoffschmidt</name>
    </author>
    <author>
      <name>Maxime Vidal</name>
    </author>
    <author>
      <name>Wacim Belblidia</name>
    </author>
    <author>
      <name>Tom Brendlé</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06033v1</id>
    <updated>2020-02-14T13:34:33Z</updated>
    <published>2020-02-14T13:34:33Z</published>
    <title>Deep Speaker Embeddings for Far-Field Speaker Recognition on Short
  Utterances</title>
    <summary>  Speaker recognition systems based on deep speaker embeddings have achieved
significant performance in controlled conditions according to the results
obtained for early NIST SRE (Speaker Recognition Evaluation) datasets. From the
practical point of view, taking into account the increased interest in virtual
assistants (such as Amazon Alexa, Google Home, AppleSiri, etc.), speaker
verification on short utterances in uncontrolled noisy environment conditions
is one of the most challenging and highly demanded tasks. This paper presents
approaches aimed to achieve two goals: a) improve the quality of far-field
speaker verification systems in the presence of environmental noise,
reverberation and b) reduce the system qualitydegradation for short utterances.
For these purposes, we considered deep neural network architectures based on
TDNN (TimeDelay Neural Network) and ResNet (Residual Neural Network) blocks. We
experimented with state-of-the-art embedding extractors and their training
procedures. Obtained results confirm that ResNet architectures outperform the
standard x-vector approach in terms of speaker verification quality for both
long-duration and short-duration utterances. We also investigate the impact of
speech activity detector, different scoring models, adaptation and score
normalization techniques. The experimental results are presented for publicly
available data and verification protocols for the VoxCeleb1, VoxCeleb2, and
VOiCES datasets.
</summary>
    <author>
      <name>Aleksei Gusev</name>
    </author>
    <author>
      <name>Vladimir Volokhov</name>
    </author>
    <author>
      <name>Tseren Andzhukaev</name>
    </author>
    <author>
      <name>Sergey Novoselov</name>
    </author>
    <author>
      <name>Galina Lavrentyeva</name>
    </author>
    <author>
      <name>Marina Volkova</name>
    </author>
    <author>
      <name>Alice Gazizullina</name>
    </author>
    <author>
      <name>Andrey Shulipa</name>
    </author>
    <author>
      <name>Artem Gorlanov</name>
    </author>
    <author>
      <name>Anastasia Avdeeva</name>
    </author>
    <author>
      <name>Artem Ivanov</name>
    </author>
    <author>
      <name>Alexander Kozlov</name>
    </author>
    <author>
      <name>Timur Pekhovsky</name>
    </author>
    <author>
      <name>Yuri Matveev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Odyssey 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06012v1</id>
    <updated>2020-02-14T13:09:11Z</updated>
    <published>2020-02-14T13:09:11Z</published>
    <title>Dialogue history integration into end-to-end signal-to-concept spoken
  language understanding systems</title>
    <summary>  This work investigates the embeddings for representing dialog history in
spoken language understanding (SLU) systems. We focus on the scenario when the
semantic information is extracted directly from the speech signal by means of a
single end-to-end neural network model. We proposed to integrate dialogue
history into an end-to-end signal-to-concept SLU system. The dialog history is
represented in the form of dialog history embedding vectors (so-called
h-vectors) and is provided as an additional information to end-to-end SLU
models in order to improve the system performance. Three following types of
h-vectors are proposed and experimentally evaluated in this paper: (1)
supervised-all embeddings predicting bag-of-concepts expected in the answer of
the user from the last dialog system response; (2) supervised-freq embeddings
focusing on predicting only a selected set of semantic concept (corresponding
to the most frequent errors in our experiments); and (3) unsupervised
embeddings. Experiments on the MEDIA corpus for the semantic slot filling task
demonstrate that the proposed h-vectors improve the model performance.
</summary>
    <author>
      <name>Natalia Tomashenko</name>
    </author>
    <author>
      <name>Christian Raymond</name>
    </author>
    <author>
      <name>Antoine Caubriere</name>
    </author>
    <author>
      <name>Renato De Mori</name>
    </author>
    <author>
      <name>Yannick Esteve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for ICASSP 2020 (Submitted: October 21, 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05969v2</id>
    <updated>2020-02-29T03:59:06Z</updated>
    <published>2020-02-14T11:20:10Z</published>
    <title>Query2box: Reasoning over Knowledge Graphs in Vector Space using Box
  Embeddings</title>
    <summary>  Answering complex logical queries on large-scale incomplete knowledge graphs
(KGs) is a fundamental yet challenging task. Recently, a promising approach to
this problem has been to embed KG entities as well as the query into a vector
space such that entities that answer the query are embedded close to the query.
However, prior work models queries as single points in the vector space, which
is problematic because a complex query represents a potentially large set of
its answer entities, but it is unclear how such a set can be represented as a
single point. Furthermore, prior work can only handle queries that use
conjunctions ($\wedge$) and existential quantifiers ($\exists$). Handling
queries with logical disjunctions ($\vee$) remains an open problem. Here we
propose query2box, an embedding-based framework for reasoning over arbitrary
queries with $\wedge$, $\vee$, and $\exists$ operators in massive and
incomplete KGs. Our main insight is that queries can be embedded as boxes
(i.e., hyper-rectangles), where a set of points inside the box corresponds to a
set of answer entities of the query. We show that conjunctions can be naturally
represented as intersections of boxes and also prove a negative result that
handling disjunctions would require embedding with dimension proportional to
the number of KG entities. However, we show that by transforming queries into a
Disjunctive Normal Form, query2box is capable of handling arbitrary logical
queries with $\wedge$, $\vee$, $\exists$ in a scalable manner. We demonstrate
the effectiveness of query2box on three large KGs and show that query2box
achieves up to 25% relative improvement over the state of the art.
</summary>
    <author>
      <name>Hongyu Ren</name>
    </author>
    <author>
      <name>Weihua Hu</name>
    </author>
    <author>
      <name>Jure Leskovec</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05969v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05969v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05967v1</id>
    <updated>2020-02-14T11:05:11Z</updated>
    <published>2020-02-14T11:05:11Z</published>
    <title>Integrating Discrete and Neural Features via Mixed-feature
  Trans-dimensional Random Field Language Models</title>
    <summary>  There has been a long recognition that discrete features (n-gram features)
and neural network based features have complementary strengths for language
models (LMs). Improved performance can be obtained by model interpolation,
which is, however, a suboptimal two-step integration of discrete and neural
features. The trans-dimensional random field (TRF) framework has the potential
advantage of being able to flexibly integrate a richer set of features.
However, either discrete or neural features are used alone in previous TRF LMs.
This paper develops a mixed-feature TRF LM and demonstrates its advantage in
integrating discrete and neural features. Various LMs are trained over PTB and
Google one-billion-word datasets, and evaluated in N-best list rescoring
experiments for speech recognition. Among all single LMs (i.e. without model
interpolation), the mixed-feature TRF LMs perform the best, improving over both
discrete TRF LMs and neural TRF LMs alone, and also being significantly better
than LSTM LMs. Compared to interpolating two separately trained models with
discrete and neural features respectively, the performance of mixed-feature TRF
LMs matches the best interpolated model, and with simplified one-step training
process and reduced training time.
</summary>
    <author>
      <name>Silin Gao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tsinghua University</arxiv:affiliation>
    </author>
    <author>
      <name>Zhijian Ou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tsinghua University</arxiv:affiliation>
    </author>
    <author>
      <name>Wei Yang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">State Grid Customer Service Center</arxiv:affiliation>
    </author>
    <author>
      <name>Huifang Xu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">China Electric Power Research Institute</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05955v1</id>
    <updated>2020-02-14T10:24:42Z</updated>
    <published>2020-02-14T10:24:42Z</published>
    <title>A Data Efficient End-To-End Spoken Language Understanding Architecture</title>
    <summary>  End-to-end architectures have been recently proposed for spoken language
understanding (SLU) and semantic parsing. Based on a large amount of data,
those models learn jointly acoustic and linguistic-sequential features. Such
architectures give very good results in the context of domain, intent and slot
detection, their application in a more complex semantic chunking and tagging
task is less easy. For that, in many cases, models are combined with an
external language model to enhance their performance.
  In this paper we introduce a data efficient system which is trained
end-to-end, with no additional, pre-trained external module. One key feature of
our approach is an incremental training procedure where acoustic, language and
semantic models are trained sequentially one after the other. The proposed
model has a reasonable size and achieves competitive results with respect to
state-of-the-art while using a small training dataset. In particular, we reach
24.02% Concept Error Rate (CER) on MEDIA/test while training on MEDIA/train
without any additional data.
</summary>
    <author>
      <name>Marco Dinarelli</name>
    </author>
    <author>
      <name>Nikita Kapoor</name>
    </author>
    <author>
      <name>Bassam Jabaian</name>
    </author>
    <author>
      <name>Laurent Besacier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11623v2</id>
    <updated>2020-03-04T10:10:25Z</updated>
    <published>2020-02-14T09:51:24Z</published>
    <title>Trends of digitalization and adoption of big data &amp; analytics among UK
  SMEs: Analysis and lessons drawn from a case study of 53 SMEs</title>
    <summary>  Small and Medium Enterprises (SMEs) now generate digital data at an
unprecedented rate from online transactions, social media marketing and
associated customer interactions, online product or service reviews and
feedback, clinical diagnosis, Internet of Things (IoT) sensors, and production
processes. All these forms of data can be transformed into monetary value if
put into a proper data value chain. This requires both skills and IT
investments for the long-term benefit of businesses. However, such spending is
beyond the capacity of most SMEs due to their limited resources and restricted
access to finances. This paper presents lessons learned from a case study of 53
UK SMEs, mostly from the West Midlands region of England, supported as part of
a 3-year ERDF project, Big Data Corridor, in the areas of big data management,
analytics and related IT issues. Based on our study's sample companies, several
perspectives including the digital technology trends, challenges facing the UK
SMEs, and the state of their adoption in data analytics and big data, are
presented in the paper.
</summary>
    <author>
      <name>Muhidin Mohamed</name>
    </author>
    <author>
      <name>Philip Weber</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11623v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11623v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05923v1</id>
    <updated>2020-02-14T09:04:18Z</updated>
    <published>2020-02-14T09:04:18Z</published>
    <title>Zero-Resource Cross-Domain Named Entity Recognition</title>
    <summary>  Existing models for cross-domain named entity recognition (NER) rely on
numerous unlabeled corpus or labeled NER training data in target domains.
However, collecting data for low-resource target domains is not only expensive
but also time-consuming. Hence, we propose a cross-domain NER model that does
not use any external resources. We first introduce Multi-Task Learning (MTL) by
adding a new objective function to detect whether tokens are named entities or
not. We then introduce a framework called Mixture of Entity Experts (MoEE) to
improve the robustness for zero-resource domain adaptation. Finally,
experimental results show that our model outperforms strong unsupervised
cross-domain sequence labeling models, and the performance of our model is
close to that of the state-of-the-art model which leverages extensive
resources.
</summary>
    <author>
      <name>Zihan Liu</name>
    </author>
    <author>
      <name>Genta Indra Winata</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05902v1</id>
    <updated>2020-02-14T07:45:33Z</updated>
    <published>2020-02-14T07:45:33Z</published>
    <title>Understanding patient complaint characteristics using contextual
  clinical BERT embeddings</title>
    <summary>  In clinical conversational applications, extracted entities tend to capture
the main subject of a patient's complaint, namely symptoms or diseases.
However, they mostly fail to recognize the characterizations of a complaint
such as the time, the onset, and the severity. For example, if the input is "I
have a headache and it is extreme", state-of-the-art models only recognize the
main symptom entity - headache, but ignore the severity factor of "extreme",
that characterizes headache. In this paper, we design a two-stage approach to
detect the characterizations of entities like symptoms presented by general
users in contexts where they would describe their symptoms to a clinician. We
use Word2Vec and BERT to encode clinical text given by the patients. We
transform the output and re-frame the task as multi-label classification
problem. Finally, we combine the processed encodings with the Linear
Discriminant Analysis (LDA) algorithm to classify the characterizations of the
main entity. Experimental results demonstrate that our method achieves 40-50%
improvement on the accuracy over the state-of-the-art models.
</summary>
    <author>
      <name>Budhaditya Saha</name>
    </author>
    <author>
      <name>Sanal Lisboa</name>
    </author>
    <author>
      <name>Shameek Ghosh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been communicated to 42nd IEEE Annual Conference of
  Engineering in Medicine and Biology Society, Montreal, Canada. It is 5 pages
  long. It has 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05867v1</id>
    <updated>2020-02-14T04:23:28Z</updated>
    <published>2020-02-14T04:23:28Z</published>
    <title>Transformers as Soft Reasoners over Language</title>
    <summary>  AI has long pursued the goal of having systems reason over *explicitly
provided* knowledge, but building suitable representations has proved
challenging. Here we explore whether transformers can similarly learn to reason
(or emulate reasoning), but using rules expressed in language, thus bypassing a
formal representation. We provide the first demonstration that this is
possible, and characterize the extent of this capability. To do this, we use a
collection of synthetic datasets that test increasing levels of reasoning
complexity (number of rules, presence of negation, and depth of chaining). We
find transformers appear to learn rule-based reasoning with high (99%) accuracy
on these datasets, and in a way that generalizes to test data requiring
substantially deeper chaining than in the training data (95%+ scores). We also
demonstrate that the models transfer well to two hand-authored rulebases, and
to rulebases paraphrased into more natural language. These findings are
significant as it suggests a new role for transformers, namely as a limited
"soft theorem prover" operating over explicit theories in language. This in
turn suggests new possibilities for explainability, correctability, and
counterfactual reasoning in question-answering. All datasets and a live demo
are available at http://rule-reasoning.apps.allenai.org/
</summary>
    <author>
      <name>Peter Clark</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Kyle Richardson</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05829v1</id>
    <updated>2020-02-14T01:04:19Z</updated>
    <published>2020-02-14T01:04:19Z</published>
    <title>HULK: An Energy Efficiency Benchmark Platform for Responsible Natural
  Language Processing</title>
    <summary>  Computation-intensive pretrained models have been taking the lead of many
natural language processing benchmarks such as GLUE. However, energy efficiency
in the process of model training and inference becomes a critical bottleneck.
We introduce HULK, a multi-task energy efficiency benchmarking platform for
responsible natural language processing. With HULK, we compare pretrained
models' energy efficiency from the perspectives of time and cost. Baseline
benchmarking results are provided for further analysis. The fine-tuning
efficiency of different pretrained models can differ a lot among different
tasks and fewer parameter number does not necessarily imply better efficiency.
We analyzed such phenomenon and demonstrate the method of comparing the
multi-task efficiency of pretrained models. Our platform is available at
https://sites.engineering.ucsb.edu/~xiyou/hulk/.
</summary>
    <author>
      <name>Xiyou Zhou</name>
    </author>
    <author>
      <name>Zhiyu Chen</name>
    </author>
    <author>
      <name>Xiaoyong Jin</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05639v1</id>
    <updated>2020-02-13T17:12:51Z</updated>
    <published>2020-02-13T17:12:51Z</published>
    <title>Looking Enhances Listening: Recovering Missing Speech Using Images</title>
    <summary>  Speech is understood better by using visual context; for this reason, there
have been many attempts to use images to adapt automatic speech recognition
(ASR) systems. Current work, however, has shown that visually adapted ASR
models only use images as a regularization signal, while completely ignoring
their semantic content. In this paper, we present a set of experiments where we
show the utility of the visual modality under noisy conditions. Our results
show that multimodal ASR models can recover words which are masked in the input
acoustic signal, by grounding its transcriptions using the visual
representations. We observe that integrating visual context can result in up to
35% relative improvement in masked word recovery. These results demonstrate
that end-to-end multimodal ASR systems can become more robust to noise by
leveraging the visual context.
</summary>
    <author>
      <name>Tejas Srinivasan</name>
    </author>
    <author>
      <name>Ramon Sanabria</name>
    </author>
    <author>
      <name>Florian Metze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05607v1</id>
    <updated>2020-02-13T16:31:50Z</updated>
    <published>2020-02-13T16:31:50Z</published>
    <title>Pre-Training for Query Rewriting in A Spoken Language Understanding
  System</title>
    <summary>  Query rewriting (QR) is an increasingly important technique to reduce
customer friction caused by errors in a spoken language understanding pipeline,
where the errors originate from various sources such as speech recognition
errors, language understanding errors or entity resolution errors. In this
work, we first propose a neural-retrieval based approach for query rewriting.
Then, inspired by the wide success of pre-trained contextual language
embeddings, and also as a way to compensate for insufficient QR training data,
we propose a language-modeling (LM) based approach to pre-train query
embeddings on historical user conversation data with a voice assistant. In
addition, we propose to use the NLU hypotheses generated by the language
understanding system to augment the pre-training. Our experiments show
pre-training provides rich prior information and help the QR task achieve
strong performance. We also show joint pre-training with NLU hypotheses has
further benefit. Finally, after pre-training, we find a small set of rewrite
pairs is enough to fine-tune the QR model to outperform a strong baseline by
full training on all QR training data.
</summary>
    <author>
      <name>Zheng Chen</name>
    </author>
    <author>
      <name>Xing Fan</name>
    </author>
    <author>
      <name>Yuan Ling</name>
    </author>
    <author>
      <name>Lambert Mathias</name>
    </author>
    <author>
      <name>Chenlei Guo</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05606v1</id>
    <updated>2020-02-13T16:30:34Z</updated>
    <published>2020-02-13T16:30:34Z</published>
    <title>Sentiment Analysis Using Averaged Weighted Word Vector Features</title>
    <summary>  People use the world wide web heavily to share their experience with entities
such as products, services, or travel destinations. Texts that provide online
feedback in the form of reviews and comments are essential to make consumer
decisions. These comments create a valuable source that may be used to measure
satisfaction related to products or services. Sentiment analysis is the task of
identifying opinions expressed in such text fragments. In this work, we develop
two methods that combine different types of word vectors to learn and estimate
polarity of reviews. We develop average review vectors from word vectors and
add weights to this review vectors using word frequencies in positive and
negative sensitivity-tagged reviews. We applied the methods to several datasets
from different domains that are used as standard benchmarks for sentiment
analysis. We ensemble the techniques with each other and existing methods, and
we make a comparison with the approaches in the literature. The results show
that the performances of our approaches outperform the state-of-the-art success
rates.
</summary>
    <author>
      <name>Ali Erkan</name>
    </author>
    <author>
      <name>Tunga Gungor</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05556v1</id>
    <updated>2020-02-13T15:08:12Z</updated>
    <published>2020-02-13T15:08:12Z</published>
    <title>Sparse and Structured Visual Attention</title>
    <summary>  Visual attention mechanisms are widely used in multimodal tasks, such as
image captioning and visual question answering (VQA). One drawback of
softmax-based attention mechanisms is that they assign probability mass to all
image regions, regardless of their adjacency structure and of their relevance
to the text. In this paper, to better link the image structure with the text,
we replace the traditional softmax attention mechanism with two alternative
sparsity-promoting transformations: sparsemax, which is able to select the
relevant regions only (assigning zero weight to the rest), and a newly proposed
Total-Variation Sparse Attention (TVmax), which further encourages the joint
selection of adjacent spatial locations. Experiments in image captioning and
VQA, using both LSTM and Transformer architectures, show gains in terms of
human-rated caption quality, attention relevance, and VQA accuracy, with
improved interpretability.
</summary>
    <author>
      <name>Pedro Henrique Martins</name>
    </author>
    <author>
      <name>Vlad Niculae</name>
    </author>
    <author>
      <name>Zita Marinho</name>
    </author>
    <author>
      <name>André Martins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05417v1</id>
    <updated>2020-02-13T10:09:31Z</updated>
    <published>2020-02-13T10:09:31Z</published>
    <title>Comparison of Turkish Word Representations Trained on Different
  Morphological Forms</title>
    <summary>  Increased popularity of different text representations has also brought many
improvements in Natural Language Processing (NLP) tasks. Without need of
supervised data, embeddings trained on large corpora provide us meaningful
relations to be used on different NLP tasks. Even though training these vectors
is relatively easy with recent methods, information gained from the data
heavily depends on the structure of the corpus language. Since the popularly
researched languages have a similar morphological structure, problems occurring
for morphologically rich languages are mainly disregarded in studies. For
morphologically rich languages, context-free word vectors ignore morphological
structure of languages. In this study, we prepared texts in morphologically
different forms in a morphologically rich language, Turkish, and compared the
results on different intrinsic and extrinsic tasks. To see the effect of
morphological structure, we trained word2vec model on texts which lemma and
suffixes are treated differently. We also trained subword model fastText and
compared the embeddings on word analogy, text classification, sentimental
analysis, and language model tasks.
</summary>
    <author>
      <name>Gökhan Güler</name>
    </author>
    <author>
      <name>A. Cüneyd Tantuğ</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05407v1</id>
    <updated>2020-02-13T09:48:31Z</updated>
    <published>2020-02-13T09:48:31Z</published>
    <title>Keyphrase Extraction with Span-based Feature Representations</title>
    <summary>  Keyphrases are capable of providing semantic metadata characterizing
documents and producing an overview of the content of a document. Since
keyphrase extraction is able to facilitate the management, categorization, and
retrieval of information, it has received much attention in recent years. There
are three approaches to address keyphrase extraction: (i) traditional two-step
ranking method, (ii) sequence labeling and (iii) generation using neural
networks. Two-step ranking approach is based on feature engineering, which is
labor intensive and domain dependent. Sequence labeling is not able to tackle
overlapping phrases. Generation methods (i.e., Sequence-to-sequence neural
network models) overcome those shortcomings, so they have been widely studied
and gain state-of-the-art performance. However, generation methods can not
utilize context information effectively. In this paper, we propose a novelty
Span Keyphrase Extraction model that extracts span-based feature representation
of keyphrase directly from all the content tokens. In this way, our model
obtains representation for each keyphrase and further learns to capture the
interaction between keyphrases in one document to get better ranking results.
In addition, with the help of tokens, our model is able to extract overlapped
keyphrases. Experimental results on the benchmark datasets show that our
proposed model outperforms the existing methods by a large margin.
</summary>
    <author>
      <name>Funan Mu</name>
    </author>
    <author>
      <name>Zhenting Yu</name>
    </author>
    <author>
      <name>LiFeng Wang</name>
    </author>
    <author>
      <name>Yequan Wang</name>
    </author>
    <author>
      <name>Qingyu Yin</name>
    </author>
    <author>
      <name>Yibo Sun</name>
    </author>
    <author>
      <name>Liqun Liu</name>
    </author>
    <author>
      <name>Teng Ma</name>
    </author>
    <author>
      <name>Jing Tang</name>
    </author>
    <author>
      <name>Xing Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05295v1</id>
    <updated>2020-02-13T00:40:36Z</updated>
    <published>2020-02-13T00:40:36Z</published>
    <title>Exploiting the Matching Information in the Support Set for Few Shot
  Event Classification</title>
    <summary>  The existing event classification (EC) work primarily focuseson the
traditional supervised learning setting in which models are unableto extract
event mentions of new/unseen event types. Few-shot learninghas not been
investigated in this area although it enables EC models toextend their
operation to unobserved event types. To fill in this gap, inthis work, we
investigate event classification under the few-shot learningsetting. We propose
a novel training method for this problem that exten-sively exploit the support
set during the training process of a few-shotlearning model. In particular, in
addition to matching the query exam-ple with those in the support set for
training, we seek to further matchthe examples within the support set
themselves. This method providesmore training signals for the models and can be
applied to every metric-learning-based few-shot learning methods. Our extensive
experiments ontwo benchmark EC datasets show that the proposed method can
improvethe best reported few-shot learning models by up to 10% on accuracyfor
event classification
</summary>
    <author>
      <name>Viet Dac Lai</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Thien Huu Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PAKDD 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05235v1</id>
    <updated>2020-02-12T21:09:15Z</updated>
    <published>2020-02-12T21:09:15Z</published>
    <title>Image-to-Image Translation with Text Guidance</title>
    <summary>  The goal of this paper is to embed controllable factors, i.e., natural
language descriptions, into image-to-image translation with generative
adversarial networks, which allows text descriptions to determine the visual
attributes of synthetic images. We propose four key components: (1) the
implementation of part-of-speech tagging to filter out non-semantic words in
the given description, (2) the adoption of an affine combination module to
effectively fuse different modality text and image features, (3) a novel
refined multi-stage architecture to strengthen the differential ability of
discriminators and the rectification ability of generators, and (4) a new
structure loss to further improve discriminators to better distinguish real and
synthetic images. Extensive experiments on the COCO dataset demonstrate that
our method has a superior performance on both visual realism and semantic
consistency with given descriptions.
</summary>
    <author>
      <name>Bowen Li</name>
    </author>
    <author>
      <name>Xiaojuan Qi</name>
    </author>
    <author>
      <name>Philip H. S. Torr</name>
    </author>
    <author>
      <name>Thomas Lukasiewicz</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05201v2</id>
    <updated>2020-02-19T16:21:46Z</updated>
    <published>2020-02-12T19:56:58Z</published>
    <title>Deep compositional robotic planners that follow natural language
  commands</title>
    <summary>  We demonstrate how a sampling-based robotic planner can be augmented to learn
to understand a sequence of natural language commands in a continuous
configuration space to move and manipulate objects. Our approach combines a
deep network structured according to the parse of a complex command that
includes objects, verbs, spatial relations, and attributes, with a
sampling-based planner, RRT. A recurrent hierarchical deep network controls how
the planner explores the environment, determines when a planned path is likely
to achieve a goal, and estimates the confidence of each move to trade off
exploitation and exploration between the network and the planner. Planners are
designed to have near-optimal behavior when information about the task is
missing, while networks learn to exploit observations which are available from
the environment, making the two naturally complementary. Combining the two
enables generalization to new maps, new kinds of obstacles, and more complex
sentences that do not occur in the training set. Little data is required to
train the model despite it jointly acquiring a CNN that extracts features from
the environment as it learns the meanings of words. The model provides a level
of interpretability through the use of attention maps allowing users to see its
reasoning steps despite being an end-to-end model. This end-to-end model allows
robots to learn to follow natural language commands in challenging continuous
environments.
</summary>
    <author>
      <name>Yen-Ling Kuo</name>
    </author>
    <author>
      <name>Boris Katz</name>
    </author>
    <author>
      <name>Andrei Barbu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ICRA 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05201v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05201v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05150v1</id>
    <updated>2020-02-12T18:53:56Z</updated>
    <published>2020-02-12T18:53:56Z</published>
    <title>Attentional Speech Recognition Models Misbehave on Out-of-domain
  Utterances</title>
    <summary>  We discuss the problem of echographic transcription in autoregressive
sequence-to-sequence attentional architectures for automatic speech
recognition, where a model produces very long sequences of repetitive outputs
when presented with out-of-domain utterances. We decode audio from the British
National Corpus with an attentional encoder-decoder model trained solely on the
LibriSpeech corpus. We observe that there are many 5-second recordings that
produce more than 500 characters of decoding output (i.e. more than 100
characters per second). A frame-synchronous hybrid (DNN-HMM) model trained on
the same data does not produce these unusually long transcripts. These decoding
issues are reproducible in a speech transformer model from ESPnet, and to a
lesser extent in a self-attention CTC model, suggesting that these issues are
intrinsic to the use of the attention mechanism. We create a separate length
prediction model to predict the correct number of wordpieces in the output,
which allows us to identify and truncate problematic decoding results without
increasing word error rates on the LibriSpeech task.
</summary>
    <author>
      <name>Phillip Keung</name>
    </author>
    <author>
      <name>Wei Niu</name>
    </author>
    <author>
      <name>Yichao Lu</name>
    </author>
    <author>
      <name>Julian Salazar</name>
    </author>
    <author>
      <name>Vikas Bhardwaj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Artifacts like our filtered Audio BNC dataset can be found at
  https://github.com/aws-samples/seq2seq-asr-misbehaves</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05162v2</id>
    <updated>2020-02-17T11:12:59Z</updated>
    <published>2020-02-12T17:28:30Z</published>
    <title>A Combined Stochastic and Physical Framework for Modeling Indoor 5G
  Millimeter Wave Propagation</title>
    <summary>  Indoor coverage is a major challenge for 5G millimeter waves (mmWaves). In
this paper, we address this problem through a novel theoretical framework that
combines stochastic indoor environment modeling with advanced physical
propagation simulation. This approach is particularly adapted to investigate
indoor-to-indoor 5G mmWave propagation. Its system implementation, so-called
iGeoStat, generates parameterized typical environments that account for the
indoor spatial variations, then simulates radio propagation based on the
physical interaction between electromagnetic waves and material properties.
This framework is not dedicated to a particular environment, material,
frequency or use case and aims to statistically understand the influence of
indoor environment parameters on mmWave propagation properties, especially
coverage and path loss. Its implementation raises numerous computational
challenges that we solve by formulating an adapted link budget and designing
new memory optimization algorithms. The first simulation results for two major
5G applications are validated with measurement data and show the efficiency of
iGeoStat to simulate multiple diffusion in realistic environments, within a
reasonable amount of time and memory resources. Generated output maps confirm
that diffusion has a critical impact on indoor mmWave propagation and that
proper physical modeling is of the utmost importance to generate relevant
propagation models.
</summary>
    <author>
      <name>Georges Nassif</name>
    </author>
    <author>
      <name>Catherine Gloaguen</name>
    </author>
    <author>
      <name>Philippe Martins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 18 figures, and 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05162v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05162v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05104v1</id>
    <updated>2020-02-12T17:25:50Z</updated>
    <published>2020-02-12T17:25:50Z</published>
    <title>Component Analysis for Visual Question Answering Architectures</title>
    <summary>  Recent research advances in Computer Vision and Natural Language Processing
have introduced novel tasks that are paving the way for solving AI-complete
problems. One of those tasks is called Visual Question Answering (VQA). A VQA
system must take an image and a free-form, open-ended natural language question
about the image, and produce a natural language answer as the output. Such a
task has drawn great attention from the scientific community, which generated a
plethora of approaches that aim to improve the VQA predictive accuracy. Most of
them comprise three major components: (i) independent representation learning
of images and questions; (ii) feature fusion so the model can use information
from both sources to answer visual questions; and (iii) the generation of the
correct answer in natural language. With so many approaches being recently
introduced, it became unclear the real contribution of each component for the
ultimate performance of the model. The main goal of this paper is to provide a
comprehensive analysis regarding the impact of each component in VQA models.
Our extensive set of experiments cover both visual and textual elements, as
well as the combination of these representations in form of fusion and
attention mechanisms. Our major contribution is to identify core components for
training VQA models so as to maximize their predictive performance.
</summary>
    <author>
      <name>Camila Kolling</name>
    </author>
    <author>
      <name>Jônatas Wehrmann</name>
    </author>
    <author>
      <name>Rodrigo C. Barros</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05058v1</id>
    <updated>2020-02-12T15:52:21Z</updated>
    <published>2020-02-12T15:52:21Z</published>
    <title>Learning to Compare for Better Training and Evaluation of Open Domain
  Natural Language Generation Models</title>
    <summary>  Automated evaluation of open domain natural language generation (NLG) models
remains a challenge and widely used metrics such as BLEU and Perplexity can be
misleading in some cases. In our paper, we propose to evaluate natural language
generation models by learning to compare a pair of generated sentences by
fine-tuning BERT, which has been shown to have good natural language
understanding ability. We also propose to evaluate the model-level quality of
NLG models with sample-level comparison results with skill rating system. While
able to be trained in a fully self-supervised fashion, our model can be further
fine-tuned with a little amount of human preference annotation to better
imitate human judgment. In addition to evaluating trained models, we propose to
apply our model as a performance indicator during training for better
hyperparameter tuning and early-stopping. We evaluate our approach on both
story generation and chit-chat dialogue response generation. Experimental
results show that our model correlates better with human preference compared
with previous automated evaluation approaches. Training with the proposed
metric yields better performance in human evaluation, which further
demonstrates the effectiveness of the proposed model.
</summary>
    <author>
      <name>Wangchunshu Zhou</name>
    </author>
    <author>
      <name>Ke Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04608v1</id>
    <updated>2020-02-12T15:18:31Z</updated>
    <published>2020-02-12T15:18:31Z</published>
    <title>Constructing a Highlight Classifier with an Attention Based LSTM Neural
  Network</title>
    <summary>  Data is being produced in larger quantities than ever before in human
history. It's only natural to expect a rise in demand for technology that aids
humans in sifting through and analyzing this inexhaustible supply of
information. This need exists in the market research industry, where large
amounts of consumer research data is collected through video recordings. At
present, the standard method for analyzing video data is human labor. Market
researchers manually review the vast majority of consumer research video in
order to identify relevant portions - highlights. The industry state of the art
turnaround ratio is 2.2 - for every hour of video content 2.2 hours of manpower
are required. In this study we present a novel approach for NLP-based highlight
identification and extraction based on a supervised learning model that aides
market researchers in sifting through their data. Our approach hinges on a
manually curated user-generated highlight clips constructed from long and
short-form video data. The problem is best suited for an NLP approach due to
the availability of video transcription. We evaluate multiple classes of
models, from gradient boosting to recurrent neural networks, comparing their
performance in extraction and identification of highlights. The best performing
models are then evaluated using four sampling methods designed to analyze
documents much larger than the maximum input length of the classifiers. We
report very high performances for the standalone classifiers, ROC AUC scores in
the range 0.93-0.94, but observe a significant drop in effectiveness when
evaluated on large documents. Based on our results we suggest combinations of
models/sampling algorithms for various use cases.
</summary>
    <author>
      <name>Michael Kuehne</name>
    </author>
    <author>
      <name>Marius Radu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04936v1</id>
    <updated>2020-02-12T12:06:32Z</updated>
    <published>2020-02-12T12:06:32Z</published>
    <title>Joint Embedding in Named Entity Linking on Sentence Level</title>
    <summary>  Named entity linking is to map an ambiguous mention in documents to an entity
in a knowledge base. The named entity linking is challenging, given the fact
that there are multiple candidate entities for a mention in a document. It is
difficult to link a mention when it appears multiple times in a document, since
there are conflicts by the contexts around the appearances of the mention. In
addition, it is difficult since the given training dataset is small due to the
reason that it is done manually to link a mention to its mapping entity. In the
literature, there are many reported studies among which the recent embedding
methods learn vectors of entities from the training dataset at document level.
To address these issues, we focus on how to link entity for mentions at a
sentence level, which reduces the noises introduced by different appearances of
the same mention in a document at the expense of insufficient information to be
used. We propose a new unified embedding method by maximizing the relationships
learned from knowledge graphs. We confirm the effectiveness of our method in
our experimental studies.
</summary>
    <author>
      <name>Wei Shi</name>
    </author>
    <author>
      <name>Siyuan Zhang</name>
    </author>
    <author>
      <name>Zhiwei Zhang</name>
    </author>
    <author>
      <name>Hong Cheng</name>
    </author>
    <author>
      <name>Jeffrey Xu Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04815v1</id>
    <updated>2020-02-12T06:11:48Z</updated>
    <published>2020-02-12T06:11:48Z</published>
    <title>Utilizing BERT Intermediate Layers for Aspect Based Sentiment Analysis
  and Natural Language Inference</title>
    <summary>  Aspect based sentiment analysis aims to identify the sentimental tendency
towards a given aspect in text. Fine-tuning of pretrained BERT performs
excellent on this task and achieves state-of-the-art performances. Existing
BERT-based works only utilize the last output layer of BERT and ignore the
semantic knowledge in the intermediate layers. This paper explores the
potential of utilizing BERT intermediate layers to enhance the performance of
fine-tuning of BERT. To the best of our knowledge, no existing work has been
done on this research. To show the generality, we also apply this approach to a
natural language inference task. Experimental results demonstrate the
effectiveness and generality of the proposed approach.
</summary>
    <author>
      <name>Youwei Song</name>
    </author>
    <author>
      <name>Jiahai Wang</name>
    </author>
    <author>
      <name>Zhiwei Liang</name>
    </author>
    <author>
      <name>Zhiyue Liu</name>
    </author>
    <author>
      <name>Tao Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04793v1</id>
    <updated>2020-02-12T04:31:40Z</updated>
    <published>2020-02-12T04:31:40Z</published>
    <title>ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and
  Diagnosing Dialogue Systems</title>
    <summary>  We present ConvLab-2, an open-source toolkit that enables researchers to
build task-oriented dialogue systems with state-of-the-art models, perform an
end-to-end evaluation, and diagnose the weakness of systems. As the successor
of ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but
integrates more powerful dialogue models and supports more datasets. Besides,
we have developed an analysis tool and an interactive tool to assist
researchers in diagnosing dialogue systems. The analysis tool presents rich
statistics and summarizes common mistakes from simulated dialogues, which
facilitates error analysis and system improvement. The interactive tool
provides a user interface that allows developers to diagnose an assembled
dialogue system by interacting with the system and modifying the output of each
system component.
</summary>
    <author>
      <name>Qi Zhu</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Yan Fang</name>
    </author>
    <author>
      <name>Xiang Li</name>
    </author>
    <author>
      <name>Ryuichi Takanobu</name>
    </author>
    <author>
      <name>Jinchao Li</name>
    </author>
    <author>
      <name>Baolin Peng</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05527v1</id>
    <updated>2020-02-12T04:01:57Z</updated>
    <published>2020-02-12T04:01:57Z</published>
    <title>Unsupervised Separation of Native and Loanwords for Malayalam and Telugu</title>
    <summary>  Quite often, words from one language are adopted within a different language
without translation; these words appear in transliterated form in text written
in the latter language. This phenomenon is particularly widespread within
Indian languages where many words are loaned from English. In this paper, we
address the task of identifying loanwords automatically and in an unsupervised
manner, from large datasets of words from agglutinative Dravidian languages. We
target two specific languages from the Dravidian family, viz., Malayalam and
Telugu. Based on familiarity with the languages, we outline an observation that
native words in both these languages tend to be characterized by a much more
versatile stem - stem being a shorthand to denote the subword sequence formed
by the first few characters of the word - than words that are loaned from other
languages. We harness this observation to build an objective function and an
iterative optimization formulation to optimize for it, yielding a scoring of
each word's nativeness in the process. Through an extensive empirical analysis
over real-world datasets from both Malayalam and Telugu, we illustrate the
effectiveness of our method in quantifying nativeness effectively over
available baselines for the task.
</summary>
    <author>
      <name>Sridhama Prakhya</name>
    </author>
    <author>
      <name>Deepak P</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Natural Language Engineering; 22 pages; 4 figures. arXiv
  admin note: text overlap with arXiv:1803.09641</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04760v2</id>
    <updated>2020-02-13T01:32:42Z</updated>
    <published>2020-02-12T01:57:41Z</published>
    <title>DeepMutation: A Neural Mutation Tool</title>
    <summary>  Mutation testing can be used to assess the fault-detection capabilities of a
given test suite. To this aim, two characteristics of mutation testing
frameworks are of paramount importance: (i) they should generate mutants that
are representative of real faults; and (ii) they should provide a complete tool
chain able to automatically generate, inject, and test the mutants. To address
the first point, we recently proposed an approach using a Recurrent Neural
Network Encoder-Decoder architecture to learn mutants from ~787k faults mined
from real programs. The empirical evaluation of this approach confirmed its
ability to generate mutants representative of real faults. In this paper, we
address the second point, presenting DeepMutation, a tool wrapping our deep
learning model into a fully automated tool chain able to generate, inject, and
test mutants learned from real faults. Video:
https://sites.google.com/view/learning-mutation/deepmutation
</summary>
    <author>
      <name>Michele Tufano</name>
    </author>
    <author>
      <name>Jason Kimko</name>
    </author>
    <author>
      <name>Shiya Wang</name>
    </author>
    <author>
      <name>Cody Watson</name>
    </author>
    <author>
      <name>Gabriele Bavota</name>
    </author>
    <author>
      <name>Massimiliano Di Penta</name>
    </author>
    <author>
      <name>Denys Poshyvanyk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3377812.3382146</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3377812.3382146" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 42nd ACM/IEEE International Conference on Software
  Engineering (ICSE 2020), Demonstrations Track - Seoul, South Korea, May
  23-29, 2020, 4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04760v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04760v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04745v1</id>
    <updated>2020-02-12T00:33:03Z</updated>
    <published>2020-02-12T00:33:03Z</published>
    <title>On Layer Normalization in the Transformer Architecture</title>
    <summary>  The Transformer is widely used in natural language processing tasks. To train
a Transformer however, one usually needs a carefully designed learning rate
warm-up stage, which is shown to be crucial to the final performance but will
slow down the optimization and bring more hyper-parameter tunings. In this
paper, we first study theoretically why the learning rate warm-up stage is
essential and show that the location of layer normalization matters.
Specifically, we prove with mean field theory that at initialization, for the
original-designed Post-LN Transformer, which places the layer normalization
between the residual blocks, the expected gradients of the parameters near the
output layer are large. Therefore, using a large learning rate on those
gradients makes the training unstable. The warm-up stage is practically helpful
for avoiding this problem. On the other hand, our theory also shows that if the
layer normalization is put inside the residual blocks (recently proposed as
Pre-LN Transformer), the gradients are well-behaved at initialization. This
motivates us to remove the warm-up stage for the training of Pre-LN
Transformers. We show in our experiments that Pre-LN Transformers without the
warm-up stage can reach comparable results with baselines while requiring
significantly less training time and hyper-parameter tuning on a wide range of
applications.
</summary>
    <author>
      <name>Ruibin Xiong</name>
    </author>
    <author>
      <name>Yunchang Yang</name>
    </author>
    <author>
      <name>Di He</name>
    </author>
    <author>
      <name>Kai Zheng</name>
    </author>
    <author>
      <name>Shuxin Zheng</name>
    </author>
    <author>
      <name>Chen Xing</name>
    </author>
    <author>
      <name>Huishuai Zhang</name>
    </author>
    <author>
      <name>Yanyan Lan</name>
    </author>
    <author>
      <name>Liwei Wang</name>
    </author>
    <author>
      <name>Tie-Yan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04723v1</id>
    <updated>2020-02-11T22:52:40Z</updated>
    <published>2020-02-11T22:52:40Z</published>
    <title>Superbloom: Bloom filter meets Transformer</title>
    <summary>  We extend the idea of word pieces in natural language models to machine
learning tasks on opaque ids. This is achieved by applying hash functions to
map each id to multiple hash tokens in a much smaller space, similarly to a
Bloom filter. We show that by applying a multi-layer Transformer to these Bloom
filter digests, we are able to obtain models with high accuracy. They
outperform models of a similar size without hashing and, to a large degree,
models of a much larger size trained using sampled softmax with the same
computational budget. Our key observation is that it is important to use a
multi-layer Transformer for Bloom filter digests to remove ambiguity in the
hashed input. We believe this provides an alternative method to solving
problems with large vocabulary size.
</summary>
    <author>
      <name>John Anderson</name>
    </author>
    <author>
      <name>Qingqing Huang</name>
    </author>
    <author>
      <name>Walid Krichene</name>
    </author>
    <author>
      <name>Steffen Rendle</name>
    </author>
    <author>
      <name>Li Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04689v1</id>
    <updated>2020-02-11T21:17:29Z</updated>
    <published>2020-02-11T21:17:29Z</published>
    <title>Two Huge Title and Keyword Generation Corpora of Research Articles</title>
    <summary>  Recent developments in sequence-to-sequence learning with neural networks
have considerably improved the quality of automatically generated text
summaries and document keywords, stipulating the need for even bigger training
corpora. Metadata of research articles are usually easy to find online and can
be used to perform research on various tasks. In this paper, we introduce two
huge datasets for text summarization (OAGSX) and keyword generation (OAGKX)
research, containing 34 million and 23 million records, respectively. The data
were retrieved from the Open Academic Graph which is a network of research
profiles and publications. We carefully processed each record and also tried
several extractive and abstractive methods of both tasks to create performance
baselines for other researchers. We further illustrate the performance of those
methods previewing their outputs. In the near future, we would like to apply
topic modeling on the two sets to derive subsets of research articles from more
specific disciplines.
</summary>
    <author>
      <name>Erion Çano</name>
    </author>
    <author>
      <name>Ondřej Bojar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 tables. Published in proceedings of LREC 2020, the 12th
  International Conference on Language Resources and Evaluation, Marseille,
  France</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04678v1</id>
    <updated>2020-02-11T20:59:34Z</updated>
    <published>2020-02-11T20:59:34Z</published>
    <title>Adjusting Image Attributes of Localized Regions with Low-level Dialogue</title>
    <summary>  Natural Language Image Editing (NLIE) aims to use natural language
instructions to edit images. Since novices are inexperienced with image editing
techniques, their instructions are often ambiguous and contain high-level
abstractions that tend to correspond to complex editing steps to accomplish.
Motivated by this inexperience aspect, we aim to smooth the learning curve by
teaching the novices to edit images using low-level commanding terminologies.
Towards this end, we develop a task-oriented dialogue system to investigate
low-level instructions for NLIE. Our system grounds language on the level of
edit operations, and suggests options for a user to choose from. Though
compelled to express in low-level terms, a user evaluation shows that 25% of
users found our system easy-to-use, resonating with our motivation. An analysis
shows that users generally adapt to utilizing the proposed low-level language
interface. In this study, we identify that object segmentation as the key
factor to the user satisfaction. Our work demonstrates the advantages of the
low-level, direct language-action mapping approach that can be applied to other
problem domains beyond image editing such as audio editing or industrial
design.
</summary>
    <author>
      <name>Tzu-Hsiang Lin</name>
    </author>
    <author>
      <name>Alexander Rudnicky</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Doo Soon Kim</name>
    </author>
    <author>
      <name>Jean Oh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a Poster presentation at the 12th International
  Conference on Language Resources and Evaluation (LREC 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04494v2</id>
    <updated>2020-02-16T14:23:28Z</updated>
    <published>2020-02-11T15:49:32Z</published>
    <title>The Rumour Mill: Making the Spread of Misinformation Explicit and
  Tangible</title>
    <summary>  Misinformation spread presents a technological and social threat to society.
With the advance of AI-based language models, automatically generated texts
have become difficult to identify and easy to create at scale. We present "The
Rumour Mill", a playful art piece, designed as a commentary on the spread of
rumours and automatically-generated misinformation. The mill is a tabletop
interactive machine, which invites a user to experience the process of creating
believable text by interacting with different tangible controls on the mill.
The user manipulates visible parameters to adjust the genre and type of an
automatically generated text rumour. The Rumour Mill is a physical
demonstration of the state of current technology and its ability to generate
and manipulate natural language text, and of the act of starting and spreading
rumours.
</summary>
    <author>
      <name>Nanna Inie</name>
    </author>
    <author>
      <name>Jeanette Falk Olesen</name>
    </author>
    <author>
      <name>Leon Derczynski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3334480.3383159</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3334480.3383159" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to CHI 2020 Interactivity</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04494v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04494v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04374v1</id>
    <updated>2020-02-11T13:48:38Z</updated>
    <published>2020-02-11T13:48:38Z</published>
    <title>Convolutional Neural Networks and a Transfer Learning Strategy to
  Classify Parkinson's Disease from Speech in Three Different Languages</title>
    <summary>  Parkinson's disease patients develop different speech impairments that affect
their communication capabilities. The automatic assessment of the speech of the
patients allows the development of computer aided tools to support the
diagnosis and the evaluation of the disease severity. This paper introduces a
methodology to classify Parkinson's disease from speech in three different
languages: Spanish, German, and Czech. The proposed approach considers
convolutional neural networks trained with time frequency representations and a
transfer learning strategy among the three languages. The transfer learning
scheme aims to improve the accuracy of the models when the weights of the
neural network are initialized with utterances from a different language than
the used for the test set. The results suggest that the proposed strategy
improves the accuracy of the models in up to 8\% when the base model used to
initialize the weights of the classifier is robust enough. In addition, the
results obtained after the transfer learning are in most cases more balanced in
terms of specificity-sensitivity than those trained without the transfer
learning strategy.
</summary>
    <author>
      <name>J. C. Vásquez-Correa</name>
    </author>
    <author>
      <name>T. Arias-Vergara</name>
    </author>
    <author>
      <name>C. D. Rios-Urrego</name>
    </author>
    <author>
      <name>M. Schuster</name>
    </author>
    <author>
      <name>J. Rusz</name>
    </author>
    <author>
      <name>J. R. Orozco-Arroyave</name>
    </author>
    <author>
      <name>E. Nöth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-33904-3_66</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-33904-3_66" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Iberoamerican Congress on Pattern Recognition (pp. 697-706)
  2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.04374v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04374v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04326v1</id>
    <updated>2020-02-11T11:54:29Z</updated>
    <published>2020-02-11T11:54:29Z</published>
    <title>ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning</title>
    <summary>  Recent powerful pre-trained language models have achieved remarkable
performance on most of the popular datasets for reading comprehension. It is
time to introduce more challenging datasets to push the development of this
field towards more comprehensive reasoning of text. In this paper, we introduce
a new Reading Comprehension dataset requiring logical reasoning (ReClor)
extracted from standardized graduate admission examinations. As earlier studies
suggest, human-annotated datasets usually contain biases, which are often
exploited by models to achieve high accuracy without truly understanding the
text. In order to comprehensively evaluate the logical reasoning ability of
models on ReClor, we propose to identify biased data points and separate them
into EASY set while the rest as HARD set. Empirical results show that
state-of-the-art models have an outstanding ability to capture biases contained
in the dataset with high accuracy on EASY set. However, they struggle on HARD
set with poor performance near that of random guess, indicating more research
is needed to essentially enhance the logical reasoning ability of current
models.
</summary>
    <author>
      <name>Weihao Yu</name>
    </author>
    <author>
      <name>Zihang Jiang</name>
    </author>
    <author>
      <name>Yanfei Dong</name>
    </author>
    <author>
      <name>Jiashi Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04306v1</id>
    <updated>2020-02-11T10:56:42Z</updated>
    <published>2020-02-11T10:56:42Z</published>
    <title>Learning Coupled Policies for Simultaneous Machine Translation</title>
    <summary>  In simultaneous machine translation, the system needs to incrementally
generate the output translation before the input sentence ends. This is a
coupled decision process consisting of a programmer and interpreter. The
programmer's policy decides about when to WRITE the next output or READ the
next input, and the interpreter's policy decides what word to write. We present
an imitation learning (IL) approach to efficiently learn effective coupled
programmer-interpreter policies. To enable IL, we present an algorithmic oracle
to produce oracle READ/WRITE actions for training bilingual sentence-pairs
using the notion of word alignments. We attribute the effectiveness of the
learned coupled policies to (i) scheduled sampling addressing the coupled
exposure bias, and (ii) quality of oracle actions capturing enough information
from the partial input before writing the output. Experiments show our method
outperforms strong baselines in terms of translation quality and delay, when
translating from German/Arabic/Czech/Bulgarian/Romanian to English.
</summary>
    <author>
      <name>Philip Arthur</name>
    </author>
    <author>
      <name>Trevor Cohn</name>
    </author>
    <author>
      <name>Gholamreza Haffari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04250v2</id>
    <updated>2020-02-13T13:37:24Z</updated>
    <published>2020-02-11T08:19:28Z</published>
    <title>Non-Autoregressive Neural Dialogue Generation</title>
    <summary>  Maximum Mutual information (MMI), which models the bidirectional dependency
between responses ($y$) and contexts ($x$), i.e., the forward probability $\log
p(y|x)$ and the backward probability $\log p(x|y)$, has been widely used as the
objective in the \sts model to address the dull-response issue in open-domain
dialog generation. Unfortunately, under the framework of the \sts model, direct
decoding from $\log p(y|x) + \log p(x|y)$ is infeasible since the second part
(i.e., $p(x|y)$) requires the completion of target generation before it can be
computed, and the search space for $y$ is enormous. Empirically, an N-best list
is first generated given $p(y|x)$, and $p(x|y)$ is then used to rerank the
N-best list, which inevitably results in non-globally-optimal solutions. In
this paper, we propose to use non-autoregressive (non-AR) generation model to
address this non-global optimality issue. Since target tokens are generated
independently in non-AR generation, $p(x|y)$ for each target word can be
computed as soon as it's generated, and does not have to wait for the
completion of the whole sequence. This naturally resolves the non-global
optimal issue in decoding. Experimental results demonstrate that the proposed
non-AR strategy produces more diverse, coherent, and appropriate responses,
yielding substantive gains in BLEU scores and in human evaluations.
</summary>
    <author>
      <name>Qinghong Han</name>
    </author>
    <author>
      <name>Yuxian Meng</name>
    </author>
    <author>
      <name>Fei Wu</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04250v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04250v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04181v1</id>
    <updated>2020-02-11T03:03:20Z</updated>
    <published>2020-02-11T03:03:20Z</published>
    <title>Performance Comparison of Crowdworkers and NLP Tools onNamed-Entity
  Recognition and Sentiment Analysis of Political Tweets</title>
    <summary>  We report results of a comparison of the accuracy of crowdworkers and seven
NaturalLanguage Processing (NLP) toolkits in solving two important NLP tasks,
named-entity recognition (NER) and entity-level sentiment(ELS) analysis. We
here focus on a challenging dataset, 1,000 political tweets that were collected
during the U.S. presidential primary election in February 2016. Each tweet
refers to at least one of four presidential candidates,i.e., four named
entities. The groundtruth, established by experts in political communication,
has entity-level sentiment information for each candidate mentioned in the
tweet. We tested several commercial and open-source tools. Our experiments show
that, for our dataset of political tweets, the most accurate NER system, Google
Cloud NL, performed almost on par with crowdworkers, but the most accurate ELS
analysis system, TensiStrength, did not match the accuracy of crowdworkers by a
large margin of more than 30 percent points.
</summary>
    <author>
      <name>Mona Jalal</name>
    </author>
    <author>
      <name>Kate K. Mays</name>
    </author>
    <author>
      <name>Lei Guo</name>
    </author>
    <author>
      <name>Margrit Betke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, WiNLP Workshop at NAACL 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04165v1</id>
    <updated>2020-02-11T01:52:05Z</updated>
    <published>2020-02-11T01:52:05Z</published>
    <title>Training with Streaming Annotation</title>
    <summary>  In this paper, we address a practical scenario where training data is
released in a sequence of small-scale batches and annotation in earlier phases
has lower quality than the later counterparts. To tackle the situation, we
utilize a pre-trained transformer network to preserve and integrate the most
salient document information from the earlier batches while focusing on the
annotation (presumably with higher quality) from the current batch. Using event
extraction as a case study, we demonstrate in the experiments that our proposed
framework can perform better than conventional approaches (the improvement
ranges from 3.6 to 14.9% absolute F-score gain), especially when there is more
noise in the early annotation; and our approach spares 19.1% time with regard
to the best conventional method.
</summary>
    <author>
      <name>Tongtao Zhang</name>
    </author>
    <author>
      <name>Heng Ji</name>
    </author>
    <author>
      <name>Shih-Fu Chang</name>
    </author>
    <author>
      <name>Marjorie Freedman</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04108v2</id>
    <updated>2020-02-20T05:37:37Z</updated>
    <published>2020-02-10T21:59:21Z</published>
    <title>Adversarial Filters of Dataset Biases</title>
    <summary>  Large neural models have demonstrated human-level performance on language and
vision benchmarks such as ImageNet and Stanford Natural Language Inference
(SNLI). Yet, their performance degrades considerably when tested on adversarial
or out-of-distribution samples. This raises the question of whether these
models have learned to solve a dataset rather than the underlying task by
overfitting on spurious dataset biases. We investigate one recently proposed
approach, AFLite, which adversarially filters such dataset biases, as a means
to mitigate the prevalent overestimation of machine performance. We provide a
theoretical understanding for AFLite, by situating it in the generalized
framework for optimum bias reduction. Our experiments show that as a result of
the substantial reduction of these biases, models trained on the filtered
datasets yield better generalization to out-of-distribution tasks, especially
when the benchmarks used for training are over-populated with biased samples.
We show that AFLite is broadly applicable to a variety of both real and
synthetic datasets for reduction of measurable dataset biases and provide
extensive supporting analyses. Finally, filtering results in a large drop in
model performance (e.g., from 92% to 63% for SNLI), while human performance
still remains high. Our work thus shows that such filtered datasets can pose
new research challenges for robust generalization by serving as upgraded
benchmarks.
</summary>
    <author>
      <name>Ronan Le Bras</name>
    </author>
    <author>
      <name>Swabha Swayamdipta</name>
    </author>
    <author>
      <name>Chandra Bhagavatula</name>
    </author>
    <author>
      <name>Rowan Zellers</name>
    </author>
    <author>
      <name>Matthew E. Peters</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04108v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04108v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04095v1</id>
    <updated>2020-02-10T21:35:39Z</updated>
    <published>2020-02-10T21:35:39Z</published>
    <title>Automatic Discourse Segmentation: an evaluation in French</title>
    <summary>  In this article, we describe some discursive segmentation methods as well as
a preliminary evaluation of the segmentation quality. Although our experiment
were carried for documents in French, we have developed three discursive
segmentation models solely based on resources simultaneously available in
several languages: marker lists and a statistic POS labeling. We have also
carried out automatic evaluations of these systems against the Annodis corpus,
which is a manually annotated reference. The results obtained are very
encouraging.
</summary>
    <author>
      <name>Rémy Saksik</name>
    </author>
    <author>
      <name>Alejandro Molina-Villegas</name>
    </author>
    <author>
      <name>Andréa Carneiro Linhares</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06053v1</id>
    <updated>2020-02-10T21:02:05Z</updated>
    <published>2020-02-10T21:02:05Z</published>
    <title>Exploring Chemical Space using Natural Language Processing Methodologies
  for Drug Discovery</title>
    <summary>  Text-based representations of chemicals and proteins can be thought of as
unstructured languages codified by humans to describe domain-specific
knowledge. Advances in natural language processing (NLP) methodologies in the
processing of spoken languages accelerated the application of NLP to elucidate
hidden knowledge in textual representations of these biochemical entities and
then use it to construct models to predict molecular properties or to design
novel molecules. This review outlines the impact made by these advances on drug
discovery and aims to further the dialogue between medicinal chemists and
computer scientists.
</summary>
    <author>
      <name>Hakime Öztürk</name>
    </author>
    <author>
      <name>Arzucan Özgür</name>
    </author>
    <author>
      <name>Philippe Schwaller</name>
    </author>
    <author>
      <name>Teodoro Laino</name>
    </author>
    <author>
      <name>Elif Ozkirimli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.drudis.2020.01.020</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.drudis.2020.01.020" rel="related"/>
    <link href="http://arxiv.org/abs/2002.06053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08910v2</id>
    <updated>2020-02-24T04:54:34Z</updated>
    <published>2020-02-10T18:55:58Z</published>
    <title>How Much Knowledge Can You Pack Into the Parameters of a Language Model?</title>
    <summary>  It has recently been observed that neural language models trained on
unstructured text can implicitly store and retrieve knowledge using natural
language queries. In this short paper, we measure the practical utility of this
approach by fine-tuning pre-trained models to answer questions without access
to any external context or knowledge. We show that this approach scales
surprisingly well with model size and outperforms models that explicitly look
up knowledge on the open-domain variants of Natural Questions and WebQuestions.
</summary>
    <author>
      <name>Adam Roberts</name>
    </author>
    <author>
      <name>Colin Raffel</name>
    </author>
    <author>
      <name>Noam Shazeer</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08910v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08910v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08909v1</id>
    <updated>2020-02-10T18:40:59Z</updated>
    <published>2020-02-10T18:40:59Z</published>
    <title>REALM: Retrieval-Augmented Language Model Pre-Training</title>
    <summary>  Language model pre-training has been shown to capture a surprising amount of
world knowledge, crucial for NLP tasks such as question answering. However,
this knowledge is stored implicitly in the parameters of a neural network,
requiring ever-larger networks to cover more facts.
  To capture knowledge in a more modular and interpretable way, we augment
language model pre-training with a latent knowledge retriever, which allows the
model to retrieve and attend over documents from a large corpus such as
Wikipedia, used during pre-training, fine-tuning and inference. For the first
time, we show how to pre-train such a knowledge retriever in an unsupervised
manner, using masked language modeling as the learning signal and
backpropagating through a retrieval step that considers millions of documents.
  We demonstrate the effectiveness of Retrieval-Augmented Language Model
pre-training (REALM) by fine-tuning on the challenging task of Open-domain
Question Answering (Open-QA). We compare against state-of-the-art models for
both explicit and implicit knowledge storage on three popular Open-QA
benchmarks, and find that we outperform all previous methods by a significant
margin (4-16% absolute accuracy), while also providing qualitative benefits
such as interpretability and modularity.
</summary>
    <author>
      <name>Kelvin Guu</name>
    </author>
    <author>
      <name>Kenton Lee</name>
    </author>
    <author>
      <name>Zora Tung</name>
    </author>
    <author>
      <name>Panupong Pasupat</name>
    </author>
    <author>
      <name>Ming-Wei Chang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08909v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08909v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03932v1</id>
    <updated>2020-02-10T16:44:00Z</updated>
    <published>2020-02-10T16:44:00Z</published>
    <title>Pre-training Tasks for Embedding-based Large-scale Retrieval</title>
    <summary>  We consider the large-scale query-document retrieval problem: given a query
(e.g., a question), return the set of relevant documents (e.g., paragraphs
containing the answer) from a large document corpus. This problem is often
solved in two steps. The retrieval phase first reduces the solution space,
returning a subset of candidate documents. The scoring phase then re-ranks the
documents. Critically, the retrieval algorithm not only desires high recall but
also requires to be highly efficient, returning candidates in time sublinear to
the number of documents. Unlike the scoring phase witnessing significant
advances recently due to the BERT-style pre-training tasks on cross-attention
models, the retrieval phase remains less well studied. Most previous works rely
on classic Information Retrieval (IR) methods such as BM-25 (token matching +
TF-IDF weights). These models only accept sparse handcrafted features and can
not be optimized for different downstream tasks of interest. In this paper, we
conduct a comprehensive study on the embedding-based retrieval models. We show
that the key ingredient of learning a strong embedding-based Transformer model
is the set of pre-training tasks. With adequately designed paragraph-level
pre-training tasks, the Transformer models can remarkably improve over the
widely-used BM-25 as well as embedding models without Transformers. The
paragraph-level pre-training tasks we studied are Inverse Cloze Task (ICT),
Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of
all three.
</summary>
    <author>
      <name>Wei-Cheng Chang</name>
    </author>
    <author>
      <name>Felix X. Yu</name>
    </author>
    <author>
      <name>Yin-Wen Chang</name>
    </author>
    <author>
      <name>Yiming Yang</name>
    </author>
    <author>
      <name>Sanjiv Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03921v2</id>
    <updated>2020-02-13T00:50:39Z</updated>
    <published>2020-02-10T16:29:26Z</published>
    <title>End-to-End Multi-speaker Speech Recognition with Transformer</title>
    <summary>  Recently, fully recurrent neural network (RNN) based end-to-end models have
been proven to be effective for multi-speaker speech recognition in both the
single-channel and multi-channel scenarios. In this work, we explore the use of
Transformer models for these tasks by focusing on two aspects. First, we
replace the RNN-based encoder-decoder in the speech recognition model with a
Transformer architecture. Second, in order to use the Transformer in the
masking network of the neural beamformer in the multi-channel case, we modify
the self-attention component to be restricted to a segment rather than the
whole sequence in order to reduce computation. Besides the model architecture
improvements, we also incorporate an external dereverberation preprocessing,
the weighted prediction error (WPE), enabling our model to handle reverberated
signals. Experiments on the spatialized wsj1-2mix corpus show that the
Transformer-based models achieve 40.9% and 25.6% relative WER reduction, down
to 12.1% and 6.4% WER, under the anechoic condition in single-channel and
multi-channel tasks, respectively, while in the reverberant case, our methods
achieve 41.5% and 13.8% relative WER reduction, down to 16.5% and 15.2% WER.
</summary>
    <author>
      <name>Xuankai Chang</name>
    </author>
    <author>
      <name>Wangyou Zhang</name>
    </author>
    <author>
      <name>Yanmin Qian</name>
    </author>
    <author>
      <name>Jonathan Le Roux</name>
    </author>
    <author>
      <name>Shinji Watanabe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03921v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03921v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03912v1</id>
    <updated>2020-02-10T16:20:49Z</updated>
    <published>2020-02-10T16:20:49Z</published>
    <title>A Probabilistic Formulation of Unsupervised Text Style Transfer</title>
    <summary>  We present a deep generative model for unsupervised text style transfer that
unifies previously proposed non-generative techniques. Our probabilistic
approach models non-parallel data from two domains as a partially observed
parallel corpus. By hypothesizing a parallel latent sequence that generates
each observed sequence, our model learns to transform sequences from one domain
to another in a completely unsupervised fashion. In contrast with traditional
generative sequence models (e.g. the HMM), our model makes few assumptions
about the data it generates: it uses a recurrent language model as a prior and
an encoder-decoder as a transduction distribution. While computation of
marginal data likelihood is intractable in this model class, we show that
amortized variational inference admits a practical surrogate. Further, by
drawing connections between our variational objective and other recent
unsupervised style transfer and machine translation techniques, we show how our
probabilistic view can unify some known non-generative objectives such as
backtranslation and adversarial loss. Finally, we demonstrate the effectiveness
of our method on a wide range of unsupervised style transfer tasks, including
sentiment transfer, formality transfer, word decipherment, author imitation,
and related language translation. Across all style transfer tasks, our approach
yields substantial gains over state-of-the-art non-generative baselines,
including the state-of-the-art unsupervised machine translation techniques that
our approach generalizes. Further, we conduct experiments on a standard
unsupervised machine translation task and find that our unified approach
matches the current state-of-the-art.
</summary>
    <author>
      <name>Junxian He</name>
    </author>
    <author>
      <name>Xinyi Wang</name>
    </author>
    <author>
      <name>Graham Neubig</name>
    </author>
    <author>
      <name>Taylor Berg-Kirkpatrick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020 conference paper (spotlight). The first two authors
  contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03604v1</id>
    <updated>2020-02-10T08:53:27Z</updated>
    <published>2020-02-10T08:53:27Z</published>
    <title>A Study of Human Summaries of Scientific Articles</title>
    <summary>  Researchers and students face an explosion of newly published papers which
may be relevant to their work. This led to a trend of sharing human summaries
of scientific papers. We analyze the summaries shared in one of these platforms
Shortscience.org. The goal is to characterize human summaries of scientific
papers, and use some of the insights obtained to improve and adapt existing
automatic summarization systems to the domain of scientific papers.
</summary>
    <author>
      <name>Odellia Boni</name>
    </author>
    <author>
      <name>Guy Feigenblat</name>
    </author>
    <author>
      <name>Doron Cohen</name>
    </author>
    <author>
      <name>Haggai Roitman</name>
    </author>
    <author>
      <name>David Konopnicki</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03562v1</id>
    <updated>2020-02-10T05:47:35Z</updated>
    <published>2020-02-10T05:47:35Z</published>
    <title>NPLDA: A Deep Neural PLDA Model for Speaker Verification</title>
    <summary>  The state-of-art approach for speaker verification consists of a neural
network based embedding extractor along with a backend generative model such as
the Probabilistic Linear Discriminant Analysis (PLDA). In this work, we propose
a neural network approach for backend modeling in speaker recognition. The
likelihood ratio score of the generative PLDA model is posed as a
discriminative similarity function and the learnable parameters of the score
function are optimized using a verification cost. The proposed model, termed as
neural PLDA (NPLDA), is initialized using the generative PLDA model parameters.
The loss function for the NPLDA model is an approximation of the minimum
detection cost function (DCF). The speaker recognition experiments using the
NPLDA model are performed on the speaker verificiation task in the VOiCES
datasets as well as the SITW challenge dataset. In these experiments, the NPLDA
model optimized using the proposed loss function improves significantly over
the state-of-art PLDA based speaker verification system.
</summary>
    <author>
      <name>Shreyas Ramoji</name>
    </author>
    <author>
      <name>Prashant Krishnan</name>
    </author>
    <author>
      <name>Sriram Ganapathy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Odyssey 2020, the Speaker and Language Recognition
  Workshop (VOiCES Special Session). Link to GitHub Implementation:
  https://github.com/iiscleap/NeuralPlda. arXiv admin note: substantial text
  overlap with arXiv:2001.07034</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03552v1</id>
    <updated>2020-02-10T05:23:38Z</updated>
    <published>2020-02-10T05:23:38Z</published>
    <title>Automating App Review Response Generation</title>
    <summary>  Previous studies showed that replying to a user review usually has a positive
effect on the rating that is given by the user to the app. For example, Hassan
et al. found that responding to a review increases the chances of a user
updating their given rating by up to six times compared to not responding. To
alleviate the labor burden in replying to the bulk of user reviews, developers
usually adopt a template-based strategy where the templates can express
appreciation for using the app or mention the company email address for users
to follow up. However, reading a large number of user reviews every day is not
an easy task for developers. Thus, there is a need for more automation to help
developers respond to user reviews.
  Addressing the aforementioned need, in this work we propose a novel approach
RRGen that automatically generates review responses by learning knowledge
relations between reviews and their responses. RRGen explicitly incorporates
review attributes, such as user rating and review length, and learns the
relations between reviews and corresponding responses in a supervised way from
the available training data. Experiments on 58 apps and 309,246 review-response
pairs highlight that RRGen outperforms the baselines by at least 67.4% in terms
of BLEU-4 (an accuracy measure that is widely used to evaluate dialogue
response generation systems). Qualitative analysis also confirms the
effectiveness of RRGen in generating relevant and accurate responses.
</summary>
    <author>
      <name>Cuiyun Gao</name>
    </author>
    <author>
      <name>Jichuan Zeng</name>
    </author>
    <author>
      <name>Xin Xia</name>
    </author>
    <author>
      <name>David Lo</name>
    </author>
    <author>
      <name>Michael R. Lyu</name>
    </author>
    <author>
      <name>Irwin King</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, accepted by ASE'19</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03536v1</id>
    <updated>2020-02-10T04:27:48Z</updated>
    <published>2020-02-10T04:27:48Z</published>
    <title>What Changed Your Mind: The Roles of Dynamic Topics and Discourse in
  Argumentation Process</title>
    <summary>  In our world with full of uncertainty, debates and argumentation contribute
to the progress of science and society. Despite of the increasing attention to
characterize human arguments, most progress made so far focus on the debate
outcome, largely ignoring the dynamic patterns in argumentation processes. This
paper presents a study that automatically analyzes the key factors in argument
persuasiveness, beyond simply predicting who will persuade whom. Specifically,
we propose a novel neural model that is able to dynamically track the changes
of latent topics and discourse in argumentative conversations, allowing the
investigation of their roles in influencing the outcomes of persuasion.
Extensive experiments have been conducted on argumentative conversations on
both social media and supreme court. The results show that our model
outperforms state-of-the-art models in identifying persuasive arguments via
explicitly exploring dynamic factors of topic and discourse. We further analyze
the effects of topics and discourse on persuasiveness, and find that they are
both useful - topics provide concrete evidence while superior discourse styles
may bias participants, especially in social media arguments. In addition, we
draw some findings from our empirical results, which will help people better
engage in future persuasive conversations.
</summary>
    <author>
      <name>Jichuan Zeng</name>
    </author>
    <author>
      <name>Jing Li</name>
    </author>
    <author>
      <name>Yulan He</name>
    </author>
    <author>
      <name>Cuiyun Gao</name>
    </author>
    <author>
      <name>Michael R. Lyu</name>
    </author>
    <author>
      <name>Irwin King</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, accepted by The Web Conference 2020 (WWW'20)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03531v1</id>
    <updated>2020-02-10T04:00:07Z</updated>
    <published>2020-02-10T04:00:07Z</published>
    <title>A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly
  Articles</title>
    <summary>  Thomas Kuhn proposed his paradigmatic view of scientific discovery five
decades ago. The concept of paradigm has not only explained the progress of
science, but has also become the central epistemic concept among STM
scientists. Here, we adopt the principles of Kuhnian philosophy to construct a
novel ontology aims at classifying and evaluating the impact of STM scholarly
articles. First, we explain how the Kuhnian cycle of science describes research
at different epistemic stages. Second, we show how the Kuhnian cycle could be
reconstructed into modular ontologies which classify scholarly articles
according to their contribution to paradigm-centred knowledge. The proposed
ontology and its scenarios are discussed. To the best of the authors knowledge,
this is the first attempt for creating an ontology for describing scholarly
articles based on the Kuhnian paradigmatic view of science.
</summary>
    <author>
      <name>Khalid M. Saqr</name>
    </author>
    <author>
      <name>Abdelrahman Elsharawy</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03518v2</id>
    <updated>2020-02-12T23:28:06Z</updated>
    <published>2020-02-10T03:27:21Z</published>
    <title>Multilingual Alignment of Contextual Word Representations</title>
    <summary>  We propose procedures for evaluating and strengthening contextual embedding
alignment and show that they are useful in analyzing and improving multilingual
BERT. In particular, after our proposed alignment procedure, BERT exhibits
significantly improved zero-shot performance on XNLI compared to the base
model, remarkably matching pseudo-fully-supervised translate-train models for
Bulgarian and Greek. Further, to measure the degree of alignment, we introduce
a contextual version of word retrieval and show that it correlates well with
downstream zero-shot transfer. Using this word retrieval task, we also analyze
BERT and find that it exhibits systematic deficiencies, e.g. worse alignment
for open-class parts-of-speech and word pairs written in different scripts,
that are corrected by the alignment procedure. These results support contextual
alignment as a useful concept for understanding large multilingual pre-trained
models.
</summary>
    <author>
      <name>Steven Cao</name>
    </author>
    <author>
      <name>Nikita Kitaev</name>
    </author>
    <author>
      <name>Dan Klein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03518v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03518v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03438v1</id>
    <updated>2020-02-09T19:53:23Z</updated>
    <published>2020-02-09T19:53:23Z</published>
    <title>Limits of Detecting Text Generated by Large-Scale Language Models</title>
    <summary>  Some consider large-scale language models that can generate long and coherent
pieces of text as dangerous, since they may be used in misinformation
campaigns. Here we formulate large-scale language model output detection as a
hypothesis testing problem to classify text as genuine or generated. We show
that error exponents for particular language models are bounded in terms of
their perplexity, a standard measure of language generation performance. Under
the assumption that human language is stationary and ergodic, the formulation
is extended from considering specific language models to considering maximum
likelihood language models, among the class of k-order Markov approximations;
error probabilities are characterized. Some discussion of incorporating
semantic side information is also given.
</summary>
    <author>
      <name>Lav R. Varshney</name>
    </author>
    <author>
      <name>Nitish Shirish Keskar</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ITA 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03407v1</id>
    <updated>2020-02-09T17:49:08Z</updated>
    <published>2020-02-09T17:49:08Z</published>
    <title>Abstractive Summarization for Low Resource Data using Domain Transfer
  and Data Synthesis</title>
    <summary>  Training abstractive summarization models typically requires large amounts of
data, which can be a limitation for many domains. In this paper we explore
using domain transfer and data synthesis to improve the performance of recent
abstractive summarization methods when applied to small corpora of student
reflections. First, we explored whether tuning state of the art model trained
on newspaper data could boost performance on student reflection data.
Evaluations demonstrated that summaries produced by the tuned model achieved
higher ROUGE scores compared to model trained on just student reflection data
or just newspaper data. The tuned model also achieved higher scores compared to
extractive summarization baselines, and additionally was judged to produce more
coherent and readable summaries in human evaluations. Second, we explored
whether synthesizing summaries of student data could additionally boost
performance. We proposed a template-based model to synthesize new data, which
when incorporated into training further increased ROUGE scores. Finally, we
showed that combining data synthesis with domain transfer achieved higher ROUGE
scores compared to only using one of the two approaches.
</summary>
    <author>
      <name>Ahmed Magooda</name>
    </author>
    <author>
      <name>Diane Litman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in FLAIRS33 (https://www.flairs-33.info/) and appear
  in he proceedings of AAAI</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03405v1</id>
    <updated>2020-02-09T17:46:22Z</updated>
    <published>2020-02-09T17:46:22Z</published>
    <title>Attend to the beginning: A study on using bidirectional attention for
  extractive summarization</title>
    <summary>  Forum discussion data differ in both structure and properties from generic
form of textual data such as news. Henceforth, summarization techniques should,
in turn, make use of such differences, and craft models that can benefit from
the structural nature of discussion data. In this work, we propose attending to
the beginning of a document, to improve the performance of extractive
summarization models when applied to forum discussion data. Evaluations
demonstrated that with the help of bidirectional attention mechanism, attending
to the beginning of a document (initial comment/post) in a discussion thread,
can introduce a consistent boost in ROUGE scores, as well as introducing a new
State Of The Art (SOTA) ROUGE scores on the forum discussions dataset.
Additionally, we explored whether this hypothesis is extendable to other
generic forms of textual data. We make use of the tendency of introducing
important information early in the text, by attending to the first few
sentences in generic textual data. Evaluations demonstrated that attending to
introductory sentences using bidirectional attention, improves the performance
of extractive summarization models when even applied to more generic form of
textual data.
</summary>
    <author>
      <name>Ahmed Magooda</name>
    </author>
    <author>
      <name>Cezary Marcjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in FLAIRS33 (https://www.flairs-33.info/) and appear
  in he proceedings of AAAI</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03350v1</id>
    <updated>2020-02-09T12:08:43Z</updated>
    <published>2020-02-09T12:08:43Z</published>
    <title>Short Text Classification via Knowledge powered Attention with
  Similarity Matrix based CNN</title>
    <summary>  Short text is becoming more and more popular on the web, such as Chat
Message, SMS and Product Reviews. Accurately classifying short text is an
important and challenging task. A number of studies have difficulties in
addressing this problem because of the word ambiguity and data sparsity. To
address this issue, we propose a knowledge powered attention with similarity
matrix based convolutional neural network (KASM) model, which can compute
comprehensive information by utilizing the knowledge and deep neural network.
We use knowledge graph (KG) to enrich the semantic representation of short
text, specially, the information of parent-entity is introduced in our model.
Meanwhile, we consider the word interaction in the literal-level between short
text and the representation of label, and utilize similarity matrix based
convolutional neural network (CNN) to extract it. For the purpose of measuring
the importance of knowledge, we introduce the attention mechanisms to choose
the important information. Experimental results on five standard datasets show
that our model significantly outperforms state-of-the-art methods.
</summary>
    <author>
      <name>Mingchen Li</name>
    </author>
    <author>
      <name>Gabtone. Clinton</name>
    </author>
    <author>
      <name>Yijia Miao</name>
    </author>
    <author>
      <name>Feng Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08902v1</id>
    <updated>2020-02-09T08:18:20Z</updated>
    <published>2020-02-09T08:18:20Z</published>
    <title>Application of Pre-training Models in Named Entity Recognition</title>
    <summary>  Named Entity Recognition (NER) is a fundamental Natural Language Processing
(NLP) task to extract entities from unstructured data. The previous methods for
NER were based on machine learning or deep learning. Recently, pre-training
models have significantly improved performance on multiple NLP tasks. In this
paper, firstly, we introduce the architecture and pre-training tasks of four
common pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa. Then, we
apply these pre-training models to a NER task by fine-tuning, and compare the
effects of the different model architecture and pre-training tasks on the NER
task. The experiment results showed that RoBERTa achieved state-of-the-art
results on the MSRA-2006 dataset.
</summary>
    <author>
      <name>Yu Wang</name>
    </author>
    <author>
      <name>Yining Sun</name>
    </author>
    <author>
      <name>Zuchang Ma</name>
    </author>
    <author>
      <name>Lisheng Gao</name>
    </author>
    <author>
      <name>Yang Xu</name>
    </author>
    <author>
      <name>Ting Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03259v1</id>
    <updated>2020-02-09T01:03:25Z</updated>
    <published>2020-02-09T01:03:25Z</published>
    <title>Rough Set based Aggregate Rank Measure &amp; its Application to Supervised
  Multi Document Summarization</title>
    <summary>  Most problems in Machine Learning cater to classification and the objects of
universe are classified to a relevant class. Ranking of classified objects of
universe per decision class is a challenging problem. We in this paper propose
a novel Rough Set based membership called Rank Measure to solve to this
problem. It shall be utilized for ranking the elements to a particular class.
It differs from Pawlak Rough Set based membership function which gives an
equivalent characterization of the Rough Set based approximations. It becomes
paramount to look beyond the traditional approach of computing memberships
while handling inconsistent, erroneous and missing data that is typically
present in real world problems. This led us to propose the aggregate Rank
Measure. The contribution of the paper is three fold. Firstly, it proposes a
Rough Set based measure to be utilized for numerical characterization of within
class ranking of objects. Secondly, it proposes and establish the properties of
Rank Measure and aggregate Rank Measure based membership. Thirdly, we apply the
concept of membership and aggregate ranking to the problem of supervised Multi
Document Summarization wherein first the important class of sentences are
determined using various supervised learning techniques and are post processed
using the proposed ranking measure. The results proved to have significant
improvement in accuracy.
</summary>
    <author>
      <name>Nidhika Yadav</name>
    </author>
    <author>
      <name>Niladri Chatterjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper proposes a novel Rough Set based technique to compute rank
  in a decision system. This is further evaluated on the problem of Supervised
  Text Summarization. The paper contains 9 pages, illustrative examples,
  theoretical properties, and experimental evaluations on standard datasets</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03246v1</id>
    <updated>2020-02-08T23:15:06Z</updated>
    <published>2020-02-08T23:15:06Z</published>
    <title>SPA: Verbal Interactions between Agents and Avatars in Shared Virtual
  Environments using Propositional Planning</title>
    <summary>  We present a novel approach for generating plausible verbal interactions
between virtual human-like agents and user avatars in shared virtual
environments. Sense-Plan-Ask, or SPA, extends prior work in propositional
planning and natural language processing to enable agents to plan with
uncertain information, and leverage question and answer dialogue with other
agents and avatars to obtain the needed information and complete their goals.
The agents are additionally able to respond to questions from the avatars and
other agents using natural-language enabling real-time multi-agent multi-avatar
communication environments.
  Our algorithm can simulate tens of virtual agents at interactive rates
interacting, moving, communicating, planning, and replanning. We find that our
algorithm creates a small runtime cost and enables agents to complete their
goals more effectively than agents without the ability to leverage
natural-language communication. We demonstrate quantitative results on a set of
simulated benchmarks and detail the results of a preliminary user-study
conducted to evaluate the plausibility of the virtual interactions generated by
SPA. Overall, we find that participants prefer SPA to prior techniques in 84\%
of responses including significant benefits in terms of the plausibility of
natural-language interactions and the positive impact of those interactions.
</summary>
    <author>
      <name>Andrew Best</name>
    </author>
    <author>
      <name>Sahil Narang</name>
    </author>
    <author>
      <name>Dinesh Manocha</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03184v1</id>
    <updated>2020-02-08T15:30:28Z</updated>
    <published>2020-02-08T15:30:28Z</published>
    <title>Time-aware Large Kernel Convolutions</title>
    <summary>  To date, most state-of-the-art sequence modelling architectures use attention
to build generative models for language based tasks. Some of these models use
all the available sequence tokens to generate an attention distribution which
results in time complexity of $O(n^2)$. Alternatively, they utilize depthwise
convolutions with softmax normalized kernels of size $k$ acting as a
limited-window self-attention, resulting in time complexity of $O(k{\cdot}n)$.
In this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a
novel adaptive convolution operation that learns to predict the size of a
summation kernel instead of using the fixed-sized kernel matrix. This method
yields a time complexity of $O(n)$, effectively making the sequence encoding
process linear to the number of tokens. We evaluate the proposed method on
large-scale standard machine translation and language modelling datasets and
show that TaLK Convolutions constitute an efficient improvement over other
attention/convolution based approaches.
</summary>
    <author>
      <name>Vasileios Lioutas</name>
    </author>
    <author>
      <name>Yuhong Guo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03149v2</id>
    <updated>2020-02-11T04:16:47Z</updated>
    <published>2020-02-08T12:02:45Z</published>
    <title>Mining Commonsense Facts from the Physical World</title>
    <summary>  Textual descriptions of the physical world implicitly mention commonsense
facts, while the commonsense knowledge bases explicitly represent such facts as
triples. Compared to dramatically increased text data, the coverage of existing
knowledge bases is far away from completion. Most of the prior studies on
populating knowledge bases mainly focus on Freebase. To automatically complete
commonsense knowledge bases to improve their coverage is under-explored. In
this paper, we propose a new task of mining commonsense facts from the raw text
that describes the physical world. We build an effective new model that fuses
information from both sequence text and existing knowledge base resource. Then
we create two large annotated datasets each with approximate 200k instances for
commonsense knowledge base completion. Empirical results demonstrate that our
model significantly outperforms baselines.
</summary>
    <author>
      <name>Yanyan Zou</name>
    </author>
    <author>
      <name>Wei Lu</name>
    </author>
    <author>
      <name>Xu Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03149v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03149v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03140v1</id>
    <updated>2020-02-08T11:06:27Z</updated>
    <published>2020-02-08T11:06:27Z</published>
    <title>HHH: An Online Medical Chatbot System based on Knowledge Graph and
  Hierarchical Bi-Directional Attention</title>
    <summary>  This paper proposes a chatbot framework that adopts a hybrid model which
consists of a knowledge graph and a text similarity model. Based on this
chatbot framework, we build HHH, an online question-and-answer (QA) Healthcare
Helper system for answering complex medical questions. HHH maintains a
knowledge graph constructed from medical data collected from the Internet. HHH
also implements a novel text representation and similarity deep learning model,
Hierarchical BiLSTM Attention Model (HBAM), to find the most similar question
from a large QA dataset. We compare HBAM with other state-of-the-art language
models such as bidirectional encoder representation from transformers (BERT)
and Manhattan LSTM Model (MaLSTM). We train and test the models with a subset
of the Quora duplicate questions dataset in the medical area. The experimental
results show that our model is able to achieve a superior performance than
these existing methods.
</summary>
    <author>
      <name>Qiming Bao</name>
    </author>
    <author>
      <name>Lin Ni</name>
    </author>
    <author>
      <name>Jiamou Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3373017.3373049</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3373017.3373049" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures, 3 tables. Proceedings of the Australasian
  Computer Science Week Multiconference (ACSW 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03084v1</id>
    <updated>2020-02-08T04:11:03Z</updated>
    <published>2020-02-08T04:11:03Z</published>
    <title>LAVA NAT: A Non-Autoregressive Translation Model with Look-Around
  Decoding and Vocabulary Attention</title>
    <summary>  Non-autoregressive translation (NAT) models generate multiple tokens in one
forward pass and is highly efficient at inference stage compared with
autoregressive translation (AT) methods. However, NAT models often suffer from
the multimodality problem, i.e., generating duplicated tokens or missing
tokens. In this paper, we propose two novel methods to address this issue, the
Look-Around (LA) strategy and the Vocabulary Attention (VA) mechanism. The
Look-Around strategy predicts the neighbor tokens in order to predict the
current token, and the Vocabulary Attention models long-term token dependencies
inside the decoder by attending the whole vocabulary for each position to
acquire knowledge of which token is about to generate. %We also propose a
dynamic bidirectional decoding approach to accelerate the inference process of
the LAVA model while preserving the high-quality of the generated output. Our
proposed model uses significantly less time during inference compared with
autoregressive models and most other NAT models. Our experiments on four
benchmarks (WMT14 En$\rightarrow$De, WMT14 De$\rightarrow$En, WMT16
Ro$\rightarrow$En and IWSLT14 De$\rightarrow$En) show that the proposed model
achieves competitive performance compared with the state-of-the-art
non-autoregressive and autoregressive models while significantly reducing the
time cost in inference phase.
</summary>
    <author>
      <name>Xiaoya Li</name>
    </author>
    <author>
      <name>Yuxian Meng</name>
    </author>
    <author>
      <name>Arianna Yuan</name>
    </author>
    <author>
      <name>Fei Wu</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03079v1</id>
    <updated>2020-02-08T03:41:37Z</updated>
    <published>2020-02-08T03:41:37Z</published>
    <title>Blank Language Models</title>
    <summary>  We propose Blank Language Model (BLM), a model that generates sequences by
dynamically creating and filling in blanks. Unlike previous masked language
models or the Insertion Transformer, BLM uses blanks to control which part of
the sequence to expand. This fine-grained control of generation is ideal for a
variety of text editing and rewriting tasks. The model can start from a single
blank or partially completed text with blanks at specified locations. It
iteratively determines which word to place in a blank and whether to insert new
blanks, and stops generating when no blanks are left to fill. BLM can be
efficiently trained using a lower bound of the marginal data likelihood, and
achieves perplexity comparable to traditional left-to-right language models on
the Penn Treebank and WikiText datasets. On the task of filling missing text
snippets, BLM significantly outperforms all other baselines in terms of both
accuracy and fluency. Experiments on style transfer and damaged ancient text
restoration demonstrate the potential of this framework for a wide range of
applications.
</summary>
    <author>
      <name>Tianxiao Shen</name>
    </author>
    <author>
      <name>Victor Quach</name>
    </author>
    <author>
      <name>Regina Barzilay</name>
    </author>
    <author>
      <name>Tommi Jaakkola</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03067v1</id>
    <updated>2020-02-08T02:14:28Z</updated>
    <published>2020-02-08T02:14:28Z</published>
    <title>Description Based Text Classification with Reinforcement Learning</title>
    <summary>  The task of text classification is usually divided into two stages: {\it text
feature extraction} and {\it classification}. In this standard formalization
categories are merely represented as indexes in the label vocabulary, and the
model lacks for explicit instructions on what to classify. Inspired by the
current trend of formalizing NLP problems as question answering tasks, we
propose a new framework for text classification, in which each category label
is associated with a category description. Descriptions are generated by
hand-crafted templates or using abstractive/extractive models from
reinforcement learning. The concatenation of the description and the text is
fed to the classifier to decide whether or not the current label should be
assigned to the text. The proposed strategy forces the model to attend to the
most salient texts with respect to the label, which can be regarded as a hard
version of attention, leading to better performances. We observe significant
performance boosts over strong baselines on a wide range of text classification
tasks including single-label classification, multi-label classification and
multi-aspect sentiment analysis.
</summary>
    <author>
      <name>Duo Chai</name>
    </author>
    <author>
      <name>Wei Wu</name>
    </author>
    <author>
      <name>Qinghong Han</name>
    </author>
    <author>
      <name>Fei Wu</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03056v1</id>
    <updated>2020-02-08T00:42:21Z</updated>
    <published>2020-02-08T00:42:21Z</published>
    <title>autoNLP: NLP Feature Recommendations for Text Analytics Applications</title>
    <summary>  While designing machine learning based text analytics applications, often,
NLP data scientists manually determine which NLP features to use based upon
their knowledge and experience with related problems. This results in increased
efforts during feature engineering process and renders automated reuse of
features across semantically related applications inherently difficult. In this
paper, we argue for standardization in feature specification by outlining
structure of a language for specifying NLP features and present an approach for
their reuse across applications to increase likelihood of identifying optimal
features.
</summary>
    <author>
      <name>Janardan Misra</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03049v1</id>
    <updated>2020-02-07T23:54:23Z</updated>
    <published>2020-02-07T23:54:23Z</published>
    <title>Snippext: Semi-supervised Opinion Mining with Augmented Data</title>
    <summary>  Online services are interested in solutions to opinion mining, which is the
problem of extracting aspects, opinions, and sentiments from text. One method
to mine opinions is to leverage the recent success of pre-trained language
models which can be fine-tuned to obtain high-quality extractions from reviews.
However, fine-tuning language models still requires a non-trivial amount of
training data. In this paper, we study the problem of how to significantly
reduce the amount of labeled training data required in fine-tuning language
models for opinion mining. We describe Snippext, an opinion mining system
developed over a language model that is fine-tuned through semi-supervised
learning with augmented data. A novelty of Snippext is its clever use of a
two-prong approach to achieve state-of-the-art (SOTA) performance with little
labeled training data through: (1) data augmentation to automatically generate
more labeled training data from existing ones, and (2) a semi-supervised
learning technique to leverage the massive amount of unlabeled data in addition
to the (limited amount of) labeled data. We show with extensive experiments
that Snippext performs comparably and can even exceed previous SOTA results on
several opinion mining tasks with only half the training data required.
Furthermore, it achieves new SOTA results when all training data are leveraged.
By comparison to a baseline pipeline, we found that Snippext extracts
significantly more fine-grained opinions which enable new opportunities of
downstream applications.
</summary>
    <author>
      <name>Zhengjie Miao</name>
    </author>
    <author>
      <name>Yuliang Li</name>
    </author>
    <author>
      <name>Xiaolan Wang</name>
    </author>
    <author>
      <name>Wang-Chiew Tan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380144</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380144" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to WWW 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02955v2</id>
    <updated>2020-02-21T20:39:34Z</updated>
    <published>2020-02-07T18:50:21Z</published>
    <title>A Multilingual View of Unsupervised Machine Translation</title>
    <summary>  We present a probabilistic framework for multilingual neural machine
translation that encompasses supervised and unsupervised setups, focusing on
unsupervised translation. In addition to studying the vanilla case where there
is only monolingual data available, we propose a novel setup where one language
in the (source, target) pair is not associated with any parallel data, but
there may exist auxiliary parallel data that contains the other. This auxiliary
data can naturally be utilized in our probabilistic framework via a novel
cross-translation loss term. Empirically, we show that our approach results in
higher BLEU scores over state-of-the-art unsupervised models on the WMT'14
English-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in
most directions. In particular, we obtain a +1.65 BLEU advantage over the
best-performing unsupervised model in the Romanian-English direction.
</summary>
    <author>
      <name>Xavier Garcia</name>
    </author>
    <author>
      <name>Pierre Foret</name>
    </author>
    <author>
      <name>Thibault Sellam</name>
    </author>
    <author>
      <name>Ankur P. Parikh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added new reference, fixed typos</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02955v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02955v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02925v2</id>
    <updated>2020-02-10T18:45:41Z</updated>
    <published>2020-02-07T17:52:16Z</published>
    <title>BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</title>
    <summary>  In this paper, we propose a novel model compression approach to effectively
compress BERT by progressive module replacing. Our approach first divides the
original BERT into several modules and builds their compact substitutes. Then,
we randomly replace the original modules with their substitutes to train the
compact modules to mimic the behavior of the original modules. We progressively
increase the probability of replacement through the training. In this way, our
approach brings a deeper level of interaction between the original and compact
models, and smooths the training process. Compared to the previous knowledge
distillation approaches for BERT compression, our approach leverages only one
loss function and one hyper-parameter, liberating human effort from
hyper-parameter tuning. Our approach outperforms existing knowledge
distillation approaches on GLUE benchmark, showing a new perspective of model
compression.
</summary>
    <author>
      <name>Canwen Xu</name>
    </author>
    <author>
      <name>Wangchunshu Zhou</name>
    </author>
    <author>
      <name>Tao Ge</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages; typo fixed</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02925v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02925v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02878v2</id>
    <updated>2020-02-10T20:45:20Z</updated>
    <published>2020-02-07T16:22:36Z</published>
    <title>I love your chain mail! Making knights smile in a fantasy game world:
  Open-domain goal-oriented dialogue agents</title>
    <summary>  Dialogue research tends to distinguish between chit-chat and goal-oriented
tasks. While the former is arguably more naturalistic and has a wider use of
language, the latter has clearer metrics and a straightforward learning signal.
Humans effortlessly combine the two, for example engaging in chit-chat with the
goal of exchanging information or eliciting a specific response. Here, we
bridge the divide between these two domains in the setting of a rich
multi-player text-based fantasy environment where agents and humans engage in
both actions and dialogue. Specifically, we train a goal-oriented model with
reinforcement learning against an imitation-learned ``chit-chat'' model with
two approaches: the policy either learns to pick a topic or learns to pick an
utterance given the top-K utterances from the chit-chat model. We show that
both models outperform an inverse model baseline and can converse naturally
with their dialogue partner in order to achieve goals.
</summary>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <author>
      <name>Margaret Li</name>
    </author>
    <author>
      <name>Jack Urbanek</name>
    </author>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02878v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02878v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05674v1</id>
    <updated>2020-02-07T15:59:49Z</updated>
    <published>2020-02-07T15:59:49Z</published>
    <title>What Would You Ask the Machine Learning Model? Identification of User
  Needs for Model Explanations Based on Human-Model Conversations</title>
    <summary>  Recently we see a rising number of methods in the field of eXplainable
Artificial Intelligence. To our surprise, their development is driven by model
developers rather than a study of needs for human end users. To answer the
question "What would a human operator like to ask the ML model?" we propose a
conversational system explaining decisions of the predictive model. In this
experiment, we implement a chatbot called dr_ant and train a model predicting
survival odds on Titanic. People can talk to dr_ant about the model to
understand the rationale behind its predictions. Having collected a corpus of
1000+ dialogues, we analyse the most common types of questions that users would
like to ask. To our knowledge, it is the first study of needs for human
operators in the context of conversations with an ML model. It is also a first
study which uses a conversational system for interactive exploration of a
predictive model trained on tabular data.
</summary>
    <author>
      <name>Michał Kuźba</name>
    </author>
    <author>
      <name>Przemysław Biecek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02848v1</id>
    <updated>2020-02-07T15:34:53Z</updated>
    <published>2020-02-07T15:34:53Z</published>
    <title>Unsupervised pretraining transfers well across languages</title>
    <summary>  Cross-lingual and multi-lingual training of Automatic Speech Recognition
(ASR) has been extensively investigated in the supervised setting. This assumes
the existence of a parallel corpus of speech and orthographic transcriptions.
Recently, contrastive predictive coding (CPC) algorithms have been proposed to
pretrain ASR systems with unlabelled data. In this work, we investigate whether
unsupervised pretraining transfers well across languages. We show that a slight
modification of the CPC pretraining extracts features that transfer well to
other languages, being on par or even outperforming supervised pretraining.
This shows the potential of unsupervised methods for languages with few
linguistic resources.
</summary>
    <author>
      <name>Morgane Rivière</name>
    </author>
    <author>
      <name>Armand Joulin</name>
    </author>
    <author>
      <name>Pierre-Emmanuel Mazaré</name>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. Accepted at ICASSP 2020. However the 2 pages of
  supplementary materials will appear only in the arxiv version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.02848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02800v1</id>
    <updated>2020-02-07T14:18:53Z</updated>
    <published>2020-02-07T14:18:53Z</published>
    <title>Depressed individuals express more distorted thinking on social media</title>
    <summary>  Depression is a leading cause of disability worldwide, but is often
under-diagnosed and under-treated. One of the tenets of cognitive-behavioral
therapy (CBT) is that individuals who are depressed exhibit distorted modes of
thinking, so-called cognitive distortions, which can negatively affect their
emotions and motivation. Here, we show that individuals with a self-reported
diagnosis of depression on social media express higher levels of distorted
thinking than a random sample. Some types of distorted thinking were found to
be more than twice as prevalent in our depressed cohort, in particular
Personalizing and Emotional Reasoning. This effect is specific to the distorted
content of the expression and can not be explained by the presence of specific
topics, sentiment, or first-person pronouns. Our results point towards the
detection, and possibly mitigation, of patterns of online language that are
generally deemed depressogenic. They may also provide insight into recent
observations that social media usage can have a negative impact on mental
health.
</summary>
    <author>
      <name>Krishna C. Bathina</name>
    </author>
    <author>
      <name>Marijn ten Thij</name>
    </author>
    <author>
      <name>Lorenzo Lorenzo-Luaces</name>
    </author>
    <author>
      <name>Lauren A. Rutter</name>
    </author>
    <author>
      <name>Johan Bollen</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08901v1</id>
    <updated>2020-02-07T13:14:58Z</updated>
    <published>2020-02-07T13:14:58Z</published>
    <title>Identifying physical health comorbidities in a cohort of individuals
  with severe mental illness: An application of SemEHR</title>
    <summary>  Multimorbidity research in mental health services requires data from physical
health conditions which is traditionally limited in mental health care
electronic health records. In this study, we aimed to extract data from
physical health conditions from clinical notes using SemEHR. Data was extracted
from Clinical Record Interactive Search (CRIS) system at South London and
Maudsley Biomedical Research Centre (SLaM BRC) and the cohort consisted of all
individuals who had received a primary or secondary diagnosis of severe mental
illness between 2007 and 2018. Three pairs of annotators annotated 2403
documents with an average Cohen's Kappa of 0.757. Results show that the NLP
performance varies across different diseases areas (F1 0.601 - 0.954)
suggesting that the language patterns or terminologies of different condition
groups entail different technical challenges to the same NLP task.
</summary>
    <author>
      <name>Rebecca Bendayan</name>
    </author>
    <author>
      <name>Honghan Wu</name>
    </author>
    <author>
      <name>Zeljko Kraljevic</name>
    </author>
    <author>
      <name>Robert Stewart</name>
    </author>
    <author>
      <name>Tom Searle</name>
    </author>
    <author>
      <name>Jaya Chaturvedi</name>
    </author>
    <author>
      <name>Jayati Das-Munshi</name>
    </author>
    <author>
      <name>Zina Ibrahim</name>
    </author>
    <author>
      <name>Aurelie Mascio</name>
    </author>
    <author>
      <name>Angus Roberts</name>
    </author>
    <author>
      <name>Daniel Bean</name>
    </author>
    <author>
      <name>Richard Dobson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02735v1</id>
    <updated>2020-02-07T12:28:56Z</updated>
    <published>2020-02-07T12:28:56Z</published>
    <title>LEAP System for SRE19 Challenge -- Improvements and Error Analysis</title>
    <summary>  The NIST Speaker Recognition Evaluation - Conversational Telephone Speech
(CTS) challenge 2019 was an open evaluation for the task of speaker
verification in challenging conditions. In this paper, we provide a detailed
account of the LEAP SRE system submitted to the CTS challenge focusing on the
novel components in the back-end system modeling. All the systems used the
time-delay neural network (TDNN) based x-vector embeddings. The x-vector system
in our SRE19 submission used a large pool of training speakers (about 14k
speakers). Following the x-vector extraction, we explored a neural network
approach to backend score computation that was optimized for a speaker
verification cost. The system combination of generative and neural PLDA models
resulted in significant improvements for the SRE evaluation dataset. We also
found additional gains for the SRE systems based on score normalization and
calibration. Subsequent to the evaluations, we have performed a detailed
analysis of the submitted systems. The analysis revealed the incremental gains
obtained for different training dataset combinations as well as the modeling
methods.
</summary>
    <author>
      <name>Shreyas Ramoji</name>
    </author>
    <author>
      <name>Prashant Krishnan</name>
    </author>
    <author>
      <name>Bhargavram Mysore</name>
    </author>
    <author>
      <name>Prachi Singh</name>
    </author>
    <author>
      <name>Sriram Ganapathy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Odyssey 2020, the Speaker and Language Recognition
  Workshop. Link to GitHub Implementation:
  https://github.com/iiscleap/NeuralPlda</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02734v1</id>
    <updated>2020-02-07T12:26:41Z</updated>
    <published>2020-02-07T12:26:41Z</published>
    <title>Incorporating Visual Semantics into Sentence Representations within a
  Grounded Space</title>
    <summary>  Language grounding is an active field aiming at enriching textual
representations with visual information. Generally, textual and visual elements
are embedded in the same representation space, which implicitly assumes a
one-to-one correspondence between modalities. This hypothesis does not hold
when representing words, and becomes problematic when used to learn sentence
representations --- the focus of this paper --- as a visual scene can be
described by a wide variety of sentences. To overcome this limitation, we
propose to transfer visual information to textual representations by learning
an intermediate representation space: the grounded space. We further propose
two new complementary objectives ensuring that (1) sentences associated with
the same visual content are close in the grounded space and (2) similarities
between related elements are preserved across modalities. We show that this
model outperforms the previous state-of-the-art on classification and semantic
relatedness tasks.
</summary>
    <author>
      <name>Patrick Bordes</name>
    </author>
    <author>
      <name>Eloi Zablocki</name>
    </author>
    <author>
      <name>Laure Soulier</name>
    </author>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02649v1</id>
    <updated>2020-02-07T07:19:15Z</updated>
    <published>2020-02-07T07:19:15Z</published>
    <title>Multimodal Matching Transformer for Live Commenting</title>
    <summary>  Automatic live commenting aims to provide real-time comments on videos for
viewers. It encourages users engagement on online video sites, and is also a
good benchmark for video-to-text generation. Recent work on this task adopts
encoder-decoder models to generate comments. However, these methods do not
model the interaction between videos and comments explicitly, so they tend to
generate popular comments that are often irrelevant to the videos. In this
work, we aim to improve the relevance between live comments and videos by
modeling the cross-modal interactions among different modalities. To this end,
we propose a multimodal matching transformer to capture the relationships among
comments, vision, and audio. The proposed model is based on the transformer
framework and can iteratively learn the attention-aware representations for
each modality. We evaluate the model on a publicly available live commenting
dataset. Experiments show that the multimodal matching transformer model
outperforms the state-of-the-art methods.
</summary>
    <author>
      <name>Chaoqun Duan</name>
    </author>
    <author>
      <name>Lei Cui</name>
    </author>
    <author>
      <name>Shuming Ma</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Conghui Zhu</name>
    </author>
    <author>
      <name>Tiejun Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02631v1</id>
    <updated>2020-02-07T05:52:06Z</updated>
    <published>2020-02-07T05:52:06Z</published>
    <title>Translating Web Search Queries into Natural Language Questions</title>
    <summary>  Users often query a search engine with a specific question in mind and often
these queries are keywords or sub-sentential fragments. For example, if the
users want to know the answer for "What's the capital of USA", they will most
probably query "capital of USA" or "USA capital" or some keyword-based
variation of this. For example, for the user entered query "capital of USA",
the most probable question intent is "What's the capital of USA?". In this
paper, we are proposing a method to generate well-formed natural language
question from a given keyword-based query, which has the same question intent
as the query. Conversion of keyword-based web query into a well-formed question
has lots of applications, with some of them being in search engines, Community
Question Answering (CQA) website and bots communication. We found a synergy
between query-to-question problem with standard machine translation(MT) task.
We have used both Statistical MT (SMT) and Neural MT (NMT) models to generate
the questions from the query. We have observed that MT models perform well in
terms of both automatic and human evaluation.
</summary>
    <author>
      <name>Adarsh Kumar</name>
    </author>
    <author>
      <name>Sandipan Dandapat</name>
    </author>
    <author>
      <name>Sushil Chordia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Eleventh International Conference on Language Resources and
  Evaluation, LREC 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08898v1</id>
    <updated>2020-02-07T05:34:58Z</updated>
    <published>2020-02-07T05:34:58Z</published>
    <title>MA-DST: Multi-Attention Based Scalable Dialog State Tracking</title>
    <summary>  Task oriented dialog agents provide a natural language interface for users to
complete their goal. Dialog State Tracking (DST), which is often a core
component of these systems, tracks the system's understanding of the user's
goal throughout the conversation. To enable accurate multi-domain DST, the
model needs to encode dependencies between past utterances and slot semantics
and understand the dialog context, including long-range cross-domain
references. We introduce a novel architecture for this task to encode the
conversation history and slot semantics more robustly by using attention
mechanisms at multiple granularities. In particular, we use cross-attention to
model relationships between the context and slots at different semantic levels
and self-attention to resolve cross-domain coreferences. In addition, our
proposed architecture does not rely on knowing the domain ontologies beforehand
and can also be used in a zero-shot setting for new domains or unseen slot
values. Our model improves the joint goal accuracy by 5% (absolute) in the
full-data setting and by up to 2% (absolute) in the zero-shot setting over the
present state-of-the-art on the MultiWoZ 2.1 dataset.
</summary>
    <author>
      <name>Adarsh Kumar</name>
    </author>
    <author>
      <name>Peter Ku</name>
    </author>
    <author>
      <name>Anuj Kumar Goyal</name>
    </author>
    <author>
      <name>Angeliki Metallinou</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02562v2</id>
    <updated>2020-02-14T21:47:10Z</updated>
    <published>2020-02-07T00:04:04Z</published>
    <title>Transformer Transducer: A Streamable Speech Recognition Model with
  Transformer Encoders and RNN-T Loss</title>
    <summary>  In this paper we present an end-to-end speech recognition model with
Transformer encoders that can be used in a streaming speech recognition system.
Transformer computation blocks based on self-attention are used to encode both
audio and label sequences independently. The activations from both audio and
label encoders are combined with a feed-forward layer to compute a probability
distribution over the label space for every combination of acoustic frame
position and label history. This is similar to the Recurrent Neural Network
Transducer (RNN-T) model, which uses RNNs for information encoding instead of
Transformer encoders. The model is trained with the RNN-T loss well-suited to
streaming decoding. We present results on the LibriSpeech dataset showing that
limiting the left context for self-attention in the Transformer layers makes
decoding computationally tractable for streaming, with only a slight
degradation in accuracy. We also show that the full attention version of our
model beats the-state-of-the art accuracy on the LibriSpeech benchmarks. Our
results also show that we can bridge the gap between full attention and limited
attention versions of our model by attending to a limited number of future
frames.
</summary>
    <author>
      <name>Qian Zhang</name>
    </author>
    <author>
      <name>Han Lu</name>
    </author>
    <author>
      <name>Hasim Sak</name>
    </author>
    <author>
      <name>Anshuman Tripathi</name>
    </author>
    <author>
      <name>Erik McDermott</name>
    </author>
    <author>
      <name>Stephen Koo</name>
    </author>
    <author>
      <name>Shankar Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the final version of the paper submitted to the ICASSP 2020
  on Oct 21, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02562v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02562v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10284v1</id>
    <updated>2020-02-06T23:45:50Z</updated>
    <published>2020-02-06T23:45:50Z</published>
    <title>Word Embeddings Inherently Recover the Conceptual Organization of the
  Human Mind</title>
    <summary>  Machine learning is a means to uncover deep patterns from rich sources of
data. Here, we find that machine learning can recover the conceptual
organization of the human mind when applied to the natural language use of
millions of people. Utilizing text from billions of webpages, we recover most
of the concepts contained in English, Dutch, and Japanese, as represented in
large scale Word Association networks. Our results justify machine learning as
a means to probe the human mind, at a depth and scale that has been
unattainable using self-report and observational methods. Beyond direct
psychological applications, our methods may prove useful for projects concerned
with defining, assessing, relating, or uncovering concepts in any scientific
field.
</summary>
    <author>
      <name>Victor Swift</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02520v1</id>
    <updated>2020-02-06T21:47:39Z</updated>
    <published>2020-02-06T21:47:39Z</published>
    <title>Robust Multi-channel Speech Recognition using Frequency Aligned Network</title>
    <summary>  Conventional speech enhancement technique such as beamforming has known
benefits for far-field speech recognition. Our own work in frequency-domain
multi-channel acoustic modeling has shown additional improvements by training a
spatial filtering layer jointly within an acoustic model. In this paper, we
further develop this idea and use frequency aligned network for robust
multi-channel automatic speech recognition (ASR). Unlike an affine layer in the
frequency domain, the proposed frequency aligned component prevents one
frequency bin influencing other frequency bins. We show that this modification
not only reduces the number of parameters in the model but also significantly
and improves the ASR performance. We investigate effects of frequency aligned
network through ASR experiments on the real-world far-field data where users
are interacting with an ASR system in uncontrolled acoustic environments. We
show that our multi-channel acoustic model with a frequency aligned network
shows up to 18% relative reduction in word error rate.
</summary>
    <author>
      <name>Taejin Park</name>
    </author>
    <author>
      <name>Kenichi Kumatani</name>
    </author>
    <author>
      <name>Minhua Wu</name>
    </author>
    <author>
      <name>Shiva Sundaram</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02511v1</id>
    <updated>2020-02-06T20:44:12Z</updated>
    <published>2020-02-06T20:44:12Z</published>
    <title>Introducing Aspects of Creativity in Automatic Poetry Generation</title>
    <summary>  Poetry Generation involves teaching systems to automatically generate text
that resembles poetic work. A deep learning system can learn to generate poetry
on its own by training on a corpus of poems and modeling the particular style
of language. In this paper, we propose taking an approach that fine-tunes
GPT-2, a pre-trained language model, to our downstream task of poetry
generation. We extend prior work on poetry generation by introducing creative
elements. Specifically, we generate poems that express emotion and elicit the
same in readers, and poems that use the language of dreams---called dream
poetry. We are able to produce poems that correctly elicit the emotions of
sadness and joy 87.5 and 85 percent, respectively, of the time. We produce
dreamlike poetry by training on a corpus of texts that describe dreams. Poems
from this model are shown to capture elements of dream poetry with scores of no
less than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for
all our poems. We also make use of the Coh-Metrix tool, outlining metrics we
use to gauge the quality of text generated.
</summary>
    <author>
      <name>Brendan Bena</name>
    </author>
    <author>
      <name>Jugal Kalita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures, 4 tables, ICON-2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02492v1</id>
    <updated>2020-02-06T19:56:15Z</updated>
    <published>2020-02-06T19:56:15Z</published>
    <title>Consistency of a Recurrent Language Model With Respect to Incomplete
  Decoding</title>
    <summary>  Despite strong performance on a variety of tasks, neural sequence models
trained with maximum likelihood have been shown to exhibit issues such as
length bias and degenerate repetition. We study the related issue of receiving
infinite-length sequences from a recurrent language model when using common
decoding algorithms. To analyze this issue, we first define inconsistency of a
decoding algorithm, meaning that the algorithm can yield an infinite-length
sequence that has zero probability under the model. We prove that commonly used
incomplete decoding algorithms - greedy search, beam search, top-k sampling,
and nucleus sampling - are inconsistent, despite the fact that recurrent
language models are trained to produce sequences of finite length. Based on
these insights, we propose two remedies which address inconsistency: consistent
variants of top-k and nucleus sampling, and a self-terminating recurrent
language model. Empirical results show that inconsistency occurs in practice,
and that the proposed methods prevent inconsistency.
</summary>
    <author>
      <name>Sean Welleck</name>
    </author>
    <author>
      <name>Ilia Kulikov</name>
    </author>
    <author>
      <name>Jaedeok Kim</name>
    </author>
    <author>
      <name>Richard Yuanzhe Pang</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08899v1</id>
    <updated>2020-02-06T18:51:16Z</updated>
    <published>2020-02-06T18:51:16Z</published>
    <title>Compositional Neural Machine Translation by Removing the Lexicon from
  Syntax</title>
    <summary>  The meaning of a natural language utterance is largely determined from its
syntax and words. Additionally, there is evidence that humans process an
utterance by separating knowledge about the lexicon from syntax knowledge.
Theories from semantics and neuroscience claim that complete word meanings are
not encoded in the representation of syntax. In this paper, we propose neural
units that can enforce this constraint over an LSTM encoder and decoder. We
demonstrate that our model achieves competitive performance across a variety of
domains including semantic parsing, syntactic parsing, and English to Mandarin
Chinese translation. In these cases, our model outperforms the standard LSTM
encoder and decoder architecture on many or all of our metrics. To demonstrate
that our model achieves the desired separation between the lexicon and syntax,
we analyze its weights and explore its behavior when different neural modules
are damaged. When damaged, we find that the model displays the knowledge
distortions that aphasics are evidenced to have.
</summary>
    <author>
      <name>Tristan Thrush</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">natural language processing; adversarial neural networks; machine
  translation; aphasia; neural attention</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02427v1</id>
    <updated>2020-02-06T18:23:27Z</updated>
    <published>2020-02-06T18:23:27Z</published>
    <title>Irony Detection in a Multilingual Context</title>
    <summary>  This paper proposes the first multilingual (French, English and Arabic) and
multicultural (Indo-European languages vs. less culturally close languages)
irony detection system. We employ both feature-based models and neural
architectures using monolingual word representation. We compare the performance
of these systems with state-of-the-art systems to identify their capabilities.
We show that these monolingual models trained separately on different languages
using multilingual word representation or text-based features can open the door
to irony detection in languages that lack of annotated data for irony.
</summary>
    <author>
      <name>Bilal Ghanem</name>
    </author>
    <author>
      <name>Jihen Karoui</name>
    </author>
    <author>
      <name>Farah Benamara</name>
    </author>
    <author>
      <name>Paolo Rosso</name>
    </author>
    <author>
      <name>Véronique Moriceau</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02406v1</id>
    <updated>2020-02-06T17:40:01Z</updated>
    <published>2020-02-06T17:40:01Z</published>
    <title>Message Passing for Query Answering over Knowledge Graphs</title>
    <summary>  Logic-based systems for query answering over knowledge graphs return only
answers that rely on information explicitly represented in the graph. To
improve recall, recent works have proposed the use of embeddings to predict
additional information like missing links, or labels. These embeddings enable
scoring entities in the graph as the answer a query, without being fully
dependent on the graph structure. In its simplest case, answering a query in
such a setting requires predicting a link between two entities. However, link
prediction is not sufficient to address complex queries that involve multiple
entities and variables. To solve this task, we propose to apply a message
passing mechanism to a graph representation of the query, where nodes
correspond to variables and entities. This results in an embedding of the
query, such that answering entities are close to it in the embedding space. The
general formulation of our method allows it to encode a more diverse set of
query types in comparison to previous work. We evaluate our method by answering
queries that rely on edges not seen during training, obtaining competitive
performance. In contrast with previous work, we show that our method can
generalize from training for the single-hop, link prediction task, to answering
queries with more complex structures. A qualitative analysis reveals that the
learned embeddings successfully capture the notion of different entity types.
</summary>
    <author>
      <name>Daniel Daza</name>
    </author>
    <author>
      <name>Michael Cochez</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02353v1</id>
    <updated>2020-02-06T16:57:27Z</updated>
    <published>2020-02-06T16:57:27Z</published>
    <title>Conversational Structure Aware and Context Sensitive Topic Model for
  Online Discussions</title>
    <summary>  Millions of online discussions are generated everyday on social media
platforms. Topic modelling is an efficient way of better understanding large
text datasets at scale. Conventional topic models have had limited success in
online discussions, and to overcome their limitations, we use the discussion
thread tree structure and propose a "popularity" metric to quantify the number
of replies to a comment to extend the frequency of word occurrences, and the
"transitivity" concept to characterize topic dependency among nodes in a nested
discussion thread. We build a Conversational Structure Aware Topic Model
(CSATM) based on popularity and transitivity to infer topics and their
assignments to comments. Experiments on real forum datasets are used to
demonstrate improved performance for topic extraction with six different
measurements of coherence and impressive accuracy for topic assignments.
</summary>
    <author>
      <name>Yingcheng Sun</name>
    </author>
    <author>
      <name>Kenneth Loparo</name>
    </author>
    <author>
      <name>Richard Kolacinski</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2020 IEEE 14th International Conference on Semantic Computing
  (ICSC)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.02353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02238v1</id>
    <updated>2020-02-06T13:11:46Z</updated>
    <published>2020-02-06T13:11:46Z</published>
    <title>Towards Semantic Noise Cleansing of Categorical Data based on Semantic
  Infusion</title>
    <summary>  Semantic Noise affects text analytics activities for the domain-specific
industries significantly. It impedes the text understanding which holds prime
importance in the critical decision making tasks. In this work, we formalize
semantic noise as a sequence of terms that do not contribute to the narrative
of the text. We look beyond the notion of standard statistically-based stop
words and consider the semantics of terms to exclude the semantic noise. We
present a novel Semantic Infusion technique to associate meta-data with the
categorical corpus text and demonstrate its near-lossless nature. Based on this
technique, we propose an unsupervised text-preprocessing framework to filter
the semantic noise using the context of the terms. Later we present the
evaluation results of the proposed framework using a web forum dataset from the
automobile-domain.
</summary>
    <author>
      <name>Rishabh Gupta</name>
    </author>
    <author>
      <name>Rajesh N Rao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02224v1</id>
    <updated>2020-02-06T12:35:14Z</updated>
    <published>2020-02-06T12:35:14Z</published>
    <title>Citation Data of Czech Apex Courts</title>
    <summary>  In this paper, we introduce the citation data of the Czech apex courts
(Supreme Court, Supreme Administrative Court and Constitutional Court). This
dataset was automatically extracted from the corpus of texts of Czech court
decisions - CzCDC 1.0. We obtained the citation data by building the natural
language processing pipeline for extraction of the court decision identifiers.
The pipeline included the (i) document segmentation model and the (ii)
reference recognition model. Furthermore, the dataset was manually processed to
achieve high-quality citation data as a base for subsequent qualitative and
quantitative analyses. The dataset will be made available to the general
public.
</summary>
    <author>
      <name>Jakub Harašta</name>
    </author>
    <author>
      <name>Tereza Novotná</name>
    </author>
    <author>
      <name>Jaromír Šavelka</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02154v1</id>
    <updated>2020-02-06T08:36:38Z</updated>
    <published>2020-02-06T08:36:38Z</published>
    <title>Related Tasks can Share! A Multi-task Framework for Affective language</title>
    <summary>  Expressing the polarity of sentiment as 'positive' and 'negative' usually
have limited scope compared with the intensity/degree of polarity. These two
tasks (i.e. sentiment classification and sentiment intensity prediction) are
closely related and may offer assistance to each other during the learning
process. In this paper, we propose to leverage the relatedness of multiple
tasks in a multi-task learning framework. Our multi-task model is based on
convolutional-Gated Recurrent Unit (GRU) framework, which is further assisted
by a diverse hand-crafted feature set. Evaluation and analysis suggest that
joint-learning of the related tasks in a multi-task framework can outperform
each of the individual tasks in the single-task frameworks.
</summary>
    <author>
      <name>Kumar Shikhar Deep</name>
    </author>
    <author>
      <name>Md Shad Akhtar</name>
    </author>
    <author>
      <name>Asif Ekbal</name>
    </author>
    <author>
      <name>Pushpak Bhattacharyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures and 3 tables. Accepted in 20th International
  Conference on Intelligent Text Processing and Computational Linguistics,
  CICLing 2019. To be published in Springer LNCS volume</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02153v1</id>
    <updated>2020-02-06T08:24:33Z</updated>
    <published>2020-02-06T08:24:33Z</published>
    <title>A Neural Topical Expansion Framework for Unstructured Persona-oriented
  Dialogue Generation</title>
    <summary>  Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated
effective in generating persona consistent responses by utilizing predefined
natural language user persona descriptions (e.g., "I am a vegan"). However, the
predefined user persona descriptions are usually short and limited to only a
few descriptive words, which makes it hard to correlate them with the
dialogues. As a result, existing methods either fail to use the persona
description or use them improperly when generating persona consistent
responses. To address this, we propose a neural topical expansion framework,
namely Persona Exploration and Exploitation (PEE), which is able to extend the
predefined user persona description with semantically correlated content before
utilizing them to generate dialogue responses. PEE consists of two main
modules: persona exploration and persona exploitation. The former learns to
extend the predefined user persona description by mining and correlating with
existing dialogue corpus using a variational auto-encoder (VAE) based topic
model. The latter learns to generate persona consistent responses by utilizing
the predefined and extended user persona description. In order to make persona
exploitation learn to utilize user persona description more properly, we also
introduce two persona-oriented loss functions: Persona-oriented Matching
(P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which
respectively supervise persona selection in encoder and decoder. Experimental
results show that our approach outperforms state-of-the-art baselines, in terms
of both automatic and human evaluations.
</summary>
    <author>
      <name>Minghong Xu</name>
    </author>
    <author>
      <name>Piji Li</name>
    </author>
    <author>
      <name>Haoran Yang</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Zhaochun Ren</name>
    </author>
    <author>
      <name>Zhumin Chen</name>
    </author>
    <author>
      <name>Jun Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ECAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02109v2</id>
    <updated>2020-02-21T14:19:56Z</updated>
    <published>2020-02-06T05:53:41Z</published>
    <title>Multilingual acoustic word embedding models for processing zero-resource
  languages</title>
    <summary>  Acoustic word embeddings are fixed-dimensional representations of
variable-length speech segments. In settings where unlabelled speech is the
only available resource, such embeddings can be used in "zero-resource" speech
search, indexing and discovery systems. Here we propose to train a single
supervised embedding model on labelled data from multiple well-resourced
languages and then apply it to unseen zero-resource languages. For this
transfer learning approach, we consider two multilingual recurrent neural
network models: a discriminative classifier trained on the joint vocabularies
of all training languages, and a correspondence autoencoder trained to
reconstruct word pairs. We test these using a word discrimination task on six
target zero-resource languages. When trained on seven well-resourced languages,
both models perform similarly and outperform unsupervised models trained on the
zero-resource languages. With just a single training language, the second model
works better, but performance depends more on the particular training--testing
language pair.
</summary>
    <author>
      <name>Herman Kamper</name>
    </author>
    <author>
      <name>Yevgen Matusevych</name>
    </author>
    <author>
      <name>Sharon Goldwater</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, 1 table; accepted to ICASSP 2020. arXiv admin
  note: text overlap with arXiv:1811.00403</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02109v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02109v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02095v1</id>
    <updated>2020-02-06T04:37:44Z</updated>
    <published>2020-02-06T04:37:44Z</published>
    <title>Attractive or Faithful? Popularity-Reinforced Learning for Inspired
  Headline Generation</title>
    <summary>  With the rapid proliferation of online media sources and published news,
headlines have become increasingly important for attracting readers to news
articles, since users may be overwhelmed with the massive information. In this
paper, we generate inspired headlines that preserve the nature of news articles
and catch the eye of the reader simultaneously. The task of inspired headline
generation can be viewed as a specific form of Headline Generation (HG) task,
with the emphasis on creating an attractive headline from a given news article.
To generate inspired headlines, we propose a novel framework called
POpularity-Reinforced Learning for inspired Headline Generation (PORL-HG).
PORL-HG exploits the extractive-abstractive architecture with 1) Popular Topic
Attention (PTA) for guiding the extractor to select the attractive sentence
from the article and 2) a popularity predictor for guiding the abstractor to
rewrite the attractive sentence. Moreover, since the sentence selection of the
extractor is not differentiable, techniques of reinforcement learning (RL) are
utilized to bridge the gap with rewards obtained from a popularity score
predictor. Through quantitative and qualitative experiments, we show that the
proposed PORL-HG significantly outperforms the state-of-the-art headline
generation models in terms of attractiveness evaluated by both human (71.03%)
and the predictor (at least 27.60%), while the faithfulness of PORL-HG is also
comparable to the state-of-the-art generation model.
</summary>
    <author>
      <name>Yun-Zhu Song</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Chiao Tung University, Taiwan</arxiv:affiliation>
    </author>
    <author>
      <name>Hong-Han Shuai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Chiao Tung University, Taiwan</arxiv:affiliation>
    </author>
    <author>
      <name>Sung-Lin Yeh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Tsing Hua University, Taiwan</arxiv:affiliation>
    </author>
    <author>
      <name>Yi-Lun Wu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Chiao Tung University, Taiwan</arxiv:affiliation>
    </author>
    <author>
      <name>Lun-Wei Ku</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Academia Sinica, Taiwan</arxiv:affiliation>
    </author>
    <author>
      <name>Wen-Chih Peng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Chiao Tung University, Taiwan</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02070v1</id>
    <updated>2020-02-06T02:10:33Z</updated>
    <published>2020-02-06T02:10:33Z</published>
    <title>Understanding Car-Speak: Replacing Humans in Dealerships</title>
    <summary>  A large portion of the car-buying experience in the United States involves
interactions at a car dealership. At the dealership, the car-buyer relays their
needs to a sales representative. However, most car-buyers are only have an
abstract description of the vehicle they need. Therefore, they are only able to
describe their ideal car in "car-speak". Car-speak is abstract language that
pertains to a car's physical attributes. In this paper, we define car-speak. We
also aim to curate a reasonable data set of car-speak language. Finally, we
train several classifiers in order to classify car-speak.
</summary>
    <author>
      <name>Habeeb Hooshmand</name>
    </author>
    <author>
      <name>James Caverlee</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02450v1</id>
    <updated>2020-02-05T22:56:12Z</updated>
    <published>2020-02-05T22:56:12Z</published>
    <title>Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker</title>
    <summary>  Dialogue State Tracking (DST) is a core component of virtual assistants such
as Alexa or Siri. To accomplish various tasks, these assistants need to support
an increasing number of services and APIs. The Schema-Guided State Tracking
track of the 8th Dialogue System Technology Challenge highlighted the DST
problem for unseen services. The organizers introduced the Schema-Guided
Dialogue (SGD) dataset with multi-domain conversations and released a zero-shot
dialogue state tracking model. In this work, we propose a GOaL-Oriented
Multi-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures
for reading comprehension question answering systems. The model "queries"
dialogue history with descriptions of slots and services as well as possible
values of slots. This allows to transfer slot values in multi-domain dialogues
and have a capability to scale to unseen slot types. Our model achieves a joint
goal accuracy of 53.97% on the SGD dataset, outperforming the baseline model.
</summary>
    <author>
      <name>Pavel Gulyaev</name>
    </author>
    <author>
      <name>Eugenia Elistratova</name>
    </author>
    <author>
      <name>Vasily Konovalov</name>
    </author>
    <author>
      <name>Yuri Kuratov</name>
    </author>
    <author>
      <name>Leonid Pugachev</name>
    </author>
    <author>
      <name>Mikhail Burtsev</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02031v1</id>
    <updated>2020-02-05T22:56:11Z</updated>
    <published>2020-02-05T22:56:11Z</published>
    <title>Stimulating Creativity with FunLines: A Case Study of Humor Generation
  in Headlines</title>
    <summary>  Building datasets of creative text, such as humor, is quite challenging. We
introduce FunLines, a competitive game where players edit news headlines to
make them funny, and where they rate the funniness of headlines edited by
others. FunLines makes the humor generation process fun, interactive,
collaborative, rewarding and educational, keeping players engaged and providing
humor data at a very low cost compared to traditional crowdsourcing approaches.
FunLines offers useful performance feedback, assisting players in getting
better over time at generating and assessing humor, as our analysis shows. This
helps to further increase the quality of the generated dataset. We show the
effectiveness of this data by training humor classification models that
outperform a previous benchmark, and we release this dataset to the public.
</summary>
    <author>
      <name>Nabil Hossain</name>
    </author>
    <author>
      <name>John Krumm</name>
    </author>
    <author>
      <name>Tanvir Sajed</name>
    </author>
    <author>
      <name>Henry Kautz</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02000v1</id>
    <updated>2020-02-05T21:40:50Z</updated>
    <published>2020-02-05T21:40:50Z</published>
    <title>Aligning the Pretraining and Finetuning Objectives of Language Models</title>
    <summary>  We demonstrate that explicitly aligning the pretraining objectives to the
finetuning objectives in language model training significantly improves the
finetuning task performance and reduces the minimum amount of finetuning
examples required. The performance margin gained from objective alignment
allows us to build language models with smaller sizes for tasks with less
available training data. We provide empirical evidence of these claims by
applying objective alignment to concept-of-interest tagging and acronym
detection tasks. We found that, with objective alignment, our 768 by 3 and 512
by 3 transformer language models can reach accuracy of 83.9%/82.5% for
concept-of-interest tagging and 73.8%/70.2% for acronym detection using only
200 finetuning examples per task, outperforming the 768 by 3 model pretrained
without objective alignment by +4.8%/+3.4% and +9.9%/+6.3%. We name finetuning
small language models in the presence of hundreds of training examples or less
"Few Example learning". In practice, Few Example Learning enabled by objective
alignment not only saves human labeling costs, but also makes it possible to
leverage language models in more real-time applications.
</summary>
    <author>
      <name>Nuo Wang Pierse</name>
    </author>
    <author>
      <name>Jingwen Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures and 6 tables. Submitted to ICML 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01984v1</id>
    <updated>2020-02-05T20:43:14Z</updated>
    <published>2020-02-05T20:43:14Z</published>
    <title>UNCC Biomedical Semantic Question Answering Systems. BioASQ: Task-7B,
  Phase-B</title>
    <summary>  In this paper, we detail our submission to the 2019, 7th year, BioASQ
competition. We present our approach for Task-7b, Phase B, Exact Answering
Task. These Question Answering (QA) tasks include Factoid, Yes/No, List Type
Question answering. Our system is based on a contextual word embedding model.
We have used a Bidirectional Encoder Representations from Transformers(BERT)
based system, fined tuned for biomedical question answering task using BioBERT.
In the third test batch set, our system achieved the highest MRR score for
Factoid Question Answering task. Also, for List type question answering task
our system achieved the highest recall score in the fourth test batch set.
Along with our detailed approach, we present the results for our submissions,
and also highlight identified downsides for our current approach and ways to
improve them in our future experiments.
</summary>
    <author>
      <name>Sai Krishna Telukuntla</name>
    </author>
    <author>
      <name>Aditya Kapri</name>
    </author>
    <author>
      <name>Wlodek Zadrozny</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 8 figures. This is an expanded version of our submission to
  2019 BioAsq competition</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04397v1</id>
    <updated>2020-02-05T19:09:13Z</updated>
    <published>2020-02-05T19:09:13Z</published>
    <title>HGAT: Hierarchical Graph Attention Network for Fake News Detection</title>
    <summary>  The explosive growth of fake news has eroded the credibility of medias and
governments. Fake news detection has become an urgent task. News articles along
with other related components like news creators and news subjects can be
modeled as a heterogeneous information network (HIN for short). In this paper,
we focus on studying the HIN- based fake news detection problem. We propose a
novel fake news detection framework, namely Hierarchical Graph Attention
Network (HGAT) which employs a novel hierarchical attention mechanism to detect
fake news by classifying news article nodes in the HIN. This method can
effectively learn information from different types of related nodes through
node-level and schema-level attention. Experiments with real-world fake news
data show that our model can outperform text-based models and other
network-based models. Besides, the experiments also demonstrate the
expandability and potential of HGAT for heterogeneous graphs representation
learning in the future.
</summary>
    <author>
      <name>Yuxiang Ren</name>
    </author>
    <author>
      <name>Jiawei Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01862v1</id>
    <updated>2020-02-05T16:52:52Z</updated>
    <published>2020-02-05T16:52:52Z</published>
    <title>If I Hear You Correctly: Building and Evaluating Interview Chatbots with
  Active Listening Skills</title>
    <summary>  Interview chatbots engage users in a text-based conversation to draw out
their views and opinions. It is, however, challenging to build effective
interview chatbots that can handle user free-text responses to open-ended
questions and deliver engaging user experience. As the first step, we are
investigating the feasibility and effectiveness of using publicly available,
practical AI technologies to build effective interview chatbots. To demonstrate
feasibility, we built a prototype scoped to enable interview chatbots with a
subset of active listening skills - the abilities to comprehend a user's input
and respond properly. To evaluate the effectiveness of our prototype, we
compared the performance of interview chatbots with or without active listening
skills on four common interview topics in a live evaluation with 206 users. Our
work presents practical design implications for building effective interview
chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview
tasks.
</summary>
    <author>
      <name>Ziang Xiao</name>
    </author>
    <author>
      <name>Michelle X. Zhou</name>
    </author>
    <author>
      <name>Wenxi Chen</name>
    </author>
    <author>
      <name>Huahai Yang</name>
    </author>
    <author>
      <name>Changyan Chi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3313831.3376131</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3313831.3376131" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working draft. To appear in the ACM CHI Conference on Human Factors
  in Computing Systems (CHI 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01861v1</id>
    <updated>2020-02-05T16:45:44Z</updated>
    <published>2020-02-05T16:45:44Z</published>
    <title>Rapid Adaptation of BERT for Information Extraction on Domain-Specific
  Business Documents</title>
    <summary>  Techniques for automatically extracting important content elements from
business documents such as contracts, statements, and filings have the
potential to make business operations more efficient. This problem can be
formulated as a sequence labeling task, and we demonstrate the adaption of BERT
to two types of business documents: regulatory filings and property lease
agreements. There are aspects of this problem that make it easier than
"standard" information extraction tasks and other aspects that make it more
difficult, but on balance we find that modest amounts of annotated data (less
than 100 documents) are sufficient to achieve reasonable accuracy. We integrate
our models into an end-to-end cloud platform that provides both an easy-to-use
annotation interface as well as an inference interface that allows users to
upload documents and inspect model outputs.
</summary>
    <author>
      <name>Ruixue Zhang</name>
    </author>
    <author>
      <name>Wei Yang</name>
    </author>
    <author>
      <name>Luyun Lin</name>
    </author>
    <author>
      <name>Zhengkai Tu</name>
    </author>
    <author>
      <name>Yuqing Xie</name>
    </author>
    <author>
      <name>Zihang Fu</name>
    </author>
    <author>
      <name>Yuhao Xie</name>
    </author>
    <author>
      <name>Luchen Tan</name>
    </author>
    <author>
      <name>Kun Xiong</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01846v1</id>
    <updated>2020-02-05T16:09:52Z</updated>
    <published>2020-02-05T16:09:52Z</published>
    <title>Automatic Location Type Classification From Social-Media Posts</title>
    <summary>  We introduce the problem of Automatic Location Type Classification from
social media posts. Our goal is to correctly associate a set of messages posted
in a small radius around a given location with their corresponding location
type, e.g., school, church, restaurant or museum. We provide a dataset of
locations associated with tweets posted in close geographical proximity. We
explore two approaches to the problem: (a) a pipeline approach where each
message is first classified, and then the location associated with the message
set is inferred from the individual message labels; and (b) a joint approach
where the individual messages are simultaneously processed to yield the desired
location type. Our results demonstrate the superiority of the joint approach.
Moreover, we show that due to the unique structure of the problem, where
weakly-related messages are jointly processed to yield a single final label,
simpler linear classifiers outperform deep neural network alternatives that
have shown superior in previous text classification tasks.
</summary>
    <author>
      <name>Elad Kravi</name>
    </author>
    <author>
      <name>Benny Kimelfeld</name>
    </author>
    <author>
      <name>Yaron Kanza</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01824v1</id>
    <updated>2020-02-05T15:12:03Z</updated>
    <published>2020-02-05T15:12:03Z</published>
    <title>Discontinuous Constituent Parsing with Pointer Networks</title>
    <summary>  One of the most complex syntactic representations used in computational
linguistics and NLP are discontinuous constituent trees, crucial for
representing all grammatical phenomena of languages such as German. Recent
advances in dependency parsing have shown that Pointer Networks excel in
efficiently parsing syntactic relations between words in a sentence. This kind
of sequence-to-sequence models achieve outstanding accuracies in building
non-projective dependency trees, but its potential has not been proved yet on a
more difficult task. We propose a novel neural network architecture that, by
means of Pointer Networks, is able to generate the most accurate discontinuous
constituent representations to date, even without the need of Part-of-Speech
tagging information. To do so, we internally model discontinuous constituent
structures as augmented non-projective dependency structures. The proposed
approach achieves state-of-the-art results on the two widely-used NEGRA and
TIGER benchmarks, outperforming previous work by a wide margin.
</summary>
    <author>
      <name>Daniel Fernández-González</name>
    </author>
    <author>
      <name>Carlos Gómez-Rodríguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of AAAI 2020. 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01808v3</id>
    <updated>2020-02-10T06:29:54Z</updated>
    <published>2020-02-05T14:30:49Z</published>
    <title>K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters</title>
    <summary>  We study the problem of injecting knowledge into large pre-trained models
like BERT and RoBERTa. Existing methods typically update the original
parameters of pre-trained models when injecting knowledge. However, when
multiple kinds of knowledge are injected, they may suffer from the problem of
catastrophic forgetting. To address this, we propose K-Adapter, which remains
the original parameters of the pre-trained model fixed and supports continual
knowledge infusion. Taking RoBERTa as the pre-trained model, K-Adapter has a
neural adapter for each kind of infused knowledge, like a plug-in connected to
RoBERTa. There is no information flow between different adapters, thus
different adapters are efficiently trained in a distributed way. We inject two
kinds of knowledge, including factual knowledge obtained from automatically
aligned text-triplets on Wikipedia and Wikidata, and linguistic knowledge
obtained from dependency parsing. Results on three knowledge-driven tasks
(total six datasets) including relation classification, entity typing and
question answering demonstrate that each adapter improves the performance, and
the combination of both adapters brings further improvements. Probing
experiments further show that K-Adapter captures richer factual and commonsense
knowledge than RoBERTa.
</summary>
    <author>
      <name>Ruize Wang</name>
    </author>
    <author>
      <name>Duyu Tang</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Zhongyu Wei</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <author>
      <name>Jianshu ji</name>
    </author>
    <author>
      <name>Guihong Cao</name>
    </author>
    <author>
      <name>Daxin Jiang</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01808v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01808v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01761v1</id>
    <updated>2020-02-05T12:44:01Z</updated>
    <published>2020-02-05T12:44:01Z</published>
    <title>Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and
  Manual Correction</title>
    <summary>  Princeton WordNet (PWN) is a lexicon-semantic network based on cognitive
linguistics, which promotes the development of natural language processing.
Based on PWN, five Chinese wordnets have been developed to solve the problems
of syntax and semantics. They include: Northeastern University Chinese WordNet
(NEW), Sinica Bilingual Ontological WordNet (BOW), Southeast University Chinese
WordNet (SEW), Taiwan University Chinese WordNet (CWN), Chinese Open WordNet
(COW). By using them, we found that these word networks have low accuracy and
coverage, and cannot completely portray the semantic network of PWN. So we
decided to make a new Chinese wordnet called Multi-Fusion Chinese Wordnet (MCW)
to make up those shortcomings. The key idea is to extend the SEW with the help
of Oxford bilingual dictionary and Xinhua bilingual dictionary, and then
correct it. More specifically, we used machine learning and manual adjustment
in our corrections. Two standards were formulated to help our work. We
conducted experiments on three tasks including relatedness calculation, word
similarity and word sense disambiguation for the comparison of lemma's
accuracy, at the same time, coverage also was compared. The results indicate
that MCW can benefit from coverage and accuracy via our method. However, it
still has room for improvement, especially with lemmas. In the future, we will
continue to enhance the accuracy of MCW and expand the concepts in it.
</summary>
    <author>
      <name>Mingchen Li</name>
    </author>
    <author>
      <name>Zili Zhou</name>
    </author>
    <author>
      <name>Yanna Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. CICLing 2019: International Conference on Computational
  Linguistics and Intelligent Text Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01685v1</id>
    <updated>2020-02-05T08:43:02Z</updated>
    <published>2020-02-05T08:43:02Z</published>
    <title>Parsing as Pretraining</title>
    <summary>  Recent analyses suggest that encoders pretrained for language modeling
capture certain morpho-syntactic structure. However, probing frameworks for
word vectors still do not report results on standard setups such as constituent
and dependency parsing. This paper addresses this problem and does full parsing
(on English) relying only on pretraining architectures -- and no decoding. We
first cast constituent and dependency parsing as sequence tagging. We then use
a single feed-forward layer to directly map word vectors to labels that encode
a linearized tree. This is used to: (i) see how far we can reach on syntax
modelling with just pretrained encoders, and (ii) shed some light about the
syntax-sensitivity of different word vectors (by freezing the weights of the
pretraining network during training). For evaluation, we use bracketing
F1-score and LAS, and analyze in-depth differences across representations for
span lengths and dependency displacements. The overall results surpass existing
sequence tagging parsers on the PTB (93.5%) and end-to-end EN-EWT UD (78.8%).
</summary>
    <author>
      <name>David Vilares</name>
    </author>
    <author>
      <name>Michalina Strzyz</name>
    </author>
    <author>
      <name>Anders Søgaard</name>
    </author>
    <author>
      <name>Carlos Gómez-Rodríguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 - The Thirty-Fourth AAAI Conference on Artificial
  Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01664v1</id>
    <updated>2020-02-05T07:07:15Z</updated>
    <published>2020-02-05T07:07:15Z</published>
    <title>Identification of Indian Languages using Ghost-VLAD pooling</title>
    <summary>  In this work, we propose a new pooling strategy for language identification
by considering Indian languages. The idea is to obtain utterance level features
for any variable length audio for robust language recognition. We use the
GhostVLAD approach to generate an utterance level feature vector for any
variable length input audio by aggregating the local frame level features
across time. The generated feature vector is shown to have very good language
discriminative features and helps in getting state of the art results for
language identification task. We conduct our experiments on 635Hrs of audio
data for 7 Indian languages. Our method outperforms the previous state of the
art x-vector [11] method by an absolute improvement of 1.88% in F1-score and
achieves 98.43% F1-score on the held-out test data. We compare our system with
various pooling approaches and show that GhostVLAD is the best pooling approach
for this task. We also provide visualization of the utterance level embeddings
generated using Ghost-VLAD pooling and show that this method creates embeddings
which has very good language discriminative features.
</summary>
    <author>
      <name>Krishna D N</name>
    </author>
    <author>
      <name>Ankita Patil</name>
    </author>
    <author>
      <name>M. S. P Raj</name>
    </author>
    <author>
      <name>Sai Prasad H S</name>
    </author>
    <author>
      <name>Prabhu Aashish Garapati</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">REJECTED ICASSP 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.01664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01535v1</id>
    <updated>2020-02-04T21:02:11Z</updated>
    <published>2020-02-04T21:02:11Z</published>
    <title>Lightweight Convolutional Representations for On-Device Natural Language
  Processing</title>
    <summary>  The increasing computational and memory complexities of deep neural networks
have made it difficult to deploy them on low-resource electronic devices (e.g.,
mobile phones, tablets, wearables). Practitioners have developed numerous model
compression methods to address these concerns, but few have condensed input
representations themselves. In this work, we propose a fast, accurate, and
lightweight convolutional representation that can be swapped into any neural
model and compressed significantly (up to 32x) with a negligible reduction in
performance. In addition, we show gains over recurrent representations when
considering resource-centric metrics (e.g., model file size, latency, memory
usage) on a Samsung Galaxy S9.
</summary>
    <author>
      <name>Shrey Desai</name>
    </author>
    <author>
      <name>Geoffrey Goh</name>
    </author>
    <author>
      <name>Arun Babu</name>
    </author>
    <author>
      <name>Ahmed Aly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to MLSys 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01510v1</id>
    <updated>2020-02-04T19:30:55Z</updated>
    <published>2020-02-04T19:30:55Z</published>
    <title>Generalizing meanings from partners to populations: Hierarchical
  inference supports convention formation on networks</title>
    <summary>  A key property of linguistic conventions is that they hold over an entire
community of speakers, allowing us to communicate efficiently even with people
we have never met before. At the same time, much of our language use is
partner-specific: we know that words may be understood differently by different
people based on local common ground. This poses a challenge for accounts of
convention formation. Exactly how do agents make the inferential leap to
community-wide expectations while maintaining partner-specific knowledge? We
propose a hierarchical Bayesian model of convention to explain how speakers and
listeners abstract away meanings that seem to be shared across partners. To
evaluate our model's predictions, we conducted an experiment where participants
played an extended natural-language communication game with different partners
in a small community. We examine several measures of generalization across
partners, and find key signatures of local adaptation as well as collective
convergence. These results suggest that local partner-specific learning is not
only compatible with global convention formation but may facilitate it when
coupled with a powerful hierarchical inductive mechanism.
</summary>
    <author>
      <name>Robert D. Hawkins</name>
    </author>
    <author>
      <name>Noah D. Goodman</name>
    </author>
    <author>
      <name>Adele E. Goldberg</name>
    </author>
    <author>
      <name>Thomas L. Griffiths</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01464v1</id>
    <updated>2020-02-04T18:42:30Z</updated>
    <published>2020-02-04T18:42:30Z</published>
    <title>Visual Concept-Metaconcept Learning</title>
    <summary>  Humans reason with concepts and metaconcepts: we recognize red and green from
visual input; we also understand that they describe the same property of
objects (i.e., the color). In this paper, we propose the visual
concept-metaconcept learner (VCML) for joint learning of concepts and
metaconcepts from images and associated question-answer pairs. The key is to
exploit the bidirectional connection between visual concepts and metaconcepts.
Visual representations provide grounding cues for predicting relations between
unseen pairs of concepts. Knowing that red and green describe the same property
of objects, we generalize to the fact that cube and sphere also describe the
same property of objects, since they both categorize the shape of objects.
Meanwhile, knowledge about metaconcepts empowers visual concept learning from
limited, noisy, and even biased data. From just a few examples of purple cubes
we can understand a new color purple, which resembles the hue of the cubes
instead of the shape of them. Evaluation on both synthetic and real-world
datasets validates our claims.
</summary>
    <author>
      <name>Chi Han</name>
    </author>
    <author>
      <name>Jiayuan Mao</name>
    </author>
    <author>
      <name>Chuang Gan</name>
    </author>
    <author>
      <name>Joshua B. Tenenbaum</name>
    </author>
    <author>
      <name>Jiajun Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019. First two authors contributed equally. Project page:
  http://vcml.csail.mit.edu/</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01462v2</id>
    <updated>2020-02-09T02:41:50Z</updated>
    <published>2020-02-04T18:40:38Z</published>
    <title>Semantic Search of Memes on Twitter</title>
    <summary>  Memes are becoming a useful source of data for analyzing behavior on social
media. However, a problem to tackle is how to correctly identify a meme. As the
number of memes published every day on social media is huge, there is a need
for automatic methods for classifying and searching in large meme datasets.
This paper proposes and compares several methods for automatically classifying
images as memes. Also, we propose a method that allows us to implement a system
for retrieving memes from a dataset using a textual query. We experimentally
evaluate the methods using a large dataset of memes collected from Twitter
users in Chile, which was annotated by a group of experts. Though some of the
evaluated methods are effective, there is still room for improvement.
</summary>
    <author>
      <name>Jesus Perez-Martin</name>
    </author>
    <author>
      <name>Benjamin Bustos</name>
    </author>
    <author>
      <name>Magdalena Saldana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Methods Interest Group of the 70th International
  Communication Association Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01462v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01462v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01454v1</id>
    <updated>2020-02-04T18:31:25Z</updated>
    <published>2020-02-04T18:31:25Z</published>
    <title>From Topic Networks to Distributed Cognitive Maps: Zipfian Topic
  Universes in the Area of Volunteered Geographic Information</title>
    <summary>  Are nearby places (e.g. cities) described by related words? In this article
we transfer this research question in the field of lexical encoding of
geographic information onto the level of intertextuality. To this end, we
explore Volunteered Geographic Information (VGI) to model texts addressing
places at the level of cities or regions with the help of so-called topic
networks. This is done to examine how language encodes and networks geographic
information on the aboutness level of texts. Our hypothesis is that the
networked thematizations of places are similar - regardless of their distances
and the underlying communities of authors. To investigate this we introduce
Multiplex Topic Networks (MTN), which we automatically derive from Linguistic
Multilayer Networks (LMN) as a novel model, especially of thematic networking
in text corpora. Our study shows a Zipfian organization of the thematic
universe in which geographical places (especially cities) are located in online
communication. We interpret this finding in the context of cognitive maps, a
notion which we extend by so-called thematic maps. According to our
interpretation of this finding, the organization of thematic maps as part of
cognitive maps results from a tendency of authors to generate shareable content
that ensures the continued existence of the underlying media. We test our
hypothesis by example of special wikis and extracts of Wikipedia. In this way
we come to the conclusion: Places, whether close to each other or not, are
located in neighboring places that span similar subnetworks in the topic
universe.
</summary>
    <author>
      <name>Alexander Mehler</name>
    </author>
    <author>
      <name>Rüdiger Gleim</name>
    </author>
    <author>
      <name>Regina Gaitsch</name>
    </author>
    <author>
      <name>Wahed Hemati</name>
    </author>
    <author>
      <name>Tolga Uslu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">65 pages, 27 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01454v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01454v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01415v1</id>
    <updated>2020-02-04T17:16:36Z</updated>
    <published>2020-02-04T17:16:36Z</published>
    <title>Plague Dot Text: Text mining and annotation of outbreak reports of the
  Third Plague Pandemic (1894-1952)</title>
    <summary>  The design of models that govern diseases in population is commonly built on
information and data gathered from past outbreaks. However, epidemic outbreaks
are never captured in statistical data alone but are communicated by
narratives, supported by empirical observations. Outbreak reports discuss
correlations between populations, locations and the disease to infer insights
into causes, vectors and potential interventions. The problem with these
narratives is usually the lack of consistent structure or strong conventions,
which prohibit their formal analysis in larger corpora. Our interdisciplinary
research investigates more than 100 reports from the third plague pandemic
(1894-1952) evaluating ways of building a corpus to extract and structure this
narrative information through text mining and manual annotation. In this paper
we discuss the progress of our ongoing exploratory project, how we enhance
optical character recognition (OCR) methods to improve text capture, our
approach to structure the narratives and identify relevant entities in the
reports. The structured corpus is made available via Solr enabling search and
analysis across the whole collection for future research dedicated, for
example, to the identification of concepts. We show preliminary visualisations
of the characteristics of causation and differences with respect to gender as a
result of syntactic-category-dependent corpus statistics. Our goal is to
develop structured accounts of some of the most significant concepts that were
used to understand the epidemiology of the third plague pandemic around the
globe. The corpus enables researchers to analyse the reports collectively
allowing for deep insights into the global epidemiological consideration of
plague in the early twentieth century.
</summary>
    <author>
      <name>Arlene Casey</name>
    </author>
    <author>
      <name>Mike Bennett</name>
    </author>
    <author>
      <name>Richard Tobin</name>
    </author>
    <author>
      <name>Claire Grover</name>
    </author>
    <author>
      <name>Iona Walker</name>
    </author>
    <author>
      <name>Lukas Engelmann</name>
    </author>
    <author>
      <name>Beatrice Alex</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01412v1</id>
    <updated>2020-02-04T17:12:43Z</updated>
    <published>2020-02-04T17:12:43Z</published>
    <title>Iterative Data Programming for Expanding Text Classification Corpora</title>
    <summary>  Real-world text classification tasks often require many labeled training
examples that are expensive to obtain. Recent advancements in machine teaching,
specifically the data programming paradigm, facilitate the creation of training
data sets quickly via a general framework for building weak models, also known
as labeling functions, and denoising them through ensemble learning techniques.
We present a fast, simple data programming method for augmenting text data sets
by generating neighborhood-based weak models with minimal supervision.
Furthermore, our method employs an iterative procedure to identify sparsely
distributed examples from large volumes of unlabeled data. The iterative data
programming techniques improve newer weak models as more labeled data is
confirmed with human-in-loop. We show empirical results on sentence
classification tasks, including those from a task of improving intent
recognition in conversational agents.
</summary>
    <author>
      <name>Neil Mallinar</name>
    </author>
    <author>
      <name>Abhishek Shah</name>
    </author>
    <author>
      <name>Tin Kam Ho</name>
    </author>
    <author>
      <name>Rajendra Ugrani</name>
    </author>
    <author>
      <name>Ayush Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, In Proceedings of the AAAI Conference on
  Artificial Intelligence 2020 (IAAI Technical Track: Emerging Papers)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01365v2</id>
    <updated>2020-02-17T11:22:04Z</updated>
    <published>2020-02-04T15:19:09Z</published>
    <title>Compositional Languages Emerge in a Neural Iterated Learning Model</title>
    <summary>  The principle of compositionality, which enables natural language to
represent complex concepts via a structured combination of simpler ones, allows
us to convey an open-ended set of messages using a limited vocabulary. If
compositionality is indeed a natural property of language, we may expect it to
appear in communication protocols that are created by neural agents in language
games. In this paper, we propose an effective neural iterated learning (NIL)
algorithm that, when applied to interacting neural agents, facilitates the
emergence of a more structured type of language. Indeed, these languages
provide learning speed advantages to neural agents during training, which can
be incrementally amplified via NIL. We provide a probabilistic model of NIL and
an explanation of why the advantage of compositional language exist. Our
experiments confirm our analysis, and also demonstrate that the emerged
languages largely improve the generalizing power of the neural agent
communication.
</summary>
    <author>
      <name>Yi Ren</name>
    </author>
    <author>
      <name>Shangmin Guo</name>
    </author>
    <author>
      <name>Matthieu Labeau</name>
    </author>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <author>
      <name>Simon Kirby</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by ICLR-2020</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR-2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.01365v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01365v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01335v1</id>
    <updated>2020-02-04T14:59:08Z</updated>
    <published>2020-02-04T14:59:08Z</published>
    <title>Exploring Structural Inductive Biases in Emergent Communication</title>
    <summary>  Human language and thought are characterized by the ability to systematically
generate a potentially infinite number of complex structures (e.g., sentences)
from a finite set of familiar components (e.g., words). Recent works in
emergent communication have discussed the propensity of artificial agents to
develop a systematically compositional language through playing co-operative
referential games. The degree of structure in the input data was found to
affect the compositionality of the emerged communication protocols. Thus, we
explore various structural priors in multi-agent communication and propose a
novel graph referential game. We compare the effect of structural inductive
bias (bag-of-words, sequences and graphs) on the emergence of compositional
understanding of the input concepts measured by topographic similarity and
generalization to unseen combinations of familiar properties. We empirically
show that graph neural networks induce a better compositional language prior
and a stronger generalization to out-of-domain data. We further perform
ablation studies that show the robustness of the emerged protocol in graph
referential games.
</summary>
    <author>
      <name>Agnieszka Słowik</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>William L. Hamilton</name>
    </author>
    <author>
      <name>Mateja Jamnik</name>
    </author>
    <author>
      <name>Sean B. Holden</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01320v1</id>
    <updated>2020-02-04T14:35:28Z</updated>
    <published>2020-02-04T14:35:28Z</published>
    <title>CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus</title>
    <summary>  Spoken language translation has recently witnessed a resurgence in
popularity, thanks to the development of end-to-end models and the creation of
new corpora, such as Augmented LibriSpeech and MuST-C. Existing datasets
involve language pairs with English as a source language, involve very specific
domains or are low resource. We introduce CoVoST, a multilingual speech-to-text
translation corpus from 11 languages into English, diversified with over 11,000
speakers and over 60 accents. We describe the dataset creation methodology and
provide empirical evidence of the quality of the data. We also provide initial
benchmarks, including, to our knowledge, the first end-to-end many-to-one
multilingual models for spoken language translation. CoVoST is released under
CC0 license and free to use. We also provide additional evaluation data derived
from Tatoeba under CC licenses.
</summary>
    <author>
      <name>Changhan Wang</name>
    </author>
    <author>
      <name>Juan Pino</name>
    </author>
    <author>
      <name>Anne Wu</name>
    </author>
    <author>
      <name>Jiatao Gu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01214v1</id>
    <updated>2020-02-04T10:30:49Z</updated>
    <published>2020-02-04T10:30:49Z</published>
    <title>On Stochastic Automata over Monoids</title>
    <summary>  Stochastic automata over monoids as input sets are studied. The
well-definedness of these automata requires an extension postulate that
replaces the inherent universal property of free monoids. As a generalization
of Turakainen's result, it will be shown that the generalized automata over
monoids have the same acceptance power as their stochastic counterparts. The
key to homomorphisms is a commuting property between the monoid homomorphism of
input states and the monoid homomorphism of transition matrices. Closure
properties of the languages accepted by stochastic automata over monoids are
investigated. matrices. Closure properties of the languages accepted by
stochastic automata over monoids are investigated.
</summary>
    <author>
      <name>Karl-Heinz Zimmermann</name>
    </author>
    <author>
      <name>Merve Nur Cakir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q70, 68Q87, 20M35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01207v1</id>
    <updated>2020-02-04T10:09:42Z</updated>
    <published>2020-02-04T10:09:42Z</published>
    <title>Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model</title>
    <summary>  Diacritics (short vowels) are typically omitted when writing Arabic text, and
readers have to reintroduce them to correctly pronounce words. There are two
types of Arabic diacritics: the first are core-word diacritics (CW), which
specify the lexical selection, and the second are case endings (CE), which
typically appear at the end of the word stem and generally specify their
syntactic roles. Recovering CEs is relatively harder than recovering core-word
diacritics due to inter-word dependencies, which are often distant. In this
paper, we use a feature-rich recurrent neural network model that uses a variety
of linguistic and surface-level features to recover both core word diacritics
and case endings. Our model surpasses all previous state-of-the-art systems
with a CW error rate (CWER) of 2.86\% and a CE error rate (CEER) of 3.7% for
Modern Standard Arabic (MSA) and CWER of 2.2% and CEER of 2.5% for Classical
Arabic (CA). When combining diacritized word cores with case endings, the
resultant word error rate is 6.0% and 4.3% for MSA and CA respectively. This
highlights the effectiveness of feature engineering for such deep neural
models.
</summary>
    <author>
      <name>Kareem Darwish</name>
    </author>
    <author>
      <name>Ahmed Abdelali</name>
    </author>
    <author>
      <name>Hamdy Mubarak</name>
    </author>
    <author>
      <name>Mohamed Eldesouki</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01207v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01207v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01196v2</id>
    <updated>2020-03-06T09:44:42Z</updated>
    <published>2020-02-04T09:49:36Z</published>
    <title>Dynamic Knowledge Routing Network For Target-Guided Open-Domain
  Conversation</title>
    <summary>  Target-guided open-domain conversation aims to proactively and naturally
guide a dialogue agent or human to achieve specific goals, topics or keywords
during open-ended conversations. Existing methods mainly rely on single-turn
datadriven learning and simple target-guided strategy without considering
semantic or factual knowledge relations among candidate topics/keywords. This
results in poor transition smoothness and low success rate. In this work, we
adopt a structured approach that controls the intended content of system
responses by introducing coarse-grained keywords, attains smooth conversation
transition through turn-level supervised learning and knowledge relations
between candidate keywords, and drives an conversation towards an specified
target with discourse-level guiding strategy. Specially, we propose a novel
dynamic knowledge routing network (DKRN) which considers semantic knowledge
relations among candidate keywords for accurate next topic prediction of next
discourse. With the help of more accurate keyword prediction, our
keyword-augmented response retrieval module can achieve better retrieval
performance and more meaningful conversations. Besides, we also propose a novel
dual discourse-level target-guided strategy to guide conversations to reach
their goals smoothly with higher success rate. Furthermore, to push the
research boundary of target-guided open-domain conversation to match real-world
scenarios better, we introduce a new large-scale Chinese target-guided
open-domain conversation dataset (more than 900K conversations) crawled from
Sina Weibo. Quantitative and human evaluations show our method can produce
meaningful and effective target-guided conversations, significantly improving
over other state-of-the-art methods by more than 20% in success rate and more
than 0.6 in average smoothness score.
</summary>
    <author>
      <name>Jinghui Qin</name>
    </author>
    <author>
      <name>Zheng Ye</name>
    </author>
    <author>
      <name>Jianheng Tang</name>
    </author>
    <author>
      <name>Xiaodan Liang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figues, 6tables, AAAI2020, fix our model's abbreviation</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01196v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01196v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01145v1</id>
    <updated>2020-02-04T06:26:37Z</updated>
    <published>2020-02-04T06:26:37Z</published>
    <title>Syntactically Look-Ahead Attention Network for Sentence Compression</title>
    <summary>  Sentence compression is the task of compressing a long sentence into a short
one by deleting redundant words. In sequence-to-sequence (Seq2Seq) based
models, the decoder unidirectionally decides to retain or delete words. Thus,
it cannot usually explicitly capture the relationships between decoded words
and unseen words that will be decoded in the future time steps. Therefore, to
avoid generating ungrammatical sentences, the decoder sometimes drops important
words in compressing sentences. To solve this problem, we propose a novel
Seq2Seq model, syntactically look-ahead attention network (SLAHAN), that can
generate informative summaries by explicitly tracking both dependency parent
and child words during decoding and capturing important words that will be
decoded in the future. The results of the automatic evaluation on the Google
sentence compression dataset showed that SLAHAN achieved the best
kept-token-based-F1, ROUGE-1, ROUGE-2 and ROUGE-L scores of 85.5, 79.3, 71.3
and 79.1, respectively. SLAHAN also improved the summarization performance on
longer sentences. Furthermore, in the human evaluation, SLAHAN improved
informativeness without losing readability.
</summary>
    <author>
      <name>Hidetaka Kamigaito</name>
    </author>
    <author>
      <name>Manabu Okumura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01127v2</id>
    <updated>2020-02-13T09:50:56Z</updated>
    <published>2020-02-04T04:53:45Z</published>
    <title>Variational Template Machine for Data-to-Text Generation</title>
    <summary>  How to generate descriptions from structured data organized in tables?
Existing approaches using neural encoder-decoder models often suffer from
lacking diversity. We claim that an open set of templates is crucial for
enriching the phrase constructions and realizing varied generations. Learning
such templates is prohibitive since it often requires a large paired &lt;table,
description&gt; corpus, which is seldom available. This paper explores the problem
of automatically learning reusable "templates" from paired and non-paired data.
We propose the variational template machine (VTM), a novel method to generate
text descriptions from data tables. Our contributions include: a) we carefully
devise a specific model architecture and losses to explicitly disentangle text
template and semantic content information, in the latent spaces, and b)we
utilize both small parallel data and large raw text without aligned tables to
enrich the template learning. Experiments on datasets from a variety of
different domains show that VTM is able to generate more diversely while
keeping a good fluency and quality.
</summary>
    <author>
      <name>Rong Ye</name>
    </author>
    <author>
      <name>Wenxian Shi</name>
    </author>
    <author>
      <name>Hao Zhou</name>
    </author>
    <author>
      <name>Zhongyu Wei</name>
    </author>
    <author>
      <name>Lei Li</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01127v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01127v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01093v1</id>
    <updated>2020-02-04T02:35:19Z</updated>
    <published>2020-02-04T02:35:19Z</published>
    <title>On the interaction between supervision and self-play in emergent
  communication</title>
    <summary>  A promising approach for teaching artificial agents to use natural language
involves using human-in-the-loop training. However, recent work suggests that
current machine learning methods are too data inefficient to be trained in this
way from scratch. In this paper, we investigate the relationship between two
categories of learning signals with the ultimate goal of improving sample
efficiency: imitating human language data via supervised learning, and
maximizing reward in a simulated multi-agent environment via self-play (as done
in emergent communication), and introduce the term supervised self-play (S2P)
for algorithms using both of these signals. We find that first training agents
via supervised learning on human data followed by self-play outperforms the
converse, suggesting that it is not beneficial to emerge languages from
scratch. We then empirically investigate various S2P schedules that begin with
supervised learning in two environments: a Lewis signaling game with symbolic
inputs, and an image-based referential game with natural language descriptions.
Lastly, we introduce population based approaches to S2P, which further improves
the performance over single-agent methods.
</summary>
    <author>
      <name>Ryan Lowe</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Joelle Pineau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally. Accepted at ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01065v1</id>
    <updated>2020-02-04T00:28:38Z</updated>
    <published>2020-02-04T00:28:38Z</published>
    <title>Fake News Detection by means of Uncertainty Weighted Causal Graphs</title>
    <summary>  Society is experimenting changes in information consumption, as new
information channels such as social networks let people share news that do not
necessarily be trust worthy. Sometimes, these sources of information produce
fake news deliberately with doubtful purposes and the consumers of that
information share it to other users thinking that the information is accurate.
This transmission of information represents an issue in our society, as can
influence negatively the opinion of people about certain figures, groups or
ideas. Hence, it is desirable to design a system that is able to detect and
classify information as fake and categorize a source of information as trust
worthy or not. Current systems experiment difficulties performing this task, as
it is complicated to design an automatic procedure that can classify this
information independent on the context. In this work, we propose a mechanism to
detect fake news through a classifier based on weighted causal graphs. These
graphs are specific hybrid models that are built through causal relations
retrieved from texts and consider the uncertainty of causal relations. We take
advantage of this representation to use the probability distributions of this
graph and built a fake news classifier based on the entropy and KL divergence
of learned and new information. We believe that the problem of fake news is
accurately tackled by this model due to its hybrid nature between a symbolic
and quantitative methodology. We describe the methodology of this classifier
and add empirical evidence of the usefulness of our proposed approach in the
form of synthetic experiments and a real experiment involving lung cancer.
</summary>
    <author>
      <name>Eduardo C. Garrido-Merchán</name>
    </author>
    <author>
      <name>Cristina Puente</name>
    </author>
    <author>
      <name>Rafael Palacios</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01030v1</id>
    <updated>2020-02-03T22:13:07Z</updated>
    <published>2020-02-03T22:13:07Z</published>
    <title>Detecting Fake News with Capsule Neural Networks</title>
    <summary>  Fake news is dramatically increased in social media in recent years. This has
prompted the need for effective fake news detection algorithms. Capsule neural
networks have been successful in computer vision and are receiving attention
for use in Natural Language Processing (NLP). This paper aims to use capsule
neural networks in the fake news detection task. We use different embedding
models for news items of different lengths. Static word embedding is used for
short news items, whereas non-static word embeddings that allow incremental
up-training and updating in the training phase are used for medium length or
large news statements. Moreover, we apply different levels of n-grams for
feature extraction. Our proposed architectures are evaluated on two recent
well-known datasets in the field, namely ISOT and LIAR. The results show
encouraging performance, outperforming the state-of-the-art methods by 7.8% on
ISOT and 3.1% on the validation set, and 1% on the test set of the LIAR
dataset.
</summary>
    <author>
      <name>Mohammad Hadi Goldani</name>
    </author>
    <author>
      <name>Saeedeh Momtazi</name>
    </author>
    <author>
      <name>Reza Safabakhsh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04513v2</id>
    <updated>2020-02-15T19:10:29Z</updated>
    <published>2020-02-03T17:55:19Z</published>
    <title>An experiment exploring the theoretical and methodological challenges in
  developing a semi-automated approach to analysis of small-N qualitative data</title>
    <summary>  This paper experiments with designing a semi-automated qualitative data
analysis (QDA) algorithm to analyse 20 transcripts by using freeware.
Text-mining (TM) and QDA were guided by frequency and association measures,
because these statistics remain robust when the sample size is small. The
refined TM algorithm split the text into various sizes based on a manually
revised dictionary. This lemmatisation approach may reflect the context of the
text better than uniformly tokenising the text into one single size. TM results
were used for initial coding. Code repacking was guided by association measures
and external data to implement a general inductive QDA approach. The
information retrieved by TM and QDA was depicted in subgraphs for comparisons.
The analyses were completed in 6-7 days. Both algorithms retrieved contextually
consistent and relevant information. However, the QDA algorithm retrieved more
specific information than TM alone. The QDA algorithm does not strictly comply
with the convention of TM or of QDA, but becomes a more efficient, systematic
and transparent text analysis approach than a conventional QDA approach.
Scaling up QDA to reliably discover knowledge from text was exactly the
research purpose. This paper also sheds light on understanding the relations
between information technologies, theory and methodologies.
</summary>
    <author>
      <name>Sandro Tsang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Page 2: "qualitative" research (QR); Page 3 and Appendix: Cited the
  second and third authors of a paper; Page 4: Redundant citation of author
  names; Page 8: Replaced wordclouds with higher resolution ones (cited
  facilities on page 3); Page 13: TM is a big-data/"quantitative" method and
  replaced "supplementary material" with "appendix"; Showed author names after
  see or cf. on pages 4, 5, 6 and 15</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04513v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04513v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2; I.1.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01336v1</id>
    <updated>2020-02-03T17:07:03Z</updated>
    <published>2020-02-03T17:07:03Z</published>
    <title>Twitter Bot Detection Using Bidirectional Long Short-term Memory Neural
  Networks and Word Embeddings</title>
    <summary>  Twitter is a web application playing dual roles of online social networking
and micro-blogging. The popularity and open structure of Twitter have attracted
a large number of automated programs, known as bots. Legitimate bots generate a
large amount of benign contextual content, i.e., tweets delivering news and
updating feeds, while malicious bots spread spam or malicious contents. To
assist human users in identifying who they are interacting with, this paper
focuses on the classification of human and spambot accounts on Twitter, by
employing recurrent neural networks, specifically bidirectional Long Short-term
Memory (BiLSTM), to efficiently capture features across tweets. To the best of
our knowledge, our work is the first that develops a recurrent neural model
with word embeddings to distinguish Twitter bots from human accounts, that
requires no prior knowledge or assumption about users' profiles, friendship
networks, or historical behavior on the target account. Moreover, our model
does not require any handcrafted features. The preliminary simulation results
are very encouraging. Experiments on the cresci-2017 dataset show that our
approach can achieve competitive performance compared with existing
state-of-the-art bot detection systems.
</summary>
    <author>
      <name>Feng Wei</name>
    </author>
    <author>
      <name>Uyen Trang Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE TPS 2019. arXiv admin note: text overlap with arXiv:1703.04482
  by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00876v1</id>
    <updated>2020-02-03T16:43:02Z</updated>
    <published>2020-02-03T16:43:02Z</published>
    <title>Torch-Struct: Deep Structured Prediction Library</title>
    <summary>  The literature on structured prediction for NLP describes a rich collection
of distributions and algorithms over sequences, segmentations, alignments, and
trees; however, these algorithms are difficult to utilize in deep learning
frameworks. We introduce Torch-Struct, a library for structured prediction
designed to take advantage of and integrate with vectorized,
auto-differentiation based frameworks. Torch-Struct includes a broad collection
of probabilistic structures accessed through a simple and flexible
distribution-based API that connects to any deep learning model. The library
utilizes batched, vectorized operations and exploits auto-differentiation to
produce readable, fast, and testable code. Internally, we also include a number
of general-purpose optimizations to provide cross-algorithm efficiency.
Experiments show significant performance gains over fast baselines and
case-studies demonstrate the benefits of the library. Torch-Struct is available
at https://github.com/harvardnlp/pytorch-struct.
</summary>
    <author>
      <name>Alexander M. Rush</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00835v1</id>
    <updated>2020-02-03T15:47:19Z</updated>
    <published>2020-02-03T15:47:19Z</published>
    <title>Learning Contextualized Document Representations for Healthcare Answer
  Retrieval</title>
    <summary>  We present Contextual Discourse Vectors (CDV), a distributed document
representation for efficient answer retrieval from long healthcare documents.
Our approach is based on structured query tuples of entities and aspects from
free text and medical taxonomies. Our model leverages a dual encoder
architecture with hierarchical LSTM layers and multi-task training to encode
the position of clinical entities and aspects alongside the document discourse.
We use our continuous representations to resolve queries with short latency
using approximate nearest neighbor search on sentence level. We apply the CDV
model for retrieving coherent answer passages from nine English public health
resources from the Web, addressing both patients and medical professionals.
Because there is no end-to-end training data available for all application
scenarios, we train our model with self-supervised data from Wikipedia. We show
that our generalized model significantly outperforms several state-of-the-art
baselines for healthcare passage ranking and is able to adapt to heterogeneous
domains without additional fine-tuning.
</summary>
    <author>
      <name>Sebastian Arnold</name>
    </author>
    <author>
      <name>Betty van Aken</name>
    </author>
    <author>
      <name>Paul Grundmann</name>
    </author>
    <author>
      <name>Felix A. Gers</name>
    </author>
    <author>
      <name>Alexander Löser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380208</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380208" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The Web Conference 2020 (WWW '20)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00768v1</id>
    <updated>2020-02-03T14:11:48Z</updated>
    <published>2020-02-03T14:11:48Z</published>
    <title>Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks</title>
    <summary>  Spoken dialogue systems typically use a list of top-N ASR hypotheses for
inferring the semantic meaning and tracking the state of the dialogue. However
ASR graphs, such as confusion networks (confnets), provide a compact
representation of a richer hypothesis space than a top-N ASR list. In this
paper, we study the benefits of using confusion networks with a
state-of-the-art neural dialogue state tracker (DST). We encode the
2-dimensional confnet into a 1-dimensional sequence of embeddings using an
attentional confusion network encoder which can be used with any DST system.
Our confnet encoder is plugged into the state-of-the-art 'Global-locally
Self-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains
significant improvements in both accuracy and inference time compared to using
top-N ASR hypotheses.
</summary>
    <author>
      <name>Vaishali Pal</name>
    </author>
    <author>
      <name>Fabien Guillot</name>
    </author>
    <author>
      <name>Jean-Michel Renders</name>
    </author>
    <author>
      <name>Laurent Besacier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00652v1</id>
    <updated>2020-02-03T11:28:10Z</updated>
    <published>2020-02-03T11:28:10Z</published>
    <title>How Far are We from Effective Context Modeling ? An Exploratory Study on
  Semantic Parsing in Context</title>
    <summary>  Recently semantic parsing in context has received a considerable attention,
which is challenging since there are complex contextual phenomena. Previous
works verified their proposed methods in limited scenarios, which motivates us
to conduct an exploratory study on context modeling methods under real-world
semantic parsing in context. We present a grammar-based decoding semantic
parser and adapt typical context modeling methods on top of it. We evaluate 13
context modeling methods on two large complex cross-domain datasets, and our
best model achieves state-of-the-art performances on both datasets with
significant improvements. Furthermore, we summarize the most frequent
contextual phenomena, with a fine-grained analysis on representative models,
which may shed light on potential research directions.
</summary>
    <author>
      <name>Qian Liu</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Jiaqi Guo</name>
    </author>
    <author>
      <name>Jian-Guang Lou</name>
    </author>
    <author>
      <name>Bin Zhou</name>
    </author>
    <author>
      <name>Dongmei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02755v1</id>
    <updated>2020-02-03T09:24:45Z</updated>
    <published>2020-02-03T09:24:45Z</published>
    <title>On-Device Information Extraction from SMS using Hybrid Hierarchical
  Classification</title>
    <summary>  Cluttering of SMS inbox is one of the serious problems that users today face
in the digital world where every online login, transaction, along with
promotions generate multiple SMS. This problem not only prevents users from
searching and navigating messages efficiently but often results in users
missing out the relevant information associated with the corresponding SMS like
offer codes, payment reminders etc. In this paper, we propose a unique
architecture to organize and extract the appropriate information from SMS and
further display it in an intuitive template. In the proposed architecture, we
use a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural
Network (CNN) to categorize SMS into multiple classes followed by a set of
entity parsers used to extract the relevant information from the classified
message. The architecture using its preprocessing techniques not only takes
into account the enormous variations observed in SMS data but also makes it
efficient for its on-device (mobile phone) functionalities in terms of
inference timing and size.
</summary>
    <author>
      <name>Shubham Vatsal</name>
    </author>
    <author>
      <name>Naresh Purre</name>
    </author>
    <author>
      <name>Sukumar Moharana</name>
    </author>
    <author>
      <name>Gopi Ramena</name>
    </author>
    <author>
      <name>Debi Prasanna Mohanty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in IEEE ICSC 2020 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00583v1</id>
    <updated>2020-02-03T07:15:29Z</updated>
    <published>2020-02-03T07:15:29Z</published>
    <title>CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of
  Text Generation</title>
    <summary>  In text generation evaluation, many practical issues, such as inconsistent
experimental settings and metric implementations, are often ignored but lead to
unfair evaluation and untenable conclusions. We present CoTK, an open-source
toolkit aiming to support fast development and fair evaluation of text
generation. In model development, CoTK helps handle the cumbersome issues, such
as data processing, metric implementation, and reproduction. It standardizes
the development steps and reduces human errors which may lead to inconsistent
experimental settings. In model evaluation, CoTK provides implementation for
many commonly used metrics and benchmark models across different experimental
settings. As a unique feature, CoTK can signify when and which metric cannot be
fairly compared. We demonstrate that it is convenient to use CoTK for model
development and evaluation, particularly across different experimental
settings.
</summary>
    <author>
      <name>Fei Huang</name>
    </author>
    <author>
      <name>Dazhen Wan</name>
    </author>
    <author>
      <name>Zhihong Shao</name>
    </author>
    <author>
      <name>Pei Ke</name>
    </author>
    <author>
      <name>Jian Guan</name>
    </author>
    <author>
      <name>Yilin Niu</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitting to ACL2020 demo</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00571v1</id>
    <updated>2020-02-03T05:59:52Z</updated>
    <published>2020-02-03T05:59:52Z</published>
    <title>IART: Intent-aware Response Ranking with Transformers in
  Information-seeking Conversation Systems</title>
    <summary>  Personal assistant systems, such as Apple Siri, Google Assistant, Amazon
Alexa, and Microsoft Cortana, are becoming ever more widely used. Understanding
user intent such as clarification questions, potential answers and user
feedback in information-seeking conversations is critical for retrieving good
responses. In this paper, we analyze user intent patterns in
information-seeking conversations and propose an intent-aware neural response
ranking model "IART", which refers to "Intent-Aware Ranking with Transformers".
IART is built on top of the integration of user intent modeling and language
representation learning with the Transformer architecture, which relies
entirely on a self-attention mechanism instead of recurrent nets. It
incorporates intent-aware utterance attention to derive an importance weighting
scheme of utterances in conversation context with the aim of better
conversation history understanding. We conduct extensive experiments with three
information-seeking conversation data sets including both standard benchmarks
and commercial data. Our proposed model outperforms all baseline methods with
respect to a variety of metrics. We also perform case studies and analysis of
learned user intent and its impact on response ranking in information-seeking
conversations to provide interpretation of results.
</summary>
    <author>
      <name>Liu Yang</name>
    </author>
    <author>
      <name>Minghui Qiu</name>
    </author>
    <author>
      <name>Chen Qu</name>
    </author>
    <author>
      <name>Cen Chen</name>
    </author>
    <author>
      <name>Jiafeng Guo</name>
    </author>
    <author>
      <name>Yongfeng Zhang</name>
    </author>
    <author>
      <name>W. Bruce Croft</name>
    </author>
    <author>
      <name>Haiqing Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by WWW2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00557v1</id>
    <updated>2020-02-03T04:52:47Z</updated>
    <published>2020-02-03T04:52:47Z</published>
    <title>Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker</title>
    <summary>  To access data stored in relational databases, users need to understand the
database schema and write a query using a query language such as SQL. To
simplify this task, text-to-SQL models attempt to translate a user's natural
language question to corresponding SQL query. Recently, several generative
text-to-SQL models have been developed. We propose a novel discriminative
re-ranker to improve the performance of generative text-to-SQL models by
extracting the best SQL query from the beam output predicted by the text-to-SQL
generator, resulting in improved performance in the cases where the best query
was in the candidate list, but not at the top of the list. We build the
re-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative
strengths of the text-to-SQL and re-ranker models across different query
hardness levels, and suggest how to combine the two models for optimal
performance. We demonstrate the effectiveness of the re-ranker by applying it
to two state-of-the-art text-to-SQL models, and achieve top 4 score on the
Spider leaderboard at the time of writing this article.
</summary>
    <author>
      <name>Amol Kelkar</name>
    </author>
    <author>
      <name>Rohan Relan</name>
    </author>
    <author>
      <name>Vaishali Bhardwaj</name>
    </author>
    <author>
      <name>Saurabh Vaichal</name>
    </author>
    <author>
      <name>Peter Relan</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00551v2</id>
    <updated>2020-02-14T06:15:58Z</updated>
    <published>2020-02-03T03:36:34Z</published>
    <title>End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection</title>
    <summary>  This paper integrates a voice activity detection (VAD) function with
end-to-end automatic speech recognition toward an online speech interface and
transcribing very long audio recordings. We focus on connectionist temporal
classification (CTC) and its extension of CTC/attention architectures. As
opposed to an attention-based architecture, input-synchronous label prediction
can be performed based on a greedy search with the CTC (pre-)softmax output.
This prediction includes consecutive long blank labels, which can be regarded
as a non-speech region. We use the labels as a cue for detecting speech
segments with simple thresholding. The threshold value is directly related to
the length of a non-speech region, which is more intuitive and easier to
control than conventional VAD hyperparameters. Experimental results on
unsegmented data show that the proposed method outperformed the baseline
methods using the conventional energy-based and neural-network-based VAD
methods and achieved an RTF less than 0.2. The proposed method is publicly
available.
</summary>
    <author>
      <name>Takenori Yoshimura</name>
    </author>
    <author>
      <name>Tomoki Hayashi</name>
    </author>
    <author>
      <name>Kazuya Takeda</name>
    </author>
    <author>
      <name>Shinji Watanabe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00551v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00551v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00544v1</id>
    <updated>2020-02-03T02:58:00Z</updated>
    <published>2020-02-03T02:58:00Z</published>
    <title>Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network</title>
    <summary>  We propose a tensor-to-vector regression approach to multi-channel speech
enhancement in order to address the issue of input size explosion and
hidden-layer size expansion. The key idea is to cast the conventional deep
neural network (DNN) based vector-to-vector regression formulation under a
tensor-train network (TTN) framework. TTN is a recently emerged solution for
compact representation of deep models with fully connected hidden layers. Thus
TTN maintains DNN's expressive power yet involves a much smaller amount of
trainable parameters. Furthermore, TTN can handle a multi-dimensional tensor
input by design, which exactly matches the desired setting in multi-channel
speech enhancement. We first provide a theoretical extension from DNN to TTN
based regression. Next, we show that TTN can attain speech enhancement quality
comparable with that for DNN but with much fewer parameters, e.g., a reduction
from 27 million to only 5 million parameters is observed in a single-channel
scenario. TTN also improves PESQ over DNN from 2.86 to 2.96 by slightly
increasing the number of trainable parameters. Finally, in 8-channel
conditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN,
whereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Our
implementation is available online
https://github.com/uwjunqi/Tensor-Train-Neural-Network.
</summary>
    <author>
      <name>Jun Qi</name>
    </author>
    <author>
      <name>Hu Hu</name>
    </author>
    <author>
      <name>Yannan Wang</name>
    </author>
    <author>
      <name>Chao-Han Huck Yang</name>
    </author>
    <author>
      <name>Sabato Marco Siniscalchi</name>
    </author>
    <author>
      <name>Chin-Hui Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020. Update reproducible code</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE ICASSP 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.00544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00527v1</id>
    <updated>2020-02-03T01:23:41Z</updated>
    <published>2020-02-03T01:23:41Z</published>
    <title>Phylogenetic signal in phonotactics</title>
    <summary>  Phylogenetic methods have broad potential in linguistics beyond tree
inference. Here, we show how a phylogenetic approach opens the possibility of
gaining historical insights from entirely new kinds of linguistic data--in this
instance, statistical phonotactics. We extract phonotactic data from 128
Pama-Nyungan vocabularies and apply tests for phylogenetic signal, quantifying
the degree to which the data reflect phylogenetic history. We test three
datasets: (1) binary variables recording the presence or absence of biphones
(two-segment sequences) in a lexicon (2) frequencies of transitions between
segments, and (3) frequencies of transitions between natural sound classes.
Australian languages have been characterised as having a high degree of
phonotactic homogeneity. Nevertheless, we detect phylogenetic signal in all
datasets. Phylogenetic signal is higher in finer-grained frequency data than in
binary data, and highest in natural-class-based data. These results demonstrate
the viability of employing a new source of readily extractable data in
historical and comparative linguistics.
</summary>
    <author>
      <name>Jayden L. Macklin-Cordes</name>
    </author>
    <author>
      <name>Claire Bowern</name>
    </author>
    <author>
      <name>Erich R. Round</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Main text: 26 pages, 13 figures, 1 table. Supplementary Information:
  17 pages, 1 figure. Code and data available at
  http://doi.org/10.5281/zenodo.3610089. This article has been submitted but
  not yet accepted for publication in a book or journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00481v1</id>
    <updated>2020-02-02T20:08:34Z</updated>
    <published>2020-02-02T20:08:34Z</published>
    <title>Assessment of Amazon Comprehend Medical: Medication Information
  Extraction</title>
    <summary>  In November 27, 2018, Amazon Web Services (AWS) released Amazon Comprehend
Medical (ACM), a deep learning based system that automatically extracts
clinical concepts (which include anatomy, medical conditions, protected health
information (PH)I, test names, treatment names, and medical procedures, and
medications) from clinical text notes. Uptake and trust in any new data product
relies on independent validation across benchmark datasets and tools to
establish and confirm expected quality of results. This work focuses on the
medication extraction task, and particularly, ACM was evaluated using the
official test sets from the 2009 i2b2 Medication Extraction Challenge and 2018
n2c2 Track 2: Adverse Drug Events and Medication Extraction in EHRs. Overall,
ACM achieved F-scores of 0.768 and 0.828. These scores ranked the lowest when
compared to the three best systems in the respective challenges. To further
establish the generalizability of its medication extraction performance, a set
of random internal clinical text notes from NYU Langone Medical Center were
also included in this work. And in this corpus, ACM garnered an F-score of
0.753.
</summary>
    <author>
      <name>Benedict Guzman</name>
    </author>
    <author>
      <name> MS</name>
    </author>
    <author>
      <name>Isabel Metzger</name>
    </author>
    <author>
      <name> MS</name>
    </author>
    <author>
      <name>Yindalon Aphinyanaphongs</name>
    </author>
    <author>
      <name>M. D.</name>
    </author>
    <author>
      <name>Ph. D.</name>
    </author>
    <author>
      <name>Himanshu Grover</name>
    </author>
    <author>
      <name>Ph. D</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00417v1</id>
    <updated>2020-02-02T15:51:22Z</updated>
    <published>2020-02-02T15:51:22Z</published>
    <title>WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss</title>
    <summary>  Tacotron-based text-to-speech (TTS) systems directly synthesize speech from
text input. Such frameworks typically consist of a feature prediction network
that maps character sequences to frequency-domain acoustic features, followed
by a waveform reconstruction algorithm or a neural vocoder that generates the
time-domain waveform from acoustic features. As the loss function is usually
calculated only for frequency-domain acoustic features, that doesn't directly
control the quality of the generated time-domain waveform. To address this
problem, we propose a new training scheme for Tacotron-based TTS, referred to
as WaveTTS, that has 2 loss functions: 1) time-domain loss, denoted as the
waveform loss, that measures the distortion between the natural and generated
waveform; and 2) frequency-domain loss, that measures the Mel-scale acoustic
feature loss between the natural and generated acoustic features. WaveTTS
ensures both the quality of the acoustic features and the resulting speech
waveform. To our best knowledge, this is the first implementation of Tacotron
with joint time-frequency domain loss. Experimental results show that the
proposed framework outperforms the baselines and achieves high-quality
synthesized speech.
</summary>
    <author>
      <name>Rui Liu</name>
    </author>
    <author>
      <name>Berrak Sisman</name>
    </author>
    <author>
      <name>Feilong Bao</name>
    </author>
    <author>
      <name>Guanglai Gao</name>
    </author>
    <author>
      <name>Haizhou Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Odyssey 2020, Tokyo, Japan</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00388v1</id>
    <updated>2020-02-02T13:17:31Z</updated>
    <published>2020-02-02T13:17:31Z</published>
    <title>A Survey on Knowledge Graphs: Representation, Acquisition and
  Applications</title>
    <summary>  Human knowledge provides a formal understanding of the world. Knowledge
graphs that represent structural relations between entities have become an
increasingly popular research direction towards cognition and human-level
intelligence. In this survey, we provide a comprehensive review on knowledge
graph covering overall research topics about 1) knowledge graph representation
learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph,
and 4) knowledge-aware applications, and summarize recent breakthroughs and
perspective directions to facilitate future research. We propose a full-view
categorization and new taxonomies on these topics. Knowledge graph embedding is
organized from four aspects of representation space, scoring function, encoding
models and auxiliary information. For knowledge acquisition, especially
knowledge graph completion, embedding methods, path inference and logical rule
reasoning are reviewed. We further explore several emerging topics including
meta relational learning, commonsense reasoning, and temporal knowledge graphs.
To facilitate future research on knowledge graphs, we also provide a curated
collection of datasets and open-source libraries on different tasks. In the
end, we have a thorough outlook on several promising research directions.
</summary>
    <author>
      <name>Shaoxiong Ji</name>
    </author>
    <author>
      <name>Shirui Pan</name>
    </author>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Pekka Marttinen</name>
    </author>
    <author>
      <name>Philip S. Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 10 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02758v1</id>
    <updated>2020-02-02T07:15:18Z</updated>
    <published>2020-02-02T07:15:18Z</published>
    <title>Neural Machine Translation System of Indic Languages -- An Attention
  based Approach</title>
    <summary>  Neural machine translation (NMT) is a recent and effective technique which
led to remarkable improvements in comparison of conventional machine
translation techniques. Proposed neural machine translation model developed for
the Gujarati language contains encoder-decoder with attention mechanism. In
India, almost all the languages are originated from their ancestral language -
Sanskrit. They are having inevitable similarities including lexical and named
entity similarity. Translating into Indic languages is always be a challenging
task. In this paper, we have presented the neural machine translation system
(NMT) that can efficiently translate Indic languages like Hindi and Gujarati
that together covers more than 58.49 percentage of total speakers in the
country. We have compared the performance of our NMT model with automatic
evaluation matrices such as BLEU, perplexity and TER matrix. The comparison of
our network with Google translate is also presented where it outperformed with
a margin of 6 BLEU score on English-Gujarati translation.
</summary>
    <author>
      <name>Parth Shah</name>
    </author>
    <author>
      <name>Vishvajit Bakrola</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICACCP.2019.8882969</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICACCP.2019.8882969" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 Second International Conference on Advanced Computational and
  Communication Paradigms (ICACCP), Gangtok, India, 2019, pp. 1-5</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.02758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01359v1</id>
    <updated>2020-02-02T05:59:27Z</updated>
    <published>2020-02-02T05:59:27Z</published>
    <title>Schema-Guided Dialogue State Tracking Task at DSTC8</title>
    <summary>  This paper gives an overview of the Schema-Guided Dialogue State Tracking
task of the 8th Dialogue System Technology Challenge. The goal of this task is
to develop dialogue state tracking models suitable for large-scale virtual
assistants, with a focus on data-efficient joint modeling across domains and
zero-shot generalization to new APIs. This task provided a new dataset
consisting of over 16000 dialogues in the training set spanning 16 domains to
highlight these challenges, and a baseline model capable of zero-shot
generalization to new APIs. Twenty-five teams participated, developing a range
of neural network models, exceeding the performance of the baseline model by a
very high margin. The submissions incorporated a variety of pre-trained
encoders and data augmentation techniques. This paper describes the task
definition, dataset and evaluation methodology. We also summarize the approach
and results of the submitted systems to highlight the overall trends in the
state-of-the-art.
</summary>
    <author>
      <name>Abhinav Rastogi</name>
    </author>
    <author>
      <name>Xiaoxue Zang</name>
    </author>
    <author>
      <name>Srinivas Sunkara</name>
    </author>
    <author>
      <name>Raghav Gupta</name>
    </author>
    <author>
      <name>Pranav Khaitan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at DSTC workshop, AAAI 2020. arXiv admin note: text overlap
  with arXiv:1909.05855</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00317v1</id>
    <updated>2020-02-02T03:54:47Z</updated>
    <published>2020-02-02T03:54:47Z</published>
    <title>Citation Text Generation</title>
    <summary>  We introduce the task of citation text generation: given a pair of scientific
documents, explain their relationship in natural language text in the manner of
a citation from one text to the other. This task encourages systems to learn
rich relationships between scientific texts and to express them concretely in
natural language. Models for citation text generation will require robust
document understanding including the capacity to quickly adapt to new
vocabulary and to reason about document content. We believe this challenging
direction of research will benefit high-impact applications such as automatic
literature review or scientific writing assistance systems. In this paper we
establish the task of citation text generation with a standard evaluation
corpus and explore several baseline models.
</summary>
    <author>
      <name>Kelvin Luu</name>
    </author>
    <author>
      <name>Rik Koncel-Kedziorski</name>
    </author>
    <author>
      <name>Kyle Lo</name>
    </author>
    <author>
      <name>Isabel Cachola</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00293v1</id>
    <updated>2020-02-02T00:22:55Z</updated>
    <published>2020-02-02T00:22:55Z</published>
    <title>Beat the AI: Investigating Adversarial Human Annotations for Reading
  Comprehension</title>
    <summary>  Innovations in annotation methodology have been a propellant for Reading
Comprehension (RC) datasets and models. One recent trend to challenge current
RC models is to involve a model in the annotation process: humans create
questions adversarially, such that the model fails to answer them correctly. In
this work we investigate this annotation approach and apply it in three
different settings, collecting a total of 36,000 samples with progressively
stronger models in the annotation loop. This allows us to explore questions
such as the reproducibility of the adversarial effect, transfer from data
collected with varying model-in-the-loop strengths, and generalisation to data
collected without a model. We find that training on adversarially collected
samples leads to strong generalisation to non-adversarially collected datasets,
yet with progressive deterioration as the model-in-the-loop strength increases.
Furthermore we find that stronger models can still learn from datasets
collected with substantially weaker models in the loop: When trained on data
collected with a BiDAF model in the loop, RoBERTa achieves 36.0F1 on questions
that it cannot answer when trained on SQuAD - only marginally lower than when
trained on data collected using RoBERTa itself.
</summary>
    <author>
      <name>Max Bartolo</name>
    </author>
    <author>
      <name>Alastair Roberts</name>
    </author>
    <author>
      <name>Johannes Welbl</name>
    </author>
    <author>
      <name>Sebastian Riedel</name>
    </author>
    <author>
      <name>Pontus Stenetorp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages including appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00206v1</id>
    <updated>2020-02-01T13:24:03Z</updated>
    <published>2020-02-01T13:24:03Z</published>
    <title>Novel Entity Discovery from Web Tables</title>
    <summary>  When working with any sort of knowledge base (KB) one has to make sure it is
as complete and also as up-to-date as possible. Both tasks are non-trivial as
they require recall-oriented efforts to determine which entities and
relationships are missing from the KB. As such they require a significant
amount of labor. Tables on the Web, on the other hand, are abundant and have
the distinct potential to assist with these tasks. In particular, we can
leverage the content in such tables to discover new entities, properties, and
relationships. Because web tables typically only contain raw textual content we
first need to determine which cells refer to which known entities---a task we
dub table-to-KB matching. This first task aims to infer table semantics by
linking table cells and heading columns to elements of a KB. Then second task
builds upon these linked entities and properties to not only identify novel
ones in the same table but also to bootstrap their type and additional
relationships. We refer to this process as novel entity discovery and, to the
best of our knowledge, it is the first endeavor on mining the unlinked cells in
web tables. Our method identifies not only out-of-KB (``novel'') information
but also novel aliases for in-KB (``known'') entities. When evaluated using
three purpose-built test collections, we find that our proposed approaches
obtain a marked improvement in terms of precision over our baselines whilst
keeping recall stable.
</summary>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <author>
      <name>Edgar Meij</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <author>
      <name>Ridho Reinanda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380205</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380205" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of The Web Conference 2020 (WWW '20), 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00205v1</id>
    <updated>2020-02-01T13:21:33Z</updated>
    <published>2020-02-01T13:21:33Z</published>
    <title>Deep segmental phonetic posterior-grams based discovery of
  non-categories in L2 English speech</title>
    <summary>  Second language (L2) speech is often labeled with the native, phone
categories. However, in many cases, it is difficult to decide on a categorical
phone that an L2 segment belongs to. These segments are regarded as
non-categories. Most existing approaches for Mispronunciation Detection and
Diagnosis (MDD) are only concerned with categorical errors, i.e. a phone
category is inserted, deleted or substituted by another. However,
non-categorical errors are not considered. To model these non-categorical
errors, this work aims at exploring non-categorical patterns to extend the
categorical phone set. We apply a phonetic segment classifier to generate
segmental phonetic posterior-grams (SPPGs) to represent phone segment-level
information. And then we explore the non-categories by looking for the SPPGs
with more than one peak. Compared with the baseline system, this approach
explores more non-categorical patterns, and also perceptual experimental
results show that the explored non-categories are more accurate with increased
confusion degree by 7.3% and 7.5% under two different measures. Finally, we
preliminarily analyze the reason behind those non-categories.
</summary>
    <author>
      <name>Xu Li</name>
    </author>
    <author>
      <name>Xixin Wu</name>
    </author>
    <author>
      <name>Xunying Liu</name>
    </author>
    <author>
      <name>Helen Meng</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00205v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00205v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00198v1</id>
    <updated>2020-02-01T12:36:55Z</updated>
    <published>2020-02-01T12:36:55Z</published>
    <title>Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data</title>
    <summary>  Emotional voice conversion is to convert the spectrum and prosody to change
the emotional patterns of speech, while preserving the speaker identity and
linguistic content. Many studies require parallel speech data between different
emotional patterns, which is not practical in real life. Moreover, they often
model the conversion of fundamental frequency (F0) with a simple linear
transform. As F0 is a key aspect of intonation that is hierarchical in nature,
we believe that it is more adequate to model F0 in different temporal scales by
using wavelet transform. We propose a CycleGAN network to find an optimal
pseudo pair from non-parallel training data by learning forward and inverse
mappings simultaneously using adversarial and cycle-consistency losses. We also
study the use of continuous wavelet transform (CWT) to decompose F0 into ten
temporal scales, that describes speech prosody at different time resolution,
for effective F0 conversion. Experimental results show that our proposed
framework outperforms the baselines both in objective and subjective
evaluations.
</summary>
    <author>
      <name>Kun Zhou</name>
    </author>
    <author>
      <name>Berrak Sisman</name>
    </author>
    <author>
      <name>Haizhou Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Speaker Odyssey 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00181v1</id>
    <updated>2020-02-01T10:00:06Z</updated>
    <published>2020-02-01T10:00:06Z</published>
    <title>Fine-Tuning BERT for Schema-Guided Zero-Shot Dialogue State Tracking</title>
    <summary>  We present our work on Track 4 in the Dialogue System Technology Challenges 8
(DSTC8). The DSTC8-Track 4 aims to perform dialogue state tracking (DST) under
the zero-shot settings, in which the model needs to generalize on unseen
service APIs given a schema definition of these target APIs. Serving as the
core for many virtual assistants such as Siri, Alexa, and Google Assistant, the
DST keeps track of the user's goal and what happened in the dialogue history,
mainly including intent prediction, slot filling, and user state tracking,
which tests models' ability of natural language understanding. Recently, the
pretrained language models have achieved state-of-the-art results and shown
impressive generalization ability on various NLP tasks, which provide a
promising way to perform zero-shot learning for language understanding. Based
on this, we propose a schema-guided paradigm for zero-shot dialogue state
tracking (SGP-DST) by fine-tuning BERT, one of the most popular pretrained
language models. The SGP-DST system contains four modules for intent
prediction, slot prediction, slot transfer prediction, and user state
summarizing respectively. According to the official evaluation results, our
SGP-DST (team12) ranked 3rd on the joint goal accuracy (primary evaluation
metric for ranking submissions) and 1st on the requsted slots F1 among 25
participant teams.
</summary>
    <author>
      <name>Yu-Ping Ruan</name>
    </author>
    <author>
      <name>Zhen-Hua Ling</name>
    </author>
    <author>
      <name>Jia-Chen Gu</name>
    </author>
    <author>
      <name>Quan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Present on the DSTC8 Workshop @ AAAI-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00175v1</id>
    <updated>2020-02-01T09:26:07Z</updated>
    <published>2020-02-01T09:26:07Z</published>
    <title>UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image
  Captioning</title>
    <summary>  Image Captioning, the task of automatic generation of image captions, has
attracted attentions from researchers in many fields of computer science, being
computer vision, natural language processing and machine learning in recent
years. This paper contributes to research on Image Captioning task in terms of
extending dataset to a different language - Vietnamese. So far, there is no
existed Image Captioning dataset for Vietnamese language, so this is the
foremost fundamental step for developing Vietnamese Image Captioning. In this
scope, we first build a dataset which contains manually written captions for
images from Microsoft COCO dataset relating to sports played with balls, we
called this dataset UIT-ViIC. UIT-ViIC consists of 19,250 Vietnamese captions
for 3,850 images. Following that, we evaluate our dataset on deep neural
network models and do comparisons with English dataset and two Vietnamese
datasets built by different methods. UIT-ViIC is published on our lab website
for research purposes.
</summary>
    <author>
      <name>Quan Hoang Lam</name>
    </author>
    <author>
      <name>Quang Duy Le</name>
    </author>
    <author>
      <name>Kiet Van Nguyen</name>
    </author>
    <author>
      <name>Ngan Luu-Thuy Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the 2020 ICCCI Conference (The 12th International
  Conference on Computational Collective Intelligence)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01071v1</id>
    <updated>2020-02-01T09:18:56Z</updated>
    <published>2020-02-01T09:18:56Z</published>
    <title>Concept Embedding for Information Retrieval</title>
    <summary>  Concepts are used to solve the term-mismatch problem. However, we need an
effective similarity measure between concepts. Word embedding presents a
promising solution. We present in this study three approaches to build concepts
vectors based on words vectors. We use a vector-based measure to estimate
inter-concepts similarity. Our experiments show promising results. Furthermore,
words and concepts become comparable. This could be used to improve conceptual
indexing process.
</summary>
    <author>
      <name>Karam Abdulahhad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-76941-7_45</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-76941-7_45" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68-XX, 68Pxx, 68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00171v1</id>
    <updated>2020-02-01T08:49:17Z</updated>
    <published>2020-02-01T08:49:17Z</published>
    <title>Novel Language Resources for Hindi: An Aesthetics Text Corpus and a
  Comprehensive Stop Lemma List</title>
    <summary>  This paper is an effort to complement the contributions made by researchers
working toward the inclusion of non-English languages in natural language
processing studies. Two novel Hindi language resources have been created and
released for public consumption. The first resource is a corpus consisting of
nearly thousand pre-processed fictional and nonfictional texts spanning over
hundred years. The second resource is an exhaustive list of stop lemmas created
from 12 corpora across multiple domains, consisting of over 13 million words,
from which more than 200,000 lemmas were generated, and 11 publicly available
stop word lists comprising over 1000 words, from which nearly 400 unique lemmas
were generated. This research lays emphasis on the use of stop lemmas instead
of stop words owing to the presence of various, but not all morphological forms
of a word in stop word lists, as opposed to the presence of only the root form
of the word, from which variations could be derived if required. It was also
observed that stop lemmas were more consistent across multiple sources as
compared to stop words. In order to generate a stop lemma list, the parts of
speech of the lemmas were investigated but rejected as it was found that there
was no significant correlation between the rank of a word in the frequency list
and its part of speech. The stop lemma list was assessed using a comparative
method. A formal evaluation method is suggested as future work arising from
this study.
</summary>
    <author>
      <name>Gayatri Venugopal-Wairagade</name>
    </author>
    <author>
      <name>Jatinderkumar R. Saini</name>
    </author>
    <author>
      <name>Dhanya Pramod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00163v1</id>
    <updated>2020-02-01T07:50:43Z</updated>
    <published>2020-02-01T07:50:43Z</published>
    <title>Bridging Text and Video: A Universal Multimodal Transformer for
  Video-Audio Scene-Aware Dialog</title>
    <summary>  Audio-Visual Scene-Aware Dialog (AVSD) is a task to generate responses when
chatting about a given video, which is organized as a track of the 8th Dialog
System Technology Challenge (DSTC8). To solve the task, we propose a universal
multimodal transformer and introduce the multi-task learning method to learn
joint representations among different modalities as well as generate
informative and fluent responses. Our method extends the natural language
generation pre-trained model to multimodal dialogue generation task. Our system
achieves the best performance in both objective and subjective evaluations in
the challenge.
</summary>
    <author>
      <name>Zekang Li</name>
    </author>
    <author>
      <name>Zongjia Li</name>
    </author>
    <author>
      <name>Jinchao Zhang</name>
    </author>
    <author>
      <name>Yang Feng</name>
    </author>
    <author>
      <name>Cheng Niu</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI2020 DSTC8 workshop. Ranked 1st in DSTC8-AVSD track</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00119v1</id>
    <updated>2020-02-01T01:22:44Z</updated>
    <published>2020-02-01T01:22:44Z</published>
    <title>Improving Domain-Adapted Sentiment Classification by Deep Adversarial
  Mutual Learning</title>
    <summary>  Domain-adapted sentiment classification refers to training on a labeled
source domain to well infer document-level sentiment on an unlabeled target
domain. Most existing relevant models involve a feature extractor and a
sentiment classifier, where the feature extractor works towards learning
domain-invariant features from both domains, and the sentiment classifier is
trained only on the source domain to guide the feature extractor. As such, they
lack a mechanism to use sentiment polarity lying in the target domain. To
improve domain-adapted sentiment classification by learning sentiment from the
target domain as well, we devise a novel deep adversarial mutual learning
approach involving two groups of feature extractors, domain discriminators,
sentiment classifiers, and label probers. The domain discriminators enable the
feature extractors to obtain domain-invariant features. Meanwhile, the label
prober in each group explores document sentiment polarity of the target domain
through the sentiment prediction generated by the classifier in the peer group,
and guides the learning of the feature extractor in its own group. The proposed
approach achieves the mutual learning of the two groups in an end-to-end
manner. Experiments on multiple public datasets indicate our method obtains the
state-of-the-art performance, validating the effectiveness of mutual learning
through label probers.
</summary>
    <author>
      <name>Qianming Xue</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Hongyuan Zha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to appear in AAAI'20</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00037v1</id>
    <updated>2020-01-31T19:48:58Z</updated>
    <published>2020-01-31T19:48:58Z</published>
    <title>Unsupervised Bilingual Lexicon Induction Across Writing Systems</title>
    <summary>  Recent embedding-based methods in unsupervised bilingual lexicon induction
have shown good results, but generally have not leveraged orthographic
(spelling) information, which can be helpful for pairs of related languages.
This work augments a state-of-the-art method with orthographic features, and
extends prior work in this space by proposing methods that can learn and
utilize orthographic correspondences even between languages with different
scripts. We demonstrate this by experimenting on three language pairs with
different scripts and varying degrees of lexical similarity.
</summary>
    <author>
      <name>Parker Riley</name>
    </author>
    <author>
      <name>Daniel Gildea</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11985v1</id>
    <updated>2020-01-31T18:14:17Z</updated>
    <published>2020-01-31T18:14:17Z</published>
    <title>Pretrained Transformers for Simple Question Answering over Knowledge
  Graphs</title>
    <summary>  Answering simple questions over knowledge graphs is a well-studied problem in
question answering. Previous approaches for this task built on recurrent and
convolutional neural network based architectures that use pretrained word
embeddings. It was recently shown that finetuning pretrained transformer
networks (e.g. BERT) can outperform previous approaches on various natural
language processing tasks. In this work, we investigate how well BERT performs
on SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based
models in datasparse scenarios.
</summary>
    <author>
      <name>D. Lukovnikov</name>
    </author>
    <author>
      <name>A. Fischer</name>
    </author>
    <author>
      <name>J. Lehmann</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11899v1</id>
    <updated>2020-01-31T15:25:56Z</updated>
    <published>2020-01-31T15:25:56Z</published>
    <title>An efficient automated data analytics approach to large scale
  computational comparative linguistics</title>
    <summary>  This research project aimed to overcome the challenge of analysing human
language relationships, facilitate the grouping of languages and formation of
genealogical relationship between them by developing automated comparison
techniques. Techniques were based on the phonetic representation of certain key
words and concept. Example word sets included numbers 1-10 (curated), large
database of numbers 1-10 and sheep counting numbers 1-10 (other sources),
colours (curated), basic words (curated).
  To enable comparison within the sets the measure of Edit distance was
calculated based on Levenshtein distance metric. This metric between two
strings is the minimum number of single-character edits, operations including:
insertions, deletions or substitutions. To explore which words exhibit more or
less variation, which words are more preserved and examine how languages could
be grouped based on linguistic distances within sets, several data analytics
techniques were involved. Those included density evaluation, hierarchical
clustering, silhouette, mean, standard deviation and Bhattacharya coefficient
calculations. These techniques lead to the development of a workflow which was
later implemented by combining Unix shell scripts, a developed R package and
SWI Prolog. This proved to be computationally efficient and permitted the fast
exploration of large language sets and their analysis.
</summary>
    <author>
      <name>Gabija Mikulyte</name>
    </author>
    <author>
      <name>David Gilbert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, 30 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11857v1</id>
    <updated>2020-01-31T14:08:15Z</updated>
    <published>2020-01-31T14:08:15Z</published>
    <title>Hybrid Tiled Convolutional Neural Networks for Text Sentiment
  Classification</title>
    <summary>  The tiled convolutional neural network (tiled CNN) has been applied only to
computer vision for learning invariances. We adjust its architecture to NLP to
improve the extraction of the most salient features for sentiment analysis.
Knowing that the major drawback of the tiled CNN in the NLP field is its
inflexible filter structure, we propose a novel architecture called hybrid
tiled CNN that applies a filter only on the words that appear in the similar
contexts and on their neighbor words (a necessary step for preventing the loss
of some n-grams). The experiments on the datasets of IMDB movie reviews and
SemEval 2017 demonstrate the efficiency of the hybrid tiled CNN that performs
better than both CNN and tiled CNN.
</summary>
    <author>
      <name>Maria Mihaela Trusca</name>
    </author>
    <author>
      <name>Gerasimos Spanakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, accepted for publication in the 12th
  International Conference on Agents and Artificial Intelligence (ICAART 2020),
  Malta, 22-24 February 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00754v1</id>
    <updated>2020-01-31T11:54:46Z</updated>
    <published>2020-01-31T11:54:46Z</published>
    <title>Benchmarking Popular Classification Models' Robustness to Random and
  Targeted Corruptions</title>
    <summary>  Text classification models, especially neural networks based models, have
reached very high accuracy on many popular benchmark datasets. Yet, such models
when deployed in real world applications, tend to perform badly. The primary
reason is that these models are not tested against sufficient real world
natural data. Based on the application users, the vocabulary and the style of
the model's input may greatly vary. This emphasizes the need for a model
agnostic test dataset, which consists of various corruptions that are natural
to appear in the wild. Models trained and tested on such benchmark datasets,
will be more robust against real world data. However, such data sets are not
easily available. In this work, we address this problem, by extending the
benchmark datasets along naturally occurring corruptions such as Spelling
Errors, Text Noise and Synonyms and making them publicly available. Through
extensive experiments, we compare random and targeted corruption strategies
using Local Interpretable Model-Agnostic Explanations(LIME). We report the
vulnerabilities in two popular text classification models along these
corruptions and also find that targeted corruptions can expose vulnerabilities
of a model better than random choices in most cases.
</summary>
    <author>
      <name>Utkarsh Desai</name>
    </author>
    <author>
      <name>Srikanth Tamilselvam</name>
    </author>
    <author>
      <name>Jassimran Kaur</name>
    </author>
    <author>
      <name>Senthil Mani</name>
    </author>
    <author>
      <name>Shreya Khare</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11770v1</id>
    <updated>2020-01-31T11:04:52Z</updated>
    <published>2020-01-31T11:04:52Z</published>
    <title>Break It Down: A Question Understanding Benchmark</title>
    <summary>  Understanding natural language questions entails the ability to break down a
question into the requisite steps for computing its answer. In this work, we
introduce a Question Decomposition Meaning Representation (QDMR) for questions.
QDMR constitutes the ordered list of steps, expressed through natural language,
that are necessary for answering a question. We develop a crowdsourcing
pipeline, showing that quality QDMRs can be annotated at scale, and release the
Break dataset, containing over 83K pairs of questions and their QDMRs. We
demonstrate the utility of QDMR by showing that (a) it can be used to improve
open-domain question answering on the HotpotQA dataset, (b) it can be
deterministically converted to a pseudo-SQL formal language, which can
alleviate annotation in semantic parsing applications. Last, we use Break to
train a sequence-to-sequence model with copying that parses questions into QDMR
structures, and show that it substantially outperforms several natural
baselines.
</summary>
    <author>
      <name>Tomer Wolfson</name>
    </author>
    <author>
      <name>Mor Geva</name>
    </author>
    <author>
      <name>Ankit Gupta</name>
    </author>
    <author>
      <name>Matt Gardner</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <author>
      <name>Daniel Deutch</name>
    </author>
    <author>
      <name>Jonathan Berant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Transactions of the Association for
  Computational Linguistics (TACL), 2020. Author's final version</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00757v1</id>
    <updated>2020-01-31T09:37:00Z</updated>
    <published>2020-01-31T09:37:00Z</published>
    <title>Similarità per la ricerca del dominio di una frase</title>
    <summary>  English. This document aims to study the best algorithms to verify the
belonging of a specific document to a related domain by comparing different
methods for calculating the distance between two vectors. This study has been
made possible with the help of the structures made available by the Apache
Spark framework. Starting from the study illustrated in the publication "New
frontier of textual classification: Big data and distributed calculus" by
Massimiliano Morrelli et al., We wanted to carry out a study on the possible
implementation of a solution capable of calculating the Similarity of a
sentence using the distributed environment.
  Italiano. Il presente documento persegue l'obiettivo di studiare gli
algoritmi migliori per verificare l'appartenenza di un determinato documento a
un relativo dominio tramite un confronto di diversi metodi per il calcolo della
distanza fra due vettori. Tale studio \`e stato condotto con l'ausilio delle
strutture messe a disposizione dal framework Apache Spark. Partendo dallo
studio illustrato nella pubblicazione "Nuova frontiera della classificazione
testuale: Big data e calcolo distribuito" di Massimiliano Morrelli et al., si
\`e voluto realizzare uno studio sulla possibile implementazione di una
soluzione in grado di calcolare la Similarit\`a di una frase sfruttando
l'ambiente distribuito.
</summary>
    <author>
      <name>Massimiliano Morrelli</name>
    </author>
    <author>
      <name>Giacomo Pansini</name>
    </author>
    <author>
      <name>Massimiliano Polito</name>
    </author>
    <author>
      <name>Arturo Vitale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Italian</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00759v1</id>
    <updated>2020-01-31T09:28:57Z</updated>
    <published>2020-01-31T09:28:57Z</published>
    <title>Comparison Between Traditional Machine Learning Models And Neural
  Network Models For Vietnamese Hate Speech Detection</title>
    <summary>  Hate-speech detection on social network language has become one of the main
researching fields recently due to the spreading of social networks like
Facebook and Twitter. In Vietnam, the threat of offensive and harassment cause
bad impacts for online user. The VLSP - Shared task about Hate Speech Detection
on social networks showed many proposed approaches for detecting whatever
comment is clean or not. However, this problem still needs further researching.
Consequently, we compare traditional machine learning and deep learning on a
large dataset about the user's comments on social network in Vietnamese and
find out what is the advantage and disadvantage of each model by comparing
their accuracy on F1-score, then we pick two models in which has highest
accuracy in traditional machine learning models and deep neural models
respectively. Next, we compare these two models capable of predicting the right
label by referencing their confusion matrices and considering the advantages
and disadvantages of each model. Finally, from the comparison result, we
propose our ensemble method that concentrates the abilities of traditional
methods and deep learning methods.
</summary>
    <author>
      <name>Son T. Luu</name>
    </author>
    <author>
      <name>Hung P. Nguyen</name>
    </author>
    <author>
      <name>Kiet Van Nguyen</name>
    </author>
    <author>
      <name>Ngan Luu-Thuy Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IEEE RIVF 2020 Confererence</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11701v1</id>
    <updated>2020-01-31T08:28:07Z</updated>
    <published>2020-01-31T08:28:07Z</published>
    <title>Teaching Machines to Converse</title>
    <summary>  The ability of a machine to communicate with humans has long been associated
with the general success of AI. This dates back to Alan Turing's epoch-making
work in the early 1950s, which proposes that a machine's intelligence can be
tested by how well it, the machine, can fool a human into believing that the
machine is a human through dialogue conversations. Many systems learn
generation rules from a minimal set of authored rules or labels on top of
hand-coded rules or templates, and thus are both expensive and difficult to
extend to open-domain scenarios. Recently, the emergence of neural network
models the potential to solve many of the problems in dialogue learning that
earlier systems cannot tackle: the end-to-end neural frameworks offer the
promise of scalability and language-independence, together with the ability to
track the dialogue state and then mapping between states and dialogue actions
in a way not possible with conventional systems. On the other hand, neural
systems bring about new challenges: they tend to output dull and generic
responses; they lack a consistent or a coherent persona; they are usually
optimized through single-turn conversations and are incapable of handling the
long-term success of a conversation; and they are not able to take the
advantage of the interactions with humans. This dissertation attempts to tackle
these challenges: Contributions are two-fold: (1) we address new challenges
presented by neural network models in open-domain dialogue generation systems;
(2) we develop interactive question-answering dialogue systems by (a) giving
the agent the ability to ask questions and (b) training a conversation agent
through interactions with humans in an online fashion, where a bot improves
through communicating with humans and learning from the mistakes that it makes.
</summary>
    <author>
      <name>Jiwei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">phd thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11694v2</id>
    <updated>2020-02-12T14:28:41Z</updated>
    <published>2020-01-31T07:55:39Z</published>
    <title>Pseudo-Bidirectional Decoding for Local Sequence Transduction</title>
    <summary>  Local sequence transduction (LST) tasks are sequence transduction tasks where
there exists massive overlapping between the source and target sequences, such
as Grammatical Error Correction (GEC) and spell or OCR correction. Previous
work generally tackles LST tasks with standard sequence-to-sequence (seq2seq)
models that generate output tokens from left to right and suffer from the issue
of unbalanced outputs. Motivated by the characteristic of LST tasks, in this
paper, we propose a simple but versatile approach named Pseudo-Bidirectional
Decoding (PBD) for LST tasks. PBD copies the corresponding representation of
source tokens to the decoder as pseudo future context to enable the decoder to
attends to its bi-directional context. In addition, the bidirectional decoding
scheme and the characteristic of LST tasks motivate us to share the encoder and
the decoder of seq2seq models. The proposed PBD approach provides right side
context information for the decoder and models the inductive bias of LST tasks,
reducing the number of parameters by half and providing good regularization
effects. Experimental results on several benchmark datasets show that our
approach consistently improves the performance of standard seq2seq models on
LST tasks.
</summary>
    <author>
      <name>Wangchunshu Zhou</name>
    </author>
    <author>
      <name>Tao Ge</name>
    </author>
    <author>
      <name>Ke Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11694v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11694v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11691v2</id>
    <updated>2020-02-12T09:18:24Z</updated>
    <published>2020-01-31T07:50:25Z</published>
    <title>Self-Adversarial Learning with Comparative Discrimination for Text
  Generation</title>
    <summary>  Conventional Generative Adversarial Networks (GANs) for text generation tend
to have issues of reward sparsity and mode collapse that affect the quality and
diversity of generated samples. To address the issues, we propose a novel
self-adversarial learning (SAL) paradigm for improving GANs' performance in
text generation. In contrast to standard GANs that use a binary classifier as
its discriminator to predict whether a sample is real or generated, SAL employs
a comparative discriminator which is a pairwise classifier for comparing the
text quality between a pair of samples. During training, SAL rewards the
generator when its currently generated sentence is found to be better than its
previously generated samples. This self-improvement reward mechanism allows the
model to receive credits more easily and avoid collapsing towards the limited
number of real samples, which not only helps alleviate the reward sparsity
issue but also reduces the risk of mode collapse. Experiments on text
generation benchmark datasets show that our proposed approach substantially
improves both the quality and the diversity, and yields more stable performance
compared to the previous GANs for text generation.
</summary>
    <author>
      <name>Wangchunshu Zhou</name>
    </author>
    <author>
      <name>Tao Ge</name>
    </author>
    <author>
      <name>Ke Xu</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11691v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11691v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00760v1</id>
    <updated>2020-01-31T07:39:45Z</updated>
    <published>2020-01-31T07:39:45Z</published>
    <title>FastWordBug: A Fast Method To Generate Adversarial Text Against NLP
  Applications</title>
    <summary>  In this paper, we present a novel algorithm, FastWordBug, to efficiently
generate small text perturbations in a black-box setting that forces a
sentiment analysis or text classification mode to make an incorrect prediction.
By combining the part of speech attributes of words, we propose a scoring
method that can quickly identify important words that affect text
classification. We evaluate FastWordBug on three real-world text datasets and
two state-of-the-art machine learning models under black-box setting. The
results show that our method can significantly reduce the accuracy of the
model, and at the same time, we can call the model as little as possible, with
the highest attack efficiency. We also attack two popular real-world cloud
services of NLP, and the results show that our method works as well.
</summary>
    <author>
      <name>Dou Goodman</name>
    </author>
    <author>
      <name>Lv Zhonghou</name>
    </author>
    <author>
      <name>Wang minghua</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11673v1</id>
    <updated>2020-01-31T06:31:39Z</updated>
    <published>2020-01-31T06:31:39Z</published>
    <title>Augmenting Visual Question Answering with Semantic Frame Information in
  a Multitask Learning Approach</title>
    <summary>  Visual Question Answering (VQA) concerns providing answers to Natural
Language questions about images. Several deep neural network approaches have
been proposed to model the task in an end-to-end fashion. Whereas the task is
grounded in visual processing, if the question focuses on events described by
verbs, the language understanding component becomes crucial. Our hypothesis is
that models should be aware of verb semantics, as expressed via semantic role
labels, argument types, and/or frame elements. Unfortunately, no VQA dataset
exists that includes verb semantic information. Our first contribution is a new
VQA dataset (imSituVQA) that we built by taking advantage of the imSitu
annotations. The imSitu dataset consists of images manually labeled with
semantic frame elements, mostly taken from FrameNet. Second, we propose a
multitask CNN-LSTM VQA model that learns to classify the answers as well as the
semantic frame elements. Our experiments show that semantic frame element
classification helps the VQA system avoid inconsistent responses and improves
performance.
</summary>
    <author>
      <name>Mehrdad Alizadeh</name>
    </author>
    <author>
      <name>Barbara Di Eugenio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14th IEEE International Conference on SEMANTIC COMPUTING, 8 Pages,
  February 2020, San Diego CA USA</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00761v1</id>
    <updated>2020-01-31T05:14:16Z</updated>
    <published>2020-01-31T05:14:16Z</published>
    <title>Massively Multilingual Document Alignment with Cross-lingual
  Sentence-Mover's Distance</title>
    <summary>  Cross-lingual document alignment aims to identify pairs of documents in two
distinct languages that are of comparable content or translations of each
other. Such aligned data can be used for a variety of NLP tasks from training
cross-lingual representations to mining parallel bitexts for machine
translation training. In this paper we develop an unsupervised scoring function
that leverages cross-lingual sentence embeddings to compute the semantic
distance between documents in different languages. These semantic distances are
then used to guide a document alignment algorithm to properly pair
cross-lingual web documents across a variety of low, mid, and high-resource
language pairs. Recognizing that our proposed scoring function and other state
of the art methods are computationally intractable for long web documents, we
utilize a more tractable greedy algorithm that performs comparably. We
experimentally demonstrate that our distance metric performs better alignment
than current baselines outperforming them by 7% on high-resource language
pairs, 15% on mid-resource language pairs, and 22% on low-resource language
pairs
</summary>
    <author>
      <name>Ahmed El-Kishky</name>
    </author>
    <author>
      <name>Francisco Guzmán</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00763v1</id>
    <updated>2020-01-31T02:28:35Z</updated>
    <published>2020-01-31T02:28:35Z</published>
    <title>Two-path Deep Semi-supervised Learning for Timely Fake News Detection</title>
    <summary>  News in social media such as Twitter has been generated in high volume and
speed. However, very few of them are labeled (as fake or true news) by
professionals in near real time. In order to achieve timely detection of fake
news in social media, a novel framework of two-path deep semi-supervised
learning is proposed where one path is for supervised learning and the other is
for unsupervised learning. The supervised learning path learns on the limited
amount of labeled data while the unsupervised learning path is able to learn on
a huge amount of unlabeled data. Furthermore, these two paths implemented with
convolutional neural networks (CNN) are jointly optimized to complete
semi-supervised learning. In addition, we build a shared CNN to extract the low
level features on both labeled data and unlabeled data to feed them into these
two paths. To verify this framework, we implement a Word CNN based
semi-supervised learning model and test it on two datasets, namely, LIAR and
PHEME. Experimental results demonstrate that the model built on the proposed
framework can recognize fake news effectively with very few labeled data.
</summary>
    <author>
      <name>Xishuang Dong</name>
    </author>
    <author>
      <name>Uboho Victor</name>
    </author>
    <author>
      <name>Lijun Qian</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11631v1</id>
    <updated>2020-01-31T02:12:05Z</updated>
    <published>2020-01-31T02:12:05Z</published>
    <title>Enhancement of Short Text Clustering by Iterative Classification</title>
    <summary>  Short text clustering is a challenging task due to the lack of signal
contained in such short texts. In this work, we propose iterative
classification as a method to b o ost the clustering quality (e.g., accuracy)
of short texts. Given a clustering of short texts obtained using an arbitrary
clustering algorithm, iterative classification applies outlier removal to
obtain outlier-free clusters. Then it trains a classification algorithm using
the non-outliers based on their cluster distributions. Using the trained
classification model, iterative classification reclassifies the outliers to
obtain a new set of clusters. By repeating this several times, we obtain a much
improved clustering of texts. Our experimental results show that the proposed
clustering enhancement method not only improves the clustering quality of
different clustering methods (e.g., k-means, k-means--, and hierarchical
clustering) but also outperforms the state-of-the-art short text clustering
methods on several short text datasets by a statistically significant margin.
</summary>
    <author>
      <name>Md Rashadul Hasan Rakib</name>
    </author>
    <author>
      <name>Norbert Zeh</name>
    </author>
    <author>
      <name>Magdalena Jankowska</name>
    </author>
    <author>
      <name>Evangelos Milios</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00735v1</id>
    <updated>2020-01-30T21:51:58Z</updated>
    <published>2020-01-30T21:51:58Z</published>
    <title>Self-attention-based BiGRU and capsule network for named entity
  recognition</title>
    <summary>  Named entity recognition(NER) is one of the tasks of natural language
processing(NLP). In view of the problem that the traditional character
representation ability is weak and the neural network method is unable to
capture the important sequence information. An self-attention-based
bidirectional gated recurrent unit(BiGRU) and capsule network(CapsNet) for NER
is proposed. This model generates character vectors through bidirectional
encoder representation of transformers(BERT) pre-trained model. BiGRU is used
to capture sequence context features, and self-attention mechanism is proposed
to give different focus on the information captured by hidden layer of BiGRU.
Finally, we propose to use CapsNet for entity recognition. We evaluated the
recognition performance of the model on two datasets. Experimental results show
that the model has better performance without relying on external dictionary
information.
</summary>
    <author>
      <name>Jianfeng Deng</name>
    </author>
    <author>
      <name>Lianglun Cheng</name>
    </author>
    <author>
      <name>Zhuowei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11479v1</id>
    <updated>2020-01-30T17:57:56Z</updated>
    <published>2020-01-30T17:57:56Z</published>
    <title>Brand Intelligence Analytics</title>
    <summary>  Leveraging the power of big data represents an opportunity for brand managers
to reveal patterns and trends in consumer perceptions, while monitoring
positive or negative associations of the brand with desired topics. This paper
describes the functionalities of the SBS Brand Intelligence App (SBS BI), which
has been designed to assess brand importance and provide brand analytics
through the analysis of (big) textual data. To better describe the SBS BI's
functionalities, we present a case study focused on the 2020 US Democratic
Presidential Primaries. We downloaded 50,000 online articles from the Event
Registry database, which contains both mainstream and blog news collected from
around the world. These online news articles were transformed into networks of
co-occurring words and analyzed by combining methods and tools from social
network analysis and text mining.
</summary>
    <author>
      <name>A. Fronzetti Colladon</name>
    </author>
    <author>
      <name>F. Grippa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in press</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11458v1</id>
    <updated>2020-01-30T17:11:00Z</updated>
    <published>2020-01-30T17:11:00Z</published>
    <title>Don't Parse, Generate! A Sequence to Sequence Architecture for
  Task-Oriented Semantic Parsing</title>
    <summary>  Virtual assistants such as Amazon Alexa, Apple Siri, and Google Assistant
often rely on a semantic parsing component to understand which action(s) to
execute for an utterance spoken by its users. Traditionally, rule-based or
statistical slot-filling systems have been used to parse "simple" queries; that
is, queries that contain a single action and can be decomposed into a set of
non-overlapping entities. More recently, shift-reduce parsers have been
proposed to process more complex utterances. These methods, while powerful,
impose specific limitations on the type of queries that can be parsed; namely,
they require a query to be representable as a parse tree.
  In this work, we propose a unified architecture based on Sequence to Sequence
models and Pointer Generator Network to handle both simple and complex queries.
Unlike other works, our approach does not impose any restriction on the
semantic parse schema. Furthermore, experiments show that it achieves state of
the art performance on three publicly available datasets (ATIS, SNIPS, Facebook
TOP), relatively improving between 3.3% and 7.7% in exact match accuracy over
previous systems. Finally, we show the effectiveness of our approach on two
internal datasets.
</summary>
    <author>
      <name>Subendhu Rongali</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Massachusetts Amherst</arxiv:affiliation>
    </author>
    <author>
      <name>Luca Soldaini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amazon Alexa Search</arxiv:affiliation>
    </author>
    <author>
      <name>Emilio Monti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amazon Alexa</arxiv:affiliation>
    </author>
    <author>
      <name>Wael Hamza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amazon Alexa AI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380064</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380064" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in The Web Conference (WWW 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11453v1</id>
    <updated>2020-01-30T16:58:56Z</updated>
    <published>2020-01-30T16:58:56Z</published>
    <title>Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages</title>
    <summary>  Most combinations of NLP tasks and language varieties lack in-domain examples
for supervised training because of the paucity of annotated data. How can
neural models make sample-efficient generalizations from task-language
combinations with available data to low-resource ones? In this work, we propose
a Bayesian generative model for the space of neural parameters. We assume that
this space can be factorized into latent variables for each language and each
task. We infer the posteriors over such latent variables based on data from
seen task-language combinations through variational inference. This enables
zero-shot classification on unseen combinations at prediction time. For
instance, given training data for named entity recognition (NER) in Vietnamese
and for part-of-speech (POS) tagging in Wolof, our model can perform accurate
predictions for NER in Wolof. In particular, we experiment with a typologically
diverse sample of 33 languages from 4 continents and 11 families, and show that
our model yields comparable or better results than state-of-the-art, zero-shot
cross-lingual transfer methods; it increases performance by 4.49 points for POS
tagging and 7.73 points for NER on average compared to the strongest baseline.
</summary>
    <author>
      <name>Edoardo M. Ponti</name>
    </author>
    <author>
      <name>Ivan Vulić</name>
    </author>
    <author>
      <name>Ryan Cotterell</name>
    </author>
    <author>
      <name>Marinela Parovic</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <author>
      <name>Anna Korhonen</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11316v2</id>
    <updated>2020-01-31T12:33:57Z</updated>
    <published>2020-01-30T13:53:58Z</published>
    <title>Adversarial Training for Aspect-Based Sentiment Analysis with BERT</title>
    <summary>  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of
sentiments and their targets. Collecting labeled data for this task in order to
help neural networks generalize better can be laborious and time-consuming. As
an alternative, similar data to the real-world examples can be produced
artificially through an adversarial process which is carried out in the
embedding space. Although these examples are not real sentences, they have been
shown to act as a regularization method which can make neural networks more
robust. In this work, we apply adversarial training, which was put forward by
Goodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model
proposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and
Aspect Sentiment Classification in sentiment analysis. After improving the
results of post-trained BERT by an ablation study, we propose a novel
architecture called BERT Adversarial Training (BAT) to utilize adversarial
training in ABSA. The proposed model outperforms post-trained BERT in both
tasks. To the best of our knowledge, this is the first study on the application
of adversarial training in ABSA.
</summary>
    <author>
      <name>Akbar Karimi</name>
    </author>
    <author>
      <name>Leonardo Rossi</name>
    </author>
    <author>
      <name>Andrea Prati</name>
    </author>
    <author>
      <name>Katharina Full</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11316v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11316v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11285v1</id>
    <updated>2020-01-30T12:47:50Z</updated>
    <published>2020-01-30T12:47:50Z</published>
    <title>LowResourceEval-2019: a shared task on morphological analysis for
  low-resource languages</title>
    <summary>  The paper describes the results of the first shared task on morphological
analysis for the languages of Russia, namely, Evenki, Karelian, Selkup, and
Veps. For the languages in question, only small-sized corpora are available.
The tasks include morphological analysis, word form generation and morpheme
segmentation. Four teams participated in the shared task. Most of them use
machine-learning approaches, outperforming the existing rule-based ones. The
article describes the datasets prepared for the shared tasks and contains
analysis of the participants' solutions. Language corpora having different
formats were transformed into CONLL-U format. The universal format makes the
datasets comparable to other language corpura and facilitates using them in
other NLP tasks.
</summary>
    <author>
      <name>Elena Klyachko</name>
    </author>
    <author>
      <name>Alexey Sorokin</name>
    </author>
    <author>
      <name>Natalia Krizhanovskaya</name>
    </author>
    <author>
      <name>Andrew Krizhanovsky</name>
    </author>
    <author>
      <name>Galina Ryazanskaya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 tables, 2 figures, published in the conference proceeding</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dialog 2019, Issue 18, Supplementary volume, Pp. 45-62</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.11285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11268v1</id>
    <updated>2020-01-30T11:45:59Z</updated>
    <published>2020-01-30T11:45:59Z</published>
    <title>Data Mining in Clinical Trial Text: Transformers for Classification and
  Question Answering Tasks</title>
    <summary>  This research on data extraction methods applies recent advances in natural
language processing to evidence synthesis based on medical texts. Texts of
interest include abstracts of clinical trials in English and in multilingual
contexts. The main focus is on information characterized via the Population,
Intervention, Comparator, and Outcome (PICO) framework, but data extraction is
not limited to these fields. Recent neural network architectures based on
transformers show capacities for transfer learning and increased performance on
downstream natural language processing tasks such as universal reading
comprehension, brought forward by this architecture's use of contextualized
word embeddings and self-attention mechanisms. This paper contributes to
solving problems related to ambiguity in PICO sentence prediction tasks, as
well as highlighting how annotations for training named entity recognition
systems are used to train a high-performing, but nevertheless flexible
architecture for question answering in systematic review automation.
Additionally, it demonstrates how the problem of insufficient amounts of
training annotations for PICO entity extraction is tackled by augmentation. All
models in this paper were created with the aim to support systematic review
(semi)automation. They achieve high F1 scores, and demonstrate the feasibility
of applying transformer-based classification methods to support data mining in
the biomedical literature.
</summary>
    <author>
      <name>Lena Schmidt</name>
    </author>
    <author>
      <name>Julie Weeds</name>
    </author>
    <author>
      <name>Julian P. T. Higgins</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">HEALTHINF 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.11268v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11268v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11258v1</id>
    <updated>2020-01-30T11:25:06Z</updated>
    <published>2020-01-30T11:25:06Z</published>
    <title>Harnessing Code Switching to Transcend the Linguistic Barrier</title>
    <summary>  Code mixing (or code switching) is a common phenomenon observed in
social-media content generated by a linguistically diverse user-base. Studies
show that in the Indian sub-continent, a substantial fraction of social media
posts exhibit code switching. While the difficulties posed by code mixed
documents to further downstream analyses are well-understood, lending
visibility to code mixed documents under certain scenarios may have utility
that has been previously overlooked. For instance, a document written in a
mixture of multiple languages can be partially accessible to a wider audience;
this could be particularly useful if a considerable fraction of the audience
lacks fluency in one of the component languages. In this paper, we provide a
systematic approach to sample code mixed documents leveraging a polyglot
embedding based method that requires minimal supervision. In the context of the
2019 India-Pakistan conflict triggered by the Pulwama terror attack, we
demonstrate an untapped potential of harnessing code mixing for human
well-being: starting from an existing hostility diffusing \emph{hope speech}
classifier solely trained on English documents, code mixed documents are
utilized as a bridge to retrieve \emph{hope speech} content written in a
low-resource but widely used language - Romanized Hindi. Our proposed pipeline
requires minimal supervision and holds promise in substantially reducing web
moderation efforts.
</summary>
    <author>
      <name>Ashiqur R. KhudaBukhsh</name>
    </author>
    <author>
      <name>Shriphani Palakodety</name>
    </author>
    <author>
      <name>Jaime G. Carbonell</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00737v1</id>
    <updated>2020-01-30T11:06:49Z</updated>
    <published>2020-01-30T11:06:49Z</published>
    <title>Are Pre-trained Language Models Aware of Phrases? Simple but Strong
  Baselines for Grammar Induction</title>
    <summary>  With the recent success and popularity of pre-trained language models (LMs)
in natural language processing, there has been a rise in efforts to understand
their inner workings. In line with such interest, we propose a novel method
that assists us in investigating the extent to which pre-trained LMs capture
the syntactic notion of constituency. Our method provides an effective way of
extracting constituency trees from the pre-trained LMs without training. In
addition, we report intriguing findings in the induced trees, including the
fact that pre-trained LMs outperform other approaches in correctly demarcating
adverb phrases in sentences.
</summary>
    <author>
      <name>Taeuk Kim</name>
    </author>
    <author>
      <name>Jihun Choi</name>
    </author>
    <author>
      <name>Daniel Edmiston</name>
    </author>
    <author>
      <name>Sang-goo Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11224v1</id>
    <updated>2020-01-30T09:17:32Z</updated>
    <published>2020-01-30T09:17:32Z</published>
    <title>Introducing the diagrammatic mode</title>
    <summary>  In this article, we propose a multimodal perspective to diagrammatic
representations by sketching a description of what may be tentatively termed
the diagrammatic mode. We consider diagrammatic representations in the light of
contemporary multimodality theory and explicate what enables diagrammatic
representations to integrate natural language, various forms of graphics,
diagrammatic elements such as arrows, lines and other expressive resources into
coherent organisations. We illustrate the proposed approach using two recent
diagram corpora and show how a multimodal approach supports the empirical
analysis of diagrammatic representations, especially in identifying
diagrammatic constituents and describing their interrelations.
</summary>
    <author>
      <name>Tuomo Hiippala</name>
    </author>
    <author>
      <name>John A. Bateman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages; submitted to Diagrams 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00738v1</id>
    <updated>2020-01-30T06:54:39Z</updated>
    <published>2020-01-30T06:54:39Z</published>
    <title>An Efficient Architecture for Predicting the Case of Characters using
  Sequence Models</title>
    <summary>  The dearth of clean textual data often acts as a bottleneck in several
natural language processing applications. The data available often lacks proper
case (uppercase or lowercase) information. This often comes up when text is
obtained from social media, messaging applications and other online platforms.
This paper attempts to solve this problem by restoring the correct case of
characters, commonly known as Truecasing. Doing so improves the accuracy of
several processing tasks further down in the NLP pipeline. Our proposed
architecture uses a combination of convolutional neural networks (CNN),
bi-directional long short-term memory networks (LSTM) and conditional random
fields (CRF), which work at a character level without any explicit feature
engineering. In this study we compare our approach to previous statistical and
deep learning based approaches. Our method shows an increment of 0.83 in F1
score over the current state of the art. Since truecasing acts as a
preprocessing step in several applications, every increment in the F1 score
leads to a significant improvement in the language processing tasks.
</summary>
    <author>
      <name>Gopi Ramena</name>
    </author>
    <author>
      <name>Divija Nagaraju</name>
    </author>
    <author>
      <name>Sukumar Moharana</name>
    </author>
    <author>
      <name>Debi Prasanna Mohanty</name>
    </author>
    <author>
      <name>Naresh Purre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in IEEE ICSC 2020 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11164v2</id>
    <updated>2020-02-26T12:18:32Z</updated>
    <published>2020-01-30T03:35:44Z</published>
    <title>Do We Need Word Order Information for Cross-lingual Sequence Labeling</title>
    <summary>  Most of the recent work in cross-lingual adaptation does not consider the
word order variances in different languages. We hypothesize that cross-lingual
models that fit into the source language word order might fail to handle target
languages whose word orders are different. To test our conjecture, we build an
order-agnostic model for cross-lingual sequence labeling tasks. Our model does
not encode the word order information of the input sequences, and the
predictions for each token are based on the attention on the whole sequence.
Experimental results on dialogue natural language understanding, part-of-speech
tagging, and named entity recognition tasks show that getting rid of word order
information is able to achieve better zero-shot cross-lingual performance than
baseline models.
</summary>
    <author>
      <name>Zihan Liu</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">will rewrite this paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11164v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11164v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11136v1</id>
    <updated>2020-01-30T00:09:53Z</updated>
    <published>2020-01-30T00:09:53Z</published>
    <title>Lost in Embedding Space: Explaining Cross-Lingual Task Performance with
  Eigenvalue Divergence</title>
    <summary>  Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of
languages at hand: e.g., previous work has suggested there is a connection
between the expected success of bilingual lexicon induction (BLI) and the
assumption of (approximate) isomorphism between monolingual embedding spaces.
In this work, we present a large-scale study focused on the correlations
between language similarity and task performance, covering thousands of
language pairs and four different tasks: BLI, machine translation, parsing, and
POS tagging. We propose a novel language distance measure, Eigenvalue
Divergence (EVD), which quantifies the degree of isomorphism between two
monolingual spaces. We empirically show that 1) language similarity scores
derived from embedding-based EVD distances are strongly associated with
performance observed in different cross-lingual tasks, 2) EVD outperforms other
standard embedding-based language distance measures across the board, at the
same time being computationally more tractable and easier to interpret.
Finally, we demonstrate that EVD captures information which is complementary to
typologically driven language distance measures. We report that their
combination yields even higher correlations with performance levels in all
cross-lingual tasks.
</summary>
    <author>
      <name>Haim Dubossarsky</name>
    </author>
    <author>
      <name>Ivan Vulić</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <author>
      <name>Anna Korhonen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11128v1</id>
    <updated>2020-01-29T23:24:56Z</updated>
    <published>2020-01-29T23:24:56Z</published>
    <title>Learning Robust and Multilingual Speech Representations</title>
    <summary>  Unsupervised speech representation learning has shown remarkable success at
finding representations that correlate with phonetic structures and improve
downstream speech recognition performance. However, most research has been
focused on evaluating the representations in terms of their ability to improve
the performance of speech recognition systems on read English (e.g. Wall Street
Journal and LibriSpeech). This evaluation methodology overlooks two important
desiderata that speech representations should have: robustness to domain shifts
and transferability to other languages. In this paper we learn representations
from up to 8000 hours of diverse and noisy speech data and evaluate the
representations by looking at their robustness to domain shifts and their
ability to improve recognition performance in many languages. We find that our
representations confer significant robustness advantages to the resulting
recognition systems: we see significant improvements in out-of-domain transfer
relative to baseline feature sets and the features likewise provide
improvements in 25 phonetically diverse languages including tonal languages and
low-resource languages.
</summary>
    <author>
      <name>Kazuya Kawakami</name>
    </author>
    <author>
      <name>Luyu Wang</name>
    </author>
    <author>
      <name>Chris Dyer</name>
    </author>
    <author>
      <name>Phil Blunsom</name>
    </author>
    <author>
      <name>Aaron van den Oord</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11121v1</id>
    <updated>2020-01-29T22:44:05Z</updated>
    <published>2020-01-29T22:44:05Z</published>
    <title>ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional
  GANs</title>
    <summary>  A number of cross-lingual transfer learning approaches based on neural
networks have been proposed for the case when large amounts of parallel text
are at our disposal. However, in many real-world settings, the size of parallel
annotated training data is restricted. Additionally, prior cross-lingual
mapping research has mainly focused on the word level. This raises the question
of whether such techniques can also be applied to effortlessly obtain
cross-lingually aligned sentence representations. To this end, we propose an
Adversarial Bi-directional Sentence Embedding Mapping (ABSent) framework, which
learns mappings of cross-lingual sentence representations from limited
quantities of parallel data.
</summary>
    <author>
      <name>Zuohui Fu</name>
    </author>
    <author>
      <name>Yikun Xian</name>
    </author>
    <author>
      <name>Shijie Geng</name>
    </author>
    <author>
      <name>Yingqiang Ge</name>
    </author>
    <author>
      <name>Yuting Wang</name>
    </author>
    <author>
      <name>Xin Dong</name>
    </author>
    <author>
      <name>Guang Wang</name>
    </author>
    <author>
      <name>Gerard de Melo</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00741v1</id>
    <updated>2020-01-29T20:27:42Z</updated>
    <published>2020-01-29T20:27:42Z</published>
    <title>Déjà vu: A Contextualized Temporal Attention Mechanism for
  Sequential Recommendation</title>
    <summary>  Predicting users' preferences based on their sequential behaviors in history
is challenging and crucial for modern recommender systems. Most existing
sequential recommendation algorithms focus on transitional structure among the
sequential actions, but largely ignore the temporal and context information,
when modeling the influence of a historical event to current prediction.
  In this paper, we argue that the influence from the past events on a user's
current action should vary over the course of time and under different context.
Thus, we propose a Contextualized Temporal Attention Mechanism that learns to
weigh historical actions' influence on not only what action it is, but also
when and how the action took place. More specifically, to dynamically calibrate
the relative input dependence from the self-attention mechanism, we deploy
multiple parameterized kernel functions to learn various temporal dynamics, and
then use the context information to determine which of these reweighing kernels
to follow for each input. In empirical evaluations on two large public
recommendation datasets, our model consistently outperformed an extensive set
of state-of-the-art sequential recommendation methods.
</summary>
    <author>
      <name>Jibang Wu</name>
    </author>
    <author>
      <name>Renqin Cai</name>
    </author>
    <author>
      <name>Hongning Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Sequential Recommendation, Self-attention mechanism,
  Temporal Recommendation</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11003v1</id>
    <updated>2020-01-29T18:24:14Z</updated>
    <published>2020-01-29T18:24:14Z</published>
    <title>Modeling Global and Local Node Contexts for Text Generation from
  Knowledge Graphs</title>
    <summary>  Recent graph-to-text models generate text from graph-based data using either
global or local aggregation to learn node representations. Global node encoding
allows explicit communication between two distant nodes, thereby neglecting
graph topology as all nodes are connected. In contrast, local node encoding
considers the relations between directly connected nodes capturing the graph
structure, but it can fail to capture long-range relations. In this work, we
gather the best of both encoding strategies, proposing novel models that encode
an input graph combining both global and local node contexts. Our approaches
are able to learn better contextualized node embeddings for text generation. In
our experiments, we demonstrate that our models lead to significant
improvements in KG-to-text generation, achieving BLEU scores of 17.81 on AGENDA
dataset, and 63.10 on the WebNLG dataset for seen categories, outperforming the
state of the art by 3.51 and 2.51 points, respectively.
</summary>
    <author>
      <name>Leonardo F. R. Ribeiro</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Claire Gardent</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10929v1</id>
    <updated>2020-01-29T16:19:44Z</updated>
    <published>2020-01-29T16:19:44Z</published>
    <title>AMR Similarity Metrics from Principles</title>
    <summary>  Different metrics have been proposed to compare Abstract Meaning
Representation (AMR) graphs. The canonical Smatch metric (Cai and Knight, 2013)
aligns variables from one graph to another and compares the matching triples.
The recently released SemBleu metric (Song and Gildea, 2019) is based on the
machine-translation metric Bleu (Papineni et al., 2002), increasing
computational efficiency by ablating a variable-alignment step and aiming at
capturing more global graph properties.
  Our aims are threefold: i) we establish criteria that allow us to perform a
principled comparison between metrics of symbolic meaning representations like
AMR; ii) we undertake a thorough analysis of Smatch and SemBleu where we show
that the latter exhibits some undesirable properties. E.g., it violates the
identity of indiscernibles rule and introduces biases that are hard to control;
iii) we propose a novel metric S2match that is more benevolent to only very
slight meaning deviations and targets the fulfilment of all established
criteria. We assess its suitability and show its advantages over Smatch and
SemBleu.
</summary>
    <author>
      <name>Juri Opitz</name>
    </author>
    <author>
      <name>Letitia Parcalabescu</name>
    </author>
    <author>
      <name>Anette Frank</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 10 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10667v1</id>
    <updated>2020-01-29T02:37:11Z</updated>
    <published>2020-01-29T02:37:11Z</published>
    <title>Interpretable Rumor Detection in Microblogs by Attending to User
  Interactions</title>
    <summary>  We address rumor detection by learning to differentiate between the
community's response to real and fake claims in microblogs. Existing
state-of-the-art models are based on tree models that model conversational
trees. However, in social media, a user posting a reply might be replying to
the entire thread rather than to a specific user. We propose a post-level
attention model (PLAN) to model long distance interactions between tweets with
the multi-head attention mechanism in a transformer network. We investigated
variants of this model: (1) a structure aware self-attention model (StA-PLAN)
that incorporates tree structure information in the transformer network, and
(2) a hierarchical token and post-level attention model (StA-HiTPLAN) that
learns a sentence representation with token-level self-attention. To the best
of our knowledge, we are the first to evaluate our models on two rumor
detection data sets: the PHEME data set as well as the Twitter15 and Twitter16
data sets. We show that our best models outperform current state-of-the-art
models for both data sets. Moreover, the attention mechanism allows us to
explain rumor detection predictions at both token-level and post-level.
</summary>
    <author>
      <name>Ling Min Serena Khoo</name>
    </author>
    <author>
      <name>Hai Leong Chieu</name>
    </author>
    <author>
      <name>Zhong Qian</name>
    </author>
    <author>
      <name>Jing Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, AAAI 2020 Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00750v1</id>
    <updated>2020-01-28T22:09:25Z</updated>
    <published>2020-01-28T22:09:25Z</published>
    <title>Joint Contextual Modeling for ASR Correction and Language Understanding</title>
    <summary>  The quality of automatic speech recognition (ASR) is critical to Dialogue
Systems as ASR errors propagate to and directly impact downstream tasks such as
language understanding (LU). In this paper, we propose multi-task neural
approaches to perform contextual language correction on ASR outputs jointly
with LU to improve the performance of both tasks simultaneously. To measure the
effectiveness of this approach we used a public benchmark, the 2nd Dialogue
State Tracking (DSTC2) corpus. As a baseline approach, we trained task-specific
Statistical Language Models (SLM) and fine-tuned state-of-the-art Generalized
Pre-training (GPT) Language Model to re-rank the n-best ASR hypotheses,
followed by a model to identify the dialog act and slots. i) We further trained
ranker models using GPT and Hierarchical CNN-RNN models with discriminatory
losses to detect the best output given n-best hypotheses. We extended these
ranker models to first select the best ASR output and then identify the
dialogue act and slots in an end to end fashion. ii) We also proposed a novel
joint ASR error correction and LU model, a word confusion pointer network
(WCN-Ptr) with multi-head self-attention on top, which consumes the word
confusions populated from the n-best. We show that the error rates of off the
shelf ASR and following LU systems can be reduced significantly by 14% relative
with joint models trained using small amounts of in-domain data.
</summary>
    <author>
      <name>Yue Weng</name>
    </author>
    <author>
      <name>Sai Sumanth Miryala</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Runze Wang</name>
    </author>
    <author>
      <name>Huaixiu Zheng</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Alexandros Papangelis</name>
    </author>
    <author>
      <name>Hugh Williams</name>
    </author>
    <author>
      <name>Franziska Bell</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at IEEE ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00743v1</id>
    <updated>2020-01-28T19:22:07Z</updated>
    <published>2020-01-28T19:22:07Z</published>
    <title>Unsupervised Multilingual Alignment using Wasserstein Barycenter</title>
    <summary>  We study unsupervised multilingual alignment, the problem of finding
word-to-word translations between multiple languages without using any parallel
data. One popular strategy is to reduce multilingual alignment to the much
simplified bilingual setting, by picking one of the input languages as the
pivot language that we transit through. However, it is well-known that
transiting through a poorly chosen pivot language (such as English) may
severely degrade the translation quality, since the assumed transitive
relations among all pairs of languages may not be enforced in the training
process. Instead of going through a rather arbitrarily chosen pivot language,
we propose to use the Wasserstein barycenter as a more informative ''mean''
language: it encapsulates information from all languages and minimizes all
pairwise transportation costs. We evaluate our method on standard benchmarks
and demonstrate state-of-the-art performances.
</summary>
    <author>
      <name>Xin Lian</name>
    </author>
    <author>
      <name>Kshitij Jain</name>
    </author>
    <author>
      <name>Jakub Truszkowski</name>
    </author>
    <author>
      <name>Pascal Poupart</name>
    </author>
    <author>
      <name>Yaoliang Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress; comments welcome!</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10468v1</id>
    <updated>2020-01-28T17:15:02Z</updated>
    <published>2020-01-28T17:15:02Z</published>
    <title>Incorporating Joint Embeddings into Goal-Oriented Dialogues with
  Multi-Task Learning</title>
    <summary>  Attention-based encoder-decoder neural network models have recently shown
promising results in goal-oriented dialogue systems. However, these models
struggle to reason over and incorporate state-full knowledge while preserving
their end-to-end text generation functionality. Since such models can greatly
benefit from user intent and knowledge graph integration, in this paper we
propose an RNN-based end-to-end encoder-decoder architecture which is trained
with joint embeddings of the knowledge graph and the corpus as input. The model
provides an additional integration of user intent along with text generation,
trained with a multi-task learning paradigm along with an additional
regularization technique to penalize generating the wrong entity as output. The
model further incorporates a Knowledge Graph entity lookup during inference to
guarantee the generated output is state-full based on the local knowledge graph
provided. We finally evaluated the model using the BLEU score, empirical
evaluation depicts that our proposed architecture can aid in the betterment of
task-oriented dialogue system`s performance.
</summary>
    <author>
      <name>Firas Kassawat</name>
    </author>
    <author>
      <name>Debanjan Chaudhuri</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-21348-0_15</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-21348-0_15" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The Semantic Web - 16th International Conference, ESWC 2019,
  Portoro\v{z}, Slovenia, June 2-6, 2019, Proceedings, page 225-239</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00744v1</id>
    <updated>2020-01-28T16:42:40Z</updated>
    <published>2020-01-28T16:42:40Z</published>
    <title>PEL-BERT: A Joint Model for Protocol Entity Linking</title>
    <summary>  Pre-trained models such as BERT are widely used in NLP tasks and are
fine-tuned to improve the performance of various NLP tasks consistently.
Nevertheless, the fine-tuned BERT model trained on our protocol corpus still
has a weak performance on the Entity Linking (EL) task. In this paper, we
propose a model that joints a fine-tuned language model with an RFC Domain
Model. Firstly, we design a Protocol Knowledge Base as the guideline for
protocol EL. Secondly, we propose a novel model, PEL-BERT, to link named
entities in protocols to categories in Protocol Knowledge Base. Finally, we
conduct a comprehensive study on the performance of pre-trained language models
on descriptive texts and abstract concepts. Experimental results demonstrate
that our model achieves state-of-the-art performance in EL on our annotated
dataset, outperforming all the baselines.
</summary>
    <author>
      <name>Shoubin Li</name>
    </author>
    <author>
      <name>Wenzao Cui</name>
    </author>
    <author>
      <name>Yujiang Liu</name>
    </author>
    <author>
      <name>Xuran Ming</name>
    </author>
    <author>
      <name>Jun Hu</name>
    </author>
    <author>
      <name> YuanzheHu</name>
    </author>
    <author>
      <name>Qing Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00745v1</id>
    <updated>2020-01-28T09:07:47Z</updated>
    <published>2020-01-28T09:07:47Z</published>
    <title>Structural-Aware Sentence Similarity with Recursive Optimal Transport</title>
    <summary>  Measuring sentence similarity is a classic topic in natural language
processing. Light-weighted similarities are still of particular practical
significance even when deep learning models have succeeded in many other tasks.
Some light-weighted similarities with more theoretical insights have been
demonstrated to be even stronger than supervised deep learning approaches.
However, the successful light-weighted models such as Word Mover's Distance
[Kusner et al., 2015] or Smooth Inverse Frequency [Arora et al., 2017] failed
to detect the difference from the structure of sentences, i.e. order of words.
To address this issue, we present Recursive Optimal Transport (ROT) framework
to incorporate the structural information with the classic OT. Moreover, we
further develop Recursive Optimal Similarity (ROTS) for sentences with the
valuable semantic insights from the connections between cosine similarity of
weighted average of word vectors and optimal transport. ROTS is
structural-aware and with low time complexity compared to optimal transport.
Our experiments over 20 sentence textural similarity (STS) datasets show the
clear advantage of ROTS over all weakly supervised approaches. Detailed
ablation study demonstrate the effectiveness of ROT and the semantic insights.
</summary>
    <author>
      <name>Zihao Wang</name>
    </author>
    <author>
      <name>Yong Zhang</name>
    </author>
    <author>
      <name>Hao Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10179v1</id>
    <updated>2020-01-28T05:45:03Z</updated>
    <published>2020-01-28T05:45:03Z</published>
    <title>Multi-modal Sentiment Analysis using Super Characters Method on
  Low-power CNN Accelerator Device</title>
    <summary>  Recent years NLP research has witnessed the record-breaking accuracy
improvement by DNN models. However, power consumption is one of the practical
concerns for deploying NLP systems. Most of the current state-of-the-art
algorithms are implemented on GPUs, which is not power-efficient and the
deployment cost is also very high. On the other hand, CNN Domain Specific
Accelerator (CNN-DSA) has been in mass production providing low-power and low
cost computation power. In this paper, we will implement the Super Characters
method on the CNN-DSA. In addition, we modify the Super Characters method to
utilize the multi-modal data, i.e. text plus tabular data in the CL-Aff
sharedtask.
</summary>
    <author>
      <name>Baohua Sun</name>
    </author>
    <author>
      <name>Lin Yang</name>
    </author>
    <author>
      <name>Hao Sha</name>
    </author>
    <author>
      <name>Michael Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures, 6 tables. Accepted by AAAI 2020 Affective Content
  Analysis Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10175v1</id>
    <updated>2020-01-28T05:30:53Z</updated>
    <published>2020-01-28T05:30:53Z</published>
    <title>Extraction of Templates from Phrases Using Sequence Binary Decision
  Diagrams</title>
    <summary>  The extraction of templates such as ``regard X as Y'' from a set of related
phrases requires the identification of their internal structures. This paper
presents an unsupervised approach for extracting templates on-the-fly from only
tagged text by using a novel relaxed variant of the Sequence Binary Decision
Diagram (SeqBDD). A SeqBDD can compress a set of sequences into a graphical
structure equivalent to a minimal DFA, but more compact and better suited to
the task of template extraction. The main contribution of this paper is a
relaxed form of the SeqBDD construction algorithm that enables it to form
general representations from a small amount of data. The process of compression
of shared structures in the text during Relaxed SeqBDD construction, naturally
induces the templates we wish to extract. Experiments show that the method is
capable of high-quality extraction on tasks based on verb+preposition templates
from corpora and phrasal templates from short messages from social media.
</summary>
    <author>
      <name>Daiki Hirano</name>
    </author>
    <author>
      <name>Kumiko Tanaka-Ishii</name>
    </author>
    <author>
      <name>Andrew Finch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S1351324918000268</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S1351324918000268" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Natural Language Engineering, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.10175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10169v1</id>
    <updated>2020-01-28T05:03:15Z</updated>
    <published>2020-01-28T05:03:15Z</published>
    <title>A Deep Neural Framework for Contextual Affect Detection</title>
    <summary>  A short and simple text carrying no emotion can represent some strong
emotions when reading along with its context, i.e., the same sentence can
express extreme anger as well as happiness depending on its context. In this
paper, we propose a Contextual Affect Detection (CAD) framework which learns
the inter-dependence of words in a sentence, and at the same time the
inter-dependence of sentences in a dialogue. Our proposed CAD framework is
based on a Gated Recurrent Unit (GRU), which is further assisted by contextual
word embeddings and other diverse hand-crafted feature sets. Evaluation and
analysis suggest that our model outperforms the state-of-the-art methods by
5.49% and 9.14% on Friends and EmotionPush dataset, respectively.
</summary>
    <author>
      <name>Kumar Shikhar Deep</name>
    </author>
    <author>
      <name>Asif Ekbal</name>
    </author>
    <author>
      <name>Pushpak Bhattacharyya</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-36718-3_34</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-36718-3_34" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 tables and 3 figures. Accepted in ICONIP 2019
  (International Conference on Neural Information Processing) Published in
  Lecture Notes in Computer Science, vol 11955. Springer, Cham
  https://link.springer.com/chapter/10.1007/978-3-030-36718-3_34</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNCS 11955 (2019) 398-409</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.10169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10161v1</id>
    <updated>2020-01-28T04:13:05Z</updated>
    <published>2020-01-28T04:13:05Z</published>
    <title>Bringing Stories Alive: Generating Interactive Fiction Worlds</title>
    <summary>  World building forms the foundation of any task that requires narrative
intelligence. In this work, we focus on procedurally generating interactive
fiction worlds---text-based worlds that players "see" and "talk to" using
natural language. Generating these worlds requires referencing everyday and
thematic commonsense priors in addition to being semantically consistent,
interesting, and coherent throughout. Using existing story plots as
inspiration, we present a method that first extracts a partial knowledge graph
encoding basic information regarding world structure such as locations and
objects. This knowledge graph is then automatically completed utilizing
thematic knowledge and used to guide a neural language generation model that
fleshes out the rest of the world. We perform human participant-based
evaluations, testing our neural model's ability to extract and fill-in a
knowledge graph and to generate language conditioned on it against rule-based
and human-made baselines. Our code is available at
https://github.com/rajammanabrolu/WorldGeneration.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Wesley Cheung</name>
    </author>
    <author>
      <name>Dan Tu</name>
    </author>
    <author>
      <name>William Broniec</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00838v1</id>
    <updated>2020-01-28T00:44:59Z</updated>
    <published>2020-01-28T00:44:59Z</published>
    <title>Improving Generalizability of Fake News Detection Methods using
  Propensity Score Matching</title>
    <summary>  Recently, due to the booming influence of online social networks, detecting
fake news is drawing significant attention from both academic communities and
general public. In this paper, we consider the existence of confounding
variables in the features of fake news and use Propensity Score Matching (PSM)
to select generalizable features in order to reduce the effects of the
confounding variables. Experimental results show that the generalizability of
fake news method is significantly better by using PSM than using raw frequency
to select features. We investigate multiple types of fake news methods
(classifiers) such as logistic regression, random forests, and support vector
machines. We have consistent observations of performance improvement.
</summary>
    <author>
      <name>Bo Ni</name>
    </author>
    <author>
      <name>Zhichun Guo</name>
    </author>
    <author>
      <name>Jianing Li</name>
    </author>
    <author>
      <name>Meng Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00838v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00838v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10112v1</id>
    <updated>2020-01-27T22:41:02Z</updated>
    <published>2020-01-27T22:41:02Z</published>
    <title>Leveraging Schema Labels to Enhance Dataset Search</title>
    <summary>  A search engine's ability to retrieve desirable datasets is important for
data sharing and reuse. Existing dataset search engines typically rely on
matching queries to dataset descriptions. However, a user may not have enough
prior knowledge to write a query using terms that match with description
text.We propose a novel schema label generation model which generates possible
schema labels based on dataset table content. We incorporate the generated
schema labels into a mixed ranking model which not only considers the relevance
between the query and dataset metadata but also the similarity between the
query and generated schema labels. To evaluate our method on real-world
datasets, we create a new benchmark specifically for the dataset retrieval
task. Experiments show that our approach can effectively improve the precision
and NDCG scores of the dataset retrieval task compared with baseline methods.
We also test on a collection of Wikipedia tables to show that the features
generated from schema labels can improve the unsupervised and supervised web
table retrieval task as well.
</summary>
    <author>
      <name>Zhiyu Chen</name>
    </author>
    <author>
      <name>Haiyan Jia</name>
    </author>
    <author>
      <name>Jeff Heflin</name>
    </author>
    <author>
      <name>Brian D. Davison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 42nd European Conference on IR Research, ECIR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10106v1</id>
    <updated>2020-01-27T22:34:07Z</updated>
    <published>2020-01-27T22:34:07Z</published>
    <title>Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and
  Co-Expansion</title>
    <summary>  Given a small set of seed entities (e.g., ``USA'', ``Russia''), corpus-based
set expansion is to induce an extensive set of entities which share the same
semantic class (Country in this example) from a given corpus. Set expansion
benefits a wide range of downstream applications in knowledge discovery, such
as web search, taxonomy construction, and query suggestion. Existing
corpus-based set expansion algorithms typically bootstrap the given seeds by
incorporating lexical patterns and distributional similarity. However, due to
no negative sets provided explicitly, these methods suffer from semantic drift
caused by expanding the seed set freely without guidance. We propose a new
framework, Set-CoExpan, that automatically generates auxiliary sets as negative
sets that are closely related to the target set of user's interest, and then
performs multiple sets co-expansion that extracts discriminative features by
comparing target set with auxiliary sets, to form multiple cohesive sets that
are distinctive from one another, thus resolving the semantic drift issue. In
this paper we demonstrate that by generating auxiliary sets, we can guide the
expansion process of target set to avoid touching those ambiguous areas around
the border with auxiliary sets, and we show that Set-CoExpan outperforms strong
baseline methods significantly.
</summary>
    <author>
      <name>Jiaxin Huang</name>
    </author>
    <author>
      <name>Yiqing Xie</name>
    </author>
    <author>
      <name>Yu Meng</name>
    </author>
    <author>
      <name>Jiaming Shen</name>
    </author>
    <author>
      <name>Yunyi Zhang</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380284</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380284" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WWW 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10071v1</id>
    <updated>2020-01-27T20:39:32Z</updated>
    <published>2020-01-27T20:39:32Z</published>
    <title>SemClinBr -- a multi institutional and multi specialty semantically
  annotated corpus for Portuguese clinical NLP tasks</title>
    <summary>  The high volume of research focusing on extracting patient's information from
electronic health records (EHR) has led to an increase in the demand for
annotated corpora, which are a very valuable resource for both the development
and evaluation of natural language processing (NLP) algorithms. The absence of
a multi-purpose clinical corpus outside the scope of the English language,
especially in Brazilian Portuguese, is glaring and severely impacts scientific
progress in the biomedical NLP field. In this study, we developed a
semantically annotated corpus using clinical texts from multiple medical
specialties, document types, and institutions. We present the following: (1) a
survey listing common aspects and lessons learned from previous research, (2) a
fine-grained annotation schema which could be replicated and guide other
annotation initiatives, (3) a web-based annotation tool focusing on an
annotation suggestion feature, and (4) both intrinsic and extrinsic evaluation
of the annotations. The result of this work is the SemClinBr, a corpus that has
1,000 clinical notes, labeled with 65,117 entities and 11,263 relations, and
can support a variety of clinical NLP tasks and boost the EHR's secondary use
for the Portuguese language.
</summary>
    <author>
      <name>Lucas Emanuel Silva e Oliveira</name>
    </author>
    <author>
      <name>Ana Carolina Peters</name>
    </author>
    <author>
      <name>Adalniza Moura Pucca da Silva</name>
    </author>
    <author>
      <name>Caroline P. Gebeluca</name>
    </author>
    <author>
      <name>Yohan Bonescki Gumiel</name>
    </author>
    <author>
      <name>Lilian Mie Mukai Cintho</name>
    </author>
    <author>
      <name>Deborah Ribeiro Carvalho</name>
    </author>
    <author>
      <name>Sadid A. Hasan</name>
    </author>
    <author>
      <name>Claudia Maria Cabral Moro</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09977v3</id>
    <updated>2020-02-27T07:36:47Z</updated>
    <published>2020-01-27T18:53:15Z</published>
    <title>Towards a Human-like Open-Domain Chatbot</title>
    <summary>  We present Meena, a multi-turn open-domain chatbot trained end-to-end on data
mined and filtered from public domain social media conversations. This 2.6B
parameter neural network is simply trained to minimize perplexity of the next
token. We also propose a human evaluation metric called Sensibleness and
Specificity Average (SSA), which captures key elements of a human-like
multi-turn conversation. Our experiments show strong correlation between
perplexity and SSA. The fact that the best perplexity end-to-end trained Meena
scores high on SSA (72% on multi-turn evaluation) suggests that a human-level
SSA of 86% is potentially within reach if we can better optimize perplexity.
Additionally, the full version of Meena (with a filtering mechanism and tuned
decoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots
we evaluated.
</summary>
    <author>
      <name>Daniel Adiwardana</name>
    </author>
    <author>
      <name>Minh-Thang Luong</name>
    </author>
    <author>
      <name>David R. So</name>
    </author>
    <author>
      <name>Jamie Hall</name>
    </author>
    <author>
      <name>Noah Fiedel</name>
    </author>
    <author>
      <name>Romal Thoppilan</name>
    </author>
    <author>
      <name>Zi Yang</name>
    </author>
    <author>
      <name>Apoorv Kulshreshtha</name>
    </author>
    <author>
      <name>Gaurav Nemade</name>
    </author>
    <author>
      <name>Yifeng Lu</name>
    </author>
    <author>
      <name>Quoc V. Le</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09977v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09977v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00747v1</id>
    <updated>2020-01-27T17:10:11Z</updated>
    <published>2020-01-27T17:10:11Z</published>
    <title>Conversations with Documents. An Exploration of Document-Centered
  Assistance</title>
    <summary>  The role of conversational assistants has become more prevalent in helping
people increase their productivity. Document-centered assistance, for example
to help an individual quickly review a document, has seen less significant
progress, even though it has the potential to tremendously increase a user's
productivity. This type of document-centered assistance is the focus of this
paper. Our contributions are three-fold: (1) We first present a survey to
understand the space of document-centered assistance and the capabilities
people expect in this scenario. (2) We investigate the types of queries that
users will pose while seeking assistance with documents, and show that
document-centered questions form the majority of these queries. (3) We present
a set of initial machine learned models that show that (a) we can accurately
detect document-centered questions, and (b) we can build reasonably accurate
models for answering such questions. These positive results are encouraging,
and suggest that even greater results may be attained with continued study of
this interesting and novel problem space. Our findings have implications for
the design of intelligent systems to support task completion via natural
interactions with documents.
</summary>
    <author>
      <name>Maartje ter Hoeve</name>
    </author>
    <author>
      <name>Robert Sim</name>
    </author>
    <author>
      <name>Elnaz Nouri</name>
    </author>
    <author>
      <name>Adam Fourney</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <author>
      <name>Ryen W. White</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3343413.3377971</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3343413.3377971" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as full paper at CHIIR 2020; 9 pages + Appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09907v1</id>
    <updated>2020-01-27T16:51:39Z</updated>
    <published>2020-01-27T16:51:39Z</published>
    <title>PMIndia -- A Collection of Parallel Corpora of Languages of India</title>
    <summary>  Parallel text is required for building high-quality machine translation (MT)
systems, as well as for other multilingual NLP applications. For many South
Asian languages, such data is in short supply. In this paper, we described a
new publicly available corpus (PMIndia) consisting of parallel sentences which
pair 13 major languages of India with English. The corpus includes up to 56000
sentences for each language pair. We explain how the corpus was constructed,
including an assessment of two different automatic sentence alignment methods,
and present some initial NMT results on the corpus.
</summary>
    <author>
      <name>Barry Haddow</name>
    </author>
    <author>
      <name>Faheem Kirefu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09879v1</id>
    <updated>2020-01-27T16:01:10Z</updated>
    <published>2020-01-27T16:01:10Z</published>
    <title>Towards Quantifying the Distance between Opinions</title>
    <summary>  Increasingly, critical decisions in public policy, governance, and business
strategy rely on a deeper understanding of the needs and opinions of
constituent members (e.g. citizens, shareholders). While it has become easier
to collect a large number of opinions on a topic, there is a necessity for
automated tools to help navigate the space of opinions. In such contexts
understanding and quantifying the similarity between opinions is key. We find
that measures based solely on text similarity or on overall sentiment often
fail to effectively capture the distance between opinions. Thus, we propose a
new distance measure for capturing the similarity between opinions that
leverages the nuanced observation -- similar opinions express similar sentiment
polarity on specific relevant entities-of-interest. Specifically, in an
unsupervised setting, our distance measure achieves significantly better
Adjusted Rand Index scores (up to 56x) and Silhouette coefficients (up to 21x)
compared to existing approaches. Similarly, in a supervised setting, our
opinion distance measure achieves considerably better accuracy (up to 20%
increase) compared to extant approaches that rely on text similarity, stance
similarity, and sentiment similarity
</summary>
    <author>
      <name>Saket Gurukar</name>
    </author>
    <author>
      <name>Deepak Ajwani</name>
    </author>
    <author>
      <name>Sourav Dutta</name>
    </author>
    <author>
      <name>Juho Lauri</name>
    </author>
    <author>
      <name>Srinivasan Parthasarathy</name>
    </author>
    <author>
      <name>Alessandra Sala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ICWSM '20</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10617v1</id>
    <updated>2020-01-27T15:59:24Z</updated>
    <published>2020-01-27T15:59:24Z</published>
    <title>Systematic Review of Approaches to Improve Peer Assessment at Scale</title>
    <summary>  Peer Assessment is a task of analysis and commenting on student's writing by
peers, is core of all educational components both in campus and in MOOC's.
However, with the sheer scale of MOOC's &amp; its inherent personalised open ended
learning, automatic grading and tools assisting grading at scale is highly
important. Previously we presented survey on tasks of post classification,
knowledge tracing and ended with brief review on Peer Assessment (PA), with
some initial problems. In this review we shall continue review on PA from
perspective of improving the review process itself. As such rest of this review
focus on three facets of PA namely Auto grading and Peer Assessment Tools (we
shall look only on how peer reviews/auto-grading is carried), strategies to
handle Rogue Reviews, Peer Review Improvement using Natural Language
Processing. The consolidated set of papers and resources so used are released
in https://github.com/manikandan-ravikiran/cs6460-Survey-2.
</summary>
    <author>
      <name>Manikandan Ravikiran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a review assignment, work on progress. Expected to be updated
  regularly</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09876v2</id>
    <updated>2020-01-28T13:40:53Z</updated>
    <published>2020-01-27T15:58:57Z</published>
    <title>The POLAR Framework: Polar Opposites Enable Interpretability of
  Pre-Trained Word Embeddings</title>
    <summary>  We introduce POLAR - a framework that adds interpretability to pre-trained
word embeddings via the adoption of semantic differentials. Semantic
differentials are a psychometric construct for measuring the semantics of a
word by analysing its position on a scale between two polar opposites (e.g.,
cold -- hot, soft -- hard). The core idea of our approach is to transform
existing, pre-trained word embeddings via semantic differentials to a new
"polar" space with interpretable dimensions defined by such polar opposites.
Our framework also allows for selecting the most discriminative dimensions from
a set of polar dimensions provided by an oracle, i.e., an external source. We
demonstrate the effectiveness of our framework by deploying it to various
downstream tasks, in which our interpretable word embeddings achieve a
performance that is comparable to the original word embeddings. We also show
that the interpretable dimensions selected by our framework align with human
judgement. Together, these results demonstrate that interpretability can be
added to word embeddings without compromising performance. Our work is relevant
for researchers and engineers interested in interpreting pre-trained word
embeddings.
</summary>
    <author>
      <name>Binny Mathew</name>
    </author>
    <author>
      <name>Sandipan Sikdar</name>
    </author>
    <author>
      <name>Florian Lemmerich</name>
    </author>
    <author>
      <name>Markus Strohmaier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Web Conference (WWW) 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09876v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09876v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09830v1</id>
    <updated>2020-01-27T14:45:55Z</updated>
    <published>2020-01-27T14:45:55Z</published>
    <title>What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer
  Feedbacks? A Review</title>
    <summary>  Learning Management Systems (LMS) and Educational Data Mining (EDM) are two
important parts of online educational environment with the former being a
centralised web-based information systems where the learning content is managed
and learning activities are organised (Stone and Zheng,2014) and latter
focusing on using data mining techniques for the analysis of data so generated.
As part of this work, we present a literature review of three major tasks of
EDM (See section 2), by identifying shortcomings and existing open problems,
and a Blumenfield chart (See section 3). The consolidated set of papers and
resources so used are released in
https://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics
and review matrix of the survey are as shown in Figure 1 &amp; Table 1
respectively. Acronym expansions are added in the Appendix Section 4.1.
</summary>
    <author>
      <name>Manikandan Ravikiran</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09727v1</id>
    <updated>2020-01-27T12:55:02Z</updated>
    <published>2020-01-27T12:55:02Z</published>
    <title>Scaling Up Online Speech Recognition Using ConvNets</title>
    <summary>  We design an online end-to-end speech recognition system based on Time-Depth
Separable (TDS) convolutions and Connectionist Temporal Classification (CTC).
We improve the core TDS architecture in order to limit the future context and
hence reduce latency while maintaining accuracy. The system has almost three
times the throughput of a well tuned hybrid ASR baseline while also having
lower latency and a better word error rate. Also important to the efficiency of
the recognizer is our highly optimized beam search decoder. To show the impact
of our design choices, we analyze throughput, latency, accuracy, and discuss
how these metrics can be tuned based on the user requirements.
</summary>
    <author>
      <name>Vineel Pratap</name>
    </author>
    <author>
      <name>Qiantong Xu</name>
    </author>
    <author>
      <name>Jacob Kahn</name>
    </author>
    <author>
      <name>Gilad Avidov</name>
    </author>
    <author>
      <name>Tatiana Likhomanenko</name>
    </author>
    <author>
      <name>Awni Hannun</name>
    </author>
    <author>
      <name>Vitaliy Liptchinsky</name>
    </author>
    <author>
      <name>Gabriel Synnaeve</name>
    </author>
    <author>
      <name>Ronan Collobert</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09694v1</id>
    <updated>2020-01-27T11:14:34Z</updated>
    <published>2020-01-27T11:14:34Z</published>
    <title>Retrospective Reader for Machine Reading Comprehension</title>
    <summary>  Machine reading comprehension (MRC) is an AI challenge that requires machine
to determine the correct answers to questions based on a given passage. MRC
systems must not only answer question when necessary but also distinguish when
no answer is available according to the given passage and then tactfully
abstain from answering. When unanswerable questions are involved in the MRC
task, an essential verification module called verifier is especially required
in addition to the encoder, though the latest practice on MRC modeling still
most benefits from adopting well pre-trained language models as the encoder
block by only focusing on the "reading". This paper devotes itself to exploring
better verifier design for the MRC task with unanswerable questions. Inspired
by how humans solve reading comprehension questions, we proposed a
retrospective reader (Retro-Reader) that integrates two stages of reading and
verification strategies: 1) sketchy reading that briefly investigates the
overall interactions of passage and question, and yield an initial judgment; 2)
intensive reading that verifies the answer and gives the final prediction. The
proposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0
and NewsQA, achieving new state-of-the-art results. Significance tests show
that our model is significantly better than the strong ALBERT baseline. A
series of analysis is also conducted to interpret the effectiveness of the
proposed reader.
</summary>
    <author>
      <name>Zhuosheng Zhang</name>
    </author>
    <author>
      <name>Junjie Yang</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00748v2</id>
    <updated>2020-03-05T01:06:21Z</updated>
    <published>2020-01-27T05:27:09Z</published>
    <title>Asking Questions the Human Way: Scalable Question-Answer Generation from
  Text Corpus</title>
    <summary>  The ability to ask questions is important in both human and machine
intelligence. Learning to ask questions helps knowledge acquisition, improves
question-answering and machine reading comprehension tasks, and helps a chatbot
to keep the conversation flowing with a human. Existing question generation
models are ineffective at generating a large amount of high-quality
question-answer pairs from unstructured text, since given an answer and an
input passage, question generation is inherently a one-to-many mapping. In this
paper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), which
aims at automatically generating high-quality and diverse question-answer pairs
from unlabeled text corpus at scale by imitating the way a human asks
questions. Our system consists of: i) an information extractor, which samples
from the text multiple types of assistive information to guide question
generation; ii) neural question generators, which generate diverse and
controllable questions, leveraging the extracted assistive information; and
iii) a neural quality controller, which removes low-quality generated data
based on text entailment. We compare our question generation models with
existing approaches and resort to voluntary human evaluation to assess the
quality of the generated question-answer pairs. The evaluation results suggest
that our system dramatically outperforms state-of-the-art neural question
generation models in terms of the generation quality, while being scalable in
the meantime. With models trained on a relatively smaller amount of data, we
can generate 2.8 million quality-assured question-answer pairs from a million
sentences found in Wikipedia.
</summary>
    <author>
      <name>Bang Liu</name>
    </author>
    <author>
      <name>Haojie Wei</name>
    </author>
    <author>
      <name>Di Niu</name>
    </author>
    <author>
      <name>Haolan Chen</name>
    </author>
    <author>
      <name>Yancheng He</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380270</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380270" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by The Web Conference 2020 (WWW 2020) as full paper (oral
  presentation)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00748v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00748v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09522v1</id>
    <updated>2020-01-26T21:30:21Z</updated>
    <published>2020-01-26T21:30:21Z</published>
    <title>TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced
  Graph Neural Network</title>
    <summary>  Taxonomies consist of machine-interpretable semantics and provide valuable
knowledge for many web applications. For example, online retailers (e.g.,
Amazon and eBay) use taxonomies for product recommendation, and web search
engines (e.g., Google and Bing) leverage taxonomies to enhance query
understanding. Enormous efforts have been made on constructing taxonomies
either manually or semi-automatically. However, with the fast-growing volume of
web content, existing taxonomies will become outdated and fail to capture
emerging knowledge. Therefore, in many applications, dynamic expansions of an
existing taxonomy are in great demand. In this paper, we study how to expand an
existing taxonomy by adding a set of new concepts. We propose a novel
self-supervised framework, named TaxoExpan, which automatically generates a set
of &lt;query concept, anchor concept&gt; pairs from the existing taxonomy as training
data. Using such self-supervision data, TaxoExpan learns a model to predict
whether a query concept is the direct hyponym of an anchor concept. We develop
two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural
network that encodes the local structure of an anchor concept in the existing
taxonomy, and (2) a noise-robust training objective that enables the learned
model to be insensitive to the label noise in the self-supervision data.
Extensive experiments on three large-scale datasets from different domains
demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy
expansion.
</summary>
    <author>
      <name>Jiaming Shen</name>
    </author>
    <author>
      <name>Zhihong Shen</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Chi Wang</name>
    </author>
    <author>
      <name>Kuansan Wang</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380132</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380132" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WWW 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10816v1</id>
    <updated>2020-01-26T21:19:27Z</updated>
    <published>2020-01-26T21:19:27Z</published>
    <title>Multi-task Learning for Speaker Verification and Voice Trigger Detection</title>
    <summary>  Automatic speech transcription and speaker recognition are usually treated as
separate tasks even though they are interdependent. In this study, we
investigate training a single network to perform both tasks jointly. We train
the network in a supervised multi-task learning setup, where the speech
transcription branch of the network is trained to minimise a phonetic
connectionist temporal classification (CTC) loss while the speaker recognition
branch of the network is trained to label the input sequence with the correct
label for the speaker. We present a large-scale empirical study where the model
is trained using several thousand hours of labelled training data for each
task. We evaluate the speech transcription branch of the network on a voice
trigger detection task while the speaker recognition branch is evaluated on a
speaker verification task. Results demonstrate that the network is able to
encode both phonetic \emph{and} speaker information in its learnt
representations while yielding accuracies at least as good as the baseline
models for each task, with the same number of parameters as the independent
models.
</summary>
    <author>
      <name>Siddharth Sigtia</name>
    </author>
    <author>
      <name>Erik Marchi</name>
    </author>
    <author>
      <name>Sachin Kajarekar</name>
    </author>
    <author>
      <name>Devang Naik</name>
    </author>
    <author>
      <name>John Bridle</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09519v1</id>
    <updated>2020-01-26T21:13:07Z</updated>
    <published>2020-01-26T21:13:07Z</published>
    <title>Multi-task Learning for Voice Trigger Detection</title>
    <summary>  We describe the design of a voice trigger detection system for smart
speakers. In this study, we address two major challenges. The first is that the
detectors are deployed in complex acoustic environments with external noise and
loud playback by the device itself. Secondly, collecting training examples for
a specific keyword or trigger phrase is challenging resulting in a scarcity of
trigger phrase specific training data. We describe a two-stage cascaded
architecture where a low-power detector is always running and listening for the
trigger phrase. If a detection is made at this stage, the candidate audio
segment is re-scored by larger, more complex models to verify that the segment
contains the trigger phrase. In this study, we focus our attention on the
architecture and design of these second-pass detectors. We start by training a
general acoustic model that produces phonetic transcriptions given a large
labelled training dataset. Next, we collect a much smaller dataset of examples
that are challenging for the baseline system. We then use multi-task learning
to train a model to simultaneously produce accurate phonetic transcriptions on
the larger dataset \emph{and} discriminate between true and easily confusable
examples using the smaller dataset. Our results demonstrate that the proposed
model reduces errors by half compared to the baseline in a range of challenging
test conditions \emph{without} requiring extra parameters.
</summary>
    <author>
      <name>Siddharth Sigtia</name>
    </author>
    <author>
      <name>Pascal Clark</name>
    </author>
    <author>
      <name>Rob Haynes</name>
    </author>
    <author>
      <name>Hywel Richards</name>
    </author>
    <author>
      <name>John Bridle</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09466v1</id>
    <updated>2020-01-26T15:16:37Z</updated>
    <published>2020-01-26T15:16:37Z</published>
    <title>Unsupervised Extraction of Market Moving Events with Neural Attention</title>
    <summary>  We present a method to identify relevant events associated with stock price
movements without manually labeled data. We train an attention-based neural
network, which given a set of news headlines for a given time frame, predicts
the price movement of a given stock index (i.e., DOWN, STAY, UP). An attention
layer acts as an input selector; it computes a normalized weight for each
headline embedding. The weighted average of the embeddings is used to predict
the price movement. We present an analysis to understand if, after the network
has been trained, the attention layer is capable of generating a global ranking
of news events through its unnormalized weights. The ranking should be able to
rank relevant financial events higher. In this initial study we use news
categories as a proxy for relevance: news belonging to more relevant categories
should be ranked higher. Our experiments on four indices suggest that there is
an indication that the weights indeed skew the global set of events towards
those categories that are more relevant to explain the price change; this
effect reflects the performance of the network on stock prediction.
</summary>
    <author>
      <name>Luciano Del Corro</name>
    </author>
    <author>
      <name>Johannes Hoffart</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09415v3</id>
    <updated>2020-02-08T03:47:36Z</updated>
    <published>2020-01-26T07:35:02Z</published>
    <title>Dual Multi-head Co-attention for Multi-choice Reading Comprehension</title>
    <summary>  Multi-choice Machine Reading Comprehension (MRC) requires model to decide the
correct answer from a set of answer options when given a passage and a
question. Thus in addition to a powerful pre-trained Language Model as encoder,
multi-choice MRC especially relies on a matching network design which is
supposed to effectively capture the relationship among the triplet of passage,
question and answers. While the latest pre-trained Language Models have shown
powerful enough even without the support from a matching network, and the
latest matching network has been complicated enough, we thus propose a novel
going-back-to-the-basic solution which straightforwardly models the MRC
relationship as attention mechanism inside network. The proposed DUal
Multi-head Co-Attention (DUMA) has been shown simple but effective and is
capable of generally promoting pre-trained Language Models. Our proposed method
is evaluated on two benchmark multi-choice MRC tasks, DREAM and RACE, showing
that in terms of strong Language Models, DUMA may still boost the model to
reach new state-of-the-art performance.
</summary>
    <author>
      <name>Pengfei Zhu</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <author>
      <name>Xiaoguang Li</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09415v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09415v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10590v1</id>
    <updated>2020-01-26T05:59:57Z</updated>
    <published>2020-01-26T05:59:57Z</published>
    <title>An Effective Automatic Image Annotation Model Via Attention Model and
  Data Equilibrium</title>
    <summary>  Nowadays, a huge number of images are available. However, retrieving a
required image for an ordinary user is a challenging task in computer vision
systems. During the past two decades, many types of research have been
introduced to improve the performance of the automatic annotation of images,
which are traditionally focused on content-based image retrieval. Although,
recent research demonstrates that there is a semantic gap between content-based
image retrieval and image semantics understandable by humans. As a result,
existing research in this area has caused to bridge the semantic gap between
low-level image features and high-level semantics. The conventional method of
bridging the semantic gap is through the automatic image annotation (AIA) that
extracts semantic features using machine learning techniques. In this paper, we
propose a novel AIA model based on the deep learning feature extraction method.
The proposed model has three phases, including a feature extractor, a tag
generator, and an image annotator. First, the proposed model extracts
automatically the high and low-level features based on dual-tree continues
wavelet transform (DT-CWT), singular value decomposition, distribution of color
ton, and the deep neural network. Moreover, the tag generator balances the
dictionary of the annotated keywords by a new log-entropy auto-encoder (LEAE)
and then describes these keywords by word embedding. Finally, the annotator
works based on the long-short-term memory (LSTM) network in order to obtain the
importance degree of specific features of the image. The experiments conducted
on two benchmark datasets confirm that the superiority of the proposed model
compared to the previous models in terms of performance criteria.
</summary>
    <author>
      <name>Amir Vatani</name>
    </author>
    <author>
      <name>Milad Taleby Ahvanooey</name>
    </author>
    <author>
      <name>Mostafa Rahimi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14569/IJACSA.2018.090338</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14569/IJACSA.2018.090338" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Adv. Comput. Sci. Appl, 9(3), pp.269-277 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.10590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11314v2</id>
    <updated>2020-02-04T06:48:44Z</updated>
    <published>2020-01-26T02:54:49Z</published>
    <title>ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework
  for Natural Language Generation</title>
    <summary>  Current pre-training works in natural language generation pay little
attention to the problem of exposure bias on downstream tasks. To address this
issue, we propose an enhanced multi-flow sequence to sequence pre-training and
fine-tuning framework named ERNIE-GEN, which bridges the discrepancy between
training and inference with an infilling generation mechanism and a noise-aware
generation method. To make generation closer to human writing patterns, this
framework introduces a span-by-span generation flow that trains the model to
predict semantically-complete spans consecutively rather than predicting word
by word. Unlike existing pre-training methods, ERNIE-GEN incorporates
multi-granularity target sampling to construct pre-training data, which
enhances the correlation between encoder and decoder. Experimental results
demonstrate that ERNIE-GEN achieves state-of-the-art results with a much
smaller amount of pre-training data and parameters on a range of language
generation tasks, including abstractive summarization (Gigaword and
CNN/DailyMail), question generation (SQuAD), dialogue generation (Persona-Chat)
and generative question answering (CoQA).
</summary>
    <author>
      <name>Dongling Xiao</name>
    </author>
    <author>
      <name>Han Zhang</name>
    </author>
    <author>
      <name>Yukun Li</name>
    </author>
    <author>
      <name>Yu Sun</name>
    </author>
    <author>
      <name>Hao Tian</name>
    </author>
    <author>
      <name>Hua Wu</name>
    </author>
    <author>
      <name>Haifeng Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, typos corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11314v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11314v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09386v3</id>
    <updated>2020-02-01T21:39:47Z</updated>
    <published>2020-01-26T02:08:22Z</published>
    <title>Generating Representative Headlines for News Stories</title>
    <summary>  Millions of news articles are published online every day, which can be
overwhelming for readers to follow. Grouping articles that are reporting the
same event into news stories is a common way of assisting readers in their news
consumption. However, it remains a challenging research problem to efficiently
and effectively generate a representative headline for each story. Automatic
summarization of a document set has been studied for decades, while few studies
have focused on generating representative headlines for a set of articles.
Unlike summaries, which aim to capture most information with least redundancy,
headlines aim to capture information jointly shared by the story articles in
short length, and exclude information that is too specific to each individual
article. In this work, we study the problem of generating representative
headlines for news stories. We develop a distant supervision approach to train
large-scale generation models without any human annotation. This approach
centers on two technical components. First, we propose a multi-level
pre-training framework that incorporates massive unlabeled corpus with
different quality-vs.-quantity balance at different levels. We show that models
trained within this framework outperform those trained with pure human curated
corpus. Second, we propose a novel self-voting-based article attention layer to
extract salient information shared by multiple articles. We show that models
that incorporate this layer are robust to potential noises in news stories and
outperform existing baselines with or without noises. We can further enhance
our model by incorporating human labels, and we show our distant supervision
approach significantly reduces the demand on labeled data.
</summary>
    <author>
      <name>Xiaotao Gu</name>
    </author>
    <author>
      <name>Yuning Mao</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <author>
      <name>Jialu Liu</name>
    </author>
    <author>
      <name>Hongkun Yu</name>
    </author>
    <author>
      <name>You Wu</name>
    </author>
    <author>
      <name>Cong Yu</name>
    </author>
    <author>
      <name>Daniel Finnie</name>
    </author>
    <author>
      <name>Jiaqi Zhai</name>
    </author>
    <author>
      <name>Nicholas Zukoski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WebConf 2020 (WWW 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09386v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09386v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00730v1</id>
    <updated>2020-01-25T16:40:43Z</updated>
    <published>2020-01-25T16:40:43Z</published>
    <title>Reducing Noise from Competing Neighbours: Word Retrieval with Lateral
  Inhibition in Multilink</title>
    <summary>  Multilink is a computational model for word retrieval in monolingual and
multilingual individuals under different task circumstances (Dijkstra et al.,
2018). In the present study, we added lateral inhibition to Multilink's lexical
network. Parameters were fit on the basis of reaction times from the English,
British, and Dutch Lexicon Projects. We found a maximum correlation of 0.643
(N=1,205) on these data sets as a whole. Furthermore, the simulations
themselves became faster as a result of adding lateral inhibition. We tested
the fitted model to stimuli from a neighbourhood study (Mulder et al., 2018).
Lateral inhibition was found to improve Multilink's correlations for this
study, yielding an overall correlation of 0.67. Next, we explored the role of
lateral inhibition as part of the model's task/decision system by running
simulations on data from two studies concerning interlingual homographs
(Vanlangendonck et al., in press; Goertz, 2018). We found that, while lateral
inhibition plays a substantial part in the word selection process, this alone
is not enough to result in a correct response selection. To solve this problem,
we added a new task component to Multilink, especially designed to account for
the translation process of interlingual homographs, cognates, and
language-specific control words. The subsequent simulation results showed
patterns remarkably similar to those in the Goertz study. The isomorphicity of
the simulated data to the empirical data was further attested by an overall
correlation of 0.538 (N=254) between reaction times and simulated model cycle
times, as well as a condition pattern correlation of 0.853 (N=8). We conclude
that Multilink yields an excellent fit to empirical data, particularly when a
task-specific setting of the inhibition parameters is allowed.
</summary>
    <author>
      <name>Aaron van Geffen</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00720v1</id>
    <updated>2020-01-25T15:52:29Z</updated>
    <published>2020-01-25T15:52:29Z</published>
    <title>Introduction of Quantification in Frame Semantics</title>
    <summary>  Feature Structures (FSs) are a widespread tool used for decompositional
frameworks of Attribute-Value associations. Even though they thrive in simple
systems, they lack a way of representing higher-order entities and relations.
This is however needed in Frame Semantics, where semantic dependencies should
be able to connect groups of individuals and their properties, especially to
model quantification. To answer this issue, this master report introduces
wrappings as a way to envelop a sub-FS and treat it as a node. Following the
work of [Kallmeyer, Osswald 2013], we extend its syntax, semantics and some
properties (translation to FOL, subsumption, unification). We can then expand
the proposed pipeline. Lexical minimal model sets are generated from formulas.
They unify by FS value equations obtained by LTAG parsing to an underspecified
sentence representation. The syntactic approach of quantifiers allows us to use
existing methods to produce any possible reading. Finally, we give a
transcription to type-logical formulas to interact with the context in the view
of dynamic semantics. Supported by ideas of Frame Types, this system provides a
workable and tractable tool for higher-order relations with FS.
</summary>
    <author>
      <name>Valentin D. Richard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master report</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03B65 (Primary) 03C30 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; F.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09332v1</id>
    <updated>2020-01-25T15:12:01Z</updated>
    <published>2020-01-25T15:12:01Z</published>
    <title>An Analysis of Word2Vec for the Italian Language</title>
    <summary>  Word representation is fundamental in NLP tasks, because it is precisely from
the coding of semantic closeness between words that it is possible to think of
teaching a machine to understand text. Despite the spread of word embedding
concepts, still few are the achievements in linguistic contexts other than
English. In this work, analysing the semantic capacity of the Word2Vec
algorithm, an embedding for the Italian language is produced. Parameter setting
such as the number of epochs, the size of the context window and the number of
negatively backpropagated samples is explored.
</summary>
    <author>
      <name>Giovanni Di Gennaro</name>
    </author>
    <author>
      <name>Amedeo Buonanno</name>
    </author>
    <author>
      <name>Antonio Di Girolamo</name>
    </author>
    <author>
      <name>Armando Ospedale</name>
    </author>
    <author>
      <name>Francesco A. N. Palmieri</name>
    </author>
    <author>
      <name>Gianfranco Fedele</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -
  June 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09330v1</id>
    <updated>2020-01-25T15:07:07Z</updated>
    <published>2020-01-25T15:07:07Z</published>
    <title>Intent Classification in Question-Answering Using LSTM Architectures</title>
    <summary>  Question-answering (QA) is certainly the best known and probably also one of
the most complex problem within Natural Language Processing (NLP) and
artificial intelligence (AI). Since the complete solution to the problem of
finding a generic answer still seems far away, the wisest thing to do is to
break down the problem by solving single simpler parts. Assuming a modular
approach to the problem, we confine our research to intent classification for
an answer, given a question. Through the use of an LSTM network, we show how
this type of classification can be approached effectively and efficiently, and
how it can be properly used within a basic prototype responder.
</summary>
    <author>
      <name>Giovanni Di Gennaro</name>
    </author>
    <author>
      <name>Amedeo Buonanno</name>
    </author>
    <author>
      <name>Antonio Di Girolamo</name>
    </author>
    <author>
      <name>Armando Ospedale</name>
    </author>
    <author>
      <name>Francesco A. N. Palmieri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -
  June 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09309v1</id>
    <updated>2020-01-25T13:35:34Z</updated>
    <published>2020-01-25T13:35:34Z</published>
    <title>Further Boosting BERT-based Models by Duplicating Existing Layers: Some
  Intriguing Phenomena inside BERT</title>
    <summary>  Although Bidirectional Encoder Representations from Transformers (BERT) have
achieved tremendous success in many natural language processing (NLP) tasks, it
remains a black box, so much previous work has tried to lift the veil of BERT
and understand the functionality of each layer. In this paper, we found that
removing or duplicating most layers in BERT would not change their outputs.
This fact remains true across a wide variety of BERT-based models. Based on
this observation, we propose a quite simple method to boost the performance of
BERT. By duplicating some layers in the BERT-based models to make it deeper (no
extra training required in this step), they obtain better performance in the
down-stream tasks after fine-tuning.
</summary>
    <author>
      <name>Wei-Tsung Kao</name>
    </author>
    <author>
      <name>Tsung-Han Wu</name>
    </author>
    <author>
      <name>Po-Han Chi</name>
    </author>
    <author>
      <name>Chun-Cheng Hsieh</name>
    </author>
    <author>
      <name>Hung-Yi Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00733v1</id>
    <updated>2020-01-25T08:20:46Z</updated>
    <published>2020-01-25T08:20:46Z</published>
    <title>Generation-Distillation for Efficient Natural Language Understanding in
  Low-Data Settings</title>
    <summary>  Over the past year, the emergence of transfer learning with large-scale
language models (LM) has led to dramatic performance improvements across a
broad range of natural language understanding tasks. However, the size and
memory footprint of these large LMs makes them difficult to deploy in many
scenarios (e.g. on mobile phones). Recent research points to knowledge
distillation as a potential solution, showing that when training data for a
given task is abundant, it is possible to distill a large (teacher) LM into a
small task-specific (student) network with minimal loss of performance.
However, when such data is scarce, there remains a significant performance gap
between large pretrained LMs and smaller task-specific models, even when
training via distillation. In this paper, we bridge this gap with a novel
training approach, called generation-distillation, that leverages large
finetuned LMs in two ways: (1) to generate new (unlabeled) training examples,
and (2) to distill their knowledge into a small network using these examples.
Across three low-resource text classification datsets, we achieve comparable
performance to BERT while using 300x fewer parameters, and we outperform prior
approaches to distillation for text classification while using 3x fewer
parameters.
</summary>
    <author>
      <name>Luke Melas-Kyriazi</name>
    </author>
    <author>
      <name>George Han</name>
    </author>
    <author>
      <name>Celine Liang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 Workshop on Deep Learning for Low-resource NLP</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10822v1</id>
    <updated>2020-01-25T01:34:15Z</updated>
    <published>2020-01-25T01:34:15Z</published>
    <title>Lattice-based Improvements for Voice Triggering Using Graph Neural
  Networks</title>
    <summary>  Voice-triggered smart assistants often rely on detection of a trigger-phrase
before they start listening for the user request. Mitigation of false triggers
is an important aspect of building a privacy-centric non-intrusive smart
assistant. In this paper, we address the task of false trigger mitigation (FTM)
using a novel approach based on analyzing automatic speech recognition (ASR)
lattices using graph neural networks (GNN). The proposed approach uses the fact
that decoding lattice of a falsely triggered audio exhibits uncertainties in
terms of many alternative paths and unexpected words on the lattice arcs as
compared to the lattice of a correctly triggered audio. A pure trigger-phrase
detector model doesn't fully utilize the intent of the user speech whereas by
using the complete decoding lattice of user audio, we can effectively mitigate
speech not intended for the smart assistant. We deploy two variants of GNNs in
this paper based on 1) graph convolution layers and 2) self-attention mechanism
respectively. Our experiments demonstrate that GNNs are highly accurate in FTM
task by mitigating ~87% of false triggers at 99% true positive rate (TPR).
Furthermore, the proposed models are fast to train and efficient in parameter
requirements.
</summary>
    <author>
      <name>Pranay Dighe</name>
    </author>
    <author>
      <name>Saurabh Adya</name>
    </author>
    <author>
      <name>Nuoyu Li</name>
    </author>
    <author>
      <name>Srikanth Vishnubhotla</name>
    </author>
    <author>
      <name>Devang Naik</name>
    </author>
    <author>
      <name>Adithya Sagar</name>
    </author>
    <author>
      <name>Ying Ma</name>
    </author>
    <author>
      <name>Stephen Pulman</name>
    </author>
    <author>
      <name>Jason Williams</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09246v1</id>
    <updated>2020-01-25T01:19:19Z</updated>
    <published>2020-01-25T01:19:19Z</published>
    <title>Learning To Detect Keyword Parts And Whole By Smoothed Max Pooling</title>
    <summary>  We propose smoothed max pooling loss and its application to keyword spotting
systems. The proposed approach jointly trains an encoder (to detect keyword
parts) and a decoder (to detect whole keyword) in a semi-supervised manner. The
proposed new loss function allows training a model to detect parts and whole of
a keyword, without strictly depending on frame-level labeling from LVCSR (Large
vocabulary continuous speech recognition), making further optimization
possible. The proposed system outperforms the baseline keyword spotting model
in [1] due to increased optimizability. Further, it can be more easily adapted
for on-device learning applications due to reduced dependency on LVCSR.
</summary>
    <author>
      <name>Hyun-Jin Park</name>
    </author>
    <author>
      <name>Patrick Violette</name>
    </author>
    <author>
      <name>Niranjan Subrahmanya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in International Conference on Acoustics, Speech, and Signal
  Processing 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09239v1</id>
    <updated>2020-01-25T00:24:45Z</updated>
    <published>2020-01-25T00:24:45Z</published>
    <title>Multi-task self-supervised learning for Robust Speech Recognition</title>
    <summary>  Despite the growing interest in unsupervised learning, extracting meaningful
knowledge from unlabelled audio remains an open challenge. To take a step in
this direction, we recently proposed a problem-agnostic speech encoder (PASE),
that combines a convolutional encoder followed by multiple neural networks,
called workers, tasked to solve self-supervised problems (i.e., ones that do
not require manual annotations as ground truth). PASE was shown to capture
relevant speech information, including speaker voice-print and phonemes. This
paper proposes PASE+, an improved version of PASE for robust speech recognition
in noisy and reverberant environments. To this end, we employ an online speech
distortion module, that contaminates the input signals with a variety of random
disturbances. We then propose a revised encoder that better learns short- and
long-term speech dynamics with an efficient combination of recurrent and
convolutional networks. Finally, we refine the set of workers used in
self-supervision to encourage better cooperation.
  Results on TIMIT, DIRHA and CHiME-5 show that PASE+ significantly outperforms
both the previous version of PASE as well as common acoustic features.
Interestingly, PASE+ learns transferable representations suitable for highly
mismatched acoustic conditions.
</summary>
    <author>
      <name>Mirco Ravanelli</name>
    </author>
    <author>
      <name>Jianyuan Zhong</name>
    </author>
    <author>
      <name>Santiago Pascual</name>
    </author>
    <author>
      <name>Pawel Swietojanski</name>
    </author>
    <author>
      <name>Joao Monteiro</name>
    </author>
    <author>
      <name>Jan Trmal</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09221v1</id>
    <updated>2020-01-24T22:59:46Z</updated>
    <published>2020-01-24T22:59:46Z</published>
    <title>Data Techniques For Online End-to-end Speech Recognition</title>
    <summary>  Practitioners often need to build ASR systems for new use cases in a short
amount of time, given limited in-domain data. While recently developed
end-to-end methods largely simplify the modeling pipelines, they still suffer
from the data sparsity issue. In this work, we explore a few
simple-to-implement techniques for building online ASR systems in an end-to-end
fashion, with a small amount of transcribed data in the target domain. These
techniques include data augmentation in the target domain, domain adaptation
using models previously trained on a large source domain, and knowledge
distillation on non-transcribed target domain data; they are applicable in real
scenarios with different types of resources. Our experiments demonstrate that
each technique is independently useful in the low-resource setting, and
combining them yields significant improvement of the online ASR performance in
the target domain.
</summary>
    <author>
      <name>Yang Chen</name>
    </author>
    <author>
      <name>Weiran Wang</name>
    </author>
    <author>
      <name>I-Fan Chen</name>
    </author>
    <author>
      <name>Chao Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09215v1</id>
    <updated>2020-01-24T22:23:22Z</updated>
    <published>2020-01-24T22:23:22Z</published>
    <title>An Iterative Approach for Identifying Complaint Based Tweets in Social
  Media Platforms</title>
    <summary>  Twitter is a social media platform where users express opinions over a
variety of issues. Posts offering grievances or complaints can be utilized by
private/ public organizations to improve their service and promptly gauge a
low-cost assessment. In this paper, we propose an iterative methodology which
aims to identify complaint based posts pertaining to the transport domain. We
perform comprehensive evaluations along with releasing a novel dataset for the
research purposes.
</summary>
    <author>
      <name>Gyanesh Anand</name>
    </author>
    <author>
      <name>Akash Gautam</name>
    </author>
    <author>
      <name>Puneet Mathur</name>
    </author>
    <author>
      <name>Debanjan Mahata</name>
    </author>
    <author>
      <name>Rajiv Ratn Shah</name>
    </author>
    <author>
      <name>Ramit Sawhney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of paper accepted at AAAI, student abstract 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09128v1</id>
    <updated>2020-01-24T18:22:57Z</updated>
    <published>2020-01-24T18:22:57Z</published>
    <title>Semi-supervised ASR by End-to-end Self-training</title>
    <summary>  While deep learning based end-to-end automatic speech recognition (ASR)
systems have greatly simplified modeling pipelines, they suffer from the data
sparsity issue. In this work, we propose a self-training method with an
end-to-end system for semi-supervised ASR. Starting from a Connectionist
Temporal Classification (CTC) system trained on the supervised data, we
iteratively generate pseudo-labels on a mini-batch of unsupervised utterances
with the current model, and use the pseudo-labels to augment the supervised
data for immediate model update. Our method retains the simplicity of
end-to-end ASR systems, and can be seen as performing alternating optimization
over a well-defined learning objective. We also perform empirical
investigations of our method, regarding the effect of data augmentation,
decoding beamsize for pseudo-label generation, and freshness of pseudo-labels.
On a commonly used semi-supervised ASR setting with the WSJ corpus, our method
gives 14.4% relative WER improvement over a carefully-trained base system with
data augmentation, reducing the performance gap between the base system and the
oracle system by 50%.
</summary>
    <author>
      <name>Yang Chen</name>
    </author>
    <author>
      <name>Weiran Wang</name>
    </author>
    <author>
      <name>Chao Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09099v1</id>
    <updated>2020-01-24T17:09:39Z</updated>
    <published>2020-01-24T17:09:39Z</published>
    <title>TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval</title>
    <summary>  We introduce a new multimodal retrieval task - TV show Retrieval (TVR), in
which a short video moment has to be localized from a large video (with
subtitle) corpus, given a natural language query. Different from previous
moment retrieval tasks dealing with videos only, TVR requires the system to
understand both the video and the associated subtitle text, making it a more
realistic task. To support the study of this new task, we have collected a
large-scale, high-quality dataset consisting of 108,965 queries on 21,793
videos from 6 TV shows of diverse genres, where each query is associated with a
tight temporal alignment. Strict qualification and post-annotation verification
tests are applied to ensure the quality of the collected data. We present
several baselines and a novel Cross-modal Moment Localization (XML) modular
network for this new dataset and task. The proposed XML model surpasses all
presented baselines by a large margin and with better efficiency, providing a
strong starting point for future work. Extensive analysis experiments also show
that incorporating both video and subtitle modules yields better performance
than either alone. Lastly, we have also collected additional descriptions for
each annotated moment in TVR to form a new multimodal captioning dataset with
262K captions, named the TV show Caption dataset (TVC). Here models need to
jointly use the video and subtitle to generate a caption description. Both
datasets are publicly available at https://tvr.cs.unc.edu
</summary>
    <author>
      <name>Jie Lei</name>
    </author>
    <author>
      <name>Licheng Yu</name>
    </author>
    <author>
      <name>Tamara L. Berg</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09063v2</id>
    <updated>2020-02-04T14:18:31Z</updated>
    <published>2020-01-24T15:55:59Z</published>
    <title>Towards Graph Representation Learning in Emergent Communication</title>
    <summary>  Recent findings in neuroscience suggest that the human brain represents
information in a geometric structure (for instance, through conceptual spaces).
In order to communicate, we flatten the complex representation of entities and
their attributes into a single word or a sentence. In this paper we use graph
convolutional networks to support the evolution of language and cooperation in
multi-agent systems. Motivated by an image-based referential game, we propose a
graph referential game with varying degrees of complexity, and we provide
strong baseline models that exhibit desirable properties in terms of language
emergence and cooperation. We show that the emerged communication protocol is
robust, that the agents uncover the true factors of variation in the game, and
that they learn to generalize beyond the samples encountered during training.
</summary>
    <author>
      <name>Agnieszka Słowik</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>William L. Hamilton</name>
    </author>
    <author>
      <name>Mateja Jamnik</name>
    </author>
    <author>
      <name>Sean B. Holden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally. Accepted at the
  Reinforcement Learning in Games workshop at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08950v1</id>
    <updated>2020-01-24T11:36:12Z</updated>
    <published>2020-01-24T11:36:12Z</published>
    <title>PoWER-BERT: Accelerating BERT inference for Classification Tasks</title>
    <summary>  BERT has emerged as a popular model for natural language understanding. Given
its compute intensive nature, even for inference, many recent studies have
considered optimization of two important performance characteristics: model
size and inference time. We consider classification tasks and propose a novel
method, called PoWER-BERT, for improving the inference time for the BERT model
without significant loss in the accuracy. The method works by eliminating
word-vectors (intermediate vector outputs) from the encoder pipeline. We design
a strategy for measuring the significance of the word-vectors based on the
self-attention mechanism of the encoders which helps us identify the
word-vectors to be eliminated. Experimental evaluation on the standard GLUE
benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference time
over BERT with &lt; 1% loss in accuracy. We show that compared to the prior
inference time reduction methods, PoWER-BERT offers better trade-off between
accuracy and inference time. Lastly, we demonstrate that our scheme can also be
used in conjunction with ALBERT (a highly compressed version of BERT) and can
attain up to 6.8x factor reduction in inference time with &lt; 1% loss in
accuracy.
</summary>
    <author>
      <name>Saurabh Goyal</name>
    </author>
    <author>
      <name>Anamitra Roy Choudhary</name>
    </author>
    <author>
      <name>Venkatesan Chakaravarthy</name>
    </author>
    <author>
      <name>Saurabh ManishRaje</name>
    </author>
    <author>
      <name>Yogish Sabharwal</name>
    </author>
    <author>
      <name>Ashish Verma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08904v1</id>
    <updated>2020-01-24T07:16:32Z</updated>
    <published>2020-01-24T07:16:32Z</published>
    <title>MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition
  using Deep Bidirectional Transformers</title>
    <summary>  Conversational agents such as Cortana, Alexa and Siri are continuously
working on increasing their capabilities by adding new domains. The support of
a new domain includes the design and development of a number of NLU components
for domain classification, intents classification and slots tagging (including
named entity recognition). Each component only performs well when trained on a
large amount of labeled data. Second, these components are deployed on
limited-memory devices which requires some model compression. Third, for some
domains such as the health domain, it is hard to find a single training data
set that covers all the required slot types. To overcome these mentioned
problems, we present a multi-task transformer-based neural architecture for
slot tagging. We consider the training of a slot tagger using multiple data
sets covering different slot types as a multi-task learning problem. The
experimental results on the biomedical domain have shown that the proposed
approach outperforms the previous state-of-the-art systems for slot tagging on
the different benchmark biomedical datasets in terms of (time and memory)
efficiency and effectiveness. The output slot tagger can be used by the
conversational agent to better identify entities in the input utterances.
</summary>
    <author>
      <name>Muhammad Raza Khan</name>
    </author>
    <author>
      <name>Morteza Ziyadi</name>
    </author>
    <author>
      <name>Mohamed AbdelHady</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08896v3</id>
    <updated>2020-03-06T15:58:58Z</updated>
    <published>2020-01-24T06:07:21Z</published>
    <title>Compressing Language Models using Doped Kronecker Products</title>
    <summary>  Kronecker Products (KP) have been used to compress IoT RNN Applications by
15-38x compression factors, achieving better results than traditional
compression methods. However when KP is applied to large Natural Language
Processing tasks, it leads to significant accuracy loss (approx 26%). This
paper proposes a way to recover accuracy otherwise lost when applying KP to
large NLP tasks, by allowing additional degrees of freedom in the KP matrix.
More formally, we propose doping, a process of adding an extremely sparse
overlay matrix on top of the pre-defined KP structure. We call this compression
method doped kronecker product compression. To train these models, we present a
new solution to the phenomenon of co-matrix adaption (CMA), which uses a new
regularization scheme called co matrix dropout regularization (CMR). We present
experimental results that demonstrate compression of a large language model
with LSTM layers of size 25 MB by 25x with 1.4% loss in perplexity score. At
25x compression, an equivalent pruned network leads to 7.9% loss in perplexity
score, while HMD and LMF lead to 15% and 27% loss in perplexity score
respectively.
</summary>
    <author>
      <name>Urmish Thakker</name>
    </author>
    <author>
      <name>Paul Whatmough</name>
    </author>
    <author>
      <name>Matthew Mattina</name>
    </author>
    <author>
      <name>Jesse Beu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Link to Workshop -
  https://research.fb.com/programs/on-device-intelligence-workshop/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at On-device Intelligence Workshop at Third Conference
  on Machine Learning and Systems (MLSys) 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.08896v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08896v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08868v1</id>
    <updated>2020-01-24T03:03:51Z</updated>
    <published>2020-01-24T03:03:51Z</published>
    <title>Exploration Based Language Learning for Text-Based Games</title>
    <summary>  This work presents an exploration and imitation-learning-based agent capable
of state-of-the-art performance in playing text-based computer games.
Text-based computer games describe their world to the player through natural
language and expect the player to interact with the game using text. These
games are of interest as they can be seen as a testbed for language
understanding, problem-solving, and language generation by artificial agents.
Moreover, they provide a learning environment in which these skills can be
acquired through interactions with an environment rather than using fixed
corpora. One aspect that makes these games particularly challenging for
learning agents is the combinatorially large action space. Existing methods for
solving text-based games are limited to games that are either very simple or
have an action space restricted to a predetermined set of admissible actions.
In this work, we propose to use the exploration approach of Go-Explore for
solving text-based games. More specifically, in an initial exploration phase,
we first extract trajectories with high rewards, after which we train a policy
to solve the game by imitating these trajectories. Our experiments show that
this approach outperforms existing solutions in solving text-based games, and
it is more sample efficient in terms of the number of interactions with the
environment. Moreover, we show that the learned policy can generalize better
than existing solutions to unseen games without using any restriction on the
action space.
</summary>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Joost Huizinga</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Adrien Ecoffet</name>
    </author>
    <author>
      <name>Huaixiu Zheng</name>
    </author>
    <author>
      <name>Alexandros Papangelis</name>
    </author>
    <author>
      <name>Dian Yu</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under Review</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08845v1</id>
    <updated>2020-01-23T23:08:24Z</updated>
    <published>2020-01-23T23:08:24Z</published>
    <title>Linguistic Fingerprints of Internet Censorship: the Case of SinaWeibo</title>
    <summary>  This paper studies how the linguistic components of blogposts collected from
Sina Weibo, a Chinese microblogging platform, might affect the blogposts'
likelihood of being censored. Our results go along with King et al. (2013)'s
Collective Action Potential (CAP) theory, which states that a blogpost's
potential of causing riot or assembly in real life is the key determinant of it
getting censored. Although there is not a definitive measure of this construct,
the linguistic features that we identify as discriminatory go along with the
CAP theory. We build a classifier that significantly outperforms non-expert
humans in predicting whether a blogpost will be censored. The crowdsourcing
results suggest that while humans tend to see censored blogposts as more
controversial and more likely to trigger action in real life than the
uncensored counterparts, they in general cannot make a better guess than our
model when it comes to `reading the mind' of the censors in deciding whether a
blogpost should be censored. We do not claim that censorship is only determined
by the linguistic features. There are many other factors contributing to
censorship decisions. The focus of the present paper is on the linguistic form
of blogposts. Our work suggests that it is possible to use linguistic
properties of social media posts to automatically predict if they are going to
be censored.
</summary>
    <author>
      <name>Kei Yin Ng</name>
    </author>
    <author>
      <name>Anna Feldman</name>
    </author>
    <author>
      <name>Jing Peng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08837v1</id>
    <updated>2020-01-23T22:33:18Z</updated>
    <published>2020-01-23T22:33:18Z</published>
    <title>Graph Constrained Reinforcement Learning for Natural Language Action
  Spaces</title>
    <summary>  Interactive Fiction games are text-based simulations in which an agent
interacts with the world purely through natural language. They are ideal
environments for studying how to extend reinforcement learning agents to meet
the challenges of natural language understanding, partial observability, and
action generation in combinatorially-large text-based action spaces. We present
KG-A2C, an agent that builds a dynamic knowledge graph while exploring and
generates actions using a template-based action space. We contend that the dual
uses of the knowledge graph to reason about game state and to constrain natural
language generation are the keys to scalable exploration of combinatorially
large natural language actions. Results across a wide variety of IF games show
that KG-A2C outperforms current IF agents despite the exponential increase in
action space size.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Matthew Hausknecht</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08785v1</id>
    <updated>2020-01-23T19:56:35Z</updated>
    <published>2020-01-23T19:56:35Z</published>
    <title>Semi-Autoregressive Training Improves Mask-Predict Decoding</title>
    <summary>  The recently proposed mask-predict decoding algorithm has narrowed the
performance gap between semi-autoregressive machine translation models and the
traditional left-to-right approach. We introduce a new training method for
conditional masked language models, SMART, which mimics the semi-autoregressive
behavior of mask-predict, producing training examples that contain model
predictions as part of their inputs. Models trained with SMART produce
higher-quality translations when using mask-predict decoding, effectively
closing the remaining performance gap with fully autoregressive models.
</summary>
    <author>
      <name>Marjan Ghazvininejad</name>
    </author>
    <author>
      <name>Omer Levy</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10309v1</id>
    <updated>2020-01-23T19:54:19Z</updated>
    <published>2020-01-23T19:54:19Z</published>
    <title>Uncertainty based Class Activation Maps for Visual Question Answering</title>
    <summary>  Understanding and explaining deep learning models is an imperative task.
Towards this, we propose a method that obtains gradient-based certainty
estimates that also provide visual attention maps. Particularly, we solve for
visual question answering task. We incorporate modern probabilistic deep
learning methods that we further improve by using the gradients for these
estimates. These have two-fold benefits: a) improvement in obtaining the
certainty estimates that correlate better with misclassified samples and b)
improved attention maps that provide state-of-the-art results in terms of
correlation with human attention regions. The improved attention maps result in
consistent improvement for various methods for visual question answering.
Therefore, the proposed technique can be thought of as a recipe for obtaining
improved certainty estimates and explanations for deep learning models. We
provide detailed empirical analysis for the visual question answering task on
all standard benchmarks and comparison with state of the art methods.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Mayank Lunayach</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work is an extension of our ICCV-2019 work. arXiv admin note:
  text overlap with arXiv:1908.06306</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08779v1</id>
    <updated>2020-01-23T19:37:20Z</updated>
    <published>2020-01-23T19:37:20Z</published>
    <title>Deep Bayesian Network for Visual Question Generation</title>
    <summary>  Generating natural questions from an image is a semantic task that requires
using vision and language modalities to learn multimodal representations.
Images can have multiple visual and language cues such as places, captions, and
tags. In this paper, we propose a principled deep Bayesian learning framework
that combines these cues to produce natural questions. We observe that with the
addition of more cues and by minimizing uncertainty in the among cues, the
Bayesian network becomes more confident. We propose a Minimizing Uncertainty of
Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues
experts for generating probabilistic questions. This is a Bayesian framework
and the results show a remarkable similarity to natural questions as validated
by a human study. We observe that with the addition of more cues and by
minimizing uncertainty among the cues, the Bayesian framework becomes more
confident. Ablation studies of our model indicate that a subset of cues is
inferior at this task and hence the principled fusion of cues is preferred.
Further, we observe that the proposed approach substantially improves over
state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,
and CIDEr). Here we provide project link for Deep Bayesian VQG
\url{https://delta-lab-iitk.github.io/BVQG/}
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Vinod K. Kurmi</name>
    </author>
    <author>
      <name>Sandeep Kumar</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WACV-2020 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08779v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08779v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08764v1</id>
    <updated>2020-01-23T19:06:18Z</updated>
    <published>2020-01-23T19:06:18Z</published>
    <title>Fine-Tuning a Transformer-Based Language Model to Avoid Generating
  Non-Normative Text</title>
    <summary>  Large-scale, transformer-based language models such as GPT-2 are pretrained
on diverse corpora scraped from the internet. Consequently, they are prone to
generating content that one might find inappropriate or non-normative (i.e. in
violation of social norms). In this paper, we describe a technique for
fine-tuning GPT-2 such that the amount of non-normative content generated is
significantly reduced. A model capable of classifying normative behavior is
used to produce an additional reward signal; a policy gradient reinforcement
learning technique uses that reward to fine-tune the language model weights.
Using this fine-tuning technique, with 24,000 sentences from a science fiction
plot summary dataset, halves the percentage of generated text containing
non-normative behavior from 35.1% to 15.7%.
</summary>
    <author>
      <name>Xiangyu Peng</name>
    </author>
    <author>
      <name>Siyan Li</name>
    </author>
    <author>
      <name>Spencer Frazier</name>
    </author>
    <author>
      <name>Mark Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08730v1</id>
    <updated>2020-01-23T18:43:34Z</updated>
    <published>2020-01-23T18:43:34Z</published>
    <title>Robust Explanations for Visual Question Answering</title>
    <summary>  In this paper, we propose a method to obtain robust explanations for visual
question answering(VQA) that correlate well with the answers. Our model
explains the answers obtained through a VQA model by providing visual and
textual explanations. The main challenges that we address are i) Answers and
textual explanations obtained by current methods are not well correlated and
ii) Current methods for visual explanation do not focus on the right location
for explaining the answer. We address both these challenges by using a
collaborative correlated module which ensures that even if we do not train for
noise based attacks, the enhanced correlation ensures that the right
explanation and answer can be generated. We further show that this also aids in
improving the generated visual and textual explanations. The use of the
correlated module can be thought of as a robust method to verify if the answer
and explanations are coherent. We evaluate this model using VQA-X dataset. We
observe that the proposed method yields better textual and visual justification
that supports the decision. We showcase the robustness of the model against a
noise-based perturbation attack using corresponding visual and textual
explanations. A detailed empirical analysis is shown. Here we provide source
code link for our model \url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Shivansh Pate</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WACV-2020 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08728v1</id>
    <updated>2020-01-23T18:41:21Z</updated>
    <published>2020-01-23T18:41:21Z</published>
    <title>Coordinated Reasoning for Cross-Lingual Knowledge Graph Alignment</title>
    <summary>  Existing entity alignment methods mainly vary on the choices of encoding the
knowledge graph, but they typically use the same decoding method, which
independently chooses the local optimal match for each source entity. This
decoding method may not only cause the "many-to-one" problem but also neglect
the coordinated nature of this task, that is, each alignment decision may
highly correlate to the other decisions. In this paper, we introduce two
coordinated reasoning methods, i.e., the Easy-to-Hard decoding strategy and
joint entity alignment algorithm. Specifically, the Easy-to-Hard strategy first
retrieves the model-confident alignments from the predicted results and then
incorporates them as additional knowledge to resolve the remaining
model-uncertain alignments. To achieve this, we further propose an enhanced
alignment model that is built on the current state-of-the-art baseline. In
addition, to address the many-to-one problem, we propose to jointly predict
entity alignments so that the one-to-one constraint can be naturally
incorporated into the alignment prediction. Experimental results show that our
model achieves the state-of-the-art performance and our reasoning methods can
also significantly improve existing baselines.
</summary>
    <author>
      <name>Kun Xu</name>
    </author>
    <author>
      <name>Linfeng Song</name>
    </author>
    <author>
      <name>Yansong Feng</name>
    </author>
    <author>
      <name>Yan Song</name>
    </author>
    <author>
      <name>Dong Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00725v1</id>
    <updated>2020-01-23T18:23:03Z</updated>
    <published>2020-01-23T18:23:03Z</published>
    <title>Traduction des Grammaires Catégorielles de Lambek dans les Grammaires
  Catégorielles Abstraites</title>
    <summary>  Lambek Grammars (LG) are a computational modelling of natural language, based
on non-commutative compositional types. It has been widely studied, especially
for languages where the syntax plays a major role (like English). The goal of
this internship report is to demonstrate that every Lambek Grammar can be, not
entirely but efficiently, expressed in Abstract Categorial Grammars (ACG). The
latter is a novel modelling based on higher-order signature homomorphisms
(using $\lambda$-calculus), aiming at uniting the currently used models. The
main idea is to transform the type rewriting system of LGs into that of
Context-Free Grammars (CFG) by erasing introduction and elimination rules and
generating enough axioms so that the cut rule suffices. This iterative approach
preserves the derivations and enables us to stop the possible infinite
generative process at any step. Although the underlying algorithm was not fully
implemented, this proof provides another argument in favour of the relevance of
ACGs in Natural Language Processing.
</summary>
    <author>
      <name>Valentin D. Richard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Bachelor internship report, in French</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q42 (Primary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.2; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08700v1</id>
    <updated>2020-01-23T17:47:31Z</updated>
    <published>2020-01-23T17:47:31Z</published>
    <title>EventMapper: Detecting Real-World Physical Events Using Corroborative
  and Probabilistic Sources</title>
    <summary>  The ubiquity of social media makes it a rich source for physical event
detection, such as disasters, and as a potential resource for crisis management
resource allocation. There have been some recent works on leveraging social
media sources for retrospective, after-the-fact event detection of large events
such as earthquakes or hurricanes. Similarly, there is a long history of using
traditional physical sensors such as climate satellites to perform regional
event detection. However, combining social media with corroborative physical
sensors for real-time, accurate, and global physical detection has remained
unexplored.
  This paper presents EventMapper, a framework to support event recognition of
small yet equally costly events (landslides, flooding, wildfires). EventMapper
integrates high-latency, high-accuracy corroborative sources such as physical
sensors with low-latency, noisy probabilistic sources such as social media
streams to deliver real-time, global event recognition. Furthermore,
EventMapper is resilient to the concept drift phenomenon, where machine
learning models require continuous fine-tuning to maintain high performance.
  By exploiting the common features of probabilistic and corroborative sources,
EventMapper automates machine learning model updates, maintenance, and
fine-tuning. We describe three applications built on EventMapper for landslide,
wildfire, and flooding detection.
</summary>
    <author>
      <name>Abhijit Suprem</name>
    </author>
    <author>
      <name>Calton Pu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08665v1</id>
    <updated>2020-01-23T17:04:00Z</updated>
    <published>2020-01-23T17:04:00Z</published>
    <title>Action Recognition and State Change Prediction in a Recipe Understanding
  Task Using a Lightweight Neural Network Model</title>
    <summary>  Consider a natural language sentence describing a specific step in a food
recipe. In such instructions, recognizing actions (such as press, bake, etc.)
and the resulting changes in the state of the ingredients (shape molded,
custard cooked, temperature hot, etc.) is a challenging task. One way to cope
with this challenge is to explicitly model a simulator module that applies
actions to entities and predicts the resulting outcome (Bosselut et al. 2018).
However, such a model can be unnecessarily complex. In this paper, we propose a
simplified neural network model that separates action recognition and state
change prediction, while coupling the two through a novel loss function. This
allows learning to indirectly influence each other. Our model, although
simpler, achieves higher state change prediction performance (67% average
accuracy for ours vs. 55% in (Bosselut et al. 2018)) and takes fewer samples to
train (10K ours vs. 65K+ by (Bosselut et al. 2018)).
</summary>
    <author>
      <name>Qing Wan</name>
    </author>
    <author>
      <name>Yoonsuck Choe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI-2020 Student Abstract and Poster Program (Accept)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08635v1</id>
    <updated>2020-01-23T16:11:44Z</updated>
    <published>2020-01-23T16:11:44Z</published>
    <title>A Study of the Tasks and Models in Machine Reading Comprehension</title>
    <summary>  To provide a survey on the existing tasks and models in Machine Reading
Comprehension (MRC), this report reviews: 1) the dataset collection and
performance evaluation of some representative simple-reasoning and
complex-reasoning MRC tasks; 2) the architecture designs, attention mechanisms,
and performance-boosting approaches for developing neural-network-based MRC
models; 3) some recently proposed transfer learning approaches to incorporating
text-style knowledge contained in external corpora into the neural networks of
MRC models; 4) some recently proposed knowledge base encoding approaches to
incorporating graph-style knowledge contained in external knowledge bases into
the neural networks of MRC models. Besides, according to what has been achieved
and what are still deficient, this report also proposes some open problems for
the future research.
</summary>
    <author>
      <name>Chao Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Qualifying Examination Report</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08604v2</id>
    <updated>2020-02-07T12:15:35Z</updated>
    <published>2020-01-23T15:34:56Z</published>
    <title>Variational Hierarchical Dialog Autoencoder for Dialog State Tracking
  Data Augmentation</title>
    <summary>  Recent works have shown that generative data augmentation, where synthetic
samples generated from deep generative models are used to augment the training
dataset, benefit certain NLP tasks. In this work, we extend this approach to
the task of dialog state tracking for goal-oriented dialogs. Since,
goal-oriented dialogs naturally exhibit a hierarchical structure over
utterances and related annotations, deep generative data augmentation for the
task requires the generative model to be aware of the hierarchical nature. We
propose the Variational Hierarchical Dialog Autoencoder (VHDA) for modeling
complete aspects of goal-oriented dialogs, including linguistic features and
underlying structured annotations, namely dialog acts and goals. We also
propose two training policies to mitigate issues that arise with training
VAE-based models. Experiments show that our hierarchical model is able to
generate realistic and novel samples that improve the robustness of
state-of-the-art dialog state trackers, ultimately improving the dialog state
tracking performances on various dialog domains. Surprisingly, the ability to
jointly generate dialog features enables our model to outperform previous
state-of-the-arts in related subtasks, such as language generation and user
simulation.
</summary>
    <author>
      <name>Kang Min Yoo</name>
    </author>
    <author>
      <name>Hanbit Lee</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Walter Chang</name>
    </author>
    <author>
      <name>Sang-goo Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, 6 tables, preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08378v1</id>
    <updated>2020-01-23T05:36:06Z</updated>
    <published>2020-01-23T05:36:06Z</published>
    <title>Improving speaker discrimination of target speech extraction with
  time-domain SpeakerBeam</title>
    <summary>  Target speech extraction, which extracts a single target source in a mixture
given clues about the target speaker, has attracted increasing attention. We
have recently proposed SpeakerBeam, which exploits an adaptation utterance of
the target speaker to extract his/her voice characteristics that are then used
to guide a neural network towards extracting speech of that speaker.
SpeakerBeam presents a practical alternative to speech separation as it enables
tracking speech of a target speaker across utterances, and achieves promising
speech extraction performance. However, it sometimes fails when speakers have
similar voice characteristics, such as in same-gender mixtures, because it is
difficult to discriminate the target speaker from the interfering speakers. In
this paper, we investigate strategies for improving the speaker discrimination
capability of SpeakerBeam. First, we propose a time-domain implementation of
SpeakerBeam similar to that proposed for a time-domain audio separation network
(TasNet), which has achieved state-of-the-art performance for speech
separation. Besides, we investigate (1) the use of spatial features to better
discriminate speakers when microphone array recordings are available, (2)
adding an auxiliary speaker identification loss for helping to learn more
discriminative voice characteristics. We show experimentally that these
strategies greatly improve speech extraction performance, especially for
same-gender mixtures, and outperform TasNet in terms of target speech
extraction.
</summary>
    <author>
      <name>Marc Delcroix</name>
    </author>
    <author>
      <name>Tsubasa Ochiai</name>
    </author>
    <author>
      <name>Katerina Zmolikova</name>
    </author>
    <author>
      <name>Keisuke Kinoshita</name>
    </author>
    <author>
      <name>Naohiro Tawara</name>
    </author>
    <author>
      <name>Tomohiro Nakatani</name>
    </author>
    <author>
      <name>Shoko Araki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures. Submitted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08353v1</id>
    <updated>2020-01-23T02:47:39Z</updated>
    <published>2020-01-23T02:47:39Z</published>
    <title>Pre-training via Leveraging Assisting Languages and Data Selection for
  Neural Machine Translation</title>
    <summary>  Sequence-to-sequence (S2S) pre-training using large monolingual data is known
to improve performance for various S2S NLP tasks in low-resource settings.
However, large monolingual corpora might not always be available for the
languages of interest (LOI). To this end, we propose to exploit monolingual
corpora of other languages to complement the scarcity of monolingual corpora
for the LOI. A case study of low-resource Japanese-English neural machine
translation (NMT) reveals that leveraging large Chinese and French monolingual
corpora can help overcome the shortage of Japanese and English monolingual
corpora, respectively, for S2S pre-training. We further show how to utilize
script mapping (Chinese to Japanese) to increase the similarity between the two
monolingual corpora leading to further improvements in translation quality.
Additionally, we propose simple data-selection techniques to be used prior to
pre-training that significantly impact the quality of S2S pre-training. An
empirical comparison of our proposed methods reveals that leveraging assisting
language monolingual corpora, data selection and script mapping are extremely
important for NMT pre-training in low-resource scenarios.
</summary>
    <author>
      <name>Haiyue Song</name>
    </author>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Zhuoyuan Mao</name>
    </author>
    <author>
      <name>Fei Cheng</name>
    </author>
    <author>
      <name>Sadao Kurohashi</name>
    </author>
    <author>
      <name>Eiichiro Sumita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress. Submitted to a conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08279v2</id>
    <updated>2020-01-28T22:09:19Z</updated>
    <published>2020-01-22T20:58:22Z</published>
    <title>Transition-Based Dependency Parsing using Perceptron Learner</title>
    <summary>  Syntactic parsing using dependency structures has become a standard technique
in natural language processing with many different parsing models, in
particular data-driven models that can be trained on syntactically annotated
corpora. In this paper, we tackle transition-based dependency parsing using a
Perceptron Learner. Our proposed model, which adds more relevant features to
the Perceptron Learner, outperforms a baseline arc-standard parser. We beat the
UAS of the MALT and LSTM parsers. We also give possible ways to address parsing
of non-projective trees.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Miguel Ballesteros</name>
    </author>
    <author>
      <name>Chris Dyer</name>
    </author>
    <author>
      <name>Robert Frederking</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This was part of an assignment at my graduate course at LTI. This
  does not offer any major novelties</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08279v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08279v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08210v2</id>
    <updated>2020-01-23T18:58:48Z</updated>
    <published>2020-01-22T18:59:17Z</published>
    <title>Multilingual Denoising Pre-training for Neural Machine Translation</title>
    <summary>  This paper demonstrates that multilingual denoising pre-training produces
significant performance gains across a wide variety of machine translation (MT)
tasks. We present mBART -- a sequence-to-sequence denoising auto-encoder
pre-trained on large-scale monolingual corpora in many languages using the BART
objective. mBART is one of the first methods for pre-training a complete
sequence-to-sequence model by denoising full texts in multiple languages, while
previous approaches have focused only on the encoder, decoder, or
reconstructing parts of the text. Pre-training a complete model allows it to be
directly fine tuned for supervised (both sentence-level and document-level) and
unsupervised machine translation, with no task-specific modifications. We
demonstrate that adding mBART initialization produces performance gains in all
but the highest-resource settings, including up to 12 BLEU points for low
resource MT and over 5 BLEU points for many document-level and unsupervised
models. We also show it also enables new types of transfer to language pairs
with no bi-text or that were not in the pre-training corpus, and present
extensive analysis of which factors contribute the most to effective
pre-training.
</summary>
    <author>
      <name>Yinhan Liu</name>
    </author>
    <author>
      <name>Jiatao Gu</name>
    </author>
    <author>
      <name>Naman Goyal</name>
    </author>
    <author>
      <name>Xian Li</name>
    </author>
    <author>
      <name>Sergey Edunov</name>
    </author>
    <author>
      <name>Marjan Ghazvininejad</name>
    </author>
    <author>
      <name>Mike Lewis</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08210v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08210v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08140v1</id>
    <updated>2020-01-22T16:42:06Z</updated>
    <published>2020-01-22T16:42:06Z</published>
    <title>Unsupervised Domain Adaptation for Neural Machine Translation with
  Iterative Back Translation</title>
    <summary>  State-of-the-art neural machine translation (NMT) systems are data-hungry and
perform poorly on domains with little supervised data. As data collection is
expensive and infeasible in many cases, unsupervised domain adaptation methods
are needed. We apply an Iterative Back Translation (IBT) training scheme on
in-domain monolingual data, which repeatedly uses a Transformer-based NMT model
to create in-domain pseudo-parallel sentence pairs in one translation direction
on the fly and then use them to train the model in the other direction.
Evaluated on three domains of German-to-English translation task with no
supervised data, this simple technique alone (without any out-of-domain
parallel data) can already surpass all previous domain adaptation methods---up
to +9.48 BLEU over the strongest previous method, and up to +27.77 BLEU over
the unadapted baseline. Moreover, given available supervised out-of-domain data
on German-to-English and Romanian-to-English language pairs, we can further
enhance the performance and obtain up to +19.31 BLEU improvement over the
strongest baseline, and +47.69 BLEU increment against the unadapted model.
</summary>
    <author>
      <name>Di Jin</name>
    </author>
    <author>
      <name>Zhijing Jin</name>
    </author>
    <author>
      <name>Joey Tianyi Zhou</name>
    </author>
    <author>
      <name>Peter Szolovits</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IJCAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02265v1</id>
    <updated>2020-01-22T16:33:10Z</updated>
    <published>2020-01-22T16:33:10Z</published>
    <title>Zero-Shot Activity Recognition with Videos</title>
    <summary>  In this paper, we examined the zero-shot activity recognition task with the
usage of videos. We introduce an auto-encoder based model to construct a
multimodal joint embedding space between the visual and textual manifolds. On
the visual side, we used activity videos and a state-of-the-art 3D
convolutional action recognition network to extract the features. On the
textual side, we worked with GloVe word embeddings. The zero-shot recognition
results are evaluated by top-n accuracy. Then, the manifold learning ability is
measured by mean Nearest Neighbor Overlap. In the end, we provide an extensive
discussion over the results and the future directions.
</summary>
    <author>
      <name>Evin Pinar Ornek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a research report done during master's studies</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08053v1</id>
    <updated>2020-01-22T15:15:34Z</updated>
    <published>2020-01-22T15:15:34Z</published>
    <title>Contextualized Embeddings in Named-Entity Recognition: An Empirical
  Study on Generalization</title>
    <summary>  Contextualized embeddings use unsupervised language model pretraining to
compute word representations depending on their context. This is intuitively
useful for generalization, especially in Named-Entity Recognition where it is
crucial to detect mentions never seen during training. However, standard
English benchmarks overestimate the importance of lexical over contextual
features because of an unrealistic lexical overlap between train and test
mentions. In this paper, we perform an empirical analysis of the generalization
capabilities of state-of-the-art contextualized embeddings by separating
mentions by novelty and with out-of-domain evaluation. We show that they are
particularly beneficial for unseen mentions detection, especially
out-of-domain. For models trained on CoNLL03, language model contextualization
leads to a +1.2% maximal relative micro-F1 score increase in-domain against
+13% out-of-domain on the WNUT dataset
</summary>
    <author>
      <name>Bruno Taillé</name>
    </author>
    <author>
      <name>Vincent Guigue</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.08053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08051v1</id>
    <updated>2020-01-22T15:14:09Z</updated>
    <published>2020-01-22T15:14:09Z</published>
    <title>TLT-school: a Corpus of Non Native Children Speech</title>
    <summary>  This paper describes "TLT-school" a corpus of speech utterances collected in
schools of northern Italy for assessing the performance of students learning
both English and German. The corpus was recorded in the years 2017 and 2018
from students aged between nine and sixteen years, attending primary, middle
and high school. All utterances have been scored, in terms of some predefined
proficiency indicators, by human experts. In addition, most of utterances
recorded in 2017 have been manually transcribed carefully. Guidelines and
procedures used for manual transcriptions of utterances will be described in
detail, as well as results achieved by means of an automatic speech recognition
system developed by us. Part of the corpus is going to be freely distributed to
scientific community particularly interested both in non-native speech
recognition and automatic assessment of second language proficiency.
</summary>
    <author>
      <name>Roberto Gretter</name>
    </author>
    <author>
      <name>Marco Matassoni</name>
    </author>
    <author>
      <name>Stefano Bannò</name>
    </author>
    <author>
      <name>Daniele Falavigna</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08034v1</id>
    <updated>2020-01-22T14:39:28Z</updated>
    <published>2020-01-22T14:39:28Z</published>
    <title>ManyModalQA: Modality Disambiguation and QA over Diverse Inputs</title>
    <summary>  We present a new multimodal question answering challenge, ManyModalQA, in
which an agent must answer a question by considering three distinct modalities:
text, images, and tables. We collect our data by scraping Wikipedia and then
utilize crowdsourcing to collect question-answer pairs. Our questions are
ambiguous, in that the modality that contains the answer is not easily
determined based solely upon the question. To demonstrate this ambiguity, we
construct a modality selector (or disambiguator) network, and this model gets
substantially lower accuracy on our challenge set, compared to existing
datasets, indicating that our questions are more ambiguous. By analyzing this
model, we investigate which words in the question are indicative of the
modality. Next, we construct a simple baseline ManyModalQA model, which, based
on the prediction from the modality selector, fires a corresponding pre-trained
state-of-the-art unimodal QA model. We focus on providing the community with a
new manymodal evaluation set and only provide a fine-tuning set, with the
expectation that existing datasets and approaches will be transferred for most
of the training, to encourage low-resource generalization without large,
monolithic training sets for each new task. There is a significant gap between
our baseline models and human performance; therefore, we hope that this
challenge encourages research in end-to-end modality disambiguation and
multimodal QA models, as well as transfer learning. Code and data available at:
https://github.com/hannandarryl/ManyModalQA
</summary>
    <author>
      <name>Darryl Hannan</name>
    </author>
    <author>
      <name>Akshay Jain</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (10 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08013v1</id>
    <updated>2020-01-22T13:49:14Z</updated>
    <published>2020-01-22T13:49:14Z</published>
    <title>A Neural Architecture for Person Ontology population</title>
    <summary>  A person ontology comprising concepts, attributes and relationships of people
has a number of applications in data protection, didentification, population of
knowledge graphs for business intelligence and fraud prevention. While
artificial neural networks have led to improvements in Entity Recognition,
Entity Classification, and Relation Extraction, creating an ontology largely
remains a manual process, because it requires a fixed set of semantic relations
between concepts. In this work, we present a system for automatically
populating a person ontology graph from unstructured data using neural models
for Entity Classification and Relation Extraction. We introduce a new dataset
for these tasks and discuss our results.
</summary>
    <author>
      <name>Balaji Ganesan</name>
    </author>
    <author>
      <name>Riddhiman Dasgupta</name>
    </author>
    <author>
      <name>Akshay Parekh</name>
    </author>
    <author>
      <name>Hima Patel</name>
    </author>
    <author>
      <name>Berthold Reinwald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:1811.09368</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08010v1</id>
    <updated>2020-01-22T13:45:34Z</updated>
    <published>2020-01-22T13:45:34Z</published>
    <title>ARAACOM: ARAbic Algerian Corpus for Opinion Mining</title>
    <summary>  Nowadays, it is no more needed to do an enormous effort to distribute a lot
of forms to thousands of people and collect them, then convert this from into
electronic format to track people opinion about some subjects. A lot of web
sites can today reach a large spectrum with less effort. The majority of web
sites suggest to their visitors to leave backups about their feeling of the
site or events. So, this makes for us a lot of data which need powerful mean to
exploit. Opinion mining in the web becomes more and more an attracting task,
due the increasing need for individuals and societies to track the mood of
people against several subjects of daily life (sports, politics,
television,...). A lot of works in opinion mining was developed in western
languages especially English, such works in Arabic language still very scarce.
In this paper, we propose our approach, for opinion mining in Arabic Algerian
news paper. CCS CONCEPTS $\bullet$Information systems~Sentiment analysis
$\bullet$ Computing methodologies~Natural language processing
</summary>
    <author>
      <name>Zitouni Abdelhafid</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRE</arxiv:affiliation>
    </author>
    <author>
      <name>Hichem Rahab</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICOSI, LIRE</arxiv:affiliation>
    </author>
    <author>
      <name>Abdelhafid Zitouni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRE</arxiv:affiliation>
    </author>
    <author>
      <name>Mahieddine Djoudi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TECHNÉ - EA 6316</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3129186.3129193</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3129186.3129193" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICCES '17: Proceedings of the International Conference on
  Computing for Engineering and Sciences, Jul 2017, Istanbul, France. pp.35-39</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.08010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07885v2</id>
    <updated>2020-01-24T04:42:13Z</updated>
    <published>2020-01-22T05:34:45Z</published>
    <title>Normalization of Input-output Shared Embeddings in Text Generation
  Models</title>
    <summary>  Neural Network based models have been state-of-the-art models for various
Natural Language Processing tasks, however, the input and output dimension
problem in the networks has still not been fully resolved, especially in text
generation tasks (e.g. Machine Translation, Text Summarization), in which input
and output both have huge sizes of vocabularies. Therefore, input-output
embedding weight sharing has been introduced and adopted widely, which remains
to be improved. Based on linear algebra and statistical theories, this paper
locates the shortcoming of existed input-output embedding weight sharing
method, then raises methods for improving input-output weight shared embedding,
among which methods of normalization of embedding weight matrices show best
performance. These methods are nearly computational cost-free, can get combined
with other embedding techniques, and show good effectiveness when applied on
state-of-the-art Neural Network models. For Transformer-big models, the
normalization techniques can get at best 0.6 BLEU improvement compared to the
original version of model on WMT'16 En-De dataset, and similar BLEU
improvements on IWSLT 14' datasets. For DynamicConv models, 0.5 BLEU
improvement can be attained on WMT'16 En-De dataset, and 0.41 BLEU improvement
on IWSLT 14' De-En translation task is achieved.
</summary>
    <author>
      <name>Jinyang Liu</name>
    </author>
    <author>
      <name>Yujia Zhai</name>
    </author>
    <author>
      <name>Zizhong Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07885v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07885v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07876v1</id>
    <updated>2020-01-22T04:52:06Z</updated>
    <published>2020-01-22T04:52:06Z</published>
    <title>VoiceCoach: Interactive Evidence-based Training for Voice Modulation
  Skills in Public Speaking</title>
    <summary>  The modulation of voice properties, such as pitch, volume, and speed, is
crucial for delivering a successful public speech. However, it is challenging
to master different voice modulation skills. Though many guidelines are
available, they are often not practical enough to be applied in different
public speaking situations, especially for novice speakers. We present
VoiceCoach, an interactive evidence-based approach to facilitate the effective
training of voice modulation skills. Specifically, we have analyzed the voice
modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use
them as the benchmark dataset. Given a voice input, VoiceCoach automatically
recommends good voice modulation examples from the dataset based on the
similarity of both sentence structures and voice modulation skills. Immediate
and quantitative visual feedback is provided to guide further improvement. The
expert interviews and the user study provide support for the effectiveness and
usability of VoiceCoach.
</summary>
    <author>
      <name>Xingbo Wang</name>
    </author>
    <author>
      <name>Haipeng Zeng</name>
    </author>
    <author>
      <name>Yong Wang</name>
    </author>
    <author>
      <name>Aoyu Wu</name>
    </author>
    <author>
      <name>Zhida Sun</name>
    </author>
    <author>
      <name>Xiaojuan Ma</name>
    </author>
    <author>
      <name>Huamin Qu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3313831.3376726</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3313831.3376726" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by CHI '20</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07849v3</id>
    <updated>2020-02-07T10:16:28Z</updated>
    <published>2020-01-22T02:06:06Z</published>
    <title>Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion</title>
    <summary>  An effective approach for voice conversion (VC) is to disentangle linguistic
content from other components in the speech signal. The effectiveness of
variational autoencoder (VAE) based VC (VAE-VC), for instance, strongly relies
on this principle. In our prior work, we proposed a cross-domain VAE-VC
(CDVAE-VC) framework, which utilized acoustic features of different properties,
to improve the performance of VAE-VC. We believed that the success came from
more disentangled latent representations. In this paper, we extend the CDVAE-VC
framework by incorporating the concept of adversarial learning, in order to
further increase the degree of disentanglement, thereby improving the quality
and similarity of converted speech. More specifically, we first investigate the
effectiveness of incorporating the generative adversarial networks (GANs) with
CDVAE-VC. Then, we consider the concept of domain adversarial training and add
an explicit constraint to the latent representation, realized by a speaker
classifier, to explicitly eliminate the speaker information that resides in the
latent code. Experimental results confirm that the degree of disentanglement of
the learned latent representation can be enhanced by both GANs and the speaker
classifier. Meanwhile, subjective evaluation results in terms of quality and
similarity scores demonstrate the effectiveness of our proposed methods.
</summary>
    <author>
      <name>Wen-Chin Huang</name>
    </author>
    <author>
      <name>Hao Luo</name>
    </author>
    <author>
      <name>Hsin-Te Hwang</name>
    </author>
    <author>
      <name>Chen-Chou Lo</name>
    </author>
    <author>
      <name>Yu-Huai Peng</name>
    </author>
    <author>
      <name>Yu Tsao</name>
    </author>
    <author>
      <name>Hsin-Min Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to IEEE Transactions on Emerging Topics in Computational
  Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07849v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07849v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07820v1</id>
    <updated>2020-01-22T00:05:45Z</updated>
    <published>2020-01-22T00:05:45Z</published>
    <title>Elephant in the Room: An Evaluation Framework for Assessing Adversarial
  Examples in NLP</title>
    <summary>  An adversarial example is an input transformed by small perturbations that
machine learning models consistently misclassify. While there are a number of
methods proposed to generate adversarial examples for text data, it is not
trivial to assess the quality of these adversarial examples, as minor
perturbations (such as changing a word in a sentence) can lead to a significant
shift in their meaning, readability and classification label. In this paper, we
propose an evaluation framework to assess the quality of adversarial examples
based on the aforementioned properties. We experiment with five benchmark
attacking methods and an alternative approach based on an auto-encoder, and
found that these methods generate adversarial examples with poor readability
and content preservation. We also learned that there are multiple factors that
can influence the attacking performance, such as the the length of text
examples and the input domain.
</summary>
    <author>
      <name>Ying Xu</name>
    </author>
    <author>
      <name>Xu Zhong</name>
    </author>
    <author>
      <name>Antonio Jose Jimeno Yepes</name>
    </author>
    <author>
      <name>Jey Han Lau</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07786v1</id>
    <updated>2020-01-21T21:47:27Z</updated>
    <published>2020-01-21T21:47:27Z</published>
    <title>Shared Task: Lexical Semantic Change Detection in German</title>
    <summary>  Recent NLP architectures have illustrated in various ways how semantic change
can be captured across time and domains. However, in terms of evaluation there
is a lack of benchmarks to compare the performance of these systems against
each other. We present the results of the first shared task on unsupervised
lexical semantic change detection (LSCD) in German based on the evaluation
framework proposed by Schlechtweg et al. (2019).
</summary>
    <author>
      <name>Adnan Ahmad</name>
    </author>
    <author>
      <name>Kiflom Desta</name>
    </author>
    <author>
      <name>Fabian Lang</name>
    </author>
    <author>
      <name>Dominik Schlechtweg</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07752v1</id>
    <updated>2020-01-21T19:37:33Z</updated>
    <published>2020-01-21T19:37:33Z</published>
    <title>Emergence of Pragmatics from Referential Game between Theory of Mind
  Agents</title>
    <summary>  Pragmatics studies how context can contribute to language meanings [1]. In
human communication, language is never interpreted out of context, and
sentences can usually convey more information than their literal meanings [2].
However, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],
restricting the communication efficiency and the capability of human-agent
interaction. In this paper, we propose an algorithm, using which agents can
spontaneously learn the ability to "read between lines" without any explicit
hand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a
cooperative multi-agent pedagogical situation and propose an adaptive
reinforcement learning (RL) algorithm to develop a communication protocol. ToM
is a profound cognitive science concept, claiming that people regularly reason
about other's mental states, including beliefs, goals, and intentions, to
obtain performance advantage in competition, cooperation or coalition. With
this ability, agents consider language as not only messages but also rational
acts reflecting others' hidden states. Our experiments demonstrate the
advantage of pragmatic protocols over non-pragmatic protocols. We also show the
teaching complexity following the pragmatic protocol empirically approximates
to recursive teaching dimension (RTD).
</summary>
    <author>
      <name>Luyao Yuan</name>
    </author>
    <author>
      <name>Zipeng Fu</name>
    </author>
    <author>
      <name>Jingyue Shen</name>
    </author>
    <author>
      <name>Lu Xu</name>
    </author>
    <author>
      <name>Junhong Shen</name>
    </author>
    <author>
      <name>Song-Chun Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07740v1</id>
    <updated>2020-01-21T19:09:49Z</updated>
    <published>2020-01-21T19:09:49Z</published>
    <title>Where New Words Are Born: Distributional Semantic Analysis of Neologisms
  and Their Semantic Neighborhoods</title>
    <summary>  We perform statistical analysis of the phenomenon of neology, the process by
which new words emerge in a language, using large diachronic corpora of
English. We investigate the importance of two factors, semantic sparsity and
frequency growth rates of semantic neighbors, formalized in the distributional
semantics paradigm. We show that both factors are predictive of word emergence
although we find more support for the latter hypothesis. Besides presenting a
new linguistic application of distributional semantics, this study tackles the
linguistic question of the role of language-internal factors (in our case,
sparsity) in language change motivated by language-external factors (reflected
in frequency growth).
</summary>
    <author>
      <name>Maria Ryskina</name>
    </author>
    <author>
      <name>Ella Rabinovich</name>
    </author>
    <author>
      <name>Taylor Berg-Kirkpatrick</name>
    </author>
    <author>
      <name>David R. Mortensen</name>
    </author>
    <author>
      <name>Yulia Tsvetkov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7275/1jra-8m83</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7275/1jra-8m83" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SCiL 2020</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Society for Computation in Linguistics 3.1
  (2020): 43-52</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.07740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07676v1</id>
    <updated>2020-01-21T17:57:33Z</updated>
    <published>2020-01-21T17:57:33Z</published>
    <title>Exploiting Cloze Questions for Few-Shot Text Classification and Natural
  Language Inference</title>
    <summary>  Some NLP tasks can be solved in a fully unsupervised fashion by providing a
pretrained language model with "task descriptions" in natural language (e.g.,
Radford et al., 2019). While this approach underperforms its supervised
counterpart, we show in this work that the two ideas can be combined: We
introduce Pattern-Exploiting Training (PET), a semi-supervised training
procedure that reformulates input examples as cloze-style phrases which help
the language model understand the given task. Theses phrases are then used to
assign soft labels to a large set of unlabeled examples. Finally, regular
supervised training is performed on the resulting training set. On several
tasks, we show that PET outperforms both supervised training and unsupervised
approaches in low-resource settings by a large margin.
</summary>
    <author>
      <name>Timo Schick</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07615v1</id>
    <updated>2020-01-21T15:39:12Z</updated>
    <published>2020-01-21T15:39:12Z</published>
    <title>Improving Interaction Quality Estimation with BiLSTMs and the Impact on
  Dialogue Policy Learning</title>
    <summary>  Learning suitable and well-performing dialogue behaviour in statistical
spoken dialogue systems has been in the focus of research for many years. While
most work which is based on reinforcement learning employs an objective measure
like task success for modelling the reward signal, we use a reward based on
user satisfaction estimation. We propose a novel estimator and show that it
outperforms all previous estimators while learning temporal dependencies
implicitly. Furthermore, we apply this novel user satisfaction estimation model
live in simulated experiments where the satisfaction estimation model is
trained on one domain and applied in many other domains which cover a similar
task. We show that applying this model results in higher estimated
satisfaction, similar task success rates and a higher robustness to noise.
</summary>
    <author>
      <name>Stefan Ultes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at SIGDIAL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07574v1</id>
    <updated>2020-01-21T14:39:20Z</updated>
    <published>2020-01-21T14:39:20Z</published>
    <title>Generating Sense Embeddings for Syntactic and Semantic Analogy for
  Portuguese</title>
    <summary>  Word embeddings are numerical vectors which can represent words or concepts
in a low-dimensional continuous space. These vectors are able to capture useful
syntactic and semantic information. The traditional approaches like Word2Vec,
GloVe and FastText have a strict drawback: they produce a single vector
representation per word ignoring the fact that ambiguous words can assume
different meanings. In this paper we use techniques to generate sense
embeddings and present the first experiments carried out for Portuguese. Our
experiments show that sense vectors outperform traditional word vectors in
syntactic and semantic analogy tasks, proving that the language resource
generated here can improve the performance of NLP tasks in Portuguese.
</summary>
    <author>
      <name>Jessica Rodrigues da Silva</name>
    </author>
    <author>
      <name>Helena de Medeiros Caseli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, STIL 2019 Full paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">STIL XII (2019) 104-113</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.07574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07569v1</id>
    <updated>2020-01-21T14:31:01Z</updated>
    <published>2020-01-21T14:31:01Z</published>
    <title>R2DE: a NLP approach to estimating IRT parameters of newly generated
  questions</title>
    <summary>  The main objective of exams consists in performing an assessment of students'
expertise on a specific subject. Such expertise, also referred to as skill or
knowledge level, can then be leveraged in different ways (e.g., to assign a
grade to the students, to understand whether a student might need some support,
etc.). Similarly, the questions appearing in the exams have to be assessed in
some way before being used to evaluate students. Standard approaches to
questions' assessment are either subjective (e.g., assessment by human experts)
or introduce a long delay in the process of question generation (e.g.,
pretesting with real students). In this work we introduce R2DE (which is a
Regressor for Difficulty and Discrimination Estimation), a model capable of
assessing newly generated multiple-choice questions by looking at the text of
the question and the text of the possible choices. In particular, it can
estimate the difficulty and the discrimination of each question, as they are
defined in Item Response Theory. We also present the results of extensive
experiments we carried out on a real world large scale dataset coming from an
e-learning platform, showing that our model can be used to perform an initial
assessment of newly created questions and ease some of the problems that arise
in question generation.
</summary>
    <author>
      <name>Luca Benedetto</name>
    </author>
    <author>
      <name>Andrea Cappelli</name>
    </author>
    <author>
      <name>Roberto Turrin</name>
    </author>
    <author>
      <name>Paolo Cremonesi</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07526v1</id>
    <updated>2020-01-21T13:41:09Z</updated>
    <published>2020-01-21T13:41:09Z</published>
    <title>Domain-Aware Dialogue State Tracker for Multi-Domain Dialogue Systems</title>
    <summary>  In task-oriented dialogue systems the dialogue state tracker (DST) component
is responsible for predicting the state of the dialogue based on the dialogue
history. Current DST approaches rely on a predefined domain ontology, a fact
that limits their effective usage for large scale conversational agents, where
the DST constantly needs to be interfaced with ever-increasing services and
APIs. Focused towards overcoming this drawback, we propose a domain-aware
dialogue state tracker, that is completely data-driven and it is modeled to
predict for dynamic service schemas. The proposed model utilizes domain and
slot information to extract both domain and slot specific representations for a
given dialogue, and then uses such representations to predict the values of the
corresponding slot. Integrating this mechanism with a pretrained language model
(i.e. BERT), our approach can effectively learn semantic relations.
</summary>
    <author>
      <name>Vevake Balaraman</name>
    </author>
    <author>
      <name>Bernardo Magnini</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07418v1</id>
    <updated>2020-01-21T10:02:18Z</updated>
    <published>2020-01-21T10:02:18Z</published>
    <title>A Physical Embedding Model for Knowledge Graphs</title>
    <summary>  Knowledge graph embedding methods learn continuous vector representations for
entities in knowledge graphs and have been used successfully in a large number
of applications. We present a novel and scalable paradigm for the computation
of knowledge graph embeddings, which we dub PYKE . Our approach combines a
physical model based on Hooke's law and its inverse with ideas from simulated
annealing to compute embeddings for knowledge graphs efficiently. We prove that
PYKE achieves a linear space complexity. While the time complexity for the
initialization of our approach is quadratic, the time complexity of each of its
iterations is linear in the size of the input knowledge graph. Hence, PYKE's
overall runtime is close to linear. Consequently, our approach easily scales up
to knowledge graphs containing millions of triples. We evaluate our approach
against six state-of-the-art embedding approaches on the DrugBank and DBpedia
datasets in two series of experiments. The first series shows that the cluster
purity achieved by PYKE is up to 26% (absolute) better than that of the state
of art. In addition, PYKE is more than 22 times faster than existing embedding
solutions in the best case. The results of our second series of experiments
show that PYKE is up to 23% (absolute) better than the state of art on the task
of type prediction while maintaining its superior scalability. Our
implementation and results are open-source and are available at
http://github.com/dice-group/PYKE.
</summary>
    <author>
      <name>Caglar Demir</name>
    </author>
    <author>
      <name>Axel-Cyrille Ngonga Ngomo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-981-15-3412-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-981-15-3412-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9th Joint International Conference, JIST 2019, Hangzhou, China</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08546v1</id>
    <updated>2020-01-21T06:47:11Z</updated>
    <published>2020-01-21T06:47:11Z</published>
    <title>CheckThat! at CLEF 2020: Enabling the Automatic Identification and
  Verification of Claims in Social Media</title>
    <summary>  We describe the third edition of the CheckThat! Lab, which is part of the
2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four
complementary tasks and a related task from previous lab editions, offered in
English, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter
stream are worth fact-checking. Task 2 asks to determine whether a claim posted
in a tweet can be verified using a set of previously fact-checked claims. Task
3 asks to retrieve text snippets from a given set of Web pages that would be
useful for verifying a target tweet's claim. Task 4 asks to predict the
veracity of a target tweet's claim using a set of Web pages and potentially
useful snippets in them. Finally, the lab offers a fifth task that asks to
predict the check-worthiness of the claims made in English political debates
and speeches. CheckThat! features a full evaluation framework. The evaluation
is carried out using mean average precision or precision at rank k for ranking
tasks, and F1 for classification tasks.
</summary>
    <author>
      <name>Alberto Barron-Cedeno</name>
    </author>
    <author>
      <name>Tamer Elsayed</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Giovanni Da San Martino</name>
    </author>
    <author>
      <name>Maram Hasanain</name>
    </author>
    <author>
      <name>Reem Suwaileh</name>
    </author>
    <author>
      <name>Fatima Haouari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computational journalism, Check-worthiness, Fact-checking, Veracity,
  CLEF-2020 CheckThat! Lab</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CLEF-2018 ECIR-2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.08546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07331v1</id>
    <updated>2020-01-21T04:01:58Z</updated>
    <published>2020-01-21T04:01:58Z</published>
    <title>Length-controllable Abstractive Summarization by Guiding with Summary
  Prototype</title>
    <summary>  We propose a new length-controllable abstractive summarization model. Recent
state-of-the-art abstractive summarization models based on encoder-decoder
models generate only one summary per source text. However, controllable
summarization, especially of the length, is an important aspect for practical
applications. Previous studies on length-controllable abstractive summarization
incorporate length embeddings in the decoder module for controlling the summary
length. Although the length embeddings can control where to stop decoding, they
do not decide which information should be included in the summary within the
length constraint. Unlike the previous models, our length-controllable
abstractive summarization model incorporates a word-level extractive module in
the encoder-decoder model instead of length embeddings. Our model generates a
summary in two steps. First, our word-level extractor extracts a sequence of
important words (we call it the "prototype text") from the source text
according to the word-level importance scores and the length constraint.
Second, the prototype text is used as additional input to the encoder-decoder
model, which generates a summary by jointly encoding and copying words from
both the prototype text and source text. Since the prototype text is a guide to
both the content and length of the summary, our model can generate an
informative and length-controlled summary. Experiments with the CNN/Daily Mail
dataset and the NEWSROOM dataset show that our model outperformed previous
models in length-controlled settings.
</summary>
    <author>
      <name>Itsumi Saito</name>
    </author>
    <author>
      <name>Kyosuke Nishida</name>
    </author>
    <author>
      <name>Kosuke Nishida</name>
    </author>
    <author>
      <name>Atsushi Otsuka</name>
    </author>
    <author>
      <name>Hisako Asano</name>
    </author>
    <author>
      <name>Junji Tomita</name>
    </author>
    <author>
      <name>Hiroyuki Shindo</name>
    </author>
    <author>
      <name>Yuji Matsumoto</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07320v1</id>
    <updated>2020-01-21T03:10:02Z</updated>
    <published>2020-01-21T03:10:02Z</published>
    <title>A Hierarchical Location Normalization System for Text</title>
    <summary>  It's natural these days for people to know the local events from massive
documents. Many texts contain location information, such as city name or road
name, which is always incomplete or latent. It's significant to extract the
administrative area of the text and organize the hierarchy of area, called
location normalization. Existing detecting location systems either exclude
hierarchical normalization or present only a few specific regions. We propose a
system named ROIBase that normalizes the text by the Chinese hierarchical
administrative divisions. ROIBase adopts a co-occurrence constraint as the
basic framework to score the hit of the administrative area, achieves the
inference by special embeddings, and expands the recall by the ROI (region of
interest). It has high efficiency and interpretability because it mainly
establishes on the definite knowledge and has less complex logic than the
supervised models. We demonstrate that ROIBase achieves better performance
against feasible solutions and is useful as a strong support system for
location normalization.
</summary>
    <author>
      <name>Dongyun Liang</name>
    </author>
    <author>
      <name>Guohua Wang</name>
    </author>
    <author>
      <name>Jing Nie</name>
    </author>
    <author>
      <name>Binxu Zhai</name>
    </author>
    <author>
      <name>Xiusen Gu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, submitted to conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07263v1</id>
    <updated>2020-01-20T22:03:42Z</updated>
    <published>2020-01-20T22:03:42Z</published>
    <title>Single headed attention based sequence-to-sequence model for
  state-of-the-art results on Switchboard-300</title>
    <summary>  It is generally believed that direct sequence-to-sequence (seq2seq) speech
recognition models are competitive with hybrid models only when a large amount
of data, at least a thousand hours, is available for training. In this paper,
we show that state-of-the-art recognition performance can be achieved on the
Switchboard-300 database using a single headed attention, LSTM based model.
Using a cross-utterance language model, our single-pass speaker independent
system reaches 6.4% and 12.5% word error rate (WER) on the Switchboard and
CallHome subsets of Hub5'00, without a pronunciation lexicon. While careful
regularization and data augmentation are crucial in achieving this level of
performance, experiments on Switchboard-2000 show that nothing is more useful
than more data.
</summary>
    <author>
      <name>Zoltán Tüske</name>
    </author>
    <author>
      <name>George Saon</name>
    </author>
    <author>
      <name>Kartik Audhkhasi</name>
    </author>
    <author>
      <name>Brian Kingsbury</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07234v1</id>
    <updated>2020-01-20T20:02:02Z</updated>
    <published>2020-01-20T20:02:02Z</published>
    <title>Multi-level Head-wise Match and Aggregation in Transformer for Textual
  Sequence Matching</title>
    <summary>  Transformer has been successfully applied to many natural language processing
tasks. However, for textual sequence matching, simple matching between the
representation of a pair of sequences might bring in unnecessary noise. In this
paper, we propose a new approach to sequence pair matching with Transformer, by
learning head-wise matching representations on multiple levels. Experiments
show that our proposed approach can achieve new state-of-the-art performance on
multiple tasks that rely only on pre-computed sequence-vector-representation,
such as SNLI, MNLI-match, MNLI-mismatch, QQP, and SQuAD-binary.
</summary>
    <author>
      <name>Shuohang Wang</name>
    </author>
    <author>
      <name>Yunshi Lan</name>
    </author>
    <author>
      <name>Yi Tay</name>
    </author>
    <author>
      <name>Jing Jiang</name>
    </author>
    <author>
      <name>Jingjing Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020, 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07234v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07234v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07209v1</id>
    <updated>2020-01-20T18:52:45Z</updated>
    <published>2020-01-20T18:52:45Z</published>
    <title>Text-based inference of moral sentiment change</title>
    <summary>  We present a text-based framework for investigating moral sentiment change of
the public via longitudinal corpora. Our framework is based on the premise that
language use can inform people's moral perception toward right or wrong, and we
build our methodology by exploring moral biases learned from diachronic word
embeddings. We demonstrate how a parameter-free model supports inference of
historical shifts in moral sentiment toward concepts such as slavery and
democracy over centuries at three incremental levels: moral relevance, moral
polarity, and fine-grained moral dimensions. We apply this methodology to
visualizing moral time courses of individual concepts and analyzing the
relations between psycholinguistic variables and rates of moral sentiment
change at scale. Our work offers opportunities for applying natural language
processing toward characterizing moral sentiment change in society.
</summary>
    <author>
      <name>Jing Yi Xie</name>
    </author>
    <author>
      <name>Renato Ferreira Pinto Jr.</name>
    </author>
    <author>
      <name>Graeme Hirst</name>
    </author>
    <author>
      <name>Yang Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07209v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07209v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07194v2</id>
    <updated>2020-02-27T23:05:46Z</updated>
    <published>2020-01-20T18:04:10Z</published>
    <title>Recommending Themes for Ad Creative Design via Visual-Linguistic
  Representations</title>
    <summary>  There is a perennial need in the online advertising industry to refresh ad
creatives, i.e., images and text used for enticing online users towards a
brand. Such refreshes are required to reduce the likelihood of ad fatigue among
online users, and to incorporate insights from other successful campaigns in
related product categories. Given a brand, to come up with themes for a new ad
is a painstaking and time consuming process for creative strategists.
Strategists typically draw inspiration from the images and text used for past
ad campaigns, as well as world knowledge on the brands. To automatically infer
ad themes via such multimodal sources of information in past ad campaigns, we
propose a theme (keyphrase) recommender system for ad creative strategists. The
theme recommender is based on aggregating results from a visual question
answering (VQA) task, which ingests the following: (i) ad images, (ii) text
associated with the ads as well as Wikipedia pages on the brands in the ads,
and (iii) questions around the ad. We leverage transformer based cross-modality
encoders to train visual-linguistic representations for our VQA task. We study
two formulations for the VQA task along the lines of classification and
ranking; via experiments on a public dataset, we show that cross-modal
representations lead to significantly better classification accuracy and
ranking precision-recall metrics. Cross-modal representations show better
performance compared to separate image and text representations. In addition,
the use of multimodal information shows a significant lift over using only
textual or visual information.
</summary>
    <author>
      <name>Yichao Zhou</name>
    </author>
    <author>
      <name>Shaunak Mishra</name>
    </author>
    <author>
      <name>Manisha Verma</name>
    </author>
    <author>
      <name>Narayan Bhamidipati</name>
    </author>
    <author>
      <name>Wei Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures, 2 tables, accepted by The Web Conference 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07194v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07194v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07098v1</id>
    <updated>2020-01-20T13:10:01Z</updated>
    <published>2020-01-20T13:10:01Z</published>
    <title>Audio Summarization with Audio Features and Probability Distribution
  Divergence</title>
    <summary>  The automatic summarization of multimedia sources is an important task that
facilitates the understanding of an individual by condensing the source while
maintaining relevant information. In this paper we focus on audio summarization
based on audio features and the probability of distribution divergence. Our
method, based on an extractive summarization approach, aims to select the most
relevant segments until a time threshold is reached. It takes into account the
segment's length, position and informativeness value. Informativeness of each
segment is obtained by mapping a set of audio features issued from its
Mel-frequency Cepstral Coefficients and their corresponding Jensen-Shannon
divergence score. Results over a multi-evaluator scheme shows that our approach
provides understandable and informative summaries.
</summary>
    <author>
      <name>Carlos-Emiliano González-Gallardo</name>
    </author>
    <author>
      <name>Romain Deveaud</name>
    </author>
    <author>
      <name>Eric SanJuan</name>
    </author>
    <author>
      <name>Juan-Manuel Torres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20th International Conference on Computational Linguistics and
  Intelligent Text Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00734v1</id>
    <updated>2020-01-20T12:30:17Z</updated>
    <published>2020-01-20T12:30:17Z</published>
    <title>Analysis of the quotation corpus of the Russian Wiktionary</title>
    <summary>  The quantitative evaluation of quotations in the Russian Wiktionary was
performed using the developed Wiktionary parser. It was found that the number
of quotations in the dictionary is growing fast (51.5 thousands in 2011, 62
thousands in 2012). These quotations were extracted and saved in the relational
database of a machine-readable dictionary. For this database, tables related to
the quotations were designed. A histogram of distribution of quotations of
literary works written in different years was built. It was made an attempt to
explain the characteristics of the histogram by associating it with the years
of the most popular and cited (in the Russian Wiktionary) writers of the
nineteenth century. It was found that more than one-third of all the quotations
(the example sentences) contained in the Russian Wiktionary are taken by the
editors of a Wiktionary entry from the Russian National Corpus.
</summary>
    <author>
      <name>A. Smirnov</name>
    </author>
    <author>
      <name>T. Levashova</name>
    </author>
    <author>
      <name>A. Karpov</name>
    </author>
    <author>
      <name>I. Kipyatkova</name>
    </author>
    <author>
      <name>A. Ronzhin</name>
    </author>
    <author>
      <name>A. Krizhanovsky</name>
    </author>
    <author>
      <name>N. Krizhanovsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 tables, 5 figures, published in the journal (preprint)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Research in Computing Science, Vol. 56, pp. 101-112, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.00734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10337v1</id>
    <updated>2020-01-20T06:27:33Z</updated>
    <published>2020-01-20T06:27:33Z</published>
    <title>Early Forecasting of Text Classification Accuracy and F-Measure with
  Active Learning</title>
    <summary>  When creating text classification systems, one of the major bottlenecks is
the annotation of training data. Active learning has been proposed to address
this bottleneck using stopping methods to minimize the cost of data annotation.
An important capability for improving the utility of stopping methods is to
effectively forecast the performance of the text classification models.
Forecasting can be done through the use of logarithmic models regressed on some
portion of the data as learning is progressing. A critical unexplored question
is what portion of the data is needed for accurate forecasting. There is a
tension, where it is desirable to use less data so that the forecast can be
made earlier, which is more useful, versus it being desirable to use more data,
so that the forecast can be more accurate. We find that when using active
learning it is even more important to generate forecasts earlier so as to make
them more useful and not waste annotation effort. We investigate the difference
in forecasting difficulty when using accuracy and F-measure as the text
classification system performance metrics and we find that F-measure is more
difficult to forecast. We conduct experiments on seven text classification
datasets in different semantic domains with different characteristics and with
three different base machine learning algorithms. We find that forecasting is
easiest for decision tree learning, moderate for Support Vector Machines, and
most difficult for neural networks.
</summary>
    <author>
      <name>Thomas Orth</name>
    </author>
    <author>
      <name>Michael Bloodgood</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures, 2 tables; to appear in Proceedings of the IEEE
  14th International Conference on Semantic Computing (ICSC 2020), San Diego,
  California, 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.6; I.2.7; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11384v1</id>
    <updated>2020-01-20T06:12:12Z</updated>
    <published>2020-01-20T06:12:12Z</published>
    <title>Unsupervised Sentiment Analysis for Code-mixed Data</title>
    <summary>  Code-mixing is the practice of alternating between two or more languages.
Mostly observed in multilingual societies, its occurrence is increasing and
therefore its importance. A major part of sentiment analysis research has been
monolingual, and most of them perform poorly on code-mixed text. In this work,
we introduce methods that use different kinds of multilingual and cross-lingual
embeddings to efficiently transfer knowledge from monolingual text to
code-mixed text for sentiment analysis of code-mixed text. Our methods can
handle code-mixed text through a zero-shot learning. Our methods beat
state-of-the-art on English-Spanish code-mixed sentiment analysis by absolute
3\% F1-score. We are able to achieve 0.58 F1-score (without parallel corpus)
and 0.62 F1-score (with parallel corpus) on the same benchmark in a zero-shot
way as compared to 0.68 F1-score in supervised settings. Our code is publicly
available.
</summary>
    <author>
      <name>Siddharth Yadav</name>
    </author>
    <author>
      <name>Tanmoy Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06944v1</id>
    <updated>2020-01-20T02:19:13Z</updated>
    <published>2020-01-20T02:19:13Z</published>
    <title>Nested-Wasserstein Self-Imitation Learning for Sequence Generation</title>
    <summary>  Reinforcement learning (RL) has been widely studied for improving
sequence-generation models. However, the conventional rewards used for RL
training typically cannot capture sufficient semantic information and therefore
render model bias. Further, the sparse and delayed rewards make RL exploration
inefficient. To alleviate these issues, we propose the concept of
nested-Wasserstein distance for distributional semantic matching. To further
exploit it, a novel nested-Wasserstein self-imitation learning framework is
developed, encouraging the model to exploit historical high-rewarded sequences
for enhanced exploration and better semantic matching. Our solution can be
understood as approximately executing proximal policy optimization with
Wasserstein trust-regions. Experiments on a variety of unconditional and
conditional sequence-generation tasks demonstrate the proposed approach
consistently leads to improved performance.
</summary>
    <author>
      <name>Ruiyi Zhang</name>
    </author>
    <author>
      <name>Changyou Chen</name>
    </author>
    <author>
      <name>Zhe Gan</name>
    </author>
    <author>
      <name>Zheng Wen</name>
    </author>
    <author>
      <name>Wenlin Wang</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AISTATS2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06927v1</id>
    <updated>2020-01-20T01:02:36Z</updated>
    <published>2020-01-20T01:02:36Z</published>
    <title>SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions</title>
    <summary>  Existing VQA datasets contain questions with varying levels of complexity.
While the majority of questions in these datasets require perception for
recognizing existence, properties, and spatial relationships of entities, a
significant portion of questions pose challenges that correspond to reasoning
tasks -- tasks that can only be answered through a synthesis of perception and
knowledge about the world, logic and / or reasoning. This distinction allows us
to notice when existing VQA models have consistency issues -- they answer the
reasoning question correctly but fail on associated low-level perception
questions. For example, models answer the complex reasoning question "Is the
banana ripe enough to eat?" correctly, but fail on the associated perception
question "Are the bananas mostly green or yellow?" indicating that the model
likely answered the reasoning question correctly but for the wrong reason. We
quantify the extent to which this phenomenon occurs by creating a new Reasoning
split of the VQA dataset and collecting Sub-VQA, a new dataset consisting of
200K new perception questions which serve as sub questions corresponding to the
set of perceptual tasks needed to effectively answer the complex reasoning
questions in the Reasoning split. Additionally, we propose an approach called
Sub-Question Importance-aware Network Tuning (SQuINT), which encourages the
model to attend do the same parts of the image when answering the reasoning
question and the perception sub questions. We show that SQuINT improves model
consistency by 7.8%, also marginally improving its performance on the Reasoning
questions in VQA, while also displaying qualitatively better attention maps.
</summary>
    <author>
      <name>Ramprasaath R. Selvaraju</name>
    </author>
    <author>
      <name>Purva Tendulkar</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Eric Horvitz</name>
    </author>
    <author>
      <name>Marco Ribeiro</name>
    </author>
    <author>
      <name>Besmira Nushi</name>
    </author>
    <author>
      <name>Ece Kamar</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06888v1</id>
    <updated>2020-01-19T19:37:45Z</updated>
    <published>2020-01-19T19:37:45Z</published>
    <title>A multimodal deep learning approach for named entity recognition from
  social media</title>
    <summary>  Named Entity Recognition (NER) from social media posts is a challenging task.
User generated content which forms the nature of social media, is noisy and
contains grammatical and linguistic errors. This noisy content makes it much
harder for tasks such as named entity recognition. However some applications
like automatic journalism or information retrieval from social media, require
more information about entities mentioned in groups of social media posts.
Conventional methods applied to structured and well typed documents provide
acceptable results while compared to new user generated media, these methods
are not satisfactory. One valuable piece of information about an entity is the
related image to the text. Combining this multimodal data reduces ambiguity and
provides wider information about the entities mentioned. In order to address
this issue, we propose a novel deep learning approach utilizing multimodal deep
learning. Our solution is able to provide more accurate results on named entity
recognition task. Experimental results, namely the precision, recall and F1
score metrics show the superiority of our work compared to other
state-of-the-art NER solutions.
</summary>
    <author>
      <name>Meysam Asgari-Chenaghlu</name>
    </author>
    <author>
      <name>M. Reza Feizi-Derakhshi</name>
    </author>
    <author>
      <name>Leili Farzinvash</name>
    </author>
    <author>
      <name>Cina Motamed</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10340v1</id>
    <updated>2020-01-19T09:29:12Z</updated>
    <published>2020-01-19T09:29:12Z</published>
    <title>Deep Learning for Hindi Text Classification: A Comparison</title>
    <summary>  Natural Language Processing (NLP) and especially natural language text
analysis have seen great advances in recent times. Usage of deep learning in
text processing has revolutionized the techniques for text processing and
achieved remarkable results. Different deep learning architectures like CNN,
LSTM, and very recent Transformer have been used to achieve state of the art
results variety on NLP tasks. In this work, we survey a host of deep learning
architectures for text classification tasks. The work is specifically concerned
with the classification of Hindi text. The research in the classification of
morphologically rich and low resource Hindi language written in Devanagari
script has been limited due to the absence of large labeled corpus. In this
work, we used translated versions of English data-sets to evaluate models based
on CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based
on BERT and LASER are also compared to evaluate their effectiveness for the
Hindi language. The paper also serves as a tutorial for popular text
classification techniques.
</summary>
    <author>
      <name>Ramchandra Joshi</name>
    </author>
    <author>
      <name>Purvi Goel</name>
    </author>
    <author>
      <name>Raviraj Joshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at International Conference on Intelligent Human Computer
  Interaction(IHCI) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06785v3</id>
    <updated>2020-02-02T21:54:13Z</updated>
    <published>2020-01-19T07:03:05Z</published>
    <title>From Speech-to-Speech Translation to Automatic Dubbing</title>
    <summary>  We present enhancements to a speech-to-speech translation pipeline in order
to perform automatic dubbing. Our architecture features neural machine
translation generating output of preferred length, prosodic alignment of the
translation with the original speech segments, neural text-to-speech with fine
tuning of the duration of each utterance, and, finally, audio rendering to
enriches text-to-speech output with background noise and reverberation
extracted from the original audio. We report on a subjective evaluation of
automatic dubbing of excerpts of TED Talks from English into Italian, which
measures the perceived naturalness of automatic dubbing and the relative
importance of each proposed enhancement.
</summary>
    <author>
      <name>Marcello Federico</name>
    </author>
    <author>
      <name>Robert Enyedi</name>
    </author>
    <author>
      <name>Roberto Barra-Chicote</name>
    </author>
    <author>
      <name>Ritwik Giri</name>
    </author>
    <author>
      <name>Umut Isik</name>
    </author>
    <author>
      <name>Arvindh Krishnaswamy</name>
    </author>
    <author>
      <name>Hassan Sawaf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06785v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06785v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06693v1</id>
    <updated>2020-01-18T15:38:04Z</updated>
    <published>2020-01-18T15:38:04Z</published>
    <title>Fair Transfer of Multiple Style Attributes in Text</title>
    <summary>  To preserve anonymity and obfuscate their identity on online platforms users
may morph their text and portray themselves as a different gender or
demographic. Similarly, a chatbot may need to customize its communication style
to improve engagement with its audience. This manner of changing the style of
written text has gained significant attention in recent years. Yet these past
research works largely cater to the transfer of single style attributes. The
disadvantage of focusing on a single style alone is that this often results in
target text where other existing style attributes behave unpredictably or are
unfairly dominated by the new style. To counteract this behavior, it would be
nice to have a style transfer mechanism that can transfer or control multiple
styles simultaneously and fairly. Through such an approach, one could obtain
obfuscated or written text incorporated with a desired degree of multiple soft
styles such as female-quality, politeness, or formalness.
  In this work, we demonstrate that the transfer of multiple styles cannot be
achieved by sequentially performing multiple single-style transfers. This is
because each single style-transfer step often reverses or dominates over the
style incorporated by a previous transfer step. We then propose a neural
network architecture for fairly transferring multiple style attributes in a
given text. We test our architecture on the Yelp data set to demonstrate our
superior performance as compared to existing one-style transfer steps performed
in a sequence.
</summary>
    <author>
      <name>Karan Dabas</name>
    </author>
    <author>
      <name>Nishtha Madan</name>
    </author>
    <author>
      <name>Vijay Arya</name>
    </author>
    <author>
      <name>Sameep Mehta</name>
    </author>
    <author>
      <name>Gautam Singh</name>
    </author>
    <author>
      <name>Tanmoy Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06674v1</id>
    <updated>2020-01-18T14:47:10Z</updated>
    <published>2020-01-18T14:47:10Z</published>
    <title>Ranking Significant Discrepancies in Clinical Reports</title>
    <summary>  Medical errors are a major public health concern and a leading cause of death
worldwide. Many healthcare centers and hospitals use reporting systems where
medical practitioners write a preliminary medical report and the report is
later reviewed, revised, and finalized by a more experienced physician. The
revisions range from stylistic to corrections of critical errors or
misinterpretations of the case. Due to the large quantity of reports written
daily, it is often difficult to manually and thoroughly review all the
finalized reports to find such errors and learn from them. To address this
challenge, we propose a novel ranking approach, consisting of textual and
ontological overlaps between the preliminary and final versions of reports. The
approach learns to rank the reports based on the degree of discrepancy between
the versions. This allows medical practitioners to easily identify and learn
from the reports in which their interpretation most substantially differed from
that of the attending physician (who finalized the report). This is a crucial
step towards uncovering potential errors and helping medical practitioners to
learn from such errors, thus improving patient-care in the long run. We
evaluate our model on a dataset of radiology reports and show that our approach
outperforms both previously-proposed approaches and more recent language models
by 4.5% to 15.4%.
</summary>
    <author>
      <name>Sean MacAvaney</name>
    </author>
    <author>
      <name>Arman Cohan</name>
    </author>
    <author>
      <name>Nazli Goharian</name>
    </author>
    <author>
      <name>Ross Filice</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2020 (short)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06629v2</id>
    <updated>2020-01-24T01:58:05Z</updated>
    <published>2020-01-18T09:04:42Z</published>
    <title>Capturing Evolution in Word Usage: Just Add More Clusters?</title>
    <summary>  The way the words are used evolves through time, mirroring cultural or
technological evolution of society. Semantic change detection is the task of
detecting and analysing word evolution in textual data, even in short periods
of time. In this paper we focus on a new set of methods relying on
contextualised embeddings, a type of semantic modelling that revolutionised the
NLP field recently. We leverage the ability of the transformer-based BERT model
to generate contextualised embeddings capable of detecting semantic change of
words across time. Several approaches are compared in a common setting in order
to establish strengths and weaknesses for each of them. We also propose several
ideas for improvements, managing to drastically improve the performance of
existing approaches.
</summary>
    <author>
      <name>Matej Martinc</name>
    </author>
    <author>
      <name>Syrielle Montariol</name>
    </author>
    <author>
      <name>Elaine Zosa</name>
    </author>
    <author>
      <name>Lidia Pivovarova</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06629v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06629v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06626v1</id>
    <updated>2020-01-18T08:18:19Z</updated>
    <published>2020-01-18T08:18:19Z</published>
    <title>Adaptive Parameterization for Neural Dialogue Generation</title>
    <summary>  Neural conversation systems generate responses based on the
sequence-to-sequence (SEQ2SEQ) paradigm. Typically, the model is equipped with
a single set of learned parameters to generate responses for given input
contexts. When confronting diverse conversations, its adaptability is rather
limited and the model is hence prone to generate generic responses. In this
work, we propose an {\bf Ada}ptive {\bf N}eural {\bf D}ialogue generation
model, \textsc{AdaND}, which manages various conversations with
conversation-specific parameterization. For each conversation, the model
generates parameters of the encoder-decoder by referring to the input context.
In particular, we propose two adaptive parameterization mechanisms: a
context-aware and a topic-aware parameterization mechanism. The context-aware
parameterization directly generates the parameters by capturing local semantics
of the given context. The topic-aware parameterization enables parameter
sharing among conversations with similar topics by first inferring the latent
topics of the given context and then generating the parameters with respect to
the distributional topics. Extensive experiments conducted on a large-scale
real-world conversational dataset show that our model achieves superior
performance in terms of both quantitative metrics and human evaluations.
</summary>
    <author>
      <name>Hengyi Cai</name>
    </author>
    <author>
      <name>Hongshen Chen</name>
    </author>
    <author>
      <name>Cheng Zhang</name>
    </author>
    <author>
      <name>Yonghao Song</name>
    </author>
    <author>
      <name>Xiaofang Zhao</name>
    </author>
    <author>
      <name>Dawei Yin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/D19-1188</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/D19-1188" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a long paper in EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06463v1</id>
    <updated>2020-01-17T18:27:29Z</updated>
    <published>2020-01-17T18:27:29Z</published>
    <title>Plato Dialogue System: A Flexible Conversational AI Research Platform</title>
    <summary>  As the field of Spoken Dialogue Systems and Conversational AI grows, so does
the need for tools and environments that abstract away implementation details
in order to expedite the development process, lower the barrier of entry to the
field, and offer a common test-bed for new ideas. In this paper, we present
Plato, a flexible Conversational AI platform written in Python that supports
any kind of conversational agent architecture, from standard architectures to
architectures with jointly-trained components, single- or multi-party
interactions, and offline or online training of any conversational agent
component. Plato has been designed to be easy to understand and debug and is
agnostic to the underlying learning frameworks that train each component.
</summary>
    <author>
      <name>Alexandros Papangelis</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Yi-Chia Wang</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06381v1</id>
    <updated>2020-01-17T15:42:29Z</updated>
    <published>2020-01-17T15:42:29Z</published>
    <title>A Common Semantic Space for Monolingual and Cross-Lingual
  Meta-Embeddings</title>
    <summary>  This paper presents a new technique for creating monolingual and
cross-lingual meta-embeddings. Our method integrates multiple word embeddings
created from complementary techniques, textual sources, knowledge bases and
languages. Existing word vectors are projected to a common semantic space using
linear transformations and averaging. With our method the resulting
meta-embeddings maintain the dimensionality of the original embeddings without
losing information while dealing with the out-of-vocabulary problem. An
extensive empirical evaluation demonstrates the effectiveness of our technique
with respect to previous work on various intrinsic and extrinsic multilingual
evaluations, obtaining competitive results for Semantic Textual Similarity and
state-of-the-art performance for word similarity and POS tagging (English and
Spanish). The resulting cross-lingual meta-embeddings also exhibit excellent
cross-lingual transfer learning capabilities. In other words, we can leverage
pre-trained source embeddings from a resource-rich language in order to improve
the word representations for under-resourced languages.
</summary>
    <author>
      <name>Iker García</name>
    </author>
    <author>
      <name>Rodrigo Agerri</name>
    </author>
    <author>
      <name>German Rigau</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11381v1</id>
    <updated>2020-01-17T15:42:14Z</updated>
    <published>2020-01-17T15:42:14Z</published>
    <title>Generación automática de frases literarias en español</title>
    <summary>  In this work we present a state of the art in the area of Computational
Creativity (CC). In particular, we address the automatic generation of literary
sentences in Spanish. We propose three models of text generation based mainly
on statistical algorithms and shallow parsing analysis. We also present some
rather encouraging preliminary results.
</summary>
    <author>
      <name>Luis-Gil Moreno-Jiménez</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Roseli S. Wedemann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, in Spanish, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06354v1</id>
    <updated>2020-01-17T14:57:12Z</updated>
    <published>2020-01-17T14:57:12Z</published>
    <title>Modality-Balanced Models for Visual Dialogue</title>
    <summary>  The Visual Dialog task requires a model to exploit both image and
conversational context information to generate the next response to the
dialogue. However, via manual analysis, we find that a large number of
conversational questions can be answered by only looking at the image without
any access to the context history, while others still need the conversation
context to predict the correct answers. We demonstrate that due to this reason,
previous joint-modality (history and image) models over-rely on and are more
prone to memorizing the dialogue history (e.g., by extracting certain keywords
or patterns in the context information), whereas image-only models are more
generalizable (because they cannot memorize or extract keywords from history)
and perform substantially better at the primary normalized discounted
cumulative gain (NDCG) task metric which allows multiple correct answers.
Hence, this observation encourages us to explicitly maintain two models, i.e.,
an image-only model and an image-history joint model, and combine their
complementary abilities for a more balanced multimodal model. We present
multiple methods for this integration of the two models, via ensemble and
consensus dropout fusion with shared parameters. Empirically, our models
achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and
high balance across metrics), and substantially outperform the winner of the
Visual Dialog challenge 2018 on most metrics.
</summary>
    <author>
      <name>Hyounghun Kim</name>
    </author>
    <author>
      <name>Hao Tan</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (11 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06286v1</id>
    <updated>2020-01-17T13:25:44Z</updated>
    <published>2020-01-17T13:25:44Z</published>
    <title>RobBERT: a Dutch RoBERTa-based Language Model</title>
    <summary>  Pre-trained language models have been dominating the field of natural
language processing in recent years, and have led to significant performance
gains for various complex natural language tasks. One of the most prominent
pre-trained language models is BERT (Bi-directional Encoders for Transformers),
which was released as an English as well as a multilingual version. Although
multilingual BERT performs well on many tasks, recent studies showed that BERT
models trained on a single language significantly outperform the multilingual
results. Training a Dutch BERT model thus has a lot of potential for a wide
range of Dutch NLP tasks. While previous approaches have used earlier
implementations of BERT to train their Dutch BERT, we used RoBERTa, a robustly
optimized BERT approach, to train a Dutch language model called RobBERT. We
show that RobBERT improves state of the art results in Dutch-specific language
tasks, and also outperforms other existing Dutch BERT-based models in sentiment
analysis. These results indicate that RobBERT is a powerful pre-trained model
for fine-tuning for a large variety of Dutch language tasks. We publicly
release this pre-trained model in hope of supporting further downstream Dutch
NLP applications.
</summary>
    <author>
      <name>Pieter Delobelle</name>
    </author>
    <author>
      <name>Thomas Winters</name>
    </author>
    <author>
      <name>Bettina Berendt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06206v1</id>
    <updated>2020-01-17T09:18:00Z</updated>
    <published>2020-01-17T09:18:00Z</published>
    <title>Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue
  System</title>
    <summary>  Understanding dynamic scenes and dialogue contexts in order to converse with
users has been challenging for multimodal dialogue systems. The 8-th Dialog
System Technology Challenge (DSTC8) proposed an Audio Visual Scene-Aware Dialog
(AVSD) task, which contains multiple modalities including audio, vision, and
language, to evaluate how dialogue systems understand different modalities and
response to users. In this paper, we proposed a multi-step joint-modality
attention network (JMAN) based on recurrent neural network (RNN) to reason on
videos. Our model performs a multi-step attention mechanism and jointly
considers both visual and textual representations in each reasoning process to
better integrate information from the two different modalities. Compared to the
baseline released by AVSD organizers, our model achieves a relative 12.1% and
22.4% improvement over the baseline on ROUGE-L score and CIDEr score.
</summary>
    <author>
      <name>Yun-Wei Chu</name>
    </author>
    <author>
      <name>Kuan-Yen Lin</name>
    </author>
    <author>
      <name>Chao-Chun Hsu</name>
    </author>
    <author>
      <name>Lun-Wei Ku</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">DSTC8 collocated with AAAI2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06007v1</id>
    <updated>2020-01-16T18:06:43Z</updated>
    <published>2020-01-16T18:06:43Z</published>
    <title>User-in-the-loop Adaptive Intent Detection for Instructable Digital
  Assistant</title>
    <summary>  People are becoming increasingly comfortable using Digital Assistants (DAs)
to interact with services or connected objects. However, for non-programming
users, the available possibilities for customizing their DA are limited and do
not include the possibility of teaching the assistant new tasks. To make the
most of the potential of DAs, users should be able to customize assistants by
instructing them through Natural Language (NL). To provide such
functionalities, NL interpretation in traditional assistants should be
improved: (1) The intent identification system should be able to recognize new
forms of known intents, and to acquire new intents as they are expressed by the
user. (2) In order to be adaptive to novel intents, the Natural Language
Understanding module should be sample efficient, and should not rely on a
pretrained model. Rather, the system should continuously collect the training
data as it learns new intents from the user. In this work, we propose AidMe
(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop
adaptive intent detection framework that allows the assistant to adapt to its
user by learning his intents as their interaction progresses. AidMe builds its
repertoire of intents and collects data to train a model of semantic similarity
evaluation that can discriminate between the learned intents and autonomously
discover new forms of known intents. AidMe addresses two major issues - intent
learning and user adaptation - for instructable digital assistants. We
demonstrate the capabilities of AidMe as a standalone system by comparing it
with a one-shot learning system and a pretrained NLU module through simulations
of interactions with a user. We also show how AidMe can smoothly integrate to
an existing instructable digital assistant.
</summary>
    <author>
      <name>Nicolas Lair</name>
    </author>
    <author>
      <name>Clément Delgrange</name>
    </author>
    <author>
      <name>David Mugisha</name>
    </author>
    <author>
      <name>Jean-Michel Dussoux</name>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <author>
      <name>Peter Ford Dominey</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3377325.3377490</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3377325.3377490" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published as a conference paper in the proceedings of IUI'20</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">25th International Conference on Intelligent User Interfaces (IUI
  '20), March 17--20, 2020, Cagliari, Italy</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.06007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05970v1</id>
    <updated>2020-01-16T18:05:46Z</updated>
    <published>2020-01-16T18:05:46Z</published>
    <title>#MeToo on Campus: Studying College Sexual Assault at Scale Using Data
  Reported on Social Media</title>
    <summary>  Recently, the emergence of the #MeToo trend on social media has empowered
thousands of people to share their own sexual harassment experiences. This
viral trend, in conjunction with the massive personal information and content
available on Twitter, presents a promising opportunity to extract data driven
insights to complement the ongoing survey based studies about sexual harassment
in college. In this paper, we analyze the influence of the #MeToo trend on a
pool of college followers. The results show that the majority of topics
embedded in those #MeToo tweets detail sexual harassment stories, and there
exists a significant correlation between the prevalence of this trend and
official reports on several major geographical regions. Furthermore, we
discover the outstanding sentiments of the #MeToo tweets using deep semantic
meaning representations and their implications on the affected users
experiencing different types of sexual harassment. We hope this study can raise
further awareness regarding sexual misconduct in academia.
</summary>
    <author>
      <name>Viet Duong</name>
    </author>
    <author>
      <name>Phu Pham</name>
    </author>
    <author>
      <name>Ritwik Bose</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05970v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05970v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05954v1</id>
    <updated>2020-01-16T17:30:36Z</updated>
    <published>2020-01-16T17:30:36Z</published>
    <title>Lexical Sememe Prediction using Dictionary Definitions by Capturing
  Local Semantic Correspondence</title>
    <summary>  Sememes, defined as the minimum semantic units of human languages in
linguistics, have been proven useful in many NLP tasks. Since manual
construction and update of sememe knowledge bases (KBs) are costly, the task of
automatic sememe prediction has been proposed to assist sememe annotation. In
this paper, we explore the approach of applying dictionary definitions to
predicting sememes for unannotated words. We find that sememes of each word are
usually semantically matched to different words in its dictionary definition,
and we name this matching relationship local semantic correspondence.
Accordingly, we propose a Sememe Correspondence Pooling (SCorP) model, which is
able to capture this kind of matching to predict sememes. We evaluate our model
and baseline methods on a famous sememe KB HowNet and find that our model
achieves state-of-the-art performance. Moreover, further quantitative analysis
shows that our model can properly learn the local semantic correspondence
between sememes and words in dictionary definitions, which explains the
effectiveness of our model. The source codes of this paper can be obtained from
https://github.com/thunlp/scorp.
</summary>
    <author>
      <name>Jiaju Du</name>
    </author>
    <author>
      <name>Fanchao Qi</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by Journal of Chinese Information Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05954v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05954v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05908v1</id>
    <updated>2020-01-16T15:53:13Z</updated>
    <published>2020-01-16T15:53:13Z</published>
    <title>Speech Emotion Recognition Based on Multi-feature and Multi-lingual
  Fusion</title>
    <summary>  A speech emotion recognition algorithm based on multi-feature and
Multi-lingual fusion is proposed in order to resolve low recognition accuracy
caused by lack of large speech dataset and low robustness of acoustic features
in the recognition of speech emotion. First, handcrafted and deep automatic
features are extracted from existing data in Chinese and English speech
emotions. Then, the various features are fused respectively. Finally, the fused
features of different languages are fused again and trained in a classification
model. Distinguishing the fused features with the unfused ones, the results
manifest that the fused features significantly enhance the accuracy of speech
emotion recognition algorithm. The proposed solution is evaluated on the two
Chinese corpus and two English corpus, and is shown to provide more accurate
predictions compared to original solution. As a result of this study, the
multi-feature and Multi-lingual fusion algorithm can significantly improve the
speech emotion recognition accuracy when the dataset is small.
</summary>
    <author>
      <name>Chunyi Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05727v1</id>
    <updated>2020-01-16T10:16:37Z</updated>
    <published>2020-01-16T10:16:37Z</published>
    <title>Document Network Projection in Pretrained Word Embedding Space</title>
    <summary>  We present Regularized Linear Embedding (RLE), a novel method that projects a
collection of linked documents (e.g. citation network) into a pretrained word
embedding space. In addition to the textual content, we leverage a matrix of
pairwise similarities providing complementary information (e.g., the network
proximity of two documents in a citation graph). We first build a simple word
vector average for each document, and we use the similarities to alter this
average representation. The document representations can help to solve many
information retrieval tasks, such as recommendation, classification and
clustering. We demonstrate that our approach outperforms or matches existing
document network embedding methods on node classification and link prediction
tasks. Furthermore, we show that it helps identifying relevant keywords to
describe document classes.
</summary>
    <author>
      <name>Antoine Gourru</name>
    </author>
    <author>
      <name>Adrien Guille</name>
    </author>
    <author>
      <name>Julien Velcin</name>
    </author>
    <author>
      <name>Julien Jacques</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05714v1</id>
    <updated>2020-01-16T09:42:29Z</updated>
    <published>2020-01-16T09:42:29Z</published>
    <title>Comparing Rule-based, Feature-based and Deep Neural Methods for
  De-identification of Dutch Medical Records</title>
    <summary>  Unstructured information in electronic health records provide an invaluable
resource for medical research. To protect the confidentiality of patients and
to conform to privacy regulations, de-identification methods automatically
remove personally identifying information from these medical records. However,
due to the unavailability of labeled data, most existing research is
constrained to English medical text and little is known about the
generalizability of de-identification methods across languages and domains. In
this study, we construct a varied dataset consisting of the medical records of
1260 patients by sampling data from 9 institutes and three domains of Dutch
healthcare. We test the generalizability of three de-identification methods
across languages and domains. Our experiments show that an existing rule-based
method specifically developed for the Dutch language fails to generalize to
this new data. Furthermore, a state-of-the-art neural architecture performs
strongly across languages and domains, even with limited training data.
Compared to feature-based and rule-based methods the neural method requires
significantly less configuration effort and domain-knowledge. We make all code
and pre-trained de-identification models available to the research community,
allowing practitioners to apply them to their datasets and to enable future
benchmarks.
</summary>
    <author>
      <name>Jan Trienes</name>
    </author>
    <author>
      <name>Dolf Trieschnigg</name>
    </author>
    <author>
      <name>Christin Seifert</name>
    </author>
    <author>
      <name>Djoerd Hiemstra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 1st ACM WSDM Health Search and Data Mining
  Workshop (HSDM2020), 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11382v1</id>
    <updated>2020-01-16T08:38:40Z</updated>
    <published>2020-01-16T08:38:40Z</published>
    <title>Intweetive Text Summarization</title>
    <summary>  The amount of user generated contents from various social medias allows
analyst to handle a wide view of conversations on several topics related to
their business. Nevertheless keeping up-to-date with this amount of information
is not humanly feasible. Automatic Summarization then provides an interesting
mean to digest the dynamics and the mass volume of contents. In this paper, we
address the issue of tweets summarization which remains scarcely explored. We
propose to automatically generated summaries of Micro-Blogs conversations
dealing with public figures E-Reputation. These summaries are generated using
key-word queries or sample tweet and offer a focused view of the whole
Micro-Blog network. Since state-of-the-art is lacking on this point we conduct
and evaluate our experiments over the multilingual CLEF RepLab Topic-Detection
dataset according to an experimental evaluation process.
</summary>
    <author>
      <name>Jean Valère Cossu</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Eric SanJuan</name>
    </author>
    <author>
      <name>Marc El-Bèze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computational Linguistics and
  Applications vol. 7, no. 1, 2016, pp. 67-83</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.11382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05687v2</id>
    <updated>2020-03-10T10:07:39Z</updated>
    <published>2020-01-16T08:09:51Z</published>
    <title>A Pilot Study on Multiple Choice Machine Reading Comprehension for
  Vietnamese Texts</title>
    <summary>  Machine Reading Comprehension (MRC) is the task of natural language
processing that studies the ability to read and understand unstructured texts
and then find the correct answers for questions. Until now, we have not yet had
any MRC dataset for such a low-resource language as Vietnamese. In this paper,
we introduce ViMMRC, a challenging machine comprehension corpus with
multiple-choice questions, intended for research on the machine comprehension
of Vietnamese text. This corpus includes 2,783 multiple-choice questions and
answers based on a set of 417 Vietnamese texts used for teaching reading
comprehension for 1st to 5th graders. Answers may be extracted from the
contents of single or multiple sentences in the corresponding reading text. A
thorough analysis of the corpus and experimental results in this paper
illustrate that our corpus ViMMRC demands reasoning abilities beyond simple
word matching. We proposed the method of Boosted Sliding Window (BSW) that
improves 5.51% in accuracy over the best baseline method. We also measured
human performance on the corpus and compared it to our MRC models. The
performance gap between humans and our best experimental model indicates that
significant progress can be made on Vietnamese machine reading comprehension in
further research. The corpus is freely available at our website for research
purposes.
</summary>
    <author>
      <name>Kiet Van Nguyen</name>
    </author>
    <author>
      <name>Khiem Vinh Tran</name>
    </author>
    <author>
      <name>Son T. Luu</name>
    </author>
    <author>
      <name>Anh Gia-Tuan Nguyen</name>
    </author>
    <author>
      <name>Ngan Luu-Thuy Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Computer Speech &amp; Language, March 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05687v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05687v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11383v2</id>
    <updated>2020-02-03T01:52:51Z</updated>
    <published>2020-01-16T07:30:19Z</published>
    <title>Fact-aware Sentence Split and Rephrase with Permutation Invariant
  Training</title>
    <summary>  Sentence Split and Rephrase aims to break down a complex sentence into
several simple sentences with its meaning preserved. Previous studies tend to
address the issue by seq2seq learning from parallel sentence pairs, which takes
a complex sentence as input and sequentially generates a series of simple
sentences. However, the conventional seq2seq learning has two limitations for
this task: (1) it does not take into account the facts stated in the long
sentence; As a result, the generated simple sentences may miss or inaccurately
state the facts in the original sentence. (2) The order variance of the simple
sentences to be generated may confuse the seq2seq model during training because
the simple sentences derived from the long source sentence could be in any
order.
  To overcome the challenges, we first propose the Fact-aware Sentence
Encoding, which enables the model to learn facts from the long sentence and
thus improves the precision of sentence split; then we introduce Permutation
Invariant Training to alleviate the effects of order variance in seq2seq
learning for this task. Experiments on the WebSplit-v1.0 benchmark dataset show
that our approaches can largely improve the performance over the previous
seq2seq learning approaches. Moreover, an extrinsic evaluation on oie-benchmark
verifies the effectiveness of our approaches by an observation that splitting
long sentences with our state-of-the-art model as preprocessing is helpful for
improving OpenIE performance.
</summary>
    <author>
      <name>Yinuo Guo</name>
    </author>
    <author>
      <name>Tao Ge</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11383v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11383v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05672v1</id>
    <updated>2020-01-16T06:31:53Z</updated>
    <published>2020-01-16T06:31:53Z</published>
    <title>AandP: Utilizing Prolog for converting between active sentence and
  passive sentence with three-steps conversion</title>
    <summary>  I introduce a simple but efficient method to solve one of the critical
aspects of English grammar which is the relationship between active sentence
and passive sentence. In fact, an active sentence and its corresponding passive
sentence express the same meaning, but their structure is different. I utilized
Prolog [4] along with Definite Clause Grammars (DCG) [5] for doing the
conversion between active sentence and passive sentence. Some advanced
techniques were also used such as Extra Arguments, Extra Goals, Lexicon, etc. I
tried to solve a variety of cases of active and passive sentences such as 12
English tenses, modal verbs, negative form, etc. More details and my
contributions will be presented in the following sections. The source code is
available at https://github.com/tqtrunghnvn/ActiveAndPassive.
</summary>
    <author>
      <name>Trung Q. Tran</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10980v1</id>
    <updated>2020-01-16T03:39:00Z</updated>
    <published>2020-01-16T03:39:00Z</published>
    <title>Multimodal Story Generation on Plural Images</title>
    <summary>  Traditionally, text generation models take in a sequence of text as input,
and iteratively generate the next most probable word using pre-trained
parameters. In this work, we propose the architecture to use images instead of
text as the input of the text generation model, called StoryGen. In the
architecture, we design a Relational Text Data Generator algorithm that relates
different features from multiple images. The output samples from the model
demonstrate the ability to generate meaningful paragraphs of text containing
the extracted features from the input images.
</summary>
    <author>
      <name>Jing Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05614v3</id>
    <updated>2020-02-15T01:31:21Z</updated>
    <published>2020-01-16T02:18:27Z</published>
    <title>Delving Deeper into the Decoder for Video Captioning</title>
    <summary>  Video captioning is an advanced multi-modal task which aims to describe a
video clip using a natural language sentence. The encoder-decoder framework is
the most popular paradigm for this task in recent years. However, there exist
some problems in the decoder of a video captioning model. We make a thorough
investigation into the decoder and adopt three techniques to improve the
performance of the model. First of all, a combination of variational dropout
and layer normalization is embedded into a recurrent unit to alleviate the
problem of overfitting. Secondly, a new online method is proposed to evaluate
the performance of a model on a validation set so as to select the best
checkpoint for testing. Finally, a new training strategy called professional
learning is proposed which uses the strengths of a captioning model and
bypasses its weaknesses. It is demonstrated in the experiments on Microsoft
Research Video Description Corpus (MSVD) and MSR-Video to Text (MSR-VTT)
datasets that our model has achieved the best results evaluated by BLEU, CIDEr,
METEOR and ROUGE-L metrics with significant gains of up to 18% on MSVD and 3.5%
on MSR-VTT compared with the previous state-of-the-art models.
</summary>
    <author>
      <name>Haoran Chen</name>
    </author>
    <author>
      <name>Jianmin Li</name>
    </author>
    <author>
      <name>Xiaolin Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, European Conference on Artificial Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05614v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05614v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T45, 68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05609v2</id>
    <updated>2020-01-27T20:32:49Z</updated>
    <published>2020-01-16T01:49:16Z</published>
    <title>Schema2QA: Answering Complex Queries on the Structured Web with a Neural
  Model</title>
    <summary>  Virtual assistants have proprietary third-party skill platforms; they train
and own the voice interface to websites based on their submitted skill
information. This paper proposes Schema2QA, an open-source toolkit that
leverages the Schema.org markup found in many websites to automatically build
skills. Schema2QA has several advantages: (1) Schema2QA is more accurate than
commercial assistants in answering compositional queries involving multiple
properties; (2) it has a low-cost training data acquisition methodology that
requires only writing a small number of annotations per domain and paraphrasing
a small number of sentences. Schema2QA uses a novel neural model that combines
the BERT pretrained model with an LSTM; the model can generalize a training set
containing only synthesized and paraphrase data to understand real-world
crowdsourced questions. We apply Schema2QA to two different domains, showing
that the skills we built can answer useful queries with little manual effort.
Our skills achieve an overall accuracy between 73% and 81%. With transfer
learning, we show that a new domain can achieve a 59% accuracy without manual
effort. The open-source Schema2QA lets each website create and own its
linguistic interface.
</summary>
    <author>
      <name>Silei Xu</name>
    </author>
    <author>
      <name>Giovanni Campagna</name>
    </author>
    <author>
      <name>Jian Li</name>
    </author>
    <author>
      <name>Monica S. Lam</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05609v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05609v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05540v1</id>
    <updated>2020-01-15T20:26:48Z</updated>
    <published>2020-01-15T20:26:48Z</published>
    <title>Insertion-Deletion Transformer</title>
    <summary>  We propose the Insertion-Deletion Transformer, a novel transformer-based
neural architecture and training method for sequence generation. The model
consists of two phases that are executed iteratively, 1) an insertion phase and
2) a deletion phase. The insertion phase parameterizes a distribution of
insertions on the current output hypothesis, while the deletion phase
parameterizes a distribution of deletions over the current output hypothesis.
The training method is a principled and simple algorithm, where the deletion
model obtains its signal directly on-policy from the insertion model output. We
demonstrate the effectiveness of our Insertion-Deletion Transformer on
synthetic translation tasks, obtaining significant BLEU score improvement over
an insertion-only model.
</summary>
    <author>
      <name>Laura Ruis</name>
    </author>
    <author>
      <name>Mitchell Stern</name>
    </author>
    <author>
      <name>Julia Proskurnia</name>
    </author>
    <author>
      <name>William Chan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as an Extended Abstract at the Workshop of Neural Generation
  and Translation (WNGT 2019) at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05467v1</id>
    <updated>2020-01-15T18:32:06Z</updated>
    <published>2020-01-15T18:32:06Z</published>
    <title>AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses</title>
    <summary>  Many sequence-to-sequence dialogue models tend to generate safe,
uninformative responses. There have been various useful efforts on trying to
eliminate them. However, these approaches either improve decoding algorithms
during inference, rely on hand-crafted features, or employ complex models. In
our work, we build dialogue models that are dynamically aware of what
utterances or tokens are dull without any feature-engineering. Specifically, we
start with a simple yet effective automatic metric, AvgOut, which calculates
the average output probability distribution of all time steps on the decoder
side during training. This metric directly estimates which tokens are more
likely to be generated, thus making it a faithful evaluation of the model
diversity (i.e., for diverse models, the token probabilities should be more
evenly distributed rather than peaked at a few dull tokens). We then leverage
this novel metric to propose three models that promote diversity without losing
relevance. The first model, MinAvgOut, directly maximizes the diversity score
through the output distributions of each batch; the second model, Label
Fine-Tuning (LFT), prepends to the source sequence a label continuously scaled
by the diversity score to control the diversity level; the third model, RL,
adopts Reinforcement Learning and treats the diversity score as a reward
signal. Moreover, we experiment with a hybrid model by combining the loss terms
of MinAvgOut and RL. All four models outperform their base LSTM-RNN model on
both diversity and relevance by a large margin, and are comparable to or better
than competitive baselines (also verified via human evaluation). Moreover, our
approaches are orthogonal to the base model, making them applicable as an
add-on to other emerging better dialogue models in the future.
</summary>
    <author>
      <name>Tong Niu</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (8 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05495v1</id>
    <updated>2020-01-15T18:17:36Z</updated>
    <published>2020-01-15T18:17:36Z</published>
    <title>Stereotypical Bias Removal for Hate Speech Detection Task using
  Knowledge-based Generalizations</title>
    <summary>  With the ever-increasing cases of hate spread on social media platforms, it
is critical to design abuse detection mechanisms to proactively avoid and
control such incidents. While there exist methods for hate speech detection,
they stereotype words and hence suffer from inherently biased training. Bias
removal has been traditionally studied for structured datasets, but we aim at
bias mitigation from unstructured text data. In this paper, we make two
important contributions. First, we systematically design methods to quantify
the bias for any model and propose algorithms for identifying the set of words
which the model stereotypes. Second, we propose novel methods leveraging
knowledge-based generalizations for bias-free learning. Knowledge-based
generalization provides an effective way to encode knowledge because the
abstraction they provide not only generalizes content but also facilitates
retraction of information from the hate speech detection classifier, thereby
reducing the imbalance. We experiment with multiple knowledge generalization
policies and analyze their effect on general performance and in mitigating
bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages
dataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that
the use of knowledge-based generalizations results in better performance by
forcing the classifier to learn from generalized content. Our methods utilize
existing knowledge-bases and can easily be extended to other tasks
</summary>
    <author>
      <name>Pinkesh Badjatiya</name>
    </author>
    <author>
      <name>Manish Gupta</name>
    </author>
    <author>
      <name>Vasudeva Varma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313504</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313504" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In The World Wide Web Conference (WWW '19). Association for
  Computing Machinery, New York, NY, USA, 49-59. 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.05495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05493v2</id>
    <updated>2020-01-18T06:50:54Z</updated>
    <published>2020-01-15T17:06:29Z</published>
    <title>A Unified System for Aggression Identification in English Code-Mixed and
  Uni-Lingual Texts</title>
    <summary>  Wide usage of social media platforms has increased the risk of aggression,
which results in mental stress and affects the lives of people negatively like
psychological agony, fighting behavior, and disrespect to others. Majority of
such conversations contains code-mixed languages[28]. Additionally, the way
used to express thought or communication style also changes from one social
media plat-form to another platform (e.g., communication styles are different
in twitter and Facebook). These all have increased the complexity of the
problem. To solve these problems, we have introduced a unified and robust
multi-modal deep learning architecture which works for English code-mixed
dataset and uni-lingual English dataset both.The devised system, uses
psycho-linguistic features and very ba-sic linguistic features. Our multi-modal
deep learning architecture contains, Deep Pyramid CNN, Pooled BiLSTM, and
Disconnected RNN(with Glove and FastText embedding, both). Finally, the system
takes the decision based on model averaging. We evaluated our system on English
Code-Mixed TRAC 2018 dataset and uni-lingual English dataset obtained from
Kaggle. Experimental results show that our proposed system outperforms all the
previous approaches on English code-mixed dataset and uni-lingual English
dataset.
</summary>
    <author>
      <name>Anant Khandelwal</name>
    </author>
    <author>
      <name>Niraj Kumar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3371158.3371165</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3371158.3371165" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 Figures, 6 Tables, accepted at CoDS-COMAD 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05493v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05493v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05876v1</id>
    <updated>2020-01-15T16:32:51Z</updated>
    <published>2020-01-15T16:32:51Z</published>
    <title>Show, Recall, and Tell: Image Captioning with Recall Mechanism</title>
    <summary>  Generating natural and accurate descriptions in image cap-tioning has always
been a challenge. In this paper, we pro-pose a novel recall mechanism to
imitate the way human con-duct captioning. There are three parts in our recall
mecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS).
Recall unit is a text-retrieval module designedto retrieve recalled words for
images. SG and RWS are de-signed for the best use of recalled words. SG branch
cangenerate a recalled context, which can guide the process ofgenerating
caption. RWS branch is responsible for copyingrecalled words to the caption.
Inspired by pointing mecha-nism in text summarization, we adopt a soft switch
to balancethe generated-word probabilities between SG and RWS. Inthe CIDEr
optimization step, we also introduce an individualrecalled-word reward (WR) to
boost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr /
SPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 /
22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the
results of other state-of-the-artmethods.
</summary>
    <author>
      <name>Li Wang</name>
    </author>
    <author>
      <name>Zechen Bai</name>
    </author>
    <author>
      <name>Yonghua Zhang</name>
    </author>
    <author>
      <name>Hongtao Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05320v1</id>
    <updated>2020-01-15T13:35:19Z</updated>
    <published>2020-01-15T13:35:19Z</published>
    <title>A Tree Adjoining Grammar Representation for Models Of Stochastic
  Dynamical Systems</title>
    <summary>  Model structure and complexity selection remains a challenging problem in
system identification, especially for parametric non-linear models. Many
Evolutionary Algorithm (EA) based methods have been proposed in the literature
for estimating model structure and complexity. In most cases, the proposed
methods are devised for estimating structure and complexity within a specified
model class and hence these methods do not extend to other model structures
without significant changes. In this paper, we propose a Tree Adjoining Grammar
(TAG) for stochastic parametric models. TAGs can be used to generate models in
an EA framework while imposing desirable structural constraints and
incorporating prior knowledge. In this paper, we propose a TAG that can
systematically generate models ranging from FIRs to polynomial NARMAX models.
Furthermore, we demonstrate that TAGs can be easily extended to more general
model classes, such as the non-linear Box-Jenkins model class, enabling the
realization of flexible and automatic model structure and complexity selection
via EA.
</summary>
    <author>
      <name>Dhruv Khandelwal</name>
    </author>
    <author>
      <name>Maarten Schoukens</name>
    </author>
    <author>
      <name>Roland Tóth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted as brief paper to Automatica</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05272v2</id>
    <updated>2020-02-14T15:58:51Z</updated>
    <published>2020-01-15T12:39:20Z</published>
    <title>FGN: Fusion Glyph Network for Chinese Named Entity Recognition</title>
    <summary>  Chinese NER is a challenging task. As pictographs, Chinese characters contain
latent glyph information, which is often overlooked. We propose the FGN, Fusion
Glyph Network for Chinese NER. This method may offer glyph information for
fusion representation learning with BERT. The major innovations of FGN include:
(1) a novel CNN structure called CGS-CNN is proposed to capture glyph
information from both character graphs and their neighboring graphs. (2) we
provide a method with sliding window and Slice-Attention to extract interactive
information between BERT representation and glyph representation. Experiments
are conducted on four NER datasets, showing that FGN with LSTM-CRF as tagger
achieves new state-of-the-arts performance for Chinese NER. Further, more
experiments are conducted to investigate the influences of various components
and settings in FGN.
</summary>
    <author>
      <name>Zhenyu Xuan</name>
    </author>
    <author>
      <name>Rui Bao</name>
    </author>
    <author>
      <name>Chuyu Ma</name>
    </author>
    <author>
      <name>Shengyi Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05272v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05272v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05865v1</id>
    <updated>2020-01-15T08:20:54Z</updated>
    <published>2020-01-15T08:20:54Z</published>
    <title>Ensemble based discriminative models for Visual Dialog Challenge 2018</title>
    <summary>  This manuscript describes our approach for the Visual Dialog Challenge 2018.
We use an ensemble of three discriminative models with different encoders and
decoders for our final submission. Our best performing model on 'test-std'
split achieves the NDCG score of 55.46 and the MRR value of 63.77, securing
third position in the challenge.
</summary>
    <author>
      <name>Shubham Agarwal</name>
    </author>
    <author>
      <name>Raghav Goyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Rankings: https://visualdialog.org/challenge/2018#winners</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05171v1</id>
    <updated>2020-01-15T08:19:01Z</updated>
    <published>2020-01-15T08:19:01Z</published>
    <title>Teddy: A System for Interactive Review Analysis</title>
    <summary>  Reviews are integral to e-commerce services and products. They contain a
wealth of information about the opinions and experiences of users, which can
help better understand consumer decisions and improve user experience with
products and services. Today, data scientists analyze reviews by developing
rules and models to extract, aggregate, and understand information embedded in
the review text. However, working with thousands of reviews, which are
typically noisy incomplete text, can be daunting without proper tools. Here we
first contribute results from an interview study that we conducted with fifteen
data scientists who work with review text, providing insights into their
practices and challenges. Results suggest data scientists need interactive
systems for many review analysis tasks. In response we introduce Teddy, an
interactive system that enables data scientists to quickly obtain insights from
reviews and improve their extraction and modeling pipelines.
</summary>
    <author>
      <name>Xiong Zhang</name>
    </author>
    <author>
      <name>Jonathan Engel</name>
    </author>
    <author>
      <name>Sara Evensen</name>
    </author>
    <author>
      <name>Yuliang Li</name>
    </author>
    <author>
      <name>Çağatay Demiralp</name>
    </author>
    <author>
      <name>Wang-Chiew Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CHI'20</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05139v1</id>
    <updated>2020-01-15T05:42:27Z</updated>
    <published>2020-01-15T05:42:27Z</published>
    <title>A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation</title>
    <summary>  Story generation, namely generating a reasonable story from a leading
context, is an important but challenging task. In spite of the success in
modeling fluency and local coherence, existing neural language generation
models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of
long-range coherence in generated stories. We conjecture that this is because
of the difficulty of associating relevant commonsense knowledge, understanding
the causal relationships, and planning entities and events with proper temporal
order. In this paper, we devise a knowledge-enhanced pretraining model for
commonsense story generation. We propose to utilize commonsense knowledge from
external knowledge bases to generate reasonable stories. To further capture the
causal and temporal dependencies between the sentences in a reasonable story,
we employ multi-task learning which combines a discriminative objective to
distinguish true and fake stories during fine-tuning. Automatic and manual
evaluation shows that our model can generate more reasonable stories than
state-of-the-art baselines, particularly in terms of logic and global
coherence.
</summary>
    <author>
      <name>Jian Guan</name>
    </author>
    <author>
      <name>Fei Huang</name>
    </author>
    <author>
      <name>Zhihao Zhao</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accept at Transactions of the Association for Computational
  Linguistics 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05136v1</id>
    <updated>2020-01-15T05:32:18Z</updated>
    <published>2020-01-15T05:32:18Z</published>
    <title>Parallel Machine Translation with Disentangled Context Transformer</title>
    <summary>  State-of-the-art neural machine translation models generate a translation
from left to right and every step is conditioned on the previously generated
tokens. The sequential nature of this generation process causes fundamental
latency in inference since we cannot generate multiple tokens in each sentence
in parallel. We propose an attention-masking based model, called Disentangled
Context (DisCo) transformer, that simultaneously generates all tokens given
different contexts. The DisCo transformer is trained to predict every output
token given an arbitrary subset of the other reference tokens. We also develop
the parallel easy-first inference algorithm, which iteratively refines every
token in parallel and reduces the number of required iterations. Our extensive
experiments on 7 directions with varying data sizes demonstrate that our model
achieves competitive, if not better, performance compared to the state of the
art in non-autoregressive machine translation while significantly reducing
decoding time on average.
</summary>
    <author>
      <name>Jungo Kasai</name>
    </author>
    <author>
      <name>James Cross</name>
    </author>
    <author>
      <name>Marjan Ghazvininejad</name>
    </author>
    <author>
      <name>Jiatao Gu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06350v1</id>
    <updated>2020-01-14T22:37:21Z</updated>
    <published>2020-01-14T22:37:21Z</published>
    <title>A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat
  Groups</title>
    <summary>  To predict the next most likely participant to interact in a multi-party
conversation is a difficult problem. In a text-based chat group, the only
information available is the sender, the content of the text and the dialogue
history. In this paper we present our study on how these information can be
used on the prediction task through a corpus and architecture that integrates
turn-taking classifiers based on Maximum Likelihood Expectation (MLE),
Convolutional Neural Networks (CNN) and Finite State Automata (FSA). The corpus
is a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset (MultiWOZ)
to a multiple travel service-based bots scenario with dialogue errors and was
created to simulate user's interaction and evaluate the architecture. We
present experimental results which show that the CNN approach achieves better
performance than the baseline with an accuracy of 92.34%, but the integrated
solution with MLE, CNN and FSA achieves performance even better, with 95.65%.
</summary>
    <author>
      <name>Maira Gatti de Bayser</name>
    </author>
    <author>
      <name>Melina Alberio Guerra</name>
    </author>
    <author>
      <name>Paulo Cavalin</name>
    </author>
    <author>
      <name>Claudio Pinhanez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1907.02090</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04980v1</id>
    <updated>2020-01-14T21:17:55Z</updated>
    <published>2020-01-14T21:17:55Z</published>
    <title>Modeling Product Search Relevance in e-Commerce</title>
    <summary>  With the rapid growth of e-Commerce, online product search has emerged as a
popular and effective paradigm for customers to find desired products and
engage in online shopping. However, there is still a big gap between the
products that customers really desire to purchase and relevance of products
that are suggested in response to a query from the customer. In this paper, we
propose a robust way of predicting relevance scores given a search query and a
product, using techniques involving machine learning, natural language
processing and information retrieval. We compare conventional information
retrieval models such as BM25 and Indri with deep learning models such as
word2vec, sentence2vec and paragraph2vec. We share some of our insights and
findings from our experiments.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Rohan Kohli</name>
    </author>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06397v1</id>
    <updated>2020-01-14T20:13:43Z</updated>
    <published>2020-01-14T20:13:43Z</published>
    <title>Supervised Speaker Embedding De-Mixing in Two-Speaker Environment</title>
    <summary>  In this work, a speaker embedding de-mixing approach is proposed. Instead of
separating two-speaker signal in signal space like speech source separation,
the proposed approach separates different speaker properties from two-speaker
signal in embedding space. The proposed approach contains two steps. In step
one, the clean speaker embeddings are learned and collected by a residual TDNN
based network. In step two, the two-speaker signal and the embedding of one of
the speakers are input to a speaker embedding de-mixing network. The de-mixing
network is trained to generate the embedding of the other speaker of the by
reconstruction loss. Speaker identification accuracy on the de-mixed speaker
embeddings is used to evaluate the quality of the obtained embeddings.
Experiments are done in two kind of data: artificial augmented two-speaker data
(TIMIT) and real world recording of two-speaker data (MC-WSJ). Six diffident
speaker embedding de-mixing architectures are investigated. Comparing with the
speaker identification accuracy on the clean speaker embeddings (98.5%), the
obtained results show that one of the speaker embedding de-mixing architectures
obtain close performance, reaching 96.9% test accuracy on TIMIT when the SNR
between the target speaker and interfering speaker is 5 dB. More surprisingly,
we found choosing a simple subtraction as the embedding de-mixing function
could obtain the second best performance, reaching 95.2% test accuracy.
</summary>
    <author>
      <name>Yanpei Shi</name>
    </author>
    <author>
      <name>Thomas Hain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Odyssey 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05031v1</id>
    <updated>2020-01-14T20:03:07Z</updated>
    <published>2020-01-14T20:03:07Z</published>
    <title>Robust Speaker Recognition Using Speech Enhancement And Attention Model</title>
    <summary>  In this paper, a novel architecture for speaker recognition is proposed by
cascading speech enhancement and speaker processing. Its aim is to improve
speaker recognition performance when speech signals are corrupted by noise.
Instead of individually processing speech enhancement and speaker recognition,
the two modules are integrated into one framework by a joint optimisation using
deep neural networks. Furthermore, to increase robustness against noise, a
multi-stage attention mechanism is employed to highlight the speaker related
features learned from context information in time and frequency domain. To
evaluate speaker identification and verification performance of the proposed
approach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark
datasets. Moreover, the robustness of our proposed approach is also tested on
VoxCeleb1 data when being corrupted by three types of interferences, general
noise, music, and babble, at different signal-to-noise ratio (SNR) levels. The
obtained results show that the proposed approach using speech enhancement and
multi-stage attention models outperforms two strong baselines not using them in
most acoustic conditions in our experiments.
</summary>
    <author>
      <name>Yanpei Shi</name>
    </author>
    <author>
      <name>Qiang Huang</name>
    </author>
    <author>
      <name>Thomas Hain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Odyssey 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05871v1</id>
    <updated>2020-01-14T19:00:00Z</updated>
    <published>2020-01-14T19:00:00Z</published>
    <title>"Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials
  for Humans</title>
    <summary>  To support human decision making with machine learning models, we often need
to elucidate patterns embedded in the models that are unsalient, unknown, or
counterintuitive to humans. While existing approaches focus on explaining
machine predictions with real-time assistance, we explore model-driven
tutorials to help humans understand these patterns in a training phase. We
consider both tutorials with guidelines from scientific papers, analogous to
current practices of science communication, and automatically selected examples
from training data with explanations. We use deceptive review detection as a
testbed and conduct large-scale, randomized human-subject experiments to
examine the effectiveness of such tutorials. We find that tutorials indeed
improve human performance, with and without real-time assistance. In
particular, although deep learning provides superior predictive performance
than simple models, tutorials and explanations from simple models are more
useful to humans. Our work suggests future directions for human-centered
tutorials and explanations towards a synergy between humans and AI.
</summary>
    <author>
      <name>Vivian Lai</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <author>
      <name>Chenhao Tan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/10.1145/3313831.3376873</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/10.1145/3313831.3376873" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 48 figures, CHI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04935v1</id>
    <updated>2020-01-14T17:48:52Z</updated>
    <published>2020-01-14T17:48:52Z</published>
    <title>Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning</title>
    <summary>  Word embeddings, i.e., low-dimensional vector representations such as GloVe
and SGNS, encode word "meaning" in the sense that distances between words'
vectors correspond to their semantic proximity. This enables transfer learning
of semantics for a variety of natural language processing tasks.
  Word embeddings are typically trained on large public corpora such as
Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus
on which the embedding is trained can control the "meaning" of new and existing
words by changing their locations in the embedding space. We develop an
explicit expression over corpus features that serves as a proxy for distance
between words and establish a causative relationship between its values and
embedding distances. We then show how to use this relationship for two
adversarial objectives: (1) make a word a top-ranked neighbor of another word,
and (2) move a word from one semantic cluster to another.
  An attack on the embedding can affect diverse downstream tasks, demonstrating
for the first time the power of data poisoning in transfer learning scenarios.
We use this attack to manipulate query expansion in information retrieval
systems such as resume search, make certain names more or less visible to named
entity recognition models, and cause new words to be translated to a particular
target word regardless of the language. Finally, we show how the attacker can
generate linguistically likely corpus modifications, thus fooling defenses that
attempt to filter implausible sentences from the corpus using a language model.
</summary>
    <author>
      <name>Roei Schuster</name>
    </author>
    <author>
      <name>Tal Schuster</name>
    </author>
    <author>
      <name>Yoav Meri</name>
    </author>
    <author>
      <name>Vitaly Shmatikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at IEEE S&amp;P 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09899v1</id>
    <updated>2020-01-14T17:43:21Z</updated>
    <published>2020-01-14T17:43:21Z</published>
    <title>Vocabulary-based Method for Quantifying Controversy in Social Media</title>
    <summary>  Identifying controversial topics is not only interesting from a social point
of view, it also enables the application of methods to avoid the information
segregation, creating better discussion contexts and reaching agreements in the
best cases. In this paper we develop a systematic method for controversy
detection based primarily on the jargon used by the communities in social
media. Our method dispenses with the use of domain-specific knowledge, is
language-agnostic, efficient and easy to apply. We perform an extensive set of
experiments across many languages, regions and contexts, taking controversial
and non-controversial topics. We find that our vocabulary-based measure
performs better than state of the art measures that are based only on the
community graph structure. Moreover, we shows that it is possible to detect
polarization through text analysis.
</summary>
    <author>
      <name>Juan Manuel Ortiz de Zarate</name>
    </author>
    <author>
      <name>Esteban Feuerstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1507.05224 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05308v1</id>
    <updated>2020-01-14T17:24:41Z</updated>
    <published>2020-01-14T17:24:41Z</published>
    <title>Auto Completion of User Interface Layout Design Using Transformer-Based
  Tree Decoders</title>
    <summary>  It has been of increasing interest in the field to develop automatic
machineries to facilitate the design process. In this paper, we focus on
assisting graphical user interface (UI) layout design, a crucial task in app
development. Given a partial layout, which a designer has entered, our model
learns to complete the layout by predicting the remaining UI elements with a
correct position and dimension as well as the hierarchical structures. Such
automation will significantly ease the effort of UI designers and developers.
While we focus on interface layout prediction, our model can be generally
applicable for other layout prediction problems that involve tree structures
and 2-dimensional placements. Particularly, we design two versions of
Transformer-based tree decoders: Pointer and Recursive Transformer, and
experiment with these models on a public dataset. We also propose several
metrics for measuring the accuracy of tree prediction and ground these metrics
in the domain of user experience. These contribute a new task and methods to
deep learning research.
</summary>
    <author>
      <name>Yang Li</name>
    </author>
    <author>
      <name>Julien Amelot</name>
    </author>
    <author>
      <name>Xin Zhou</name>
    </author>
    <author>
      <name>Samy Bengio</name>
    </author>
    <author>
      <name>Si Si</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05326v1</id>
    <updated>2020-01-14T13:50:08Z</updated>
    <published>2020-01-14T13:50:08Z</published>
    <title>A BERT based Sentiment Analysis and Key Entity Detection Approach for
  Online Financial Texts</title>
    <summary>  The emergence and rapid progress of the Internet have brought ever-increasing
impact on financial domain. How to rapidly and accurately mine the key
information from the massive negative financial texts has become one of the key
issues for investors and decision makers. Aiming at the issue, we propose a
sentiment analysis and key entity detection approach based on BERT, which is
applied in online financial text mining and public opinion analysis in social
media. By using pre-train model, we first study sentiment analysis, and then we
consider key entity detection as a sentence matching or Machine Reading
Comprehension (MRC) task in different granularity. Among them, we mainly focus
on negative sentimental information. We detect the specific entity by using our
approach, which is different from traditional Named Entity Recognition (NER).
In addition, we also use ensemble learning to improve the performance of
proposed approach. Experimental results show that the performance of our
approach is generally higher than SVM, LR, NBM, and BERT for two financial
sentiment analysis and key entity detection datasets.
</summary>
    <author>
      <name>Lingyun Zhao</name>
    </author>
    <author>
      <name>Lin Li</name>
    </author>
    <author>
      <name>Xinhao Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04701v6</id>
    <updated>2020-02-15T17:06:34Z</updated>
    <published>2020-01-14T10:26:51Z</published>
    <title>A (Simplified) Supreme Being Necessarily Exists -- Says the Computer!</title>
    <summary>  A simplified variant of Kurt G\"odel's modal ontological argument is
presented. Some of G\"odel's, resp. Scott's, premises are modified, others are
dropped, and modal collapse is avoided. The emended argument is shown valid
already in quantified modal logic K.
  The presented simplifications have been computationally explored utilising
latest knowledge representation and reasoning technology based on higher-order
logic. The paper thus illustrates how modern symbolic AI technology can
contribute new knowledge to formal philosophy and theology.
</summary>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04701v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04701v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04693v1</id>
    <updated>2020-01-14T10:12:50Z</updated>
    <published>2020-01-14T10:12:50Z</published>
    <title>Balancing the composition of word embeddings across heterogenous data
  sets</title>
    <summary>  Word embeddings capture semantic relationships based on contextual
information and are the basis for a wide variety of natural language processing
applications. Notably these relationships are solely learned from the data and
subsequently the data composition impacts the semantic of embeddings which
arguably can lead to biased word vectors. Given qualitatively different data
subsets, we aim to align the influence of single subsets on the resulting word
vectors, while retaining their quality. In this regard we propose a criteria to
measure the shift towards a single data subset and develop approaches to meet
both objectives. We find that a weighted average of the two subset embeddings
balances the influence of those subsets while word similarity performance
decreases. We further propose a promising optimization approach to balance
influences and quality of word embeddings.
</summary>
    <author>
      <name>Stephanie Brandl</name>
    </author>
    <author>
      <name>David Lassner</name>
    </author>
    <author>
      <name>Maximilian Alber</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04619v1</id>
    <updated>2020-01-14T04:21:18Z</updated>
    <published>2020-01-14T04:21:18Z</published>
    <title>Improved Robust ASR for Social Robots in Public Spaces</title>
    <summary>  Social robots deployed in public spaces present a challenging task for ASR
because of a variety of factors, including noise SNR of 20 to 5 dB. Existing
ASR models perform well for higher SNRs in this range, but degrade considerably
with more noise. This work explores methods for providing improved ASR
performance in such conditions. We use the AiShell-1 Chinese speech corpus and
the Kaldi ASR toolkit for evaluations. We were able to exceed state-of-the-art
ASR performance with SNR lower than 20 dB, demonstrating the feasibility of
achieving relatively high performing ASR with open-source toolkits and hundreds
of hours of training data, which is commonly available.
</summary>
    <author>
      <name>Charles Jankowski</name>
    </author>
    <author>
      <name>Vishwas Mruthyunjaya</name>
    </author>
    <author>
      <name>Ruixi Lin</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04619v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04619v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04589v1</id>
    <updated>2020-01-14T02:14:09Z</updated>
    <published>2020-01-14T02:14:09Z</published>
    <title>Faster Transformer Decoding: N-gram Masked Self-Attention</title>
    <summary>  Motivated by the fact that most of the information relevant to the prediction
of target tokens is drawn from the source sentence $S=s_1, \ldots, s_S$, we
propose truncating the target-side window used for computing self-attention by
making an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show
that the $N$-gram masked self-attention model loses very little in BLEU score
for $N$ values in the range $4, \ldots, 8$, depending on the task.
</summary>
    <author>
      <name>Ciprian Chelba</name>
    </author>
    <author>
      <name>Mia Chen</name>
    </author>
    <author>
      <name>Ankur Bapna</name>
    </author>
    <author>
      <name>Noam Shazeer</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04589v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04589v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04586v1</id>
    <updated>2020-01-14T02:05:14Z</updated>
    <published>2020-01-14T02:05:14Z</published>
    <title>Bi-Decoder Augmented Network for Neural Machine Translation</title>
    <summary>  Neural Machine Translation (NMT) has become a popular technology in recent
years, and the encoder-decoder framework is the mainstream among all the
methods. It's obvious that the quality of the semantic representations from
encoding is very crucial and can significantly affect the performance of the
model. However, existing unidirectional source-to-target architectures may
hardly produce a language-independent representation of the text because they
rely heavily on the specific relations of the given language pairs. To
alleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented
Network (BiDAN) for the neural machine translation task. Besides the original
decoder which generates the target language sequence, we add an auxiliary
decoder to generate back the source language sequence at the training time.
Since each decoder transforms the representations of the input text into its
corresponding language, jointly training with two target ends can make the
shared encoder has the potential to produce a language-independent semantic
space. We conduct extensive experiments on several NMT benchmark datasets and
the results demonstrate the effectiveness of our proposed approach.
</summary>
    <author>
      <name>Boyuan Pan</name>
    </author>
    <author>
      <name>Yazheng Yang</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <author>
      <name>Yueting Zhuang</name>
    </author>
    <author>
      <name>Deng Cai</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04484v1</id>
    <updated>2020-01-13T19:01:07Z</updated>
    <published>2020-01-13T19:01:07Z</published>
    <title>On the Replicability of Combining Word Embeddings and Retrieval Models</title>
    <summary>  We replicate recent experiments attempting to demonstrate an attractive
hypothesis about the use of the Fisher kernel framework and mixture models for
aggregating word embeddings towards document representations and the use of
these representations in document classification, clustering, and retrieval.
Specifically, the hypothesis was that the use of a mixture model of von
Mises-Fisher (VMF) distributions instead of Gaussian distributions would be
beneficial because of the focus on cosine distances of both VMF and the vector
space model traditionally used in information retrieval. Previous experiments
had validated this hypothesis. Our replication was not able to validate it,
despite a large parameter scan space.
</summary>
    <author>
      <name>Luca Papariello</name>
    </author>
    <author>
      <name>Alexandros Bampoulidis</name>
    </author>
    <author>
      <name>Mihai Lupu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04451v2</id>
    <updated>2020-02-18T16:01:18Z</updated>
    <published>2020-01-13T18:38:28Z</published>
    <title>Reformer: The Efficient Transformer</title>
    <summary>  Large Transformer models routinely achieve state-of-the-art results on a
number of tasks but training these models can be prohibitively costly,
especially on long sequences. We introduce two techniques to improve the
efficiency of Transformers. For one, we replace dot-product attention by one
that uses locality-sensitive hashing, changing its complexity from O($L^2$) to
O($L\log L$), where $L$ is the length of the sequence. Furthermore, we use
reversible residual layers instead of the standard residuals, which allows
storing activations only once in the training process instead of $N$ times,
where $N$ is the number of layers. The resulting model, the Reformer, performs
on par with Transformer models while being much more memory-efficient and much
faster on long sequences.
</summary>
    <author>
      <name>Nikita Kitaev</name>
    </author>
    <author>
      <name>Łukasz Kaiser</name>
    </author>
    <author>
      <name>Anselm Levskaya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04451v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04451v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04437v1</id>
    <updated>2020-01-13T18:16:13Z</updated>
    <published>2020-01-13T18:16:13Z</published>
    <title>LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured
  Prediction</title>
    <summary>  Structured prediction requires manipulating a large number of combinatorial
structures, e.g., dependency trees or alignments, either as latent or output
variables. Recently, the SparseMAP method has been proposed as a
differentiable, sparse alternative to maximum a posteriori (MAP) and marginal
inference. SparseMAP returns a combination of a small number of structures, a
desirable property in some downstream applications. However, SparseMAP requires
a tractable MAP inference oracle. This excludes, e.g., loopy graphical models
or factor graphs with logic constraints, which generally require approximate
inference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP
that addresses this limitation via a local polytope relaxation. LP-SparseMAP
uses the flexible and powerful domain specific language of factor graphs for
defining and backpropagating through arbitrary hidden structure, supporting
coarse decompositions, hard logic constraints, and higher-order correlations.
We derive the forward and backward algorithms needed for using LP-SparseMAP as
a hidden or output layer. Experiments in three structured prediction tasks show
benefits compared to SparseMAP and Structured SVM.
</summary>
    <author>
      <name>Vlad Niculae</name>
    </author>
    <author>
      <name>André F. T. Martins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 5 tables, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04425v3</id>
    <updated>2020-01-20T14:45:01Z</updated>
    <published>2020-01-13T17:49:37Z</published>
    <title>Negative Statements Considered Useful</title>
    <summary>  Knowledge bases (KBs), pragmatic collections of knowledge about notable
entities, are an important asset in applications such as search, question
answering and dialogue. Rooted in a long tradition in knowledge representation,
all popular KBs only store positive information, while they abstain from taking
any stance towards statements not contained in them.
  In this paper, we make the case for explicitly stating interesting statements
which are not true. Negative statements would be important to overcome current
limitations of question answering, yet due to their potential abundance, any
effort towards compiling them needs a tight coupling with ranking. We introduce
two approaches towards compiling negative statements. (i) In peer-based
statistical inferences, we compare entities with highly related entities in
order to derive potential negative statements, which we then rank using
supervised and unsupervised features. (ii) In query-log-based text extraction,
we use a pattern-based approach for harvesting search engine query logs.
Experimental results show that both approaches hold promising and complementary
potential. Along with this paper, we publish the first datasets on interesting
negative information, containing over 1.1M statements for 100K popular Wikidata
entities.
</summary>
    <author>
      <name>Hiba Arnaout</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04425v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04425v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04362v3</id>
    <updated>2020-03-03T21:21:22Z</updated>
    <published>2020-01-13T15:53:41Z</published>
    <title>Multi-Source Domain Adaptation for Text Classification via
  DistanceNet-Bandits</title>
    <summary>  Domain adaptation performance of a learning algorithm on a target domain is a
function of its source domain error and a divergence measure between the data
distribution of these two domains. We present a study of various distance-based
measures in the context of NLP tasks, that characterize the dissimilarity
between domains based on sample estimates. We first conduct analysis
experiments to show which of these distance measures can best differentiate
samples from same versus different domains, and are correlated with empirical
results. Next, we develop a DistanceNet model which uses these distance
measures, or a mixture of these distance measures, as an additional loss
function to be minimized jointly with the task's loss function, so as to
achieve better unsupervised domain adaptation. Finally, we extend this model to
a novel DistanceNet-Bandit model, which employs a multi-armed bandit controller
to dynamically switch between multiple source domains and allow the model to
learn an optimal trajectory and mixture of domains for transfer to the
low-resource target domain. We conduct experiments on popular sentiment
analysis datasets with several diverse domains and show that our DistanceNet
model, as well as its dynamic bandit variant, can outperform competitive
baselines in the context of unsupervised domain adaptation.
</summary>
    <author>
      <name>Han Guo</name>
    </author>
    <author>
      <name>Ramakanth Pasunuru</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (10 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04362v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04362v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04351v4</id>
    <updated>2020-01-20T16:32:50Z</updated>
    <published>2020-01-13T15:39:56Z</published>
    <title>CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark
  for Chinese</title>
    <summary>  In this paper, we introduce the NER dataset from CLUE organization
(CLUENER2020), a well-defined fine-grained dataset for named entity recognition
in Chinese. CLUENER2020 contains 10 categories. Apart from common labels like
person, organization, and location, it contains more diverse categories. It is
more challenging than current other Chinese NER datasets and could better
reflect real-world applications. For comparison, we implement several
state-of-the-art baselines as sequence labeling tasks and report human
performance, as well as its analysis. To facilitate future work on fine-grained
NER for Chinese, we release our dataset, baselines, and leader-board.
</summary>
    <author>
      <name>Liang Xu</name>
    </author>
    <author>
      <name>Yu tong</name>
    </author>
    <author>
      <name>Qianqian Dong</name>
    </author>
    <author>
      <name>Yixuan Liao</name>
    </author>
    <author>
      <name>Cong Yu</name>
    </author>
    <author>
      <name>Yin Tian</name>
    </author>
    <author>
      <name>Weitang Liu</name>
    </author>
    <author>
      <name>Lu Li</name>
    </author>
    <author>
      <name>Caiquan Liu</name>
    </author>
    <author>
      <name>Xuanwei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 tables, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04351v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04351v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04246v1</id>
    <updated>2020-01-13T14:03:26Z</updated>
    <published>2020-01-13T14:03:26Z</published>
    <title>AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural
  Architecture Search</title>
    <summary>  Large pre-trained language models such as BERT have shown their effectiveness
in various natural language processing tasks. However, the huge parameter size
makes them difficult to be deployed in real-time applications that require
quick inference with limited resources. Existing methods compress BERT into
small models while such compression is task-independent, i.e., the same
compressed BERT for all different downstream tasks. Motivated by the necessity
and benefits of task-oriented BERT compression, we propose a novel compression
method, AdaBERT, that leverages differentiable Neural Architecture Search to
automatically compress BERT into task-adaptive small models for specific tasks.
We incorporate a task-oriented knowledge distillation loss to provide search
hints and an efficiency-aware loss as search constraints, which enables a good
trade-off between efficiency and effectiveness for task-adaptive BERT
compression. We evaluate AdaBERT on several NLP tasks, and the results
demonstrate that those task-adaptive compressed models are 12.7x to 29.3x
faster than BERT in inference time and 11.5x to 17.0x smaller in terms of
parameter size, while comparable performance is maintained.
</summary>
    <author>
      <name>Daoyuan Chen</name>
    </author>
    <author>
      <name>Yaliang Li</name>
    </author>
    <author>
      <name>Minghui Qiu</name>
    </author>
    <author>
      <name>Zhen Wang</name>
    </author>
    <author>
      <name>Bofang Li</name>
    </author>
    <author>
      <name>Bolin Ding</name>
    </author>
    <author>
      <name>Hongbo Deng</name>
    </author>
    <author>
      <name>Jun Huang</name>
    </author>
    <author>
      <name>Wei Lin</name>
    </author>
    <author>
      <name>Jingren Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04219v1</id>
    <updated>2020-01-13T13:16:13Z</updated>
    <published>2020-01-13T13:16:13Z</published>
    <title>Structural Decompositions of Epistemic Logic Programs</title>
    <summary>  Epistemic logic programs (ELPs) are a popular generalization of standard
Answer Set Programming (ASP) providing means for reasoning over answer sets
within the language. This richer formalism comes at the price of higher
computational complexity reaching up to the fourth level of the polynomial
hierarchy. However, in contrast to standard ASP, dedicated investigations
towards tractability have not been undertaken yet. In this paper, we give first
results in this direction and show that central ELP problems can be solved in
linear time for ELPs exhibiting structural properties in terms of bounded
treewidth. We also provide a full dynamic programming algorithm that adheres to
these bounds. Finally, we show that applying treewidth to a novel dependency
structure---given in terms of epistemic literals---allows to bound the number
of ASP solver calls in typical ELP solving procedures.
</summary>
    <author>
      <name>Markus Hecher</name>
    </author>
    <author>
      <name>Michael Morak</name>
    </author>
    <author>
      <name>Stefan Woltran</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T27" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8; G.2.2; G.2.3; F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04200v1</id>
    <updated>2020-01-13T13:01:14Z</updated>
    <published>2020-01-13T13:01:14Z</published>
    <title>Mining customer product reviews for product development: A summarization
  process</title>
    <summary>  This research set out to identify and structure from online reviews the words
and expressions related to customers' likes and dislikes to guide product
development. Previous methods were mainly focused on product features. However,
reviewers express their preference not only on product features. In this paper,
based on an extensive literature review in design science, the authors propose
a summarization model containing multiples aspects of user preference, such as
product affordances, emotions, usage conditions. Meanwhile, the linguistic
patterns describing these aspects of preference are discovered and drafted as
annotation guidelines. A case study demonstrates that with the proposed model
and the annotation guidelines, human annotators can structure the online
reviews with high inter-agreement. As high inter-agreement human annotation
results are essential for automatizing the online review summarization process
with the natural language processing, this study provides materials for the
future study of automatization.
</summary>
    <author>
      <name>Tianjun Hou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Yannou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>Yann Leroy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Emilie Poirson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.eswa.2019.04.069</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.eswa.2019.04.069" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Expert Systems with Applications, Elsevier, 2019, 132, pp.141-150</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04192v1</id>
    <updated>2020-01-13T12:47:49Z</updated>
    <published>2020-01-13T12:47:49Z</published>
    <title>A logic-based relational learning approach to relation extraction: The
  OntoILPER system</title>
    <summary>  Relation Extraction (RE), the task of detecting and characterizing semantic
relations between entities in text, has gained much importance in the last two
decades, mainly in the biomedical domain. Many papers have been published on
Relation Extraction using supervised machine learning techniques. Most of these
techniques rely on statistical methods, such as feature-based and
tree-kernels-based methods. Such statistical learning techniques are usually
based on a propositional hypothesis space for representing examples, i.e., they
employ an attribute-value representation of features. This kind of
representation has some drawbacks, particularly in the extraction of complex
relations which demand more contextual information about the involving
instances, i.e., it is not able to effectively capture structural information
from parse trees without loss of information. In this work, we present
OntoILPER, a logic-based relational learning approach to Relation Extraction
that uses Inductive Logic Programming for generating extraction models in the
form of symbolic extraction rules. OntoILPER takes profit of a rich relational
representation of examples, which can alleviate the aforementioned drawbacks.
The proposed relational approach seems to be more suitable for Relation
Extraction than statistical ones for several reasons that we argue. Moreover,
OntoILPER uses a domain ontology that guides the background knowledge
generation process and is used for storing the extracted relation instances.
The induced extraction rules were evaluated on three protein-protein
interaction datasets from the biomedical domain. The performance of OntoILPER
extraction models was compared with other state-of-the-art RE systems. The
encouraging results seem to demonstrate the effectiveness of the proposed
solution.
</summary>
    <author>
      <name>Rinaldo Lima</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, R2I</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Espinasse</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, R2I</arxiv:affiliation>
    </author>
    <author>
      <name>Fred Freitas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.engappai.2018.11.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.engappai.2018.11.001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Engineering Applications of Artificial Intelligence, Elsevier,
  2019, 78, pp.142-157</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04170v1</id>
    <updated>2020-01-13T11:34:25Z</updated>
    <published>2020-01-13T11:34:25Z</published>
    <title>Joint Reasoning for Multi-Faceted Commonsense Knowledge</title>
    <summary>  Commonsense knowledge (CSK) supports a variety of AI applications, from
visual understanding to chatbots. Prior works on acquiring CSK, such as
ConceptNet, have compiled statements that associate concepts, like everyday
objects or activities, with properties that hold for most or some instances of
the concept. Each concept is treated in isolation from other concepts, and the
only quantitative measure (or ranking) of properties is a confidence score that
the statement is valid. This paper aims to overcome these limitations by
introducing a multi-faceted model of CSK statements and methods for joint
reasoning over sets of inter-related statements. Our model captures four
different dimensions of CSK statements: plausibility, typicality, remarkability
and salience, with scoring and ranking along each dimension. For example,
hyenas drinking water is typical but not salient, whereas hyenas eating
carcasses is salient. For reasoning and ranking, we develop a method with soft
constraints, to couple the inference over concepts that are related in in a
taxonomic hierarchy. The reasoning is cast into an integer linear programming
(ILP), and we leverage the theory of reduction costs of a relaxed LP to compute
informative rankings. This methodology is applied to several large CSK
collections. Our evaluation shows that we can consolidate these inputs into
much cleaner and more expressive knowledge. Results are available at
https://dice.mpi-inf.mpg.de.
</summary>
    <author>
      <name>Yohan Chalier</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05297v1</id>
    <updated>2020-01-13T11:23:28Z</updated>
    <published>2020-01-13T11:23:28Z</published>
    <title>Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process
  Approach to Linguistic Relationships</title>
    <summary>  This paper addresses a series of complex and unresolved issues in the
historical phonology of West Iranian languages. The West Iranian languages
(Persian, Kurdish, Balochi, and other languages) display a high degree of
non-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to
language contact; we argue, however, that an oversimplified view of the
processes at work has prevailed in the literature on West Iranian dialectology,
with specialists assuming that deviations from an expected outcome in a given
non-Persian language are due to lexical borrowing from some chronological stage
of Persian. It is demonstrated that this qualitative approach yields at times
problematic conclusions stemming from the lack of explicit probabilistic
inferences regarding the distribution of the data: Persian may not be the sole
donor language; additionally, borrowing at the lexical level is not always the
mechanism that introduces irregularity. In many cases, the possibility that
West Iranian languages show different reflexes in different conditioning
environments remains under-explored. We employ a novel Bayesian approach
designed to overcome these problems and tease apart the different determinants
of irregularity in patterns of West Iranian sound change. Our methodology
allows us to provisionally resolve a number of outstanding questions in the
literature on West Iranian dialectology concerning the dialectal affiliation of
certain sound changes. We outline future directions for work of this sort.
</summary>
    <author>
      <name>Chundra Aroor Cathcart</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pp</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04809v2</id>
    <updated>2020-01-27T23:16:48Z</updated>
    <published>2020-01-13T10:47:13Z</published>
    <title>Detecting depression in dyadic conversations with multimodal narratives
  and visualizations</title>
    <summary>  Conversations contain a wide spectrum of multimodal information that gives us
hints about the emotions and moods of the speaker. In this paper, we developed
a system that supports humans to analyze conversations. Our main contribution
is the identification of appropriate multimodal features and the integration of
such features into verbatim conversation transcripts. We demonstrate the
ability of our system to take in a wide range of multimodal information and
automatically generated a prediction score for the depression state of the
individual. Our experiments showed that this approach yielded better
performance than the baseline model. Furthermore, the multimodal narrative
approach makes it easy to integrate learnings from other disciplines, such as
conversational analysis and psychology. Lastly, this interdisciplinary and
automated approach is a step towards emulating how practitioners record the
course of treatment as well as emulating how conversational analysts have been
analyzing conversations by hand.
</summary>
    <author>
      <name>Joshua Y. Kim</name>
    </author>
    <author>
      <name>Greyson Y. Kim</name>
    </author>
    <author>
      <name>Kalina Yacef</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-35288-2_25</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-35288-2_25" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AI 2019: Advances in Artificial Intelligence. AI 2019 vol 11919</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04063v2</id>
    <updated>2020-02-22T09:29:12Z</updated>
    <published>2020-01-13T05:12:38Z</published>
    <title>ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training</title>
    <summary>  In this paper, we present a new sequence-to-sequence pre-training model
called ProphetNet, which introduces a novel self-supervised objective named
future n-gram prediction and the proposed n-stream self-attention mechanism.
Instead of the optimization of one-step ahead prediction in traditional
sequence-to-sequence model, the ProphetNet is optimized by n-step ahead
prediction which predicts the next n tokens simultaneously based on previous
context tokens at each time step. The future n-gram prediction explicitly
encourages the model to plan for the future tokens and prevent overfitting on
strong local correlations. We pre-train ProphetNet using a base scale dataset
(16GB) and a large scale dataset (160GB) respectively. Then we conduct
experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results
show that ProphetNet achieves new state-of-the-art results on all these
datasets compared to the models using the same scale pre-training corpus.
</summary>
    <author>
      <name>Yu Yan</name>
    </author>
    <author>
      <name>Weizhen Qi</name>
    </author>
    <author>
      <name>Yeyun Gong</name>
    </author>
    <author>
      <name>Dayiheng Liu</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Jiusheng Chen</name>
    </author>
    <author>
      <name>Ruofei Zhang</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05285v1</id>
    <updated>2020-01-12T21:54:52Z</updated>
    <published>2020-01-12T21:54:52Z</published>
    <title>Detecting New Word Meanings: A Comparison of Word Embedding Models in
  Spanish</title>
    <summary>  Semantic neologisms (SN) are defined as words that acquire a new word meaning
while maintaining their form. Given the nature of this kind of neologisms, the
task of identifying these new word meanings is currently performed manually by
specialists at observatories of neology. To detect SN in a semi-automatic way,
we developed a system that implements a combination of the following
strategies: topic modeling, keyword extraction, and word sense disambiguation.
The role of topic modeling is to detect the themes that are treated in the
input text. Themes within a text give clues about the particular meaning of the
words that are used, for example: viral has one meaning in the context of
computer science (CS) and another when talking about health. To extract
keywords, we used TextRank with POS tag filtering. With this method, we can
obtain relevant words that are already part of the Spanish lexicon. We use a
deep learning model to determine if a given keyword could have a new meaning.
Embeddings that are different from all the known meanings (or topics) indicate
that a word might be a valid SN candidate. In this study, we examine the
following word embedding models: Word2Vec, Sense2Vec, and FastText. The models
were trained with equivalent parameters using Wikipedia in Spanish as corpora.
Then we used a list of words and their concordances (obtained from our database
of neologisms) to show the different embeddings that each model yields.
Finally, we present a comparison of these outcomes with the concordances of
each word to show how we can determine if a word could be a valid candidate for
SN.
</summary>
    <author>
      <name>Andrés Torres-Rivera</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">COnference en Recherche d'Informations et Applications {CORIA}
  2019 France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.05285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05296v1</id>
    <updated>2020-01-12T17:30:42Z</updated>
    <published>2020-01-12T17:30:42Z</published>
    <title>Urdu-English Machine Transliteration using Neural Networks</title>
    <summary>  Machine translation has gained much attention in recent years. It is a
sub-field of computational linguistic which focus on translating text from one
language to other language. Among different translation techniques, neural
network currently leading the domain with its capabilities of providing a
single large neural network with attention mechanism, sequence-to-sequence and
long-short term modelling. Despite significant progress in domain of machine
translation, translation of out-of-vocabulary words(OOV) which include
technical terms, named-entities, foreign words are still a challenge for
current state-of-art translation systems, and this situation becomes even worse
while translating between low resource languages or languages having different
structures. Due to morphological richness of a language, a word may have
different meninges in different context. In such scenarios, translation of word
is not only enough in order provide the correct/quality translation.
Transliteration is a way to consider the context of word/sentence during
translation. For low resource language like Urdu, it is very difficult to
have/find parallel corpus for transliteration which is large enough to train
the system. In this work, we presented transliteration technique based on
Expectation Maximization (EM) which is un-supervised and language independent.
Systems learns the pattern and out-of-vocabulary (OOV) words from parallel
corpus and there is no need to train it on transliteration corpus explicitly.
This approach is tested on three models of statistical machine translation
(SMT) which include phrasebased, hierarchical phrase-based and factor based
models and two models of neural machine translation which include LSTM and
transformer model.
</summary>
    <author>
      <name>Usman Mohy ud Din</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05313v1</id>
    <updated>2020-01-12T14:28:33Z</updated>
    <published>2020-01-12T14:28:33Z</published>
    <title>Tensor Graph Convolutional Networks for Text Classification</title>
    <summary>  Compared to sequential learning models, graph-based neural networks exhibit
some excellent properties, such as ability capturing global information. In
this paper, we investigate graph-based neural networks for text classification
problem. A new framework TensorGCN (tensor graph convolutional networks), is
presented for this task. A text graph tensor is firstly constructed to describe
semantic, syntactic, and sequential contextual information. Then, two kinds of
propagation learning perform on the text graph tensor. The first is intra-graph
propagation used for aggregating information from neighborhood nodes in a
single graph. The second is inter-graph propagation used for harmonizing
heterogeneous information between graphs. Extensive experiments are conducted
on benchmark datasets, and the results illustrate the effectiveness of our
proposed framework. Our proposed TensorGCN presents an effective way to
harmonize and integrate heterogeneous information from different kinds of
graphs.
</summary>
    <author>
      <name>Xien Liu</name>
    </author>
    <author>
      <name>Xinxin You</name>
    </author>
    <author>
      <name>Xiao Zhang</name>
    </author>
    <author>
      <name>Ji Wu</name>
    </author>
    <author>
      <name>Ping Lv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.05313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03897v1</id>
    <updated>2020-01-12T09:40:11Z</updated>
    <published>2020-01-12T09:40:11Z</published>
    <title>Stochastic Natural Language Generation Using Dependency Information</title>
    <summary>  This article presents a stochastic corpus-based model for generating natural
language text. Our model first encodes dependency relations from training data
through a feature set, then concatenates these features to produce a new
dependency tree for a given meaning representation, and finally generates a
natural language utterance from the produced dependency tree. We test our model
on nine domains from tabular, dialogue act and RDF format. Our model
outperforms the corpus-based state-of-the-art methods trained on tabular
datasets and also achieves comparable results with neural network-based
approaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR
evaluation metrics. Also, by reporting Human Evaluation results, we show that
our model produces high-quality utterances in aspects of informativeness and
naturalness as well as quality.
</summary>
    <author>
      <name>Elham Seifossadat</name>
    </author>
    <author>
      <name>Hossein Sameti</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03844v1</id>
    <updated>2020-01-12T04:33:53Z</updated>
    <published>2020-01-12T04:33:53Z</published>
    <title>Rethinking Generalization of Neural Models: A Named Entity Recognition
  Case Study</title>
    <summary>  While neural network-based models have achieved impressive performance on a
large body of NLP tasks, the generalization behavior of different models
remains poorly understood: Does this excellent performance imply a perfect
generalization model, or are there still some limitations? In this paper, we
take the NER task as a testbed to analyze the generalization behavior of
existing models from different perspectives and characterize the differences of
their generalization abilities through the lens of our proposed measures, which
guides us to better design models and training methods. Experiments with
in-depth analyses diagnose the bottleneck of existing neural NER models in
terms of breakdown performance analysis, annotation errors, dataset bias, and
category relationships, which suggest directions for improvement. We have
released the datasets: (ReCoNLL, PLONER) for the future research at our project
page: http://pfliu.com/InterpretNER/. As a by-product of this paper, we have
open-sourced a project that involves a comprehensive summary of recent NER
papers and classifies them into different research topics:
https://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers.
</summary>
    <author>
      <name>Jinlan Fu</name>
    </author>
    <author>
      <name>Pengfei Liu</name>
    </author>
    <author>
      <name>Qi Zhang</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03844v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03844v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03830v1</id>
    <updated>2020-01-12T02:31:07Z</updated>
    <published>2020-01-12T02:31:07Z</published>
    <title>Revisiting Challenges in Data-to-Text Generation with Fact Grounding</title>
    <summary>  Data-to-text generation models face challenges in ensuring data fidelity by
referring to the correct input source. To inspire studies in this area, Wiseman
et al. (2017) introduced the RotoWire corpus on generating NBA game summaries
from the box- and line-score tables. However, limited attempts have been made
in this direction and the challenges remain. We observe a prominent bottleneck
in the corpus where only about 60% of the summary contents can be grounded to
the boxscore records. Such information deficiency tends to misguide a
conditioned language model to produce unconditioned random facts and thus leads
to factual hallucinations. In this work, we restore the information balance and
revamp this task to focus on fact-grounded data-to-text generation. We
introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),
with 50% more data from the year 2017-19 and enriched input tables, hoping to
attract more research focuses in this direction. Moreover, we achieve improved
data fidelity over the state-of-the-art models by integrating a new form of
table reconstruction as an auxiliary task to boost the generation quality.
</summary>
    <author>
      <name>Hongmin Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/W19-8639</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/W19-8639" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Best Paper Runner-up at INLG 2019 (12th International Conference on
  Natural Language Generation)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05314v2</id>
    <updated>2020-01-23T01:01:56Z</updated>
    <published>2020-01-11T20:53:55Z</published>
    <title>Embedding Compression with Isotropic Iterative Quantization</title>
    <summary>  Continuous representation of words is a standard component in deep
learning-based NLP models. However, representing a large vocabulary requires
significant memory, which can cause problems, particularly on
resource-constrained platforms. Therefore, in this paper we propose an
isotropic iterative quantization (IIQ) approach for compressing embedding
vectors into binary ones, leveraging the iterative quantization technique well
established for image retrieval, while satisfying the desired isotropic
property of PMI based models. Experiments with pre-trained embeddings (i.e.,
GloVe and HDC) demonstrate a more than thirty-fold compression ratio with
comparable and sometimes even improved performance over the original
real-valued embedding vectors.
</summary>
    <author>
      <name>Siyu Liao</name>
    </author>
    <author>
      <name>Jie Chen</name>
    </author>
    <author>
      <name>Yanzhi Wang</name>
    </author>
    <author>
      <name>Qinru Qiu</name>
    </author>
    <author>
      <name>Bo Yuan</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05314v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05314v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05286v1</id>
    <updated>2020-01-11T18:05:15Z</updated>
    <published>2020-01-11T18:05:15Z</published>
    <title>Exploring and Improving Robustness of Multi Task Deep Neural Networks
  via Domain Agnostic Defenses</title>
    <summary>  In this paper, we explore the robustness of the Multi-Task Deep Neural
Networks (MT-DNN) against non-targeted adversarial attacks across Natural
Language Understanding (NLU) tasks as well as some possible ways to defend
against them. Liu et al., have shown that the Multi-Task Deep Neural Network,
due to the regularization effect produced when training as a result of its
cross task data, is more robust than a vanilla BERT model trained only on one
task (1.1%-1.5% absolute difference). We further show that although the MT-DNN
has generalized better, making it easily transferable across domains and tasks,
it can still be compromised as after only 2 attacks (1-character and
2-character) the accuracy drops by 42.05% and 32.24% for the SNLI and SciTail
tasks. Finally, we propose a domain agnostic defense which restores the model's
accuracy (36.75% and 25.94% respectively) as opposed to a general-purpose
defense or an off-the-shelf spell checker.
</summary>
    <author>
      <name>Kashyap Coimbatore Murali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures, 3 tables, 24 citations, 11 equations</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T35 (Primary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03765v1</id>
    <updated>2020-01-11T15:30:56Z</updated>
    <published>2020-01-11T15:30:56Z</published>
    <title>Learning Cross-Context Entity Representations from Text</title>
    <summary>  Language modeling tasks, in which words, or word-pieces, are predicted on the
basis of a local context, have been very effective for learning word embeddings
and context dependent representations of phrases. Motivated by the observation
that efforts to code world knowledge into machine readable knowledge bases or
human readable encyclopedias tend to be entity-centric, we investigate the use
of a fill-in-the-blank task to learn context independent representations of
entities from the text contexts in which those entities were mentioned. We show
that large scale training of neural models allows us to learn high quality
entity representations, and we demonstrate successful results on four domains:
(1) existing entity-level typing benchmarks, including a 64% error reduction
over previous work on TypeNet (Murty et al., 2018); (2) a novel few-shot
category reconstruction task; (3) existing entity linking benchmarks, where we
match the state-of-the-art on CoNLL-Aida without linking-specific features and
obtain a score of 89.8% on TAC-KBP 2010 without using any alias table, external
knowledge base or in domain training data and (4) answering trivia questions,
which uniquely identify entities. Our global entity representations encode
fine-grained type categories, such as Scottish footballers, and can answer
trivia questions such as: Who was the last inmate of Spandau jail in Berlin?
</summary>
    <author>
      <name>Jeffrey Ling</name>
    </author>
    <author>
      <name>Nicholas FitzGerald</name>
    </author>
    <author>
      <name>Zifei Shan</name>
    </author>
    <author>
      <name>Livio Baldini Soares</name>
    </author>
    <author>
      <name>Thibault Févry</name>
    </author>
    <author>
      <name>David Weiss</name>
    </author>
    <author>
      <name>Tom Kwiatkowski</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05316v1</id>
    <updated>2020-01-11T14:54:04Z</updated>
    <published>2020-01-11T14:54:04Z</published>
    <title>Authorship Attribution in Bangla literature using Character-level CNN</title>
    <summary>  Characters are the smallest unit of text that can extract stylometric signals
to determine the author of a text. In this paper, we investigate the
effectiveness of character-level signals in Authorship Attribution of Bangla
Literature and show that the results are promising but improvable. The time and
memory efficiency of the proposed model is much higher than the word level
counterparts but accuracy is 2-5% less than the best performing word-level
models. Comparison of various word-based models is performed and shown that the
proposed model performs increasingly better with larger datasets. We also
analyze the effect of pre-training character embedding of diverse Bangla
character set in authorship attribution. It is seen that the performance is
improved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,
balancing them before training and compare the results.
</summary>
    <author>
      <name>Aisha Khatun</name>
    </author>
    <author>
      <name>Anisur Rahman</name>
    </author>
    <author>
      <name>Md. Saiful Islam</name>
    </author>
    <author>
      <name> Marium-E-Jannat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05315v1</id>
    <updated>2020-01-11T14:50:57Z</updated>
    <published>2020-01-11T14:50:57Z</published>
    <title>A Continuous Space Neural Language Model for Bengali Language</title>
    <summary>  Language models are generally employed to estimate the probability
distribution of various linguistic units, making them one of the fundamental
parts of natural language processing. Applications of language models include a
wide spectrum of tasks such as text summarization, translation and
classification. For a low resource language like Bengali, the research in this
area so far can be considered to be narrow at the very least, with some
traditional count based models being proposed. This paper attempts to address
the issue and proposes a continuous-space neural language model, or more
specifically an ASGD weight dropped LSTM language model, along with techniques
to efficiently train it for Bengali Language. The performance analysis with
some currently existing count based models illustrated in this paper also shows
that the proposed architecture outperforms its counterparts by achieving an
inference perplexity as low as 51.2 on the held out data set for Bengali.
</summary>
    <author>
      <name>Hemayet Ahmed Chowdhury</name>
    </author>
    <author>
      <name>Md. Azizul Haque Imon</name>
    </author>
    <author>
      <name>Anisur Rahman</name>
    </author>
    <author>
      <name>Aisha Khatun</name>
    </author>
    <author>
      <name>Md. Saiful Islam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06094v1</id>
    <updated>2020-01-11T12:15:30Z</updated>
    <published>2020-01-11T12:15:30Z</published>
    <title>On- Device Information Extraction from Screenshots in form of tags</title>
    <summary>  We propose a method to make mobile screenshots easily searchable. In this
paper, we present the workflow in which we: 1) preprocessed a collection of
screenshots, 2) identified script presentin image, 3) extracted unstructured
text from images, 4) identifiedlanguage of the extracted text, 5) extracted
keywords from the text, 6) identified tags based on image features, 7) expanded
tag set by identifying related keywords, 8) inserted image tags with relevant
images after ranking and indexed them to make it searchable on device. We made
the pipeline which supports multiple languages and executed it on-device, which
addressed privacy concerns. We developed novel architectures for components in
the pipeline, optimized performance and memory for on-device computation. We
observed from experimentation that the solution developed can reduce overall
user effort and improve end user experience while searching, whose results are
published.
</summary>
    <author>
      <name>Sumit Kumar</name>
    </author>
    <author>
      <name>Gopi Ramena</name>
    </author>
    <author>
      <name>Manoj Goyal</name>
    </author>
    <author>
      <name>Debi Mohanty</name>
    </author>
    <author>
      <name>Ankur Agarwal</name>
    </author>
    <author>
      <name>Benu Changmai</name>
    </author>
    <author>
      <name>Sukumar Moharana</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03712v1</id>
    <updated>2020-01-11T05:50:19Z</updated>
    <published>2020-01-11T05:50:19Z</published>
    <title>MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding</title>
    <summary>  Visual-semantic embedding enables various tasks such as image-text retrieval,
image captioning, and visual question answering. The key to successful
visual-semantic embedding is to express visual and textual data properly by
accounting for their intricate relationship. While previous studies have
achieved much advance by encoding the visual and textual data into a joint
space where similar concepts are closely located, they often represent data by
a single vector ignoring the presence of multiple important components in an
image or text. Thus, in addition to the joint embedding space, we propose a
novel multi-head self-attention network to capture various components of visual
and textual data by attending to important parts in data. Our approach achieves
the new state-of-the-art results in image-text retrieval tasks on MS-COCO and
Flicker30K datasets. Through the visualization of the attention maps that
capture distinct semantic components at multiple positions in the image and the
text, we demonstrate that our method achieves an effective and interpretable
visual-semantic joint space.
</summary>
    <author>
      <name>Geondo Park</name>
    </author>
    <author>
      <name>Chihye Han</name>
    </author>
    <author>
      <name>Wonjun Yoon</name>
    </author>
    <author>
      <name>Daeshik Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 2020 IEEE Winter Conference on Applications of
  Computer Vision (WACV 20), 9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05284v1</id>
    <updated>2020-01-11T05:48:52Z</updated>
    <published>2020-01-11T05:48:52Z</published>
    <title>Improving Spoken Language Understanding By Exploiting ASR N-best
  Hypotheses</title>
    <summary>  In a modern spoken language understanding (SLU) system, the natural language
understanding (NLU) module takes interpretations of a speech from the automatic
speech recognition (ASR) module as the input. The NLU module usually uses the
first best interpretation of a given speech in downstream tasks such as domain
and intent classification. However, the ASR module might misrecognize some
speeches and the first best interpretation could be erroneous and noisy. Solely
relying on the first best interpretation could make the performance of
downstream tasks non-optimal. To address this issue, we introduce a series of
simple yet efficient models for improving the understanding of semantics of the
input speeches by collectively exploiting the n-best speech interpretations
from the ASR module.
</summary>
    <author>
      <name>Mingda Li</name>
    </author>
    <author>
      <name>Weitong Ruan</name>
    </author>
    <author>
      <name>Xinyue Liu</name>
    </author>
    <author>
      <name>Luca Soldaini</name>
    </author>
    <author>
      <name>Wael Hamza</name>
    </author>
    <author>
      <name>Chengwei Su</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ICASSP 2020. Have signed an e-copyright agreement with
  the IEEE during ICASSP 2020 submission</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03708v1</id>
    <updated>2020-01-11T03:54:31Z</updated>
    <published>2020-01-11T03:54:31Z</published>
    <title>PatentTransformer-2: Controlling Patent Text Generation by Structural
  Metadata</title>
    <summary>  PatentTransformer is our codename for patent text generation based on
Transformer-based models. Our goal is "Augmented Inventing." In this second
version, we leverage more of the structural metadata in patents. The structural
metadata includes patent title, abstract, and dependent claim, in addition to
independent claim previously. Metadata controls what kind of patent text for
the model to generate. Also, we leverage the relation between metadata to build
a text-to-text generation flow, for example, from a few words to a title, the
title to an abstract, the abstract to an independent claim, and the independent
claim to multiple dependent claims. The text flow can go backward because the
relation is trained bidirectionally. We release our GPT-2 models trained from
scratch and our code for inference so that readers can verify and generate
patent text on their own. As for generation quality, we measure it by both
ROUGE and Google Universal Sentence Encoder.
</summary>
    <author>
      <name>Jieh-Sheng Lee</name>
    </author>
    <author>
      <name>Jieh Hsiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">demo paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03671v1</id>
    <updated>2020-01-10T21:35:28Z</updated>
    <published>2020-01-10T21:35:28Z</published>
    <title>Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for
  Language Grounding Tasks in Street View</title>
    <summary>  The Touchdown dataset (Chen et al., 2019) provides instructions by human
annotators for navigation through New York City streets and for resolving
spatial descriptions at a given location. To enable the wider research
community to work effectively with the Touchdown tasks, we are publicly
releasing the 29k raw Street View panoramas needed for Touchdown. We follow the
process used for the StreetLearn data release (Mirowski et al., 2019) to check
panoramas for personally identifiable information and blur them as necessary.
These have been added to the StreetLearn dataset and can be obtained via the
same process as used previously for StreetLearn. We also provide a reference
implementation for both of the Touchdown tasks: vision and language navigation
(VLN) and spatial description resolution (SDR). We compare our model results to
those given in Chen et al. (2019) and show that the panoramas we have added to
StreetLearn fully support both Touchdown tasks and can be used effectively for
further research and comparison.
</summary>
    <author>
      <name>Harsh Mehta</name>
    </author>
    <author>
      <name>Yoav Artzi</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>Piotr Mirowski</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03632v1</id>
    <updated>2020-01-10T19:02:52Z</updated>
    <published>2020-01-10T19:02:52Z</published>
    <title>Does syntax need to grow on trees? Sources of hierarchical inductive
  bias in sequence-to-sequence networks</title>
    <summary>  Learners that are exposed to the same training data might generalize
differently due to differing inductive biases. In neural network models,
inductive biases could in theory arise from any aspect of the model
architecture. We investigate which architectural factors affect the
generalization behavior of neural sequence-to-sequence models trained on two
syntactic tasks, English question formation and English tense reinflection. For
both tasks, the training set is consistent with a generalization based on
hierarchical structure and a generalization based on linear order. All
architectural factors that we investigated qualitatively affected how models
generalized, including factors with no clear connection to hierarchical
structure. For example, LSTMs and GRUs displayed qualitatively different
inductive biases. However, the only factor that consistently contributed a
hierarchical bias across tasks was the use of a tree-structured model rather
than a model with sequential recurrence, suggesting that human-like syntactic
generalization requires architectural syntactic structure.
</summary>
    <author>
      <name>R. Thomas McCoy</name>
    </author>
    <author>
      <name>Robert Frank</name>
    </author>
    <author>
      <name>Tal Linzen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 figures; accepted to TACL</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03521v1</id>
    <updated>2020-01-10T15:45:59Z</updated>
    <published>2020-01-10T15:45:59Z</published>
    <title>Towards Minimal Supervision BERT-based Grammar Error Correction</title>
    <summary>  Current grammatical error correction (GEC) models typically consider the task
as sequence generation, which requires large amounts of annotated data and
limit the applications in data-limited settings. We try to incorporate
contextual information from pre-trained language model to leverage annotation
and benefit multilingual scenarios. Results show strong potential of
Bidirectional Encoder Representations from Transformers (BERT) in grammatical
error correction task.
</summary>
    <author>
      <name>Yiyuan Li</name>
    </author>
    <author>
      <name>Antonios Anastasopoulos</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03369v1</id>
    <updated>2020-01-10T10:14:07Z</updated>
    <published>2020-01-10T10:14:07Z</published>
    <title>Inductive Document Network Embedding with Topic-Word Attention</title>
    <summary>  Document network embedding aims at learning representations for a structured
text corpus i.e. when documents are linked to each other. Recent algorithms
extend network embedding approaches by incorporating the text content
associated with the nodes in their formulations. In most cases, it is hard to
interpret the learned representations. Moreover, little importance is given to
the generalization to new documents that are not observed within the network.
In this paper, we propose an interpretable and inductive document network
embedding method. We introduce a novel mechanism, the Topic-Word Attention
(TWA), that generates document representations based on the interplay between
word and topic representations. We train these word and topic vectors through
our general model, Inductive Document Network Embedding (IDNE), by leveraging
the connections in the document network. Quantitative evaluations show that our
approach achieves state-of-the-art performance on various networks and we
qualitatively show that our model produces meaningful and interpretable
representations of the words, topics and documents.
</summary>
    <author>
      <name>Robin Brochier</name>
    </author>
    <author>
      <name>Adrien Guille</name>
    </author>
    <author>
      <name>Julien Velcin</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03361v1</id>
    <updated>2020-01-10T09:29:20Z</updated>
    <published>2020-01-10T09:29:20Z</published>
    <title>Co-evolution of language and agents in referential games</title>
    <summary>  Referential games offer a grounded learning environment for neural agents,
that accounts for the functional aspects of language. However, they fail to
account for another fundamental aspect of human language: Because languages are
transmitted from generation to generation, they have to be learnable by new
language users, which makes them subject to cultural evolution. Recent work has
shown that incorporating cultural evolution in referential game results in
considerable improvements in the properties of the languages that emerge in the
game. In this work, we first substantiate this claim with a different data set
and a wider array of evaluation metrics. Then, drawing inspiration from
linguistic theories of human language evolution, we consider a scenario in
which not only cultural but also genetic evolution is integrated. As our core
contribution, we introduce the Language Transmission Engine, in which cultural
evolution of the language is combined with genetic evolution of the agents'
architecture. We show that this co-evolution scenario leads to across-the-board
improvements on all considered metrics. These results stress that cultural
evolution is important for language emergence studies, but also the suitability
of the architecture itself should be considered.
</summary>
    <author>
      <name>Gautier Dagan</name>
    </author>
    <author>
      <name>Dieuwke Hupkes</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03324v1</id>
    <updated>2020-01-10T06:40:49Z</updated>
    <published>2020-01-10T06:40:49Z</published>
    <title>Machine Learning Approaches for Amharic Parts-of-speech Tagging</title>
    <summary>  Part-of-speech (POS) tagging is considered as one of the basic but necessary
tools which are required for many Natural Language Processing (NLP)
applications such as word sense disambiguation, information retrieval,
information processing, parsing, question answering, and machine translation.
Performance of the current POS taggers in Amharic is not as good as that of the
contemporary POS taggers available for English and other European languages.
The aim of this work is to improve POS tagging performance for the Amharic
language, which was never above 91%. Usage of morphological knowledge, an
extension of the existing annotated data, feature extraction, parameter tuning
by applying grid search and the tagging algorithms have been examined and
obtained significant performance difference from the previous works. We have
used three different datasets for POS experiments.
</summary>
    <author>
      <name>Ibrahim Gashaw</name>
    </author>
    <author>
      <name>H L. Shashirekha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15th International Conference on Natural Language Processing
  (ICON-2018)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03303v1</id>
    <updated>2020-01-10T04:39:44Z</updated>
    <published>2020-01-10T04:39:44Z</published>
    <title>Linking Social Media Posts to News with Siamese Transformers</title>
    <summary>  Many computational social science projects examine online discourse
surrounding a specific trending topic. These works often involve the
acquisition of large-scale corpora relevant to the event in question to analyze
aspects of the response to the event. Keyword searches present a
precision-recall trade-off and crowd-sourced annotations, while effective, are
costly. This work aims to enable automatic and accurate ad-hoc retrieval of
comments discussing a trending topic from a large corpus, using only a handful
of seed news articles.
</summary>
    <author>
      <name>Jacob Danovitch</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03294v1</id>
    <updated>2020-01-10T03:12:28Z</updated>
    <published>2020-01-10T03:12:28Z</published>
    <title>Learning to Multi-Task Learn for Better Neural Machine Translation</title>
    <summary>  Scarcity of parallel sentence pairs is a major challenge for training high
quality neural machine translation (NMT) models in bilingually low-resource
scenarios, as NMT is data-hungry. Multi-task learning is an elegant approach to
inject linguistic-related inductive biases into NMT, using auxiliary syntactic
and semantic tasks, to improve generalisation. The challenge, however, is to
devise effective training schedules, prescribing when to make use of the
auxiliary tasks during the training process to fill the knowledge gaps of the
main translation task, a setting referred to as biased-MTL. Current approaches
for the training schedule are based on hand-engineering heuristics, whose
effectiveness vary in different MTL settings. We propose a novel framework for
learning the training schedule, ie learning to multi-task learn, for the MTL
setting of interest. We formulate the training schedule as a Markov decision
process which paves the way to employ policy learning methods to learn the
scheduling policy. We effectively and efficiently learn the training schedule
policy within the imitation learning framework using an oracle policy algorithm
that dynamically sets the importance weights of auxiliary tasks based on their
contributions to the generalisability of the main NMT task. Experiments on
low-resource NMT settings show the resulting automatically learned training
schedulers are competitive with the best heuristics, and lead to up to +1.1
BLEU score improvements.
</summary>
    <author>
      <name>Poorya Zaremoodi</name>
    </author>
    <author>
      <name>Gholamreza Haffari</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03278v1</id>
    <updated>2020-01-10T01:45:45Z</updated>
    <published>2020-01-10T01:45:45Z</published>
    <title>A Scalable Chatbot Platform Leveraging Online Community Posts: A
  Proof-of-Concept Study</title>
    <summary>  The development of natural language processing algorithms and the explosive
growth of conversational data are encouraging researches on the human-computer
conversation. Still, getting qualified conversational data on a large scale is
difficult and expensive. In this paper, we verify the feasibility of
constructing a data-driven chatbot with processed online community posts by
using them as pseudo-conversational data. We argue that chatbots for various
purposes can be built extensively through the pipeline exploiting the common
structure of community posts. Our experiment demonstrates that chatbots created
along the pipeline can yield the proper responses.
</summary>
    <author>
      <name>Sihyeon Jo</name>
    </author>
    <author>
      <name>Seungryong Yoo</name>
    </author>
    <author>
      <name>Sangwon Im</name>
    </author>
    <author>
      <name>Seung Hee Yang</name>
    </author>
    <author>
      <name>Tong Zuo</name>
    </author>
    <author>
      <name>Hee-Eun Kim</name>
    </author>
    <author>
      <name>SangWook Han</name>
    </author>
    <author>
      <name>Seong-Woo Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be Published on the 10th February, 2020, in HCI (Human-Computer
  Interaction) Conference 2020, Republic of Korea</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03278v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03278v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04260v1</id>
    <updated>2020-01-10T01:40:27Z</updated>
    <published>2020-01-10T01:40:27Z</published>
    <title>Improving Dysarthric Speech Intelligibility Using Cycle-consistent
  Adversarial Training</title>
    <summary>  Dysarthria is a motor speech impairment affecting millions of people.
Dysarthric speech can be far less intelligible than those of non-dysarthric
speakers, causing significant communication difficulties. The goal of our work
is to develop a model for dysarthric to healthy speech conversion using
Cycle-consistent GAN. Using 18,700 dysarthric and 8,610 healthy control Korean
utterances that were recorded for the purpose of automatic recognition of voice
keyboard in a previous study, the generator is trained to transform dysarthric
to healthy speech in the spectral domain, which is then converted back to
speech. Objective evaluation using automatic speech recognition of the
generated utterance on a held-out test set shows that the recognition
performance is improved compared with the original dysarthic speech after
performing adversarial training, as the absolute WER has been lowered by 33.4%.
It demonstrates that the proposed GAN-based conversion method is useful for
improving dysarthric speech intelligibility.
</summary>
    <author>
      <name>Seung Hee Yang</name>
    </author>
    <author>
      <name>Minhwa Chung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be Published on the 24th February in BIOSIGNALS 2020. arXiv admin
  note: text overlap with arXiv:1904.09407</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05292v1</id>
    <updated>2020-01-09T20:52:38Z</updated>
    <published>2020-01-09T20:52:38Z</published>
    <title>The empirical structure of word frequency distributions</title>
    <summary>  The frequencies at which individual words occur across languages follow power
law distributions, a pattern of findings known as Zipf's law. A vast literature
argues over whether this serves to optimize the efficiency of human
communication, however this claim is necessarily post hoc, and it has been
suggested that Zipf's law may in fact describe mixtures of other distributions.
From this perspective, recent findings that Sinosphere first (family) names are
geometrically distributed are notable, because this is actually consistent with
information theoretic predictions regarding optimal coding. First names form
natural communicative distributions in most languages, and I show that when
analyzed in relation to the communities in which they are used, first name
distributions across a diverse set of languages are both geometric and,
historically, remarkably similar, with power law distributions only emerging
when empirical distributions are aggregated. I then show this pattern of
findings replicates in communicative distributions of English nouns and verbs.
These results indicate that if lexical distributions support efficient
communication, they do so because their functional structures directly satisfy
the constraints described by information theory, and not because of Zipf's law.
Understanding the function of these information structures is likely to be key
to explaining humankind's remarkable communicative capacities.
</summary>
    <author>
      <name>Michael Ramscar</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03216v1</id>
    <updated>2020-01-09T20:37:49Z</updated>
    <published>2020-01-09T20:37:49Z</published>
    <title>Simulating Lexical Semantic Change from Sense-Annotated Data</title>
    <summary>  We present a novel procedure to simulate lexical semantic change from
synchronic sense-annotated data, and demonstrate its usefulness for assessing
lexical semantic change detection models. The induced dataset represents a
stronger correspondence to empirically observed lexical semantic change than
previous synthetic datasets, because it exploits the intimate relationship
between synchronic polysemy and diachronic change. We publish the data and
provide the first large-scale evaluation gold standard for LSC detection
models.
</summary>
    <author>
      <name>Dominik Schlechtweg</name>
    </author>
    <author>
      <name>Sabine Schulte im Walde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EvoLang, 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03131v1</id>
    <updated>2020-01-09T17:48:44Z</updated>
    <published>2020-01-09T17:48:44Z</published>
    <title>Offensive Language Detection: A Comparative Analysis</title>
    <summary>  Offensive behaviour has become pervasive in the Internet community.
Individuals take the advantage of anonymity in the cyber world and indulge in
offensive communications which they may not consider in the real life.
Governments, online communities, companies etc are investing into prevention of
offensive behaviour content in social media. One of the most effective solution
for tacking this enigmatic problem is the use of computational techniques to
identify offensive content and take action. The current work focuses on
detecting offensive language in English tweets. The dataset used for the
experiment is obtained from SemEval-2019 Task 6 on Identifying and Categorizing
Offensive Language in Social Media (OffensEval). The dataset contains 14,460
annotated English tweets. The present paper provides a comparative analysis and
Random kitchen sink (RKS) based approach for offensive language detection. We
explore the effectiveness of Google sentence encoder, Fasttext, Dynamic mode
decomposition (DMD) based features and Random kitchen sink (RKS) method for
offensive language detection. From the experiments and evaluation we observed
that RKS with fastetxt achieved competing results. The evaluation measures used
are accuracy, precision, recall, f1-score.
</summary>
    <author>
      <name>Vyshnav M T</name>
    </author>
    <author>
      <name>Sachin Kumar S</name>
    </author>
    <author>
      <name>Soman K P</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03436v1</id>
    <updated>2020-01-09T15:19:45Z</updated>
    <published>2020-01-09T15:19:45Z</published>
    <title>Debate Dynamics for Human-comprehensible Fact-checking on Knowledge
  Graphs</title>
    <summary>  We propose a novel method for fact-checking on knowledge graphs based on
debate dynamics. The underlying idea is to frame the task of triple
classification as a debate game between two reinforcement learning agents which
extract arguments -- paths in the knowledge graph -- with the goal to justify
the fact being true (thesis) or the fact being false (antithesis),
respectively. Based on these arguments, a binary classifier, referred to as the
judge, decides whether the fact is true or false. The two agents can be
considered as sparse feature extractors that present interpretable evidence for
either the thesis or the antithesis. In contrast to black-box methods, the
arguments enable the user to gain an understanding for the decision of the
judge. Moreover, our method allows for interactive reasoning on knowledge
graphs where the users can raise additional arguments or evaluate the debate
taking common sense reasoning and external information into account. Such
interactive systems can increase the acceptance of various AI applications
based on knowledge graphs and can further lead to higher efficiency,
robustness, and fairness.
</summary>
    <author>
      <name>Marcel Hildebrandt</name>
    </author>
    <author>
      <name>Jorge Andres Quintero Serna</name>
    </author>
    <author>
      <name>Yunpu Ma</name>
    </author>
    <author>
      <name>Martin Ringsquandl</name>
    </author>
    <author>
      <name>Mitchell Joblin</name>
    </author>
    <author>
      <name>Volker Tresp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text
  overlap with arXiv:2001.00461</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03041v1</id>
    <updated>2020-01-09T15:07:32Z</updated>
    <published>2020-01-09T15:07:32Z</published>
    <title>Open Challenge for Correcting Errors of Speech Recognition Systems</title>
    <summary>  The paper announces the new long-term challenge for improving the performance
of automatic speech recognition systems. The goal of the challenge is to
investigate methods of correcting the recognition results on the basis of
previously made errors by the speech processing system. The dataset prepared
for the task is described and evaluation criteria are presented.
</summary>
    <author>
      <name>Marek Kubis</name>
    </author>
    <author>
      <name>Zygmunt Vetulani</name>
    </author>
    <author>
      <name>Mikołaj Wypych</name>
    </author>
    <author>
      <name>Tomasz Ziętkiewicz</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vetulani, Zygmunt, Paroubek, Patrick (eds.): Proceedings of the
  9th Language and Technology Conference, pp. 219-223, Wydawnictwo Nauka i
  Innowacje, Pozna\'n, Poland, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.03041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02943v1</id>
    <updated>2020-01-09T12:34:01Z</updated>
    <published>2020-01-09T12:34:01Z</published>
    <title>Binary and Multitask Classification Model for Dutch Anaphora Resolution:
  Die/Dat Prediction</title>
    <summary>  The correct use of Dutch pronouns 'die' and 'dat' is a stumbling block for
both native and non-native speakers of Dutch due to the multiplicity of
syntactic functions and the dependency on the antecedent's gender and number.
Drawing on previous research conducted on neural context-dependent dt-mistake
correction models (Heyman et al. 2018), this study constructs the first neural
network model for Dutch demonstrative and relative pronoun resolution that
specifically focuses on the correction and part-of-speech prediction of these
two pronouns. Two separate datasets are built with sentences obtained from,
respectively, the Dutch Europarl corpus (Koehn 2015) - which contains the
proceedings of the European Parliament from 1996 to the present - and the SoNaR
corpus (Oostdijk et al. 2013) - which contains Dutch texts from a variety of
domains such as newspapers, blogs and legal texts. Firstly, a binary
classification model solely predicts the correct 'die' or 'dat'. The classifier
with a bidirectional long short-term memory architecture achieves 84.56%
accuracy. Secondly, a multitask classification model simultaneously predicts
the correct 'die' or 'dat' and its part-of-speech tag. The model containing a
combination of a sentence and context encoder with both a bidirectional long
short-term memory architecture results in 88.63% accuracy for die/dat
prediction and 87.73% accuracy for part-of-speech prediction. More
evenly-balanced data, larger word embeddings, an extra bidirectional long
short-term memory layer and integrated part-of-speech knowledge positively
affects die/dat prediction performance, while a context encoder architecture
raises part-of-speech prediction performance. This study shows promising
results and can serve as a starting point for future research on machine
learning models for Dutch anaphora resolution.
</summary>
    <author>
      <name>Liesbeth Allein</name>
    </author>
    <author>
      <name>Artuur Leeuwenberg</name>
    </author>
    <author>
      <name>Marie-Francine Moens</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02885v1</id>
    <updated>2020-01-09T08:43:30Z</updated>
    <published>2020-01-09T08:43:30Z</published>
    <title>Resolving the Scope of Speculation and Negation using Transformer-Based
  Architectures</title>
    <summary>  Speculation is a naturally occurring phenomena in textual data, forming an
integral component of many systems, especially in the biomedical information
retrieval domain. Previous work addressing cue detection and scope resolution
(the two subtasks of speculation detection) have ranged from rule-based systems
to deep learning-based approaches. In this paper, we apply three popular
transformer-based architectures, BERT, XLNet and RoBERTa to this task, on two
publicly available datasets, BioScope Corpus and SFU Review Corpus, reporting
substantial improvements over previously reported results (by at least 0.29 F1
points on cue detection and 4.27 F1 points on scope resolution). We also
experiment with joint training of the model on multiple datasets, which
outperforms the single dataset training approach by a good margin. We observe
that XLNet consistently outperforms BERT and RoBERTa, contrary to results on
other benchmark datasets. To confirm this observation, we apply XLNet and
RoBERTa to negation detection and scope resolution, reporting state-of-the-art
results on negation scope resolution for the BioScope Corpus (increase of 3.16
F1 points on the BioScope Full Papers, 0.06 F1 points on the BioScope
Abstracts) and the SFU Review Corpus (increase of 0.3 F1 points).
</summary>
    <author>
      <name>Benita Kathleen Britto</name>
    </author>
    <author>
      <name>Aditya Khandelwal</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02836v1</id>
    <updated>2020-01-09T04:47:14Z</updated>
    <published>2020-01-09T04:47:14Z</published>
    <title>Multiplex Word Embeddings for Selectional Preference Acquisition</title>
    <summary>  Conventional word embeddings represent words with fixed vectors, which are
usually trained based on co-occurrence patterns among words. In doing so,
however, the power of such representations is limited, where the same word
might be functionalized separately under different syntactic relations. To
address this limitation, one solution is to incorporate relational dependencies
of different words into their embeddings. Therefore, in this paper, we propose
a multiplex word embedding model, which can be easily extended according to
various relations among words. As a result, each word has a center embedding to
represent its overall semantics, and several relational embeddings to represent
its relational dependencies. Compared to existing models, our model can
effectively distinguish words with respect to different relations without
introducing unnecessary sparseness. Moreover, to accommodate various relations,
we use a small dimension for relational embeddings and our model is able to
keep their effectiveness. Experiments on selectional preference acquisition and
word similarity demonstrate the effectiveness of the proposed model, and a
further study of scalability also proves that our embeddings only need 1/20 of
the original embedding size to achieve better performance.
</summary>
    <author>
      <name>Hongming Zhang</name>
    </author>
    <author>
      <name>Jiaxin Bai</name>
    </author>
    <author>
      <name>Yan Song</name>
    </author>
    <author>
      <name>Kun Xu</name>
    </author>
    <author>
      <name>Changlong Yu</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <author>
      <name>Wilfred Ng</name>
    </author>
    <author>
      <name>Dong Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">emnlp-ijcnlp 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02731v1</id>
    <updated>2020-01-08T20:36:17Z</updated>
    <published>2020-01-08T20:36:17Z</published>
    <title>SirenLess: reveal the intention behind news</title>
    <summary>  News articles tend to be increasingly misleading nowadays, preventing readers
from making subjective judgments towards certain events. While some machine
learning approaches have been proposed to detect misleading news, most of them
are black boxes that provide limited help for humans in decision making. In
this paper, we present SirenLess, a visual analytical system for misleading
news detection by linguistic features. The system features article explorer, a
novel interactive tool that integrates news metadata and linguistic features to
reveal semantic structures of news articles and facilitate textual analysis. We
use SirenLess to analyze 18 news articles from different sources and summarize
some helpful patterns for misleading news detection. A user study with
journalism professionals and university students is conducted to confirm the
usefulness and effectiveness of our system.
</summary>
    <author>
      <name>Xumeng Chen</name>
    </author>
    <author>
      <name>Leo Yu-Ho Lo</name>
    </author>
    <author>
      <name>Huamin Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02674v3</id>
    <updated>2020-02-27T15:10:13Z</updated>
    <published>2020-01-08T18:58:02Z</published>
    <title>Streaming automatic speech recognition with the transformer model</title>
    <summary>  Encoder-decoder based sequence-to-sequence models have demonstrated
state-of-the-art results in end-to-end automatic speech recognition (ASR).
Recently, the transformer architecture, which uses self-attention to model
temporal context information, has been shown to achieve significantly lower
word error rates (WERs) compared to recurrent neural network (RNN) based system
architectures. Despite its success, the practical usage is limited to offline
ASR tasks, since encoder-decoder architectures typically require an entire
speech utterance as input. In this work, we propose a transformer based
end-to-end ASR system for streaming ASR, where an output must be generated
shortly after each spoken word. To achieve this, we apply time-restricted
self-attention for the encoder and triggered attention for the encoder-decoder
attention mechanism. Our proposed streaming transformer architecture achieves
2.8% and 7.3% WER for the clean and other test data of LibriSpeech, which to
our knowledge is the best published streaming end-to-end ASR result for this
task.
</summary>
    <author>
      <name>Niko Moritz</name>
    </author>
    <author>
      <name>Takaaki Hori</name>
    </author>
    <author>
      <name>Jonathan Le Roux</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02674v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02674v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02669v1</id>
    <updated>2020-01-08T18:52:39Z</updated>
    <published>2020-01-08T18:52:39Z</published>
    <title>A Correspondence Analysis Framework for Author-Conference
  Recommendations</title>
    <summary>  For many years, achievements and discoveries made by scientists are made
aware through research papers published in appropriate journals or conferences.
Often, established scientists and especially newbies are caught up in the
dilemma of choosing an appropriate conference to get their work through. Every
scientific conference and journal is inclined towards a particular field of
research and there is a vast multitude of them for any particular field.
Choosing an appropriate venue is vital as it helps in reaching out to the right
audience and also to further one's chance of getting their paper published. In
this work, we address the problem of recommending appropriate conferences to
the authors to increase their chances of acceptance. We present three different
approaches for the same involving the use of social network of the authors and
the content of the paper in the settings of dimensionality reduction and topic
modeling. In all these approaches, we apply Correspondence Analysis (CA) to
derive appropriate relationships between the entities in question, such as
conferences and papers. Our models show promising results when compared with
existing methods such as content-based filtering, collaborative filtering and
hybrid filtering.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Manish Sharma</name>
    </author>
    <author>
      <name>Vijaya Saradhi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages including references, 6 figures, 15 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02660v1</id>
    <updated>2020-01-08T18:04:52Z</updated>
    <published>2020-01-08T18:04:52Z</published>
    <title>REST: A thread embedding approach for identifying and classifying
  user-specified information in security forums</title>
    <summary>  How can we extract useful information from a security forum? We focus on
identifying threads of interest to a security professional: (a) alerts of
worrisome events, such as attacks, (b) offering of malicious services and
products, (c) hacking information to perform malicious acts, and (d) useful
security-related experiences. The analysis of security forums is in its infancy
despite several promising recent works. Novel approaches are needed to address
the challenges in this domain: (a) the difficulty in specifying the "topics" of
interest efficiently, and (b) the unstructured and informal nature of the text.
We propose, REST, a systematic methodology to: (a) identify threads of interest
based on a, possibly incomplete, bag of words, and (b) classify them into one
of the four classes above. The key novelty of the work is a multi-step weighted
embedding approach: we project words, threads and classes in appropriate
embedding spaces and establish relevance and similarity there. We evaluate our
method with real data from three security forums with a total of 164k posts and
21K threads. First, REST robustness to initial keyword selection can extend the
user-provided keyword set and thus, it can recover from missing keywords.
Second, REST categorizes the threads into the classes of interest with superior
accuracy compared to five other methods: REST exhibits an accuracy between
63.3-76.9%. We see our approach as a first step for harnessing the wealth of
information of online forums in a user-friendly way, since the user can loosely
specify her keywords of interest.
</summary>
    <author>
      <name>Joobin Gharibshah</name>
    </author>
    <author>
      <name>Evangelos E. Papalexakis</name>
    </author>
    <author>
      <name>Michalis Faloutsos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ICWSM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02524v1</id>
    <updated>2020-01-08T13:44:10Z</updated>
    <published>2020-01-08T13:44:10Z</published>
    <title>LTP: A New Active Learning Strategy for Bert-CRF Based Named Entity
  Recognition</title>
    <summary>  In recent years, deep learning has achieved great success in many natural
language processing tasks including named entity recognition. The shortcoming
is that a large amount of manually-annotated data is usually required. Previous
studies have demonstrated that both transfer learning and active learning could
elaborately reduce the cost of data annotation in terms of their corresponding
advantages, but there is still plenty of room for improvement. We assume that
the convergence of the two methods can complement with each other, so that the
model could be trained more accurately with less labelled data, and active
learning method could enhance transfer learning method to accurately select the
minimum data samples for iterative learning. However, in real applications we
found this approach is challenging because the sample selection of traditional
active learning strategy merely depends on the final probability value of its
model output, and this makes it quite difficult to evaluate the quality of the
selected data samples. In this paper, we first examine traditional active
learning strategies in a specific case of BERT-CRF that has been widely used in
named entity recognition. Then we propose an uncertainty-based active learning
strategy called Lowest Token Probability (LTP) which considers not only the
final output but also the intermediate results. We test LTP on multiple
datasets, and the experiments show that LTP performs better than traditional
strategies (incluing LC and NLC) on both token-level $F_1$ and sentence-level
accuracy, especially in complex imbalanced datasets.
</summary>
    <author>
      <name>Mingyi Liu</name>
    </author>
    <author>
      <name>Zhiying Tu</name>
    </author>
    <author>
      <name>Zhongjie Wang</name>
    </author>
    <author>
      <name>Xiaofei Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02462v1</id>
    <updated>2020-01-08T11:44:47Z</updated>
    <published>2020-01-08T11:44:47Z</published>
    <title>From Natural Language Instructions to Complex Processes: Issues in
  Chaining Trigger Action Rules</title>
    <summary>  Automation services for complex business processes usually require a high
level of information technology literacy. There is a strong demand for a
smartly assisted process automation (IPA: intelligent process automation)
service that enables even general users to easily use advanced automation. A
natural language interface for such automation is expected as an elemental
technology for the IPA realization. The workflow targeted by IPA is generally
composed of a combination of multiple tasks. However, semantic parsing, one of
the natural language processing methods, for such complex workflows has not yet
been fully studied. The reasons are that (1) the formal expression and grammar
of the workflow required for semantic analysis have not been sufficiently
examined and (2) the dataset of the workflow formal expression with its
corresponding natural language description required for learning workflow
semantics did not exist. This paper defines a new grammar for complex workflows
with chaining machine-executable meaning representations for semantic parsing.
The representations are at a high abstraction level. Additionally, an approach
to creating datasets is proposed based on this grammar.
</summary>
    <author>
      <name>Nobuhiro Ito</name>
    </author>
    <author>
      <name>Yuya Suzuki</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02380v1</id>
    <updated>2020-01-08T05:14:49Z</updated>
    <published>2020-01-08T05:14:49Z</published>
    <title>A Neural Approach to Discourse Relation Signal Detection</title>
    <summary>  Previous data-driven work investigating the types and distributions of
discourse relation signals, including discourse markers such as 'however' or
phrases such as 'as a result' has focused on the relative frequencies of signal
words within and outside text from each discourse relation. Such approaches do
not allow us to quantify the signaling strength of individual instances of a
signal on a scale (e.g. more or less discourse-relevant instances of 'and'), to
assess the distribution of ambiguity for signals, or to identify words that
hinder discourse relation identification in context ('anti-signals' or
'distractors'). In this paper we present a data-driven approach to signal
detection using a distantly supervised neural network and develop a metric,
{\Delta}s (or 'delta-softmax'), to quantify signaling strength. Ranging between
-1 and 1 and relying on recent advances in contextualized words embeddings, the
metric represents each word's positive or negative contribution to the
identifiability of a relation in specific instances in context. Based on an
English corpus annotated for discourse relations using Rhetorical Structure
Theory and signal type annotations anchored to specific tokens, our analysis
examines the reliability of the metric, the places where it overlaps with and
differs from human judgments, and the implications for identifying features
that neural models may need in order to perform better on automatic discourse
relation classification.
</summary>
    <author>
      <name>Amir Zeldes</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">D&amp;D</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02332v1</id>
    <updated>2020-01-08T01:19:08Z</updated>
    <published>2020-01-08T01:19:08Z</published>
    <title>Generative Adversarial Zero-Shot Relational Learning for Knowledge
  Graphs</title>
    <summary>  Large-scale knowledge graphs (KGs) are shown to become more important in
current information systems. To expand the coverage of KGs, previous studies on
knowledge graph completion need to collect adequate training instances for
newly-added relations. In this paper, we consider a novel formulation,
zero-shot learning, to free this cumbersome curation. For newly-added
relations, we attempt to learn their semantic features from their text
descriptions and hence recognize the facts of unseen relations with no examples
being seen. For this purpose, we leverage Generative Adversarial Networks
(GANs) to establish the connection between text and knowledge graph domain: The
generator learns to generate the reasonable relation embeddings merely with
noisy text descriptions. Under this setting, zero-shot learning is naturally
converted to a traditional supervised classification task. Empirically, our
method is model-agnostic that could be potentially applied to any version of KG
embeddings, and consistently yields performance improvements on NELL and Wiki
dataset.
</summary>
    <author>
      <name>Pengda Qin</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Wenhu Chen</name>
    </author>
    <author>
      <name>Chunyun Zhang</name>
    </author>
    <author>
      <name>Weiran Xu</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02284v1</id>
    <updated>2020-01-07T21:47:37Z</updated>
    <published>2020-01-07T21:47:37Z</published>
    <title>Multipurpose Intelligent Process Automation via Conversational Assistant</title>
    <summary>  Intelligent Process Automation (IPA) is an emerging technology with a primary
goal to assist the knowledge worker by taking care of repetitive, routine and
low-cognitive tasks. Conversational agents that can interact with users in a
natural language are potential application for IPA systems. Such intelligent
agents can assist the user by answering specific questions and executing
routine tasks that are ordinarily performed in a natural language (i.e.,
customer support). In this work, we tackle a challenge of implementing an IPA
conversational assistant in a real-world industrial setting with a lack of
structured training data. Our proposed system brings two significant benefits:
First, it reduces repetitive and time-consuming activities and, therefore,
allows workers to focus on more intelligent processes. Second, by interacting
with users, it augments the resources with structured and to some extent
labeled training data. We showcase the usage of the latter by re-implementing
several components of our system with Transfer Learning (TL) methods.
</summary>
    <author>
      <name>Alena Moiseeva</name>
    </author>
    <author>
      <name>Dietrich Trautmann</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the AAAI-20 Workshop on Intelligent Process Automation</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02214v1</id>
    <updated>2020-01-07T18:26:38Z</updated>
    <published>2020-01-07T18:26:38Z</published>
    <title>Attributed Multi-Relational Attention Network for Fact-checking URL
  Recommendation</title>
    <summary>  To combat fake news, researchers mostly focused on detecting fake news and
journalists built and maintained fact-checking sites (e.g., Snopes.com and
Politifact.com). However, fake news dissemination has been greatly promoted via
social media sites, and these fact-checking sites have not been fully utilized.
To overcome these problems and complement existing methods against fake news,
in this paper we propose a deep-learning based fact-checking URL recommender
system to mitigate impact of fake news in social media sites such as Twitter
and Facebook. In particular, our proposed framework consists of a
multi-relational attentive module and a heterogeneous graph attention network
to learn complex/semantic relationship between user-URL pairs, user-user pairs,
and URL-URL pairs. Extensive experiments on a real-world dataset show that our
proposed framework outperforms eight state-of-the-art recommendation models,
achieving at least 3~5.3% improvement.
</summary>
    <author>
      <name>Di You</name>
    </author>
    <author>
      <name>Nguyen Vo</name>
    </author>
    <author>
      <name>Kyumin Lee</name>
    </author>
    <author>
      <name>Qiang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CIKM2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02178v1</id>
    <updated>2020-01-07T17:05:16Z</updated>
    <published>2020-01-07T17:05:16Z</published>
    <title>Heaps' law and Heaps functions in tagged texts: Evidences of their
  linguistic relevance</title>
    <summary>  We study the relationship between vocabulary size and text length in a corpus
of $75$ literary works in English, authored by six writers, distinguishing
between the contributions of three grammatical classes (or ``tags,'' namely,
{\it nouns}, {\it verbs}, and {\it others}), and analyze the progressive
appearance of new words of each tag along each individual text. While the
power-law relation prescribed by Heaps' law is satisfactorily fulfilled by
total vocabulary sizes and text lengths, the appearance of new words in each
text is on the whole well described by the average of random shufflings of the
text, which does not obey a power law. Deviations from this average, however,
are statistically significant and show a systematic trend across the corpus.
Specifically, they reveal that the appearance of new words along each text is
predominantly retarded with respect to the average of random shufflings.
Moreover, different tags are shown to add systematically distinct contributions
to this tendency, with {\it verbs} and {\it others} being respectively more and
less retarded than the mean trend, and {\it nouns} following instead this
overall mean. These statistical systematicities are likely to point to the
existence of linguistically relevant information stored in the different
variants of Heaps' law, a feature that is still in need of extensive
assessment.
</summary>
    <author>
      <name>Andrés Chacoma</name>
    </author>
    <author>
      <name>Damián H. Zanette</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02107v1</id>
    <updated>2020-01-07T15:11:27Z</updated>
    <published>2020-01-07T15:11:27Z</published>
    <title>Leveraging Prior Knowledge for Protein-Protein Interaction Extraction
  with Memory Network</title>
    <summary>  Automatically extracting Protein-Protein Interactions (PPI) from biomedical
literature provides additional support for precision medicine efforts. This
paper proposes a novel memory network-based model (MNM) for PPI extraction,
which leverages prior knowledge about protein-protein pairs with memory
networks. The proposed MNM captures important context clues related to
knowledge representations learned from knowledge bases. Both entity embeddings
and relation embeddings of prior knowledge are effective in improving the PPI
extraction model, leading to a new state-of-the-art performance on the
BioCreative VI PPI dataset. The paper also shows that multiple computational
layers over an external memory are superior to long short-term memory networks
with the local memories.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Zhuang Liu</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Yunlong Yang</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Yingyu Lin</name>
    </author>
    <author>
      <name>Kun Ma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/database/bay071</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/database/bay071" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on Database-The Journal of Biological Databases and
  Curation, 11 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Database-The Journal of Biological Databases and Curation, 2018,
  2018: bay071</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.02107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02091v1</id>
    <updated>2020-01-07T15:02:28Z</updated>
    <published>2020-01-07T15:02:28Z</published>
    <title>Knowledge-aware Attention Network for Protein-Protein Interaction
  Extraction</title>
    <summary>  Protein-protein interaction (PPI) extraction from published scientific
literature provides additional support for precision medicine efforts. However,
many of the current PPI extraction methods need extensive feature engineering
and cannot make full use of the prior knowledge in knowledge bases (KB). KBs
contain huge amounts of structured information about entities and
relationships, therefore plays a pivotal role in PPI extraction. This paper
proposes a knowledge-aware attention network (KAN) to fuse prior knowledge
about protein-protein pairs and context information for PPI extraction. The
proposed model first adopts a diagonal-disabled multi-head attention mechanism
to encode context sequence along with knowledge representations learned from
KB. Then a novel multi-dimensional attention mechanism is used to select the
features that can best describe the encoded context. Experiment results on the
BioCreative VI PPI dataset show that the proposed approach could acquire
knowledge-aware dependencies between different words in a sequence and lead to
a new state-of-the-art performance.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Zhuang Liu1</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Yingyu Lin</name>
    </author>
    <author>
      <name>Lei Du</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jbi.2019.103234</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jbi.2019.103234" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on Journal of Biomedical Informatics, 14 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Biomedical Informatics, 2019, 96: 103234</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.02091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01989v1</id>
    <updated>2020-01-07T11:50:54Z</updated>
    <published>2020-01-07T11:50:54Z</published>
    <title>Latent Opinions Transfer Network for Target-Oriented Opinion Words
  Extraction</title>
    <summary>  Target-oriented opinion words extraction (TOWE) is a new subtask of ABSA,
which aims to extract the corresponding opinion words for a given opinion
target in a sentence. Recently, neural network methods have been applied to
this task and achieve promising results. However, the difficulty of annotation
causes the datasets of TOWE to be insufficient, which heavily limits the
performance of neural models. By contrast, abundant review sentiment
classification data are easily available at online review sites. These reviews
contain substantial latent opinions information and semantic patterns. In this
paper, we propose a novel model to transfer these opinions knowledge from
resource-rich review sentiment classification datasets to low-resource task
TOWE. To address the challenges in the transfer process, we design an effective
transformation method to obtain latent opinions, then integrate them into TOWE.
Extensive experimental results show that our model achieves better performance
compared to other state-of-the-art methods and significantly outperforms the
base model without transferring opinions knowledge. Further analysis validates
the effectiveness of our model.
</summary>
    <author>
      <name>Zhen Wu</name>
    </author>
    <author>
      <name>Fei Zhao</name>
    </author>
    <author>
      <name>Xin-Yu Dai</name>
    </author>
    <author>
      <name>Shujian Huang</name>
    </author>
    <author>
      <name>Jiajun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI
  2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01986v1</id>
    <updated>2020-01-07T11:47:05Z</updated>
    <published>2020-01-07T11:47:05Z</published>
    <title>Learning Speaker Embedding with Momentum Contrast</title>
    <summary>  Speaker verification can be formulated as a representation learning task,
where speaker-discriminative embeddings are extracted from utterances of
variable lengths. Momentum Contrast (MoCo) is a recently proposed unsupervised
representation learning framework, and has shown its effectiveness for learning
good feature representation for downstream vision tasks. In this work, we apply
MoCo to learn speaker embedding from speech segments. We explore MoCo for both
unsupervised learning and pretraining settings. In the unsupervised scenario,
embedding is learned by MoCo from audio data without using any speaker specific
information. On a large scale dataset with $2,500$ speakers, MoCo can achieve
EER $4.275\%$ trained unsupervisedly, and the EER can decrease further to
$3.58\%$ if extra unlabelled data are used. In the pretraining scenario,
encoder trained by MoCo is used to initialize the downstream supervised
training. With finetuning on the MoCo trained model, the equal error rate (EER)
reduces $13.7\%$ relative ($1.44\%$ to $1.242\%$) compared to a carefully tuned
baseline training from scratch. Comparative study confirms the effectiveness of
MoCo learning good speaker embedding.
</summary>
    <author>
      <name>Ke Ding</name>
    </author>
    <author>
      <name>Xuanji He</name>
    </author>
    <author>
      <name>Guanglu Wan</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01941v1</id>
    <updated>2020-01-07T09:22:58Z</updated>
    <published>2020-01-07T09:22:58Z</published>
    <title>Paraphrase Generation with Latent Bag of Words</title>
    <summary>  Paraphrase generation is a longstanding important problem in natural language
processing.
  In addition, recent progress in deep generative models has shown promising
results on discrete latent variables for text generation.
  Inspired by variational autoencoders with discrete latent structures, in this
work, we propose a latent bag of words (BOW) model for paraphrase generation.
  We ground the semantics of a discrete latent variable by the BOW from the
target sentences.
  We use this latent variable to build a fully differentiable content planning
and surface realization model.
  Specifically, we use source words to predict their neighbors and model the
target BOW with a mixture of softmax.
  We use Gumbel top-k reparameterization to perform differentiable subset
sampling from the predicted BOW distribution.
  We retrieve the sampled word embeddings and use them to augment the decoder
and guide its generation search space.
  Our latent BOW model not only enhances the decoder, but also exhibits clear
interpretability.
  We show the model interpretability with regard to \emph{(i)} unsupervised
learning of word neighbors \emph{(ii)} the step-by-step generation procedure.
  Extensive experiments demonstrate the transparent and effective generation
process of this model.\footnote{Our code can be found at
\url{https://github.com/FranxYao/dgm_latent_bow}}
</summary>
    <author>
      <name>Yao Fu</name>
    </author>
    <author>
      <name>Yansong Feng</name>
    </author>
    <author>
      <name>John P. Cunningham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 19 camera ready</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01895v1</id>
    <updated>2020-01-07T05:21:21Z</updated>
    <published>2020-01-07T05:21:21Z</published>
    <title>Machine-learning classifiers for logographic name matching in public
  health applications: approaches for incorporating phonetic, visual, and
  keystroke similarity in large-scale probabilistic record linkage</title>
    <summary>  Approximate string-matching methods to account for complex variation in
highly discriminatory text fields, such as personal names, can enhance
probabilistic record linkage. However, discriminating between matching and
non-matching strings is challenging for logographic scripts, where similarities
in pronunciation, appearance, or keystroke sequence are not directly encoded in
the string data. We leverage a large Chinese administrative dataset with known
match status to develop logistic regression and Xgboost classifiers integrating
measures of visual, phonetic, and keystroke similarity to enhance
identification of potentially-matching name pairs. We evaluate three methods of
leveraging name similarity scores in large-scale probabilistic record linkage,
which can adapt to varying match prevalence and information in supporting
fields: (1) setting a threshold score based on predicted quality of
name-matching across all record pairs; (2) setting a threshold score based on
predicted discriminatory power of the linkage model; and (3) using empirical
score distributions among matches and nonmatches to perform Bayesian adjustment
of matching probabilities estimated from exact-agreement linkage. In
experiments on holdout data, as well as data simulated with varying name error
rates and supporting fields, a logistic regression classifier incorporated via
the Bayesian method demonstrated marked improvements over exact-agreement
linkage with respect to discriminatory power, match probability estimation, and
accuracy, reducing the total number of misclassified record pairs by 21% in
test data and up to an average of 93% in simulated datasets. Our results
demonstrate the value of incorporating visual, phonetic, and keystroke
similarity for logographic name matching, as well as the promise of our
Bayesian approach to leverage name-matching within large-scale record linkage.
</summary>
    <author>
      <name>Philip A. Collender</name>
    </author>
    <author>
      <name>Zhiyue Tom Hu</name>
    </author>
    <author>
      <name>Charles Li</name>
    </author>
    <author>
      <name>Qu Cheng</name>
    </author>
    <author>
      <name>Xintong Li</name>
    </author>
    <author>
      <name>Yue You</name>
    </author>
    <author>
      <name>Song Liang</name>
    </author>
    <author>
      <name>Changhong Yang</name>
    </author>
    <author>
      <name>Justin V. Remais</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01871v2</id>
    <updated>2020-03-04T03:02:14Z</updated>
    <published>2020-01-07T03:10:42Z</published>
    <title>Attention over Parameters for Dialogue Systems</title>
    <summary>  Dialogue systems require a great deal of different but complementary
expertise to assist, inform, and entertain humans. For example, different
domains (e.g., restaurant reservation, train ticket booking) of goal-oriented
dialogue systems can be viewed as different skills, and so does ordinary
chatting abilities of chit-chat dialogue systems. In this paper, we propose to
learn a dialogue system that independently parameterizes different dialogue
skills, and learns to select and combine each of them through Attention over
Parameters (AoP). The experimental results show that this approach achieves
competitive performance on a combined dataset of MultiWOZ, In-Car Assistant,
and Persona-Chat. Finally, we demonstrate that each dialogue skill is
effectively learned and can be combined with other skills to produce selective
responses.
</summary>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Zhaojiang Lin</name>
    </author>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Jamin Shin</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS Conversational AI Workshops (Best Paper Award)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01871v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01871v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01863v1</id>
    <updated>2020-01-07T02:42:57Z</updated>
    <published>2020-01-07T02:42:57Z</published>
    <title>Text Complexity Classification Based on Linguistic Information:
  Application to Intelligent Tutoring of ESL</title>
    <summary>  The goal of this work is to build a classifier that can identify text
complexity within the context of teaching reading to English as a Second
Language (ESL) learners. To present language learners with texts that are
suitable to their level of English, a set of features that can describe the
phonological, morphological, lexical, syntactic, discursive, and psychological
complexity of a given text were identified. Using a corpus of 6171 texts, which
had already been classified into three different levels of difficulty by ESL
experts, different experiments were conducted with five machine learning
algorithms. The results showed that the adopted linguistic features provide a
good overall classification performance (F-Score = 0.97). A scalability
evaluation was conducted to test if such a classifier could be used within real
applications, where it can be, for example, plugged into a search engine or a
web-scraping module. In this evaluation, the texts in the test set are not only
different from those from the training set but also of different types (ESL
texts vs. children reading texts). Although the overall performance of the
classifier decreased significantly (F-Score = 0.65), the confusion matrix shows
that most of the classification errors are between the classes two and three
(the middle-level classes) and that the system has a robust performance in
categorizing texts of class one and four. This behavior can be explained by the
difference in classification criteria between the two corpora. Hence, the
observed results confirm the usability of such a classifier within a real-world
application.
</summary>
    <author>
      <name>M. Zakaria Kurdi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an unpublished pre-print, the JDMDH journal requires
  submission to arxiv.org before the submission to the journal (see the link:
  https://jdmdh.episciences.org/page/submissions#)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01819v1</id>
    <updated>2020-01-07T00:17:52Z</updated>
    <published>2020-01-07T00:17:52Z</published>
    <title>RECAST: Interactive Auditing of Automatic Toxicity Detection Models</title>
    <summary>  As toxic language becomes nearly pervasive online, there has been increasing
interest in leveraging the advancements in natural language processing (NLP),
from very large transformer models to automatically detecting and removing
toxic comments. Despite the fairness concerns, lack of adversarial robustness,
and limited prediction explainability for deep learning systems, there is
currently little work for auditing these systems and understanding how they
work for both developers and users. We present our ongoing work, RECAST, an
interactive tool for examining toxicity detection models by visualizing
explanations for predictions and providing alternative wordings for detected
toxic speech.
</summary>
    <author>
      <name>Austin P. Wright</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Omar Shaikh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Haekyu Park</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Will Epperson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Muhammed Ahmed</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Stephane Pinel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Diyi Yang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name>Duen Horng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Polo</arxiv:affiliation>
    </author>
    <author>
      <name> Chau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 3 figures, submitted to CHI2020 Late-Breaking Works</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; I.7; J.4; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01798v1</id>
    <updated>2020-01-06T22:30:33Z</updated>
    <published>2020-01-06T22:30:33Z</published>
    <title>Domain Adaptation via Teacher-Student Learning for End-to-End Speech
  Recognition</title>
    <summary>  Teacher-student (T/S) has shown to be effective for domain adaptation of deep
neural network acoustic models in hybrid speech recognition systems. In this
work, we extend the T/S learning to large-scale unsupervised domain adaptation
of an attention-based end-to-end (E2E) model through two levels of knowledge
transfer: teacher's token posteriors as soft labels and one-best predictions as
decoder guidance. To further improve T/S learning with the help of ground-truth
labels, we propose adaptive T/S (AT/S) learning. Instead of conditionally
choosing from either the teacher's soft token posteriors or the one-hot
ground-truth label, in AT/S, the student always learns from both the teacher
and the ground truth with a pair of adaptive weights assigned to the soft and
one-hot labels quantifying the confidence on each of the knowledge sources. The
confidence scores are dynamically estimated at each decoder step as a function
of the soft and one-hot labels. With 3400 hours parallel close-talk and
far-field Microsoft Cortana data for domain adaptation, T/S and AT/S achieve
6.3% and 10.3% relative word error rate improvement over a strong E2E model
trained with the same amount of far-field data.
</summary>
    <author>
      <name>Zhong Meng</name>
    </author>
    <author>
      <name>Jinyu Li</name>
    </author>
    <author>
      <name>Yashesh Gaur</name>
    </author>
    <author>
      <name>Yifan Gong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, ASRU 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU), Sentosa, Singapore</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05295v1</id>
    <updated>2020-01-06T22:24:59Z</updated>
    <published>2020-01-06T22:24:59Z</published>
    <title>Language Models Are An Effective Patient Representation Learning
  Technique For Electronic Health Record Data</title>
    <summary>  Widespread adoption of electronic health records (EHRs) has fueled
development of clinical outcome models using machine learning. However, patient
EHR data are complex, and how to optimally represent them is an open question.
This complexity, along with often small training set sizes available to train
these clinical outcome models, are two core challenges for training high
quality models. In this paper, we demonstrate that learning generic
representations from the data of all the patients in the EHR enables better
performing prediction models for clinical outcomes, allowing for these
challenges to be overcome. We adapt common representation learning techniques
used in other domains and find that representations inspired by language models
enable a 3.5% mean improvement in AUROC on five clinical outcomes compared to
standard baselines, with the average improvement rising to 19% when only a
small number of patients are available for training a prediction model for a
given clinical outcome.
</summary>
    <author>
      <name>Ethan Steinberg</name>
    </author>
    <author>
      <name>Ken Jung</name>
    </author>
    <author>
      <name>Jason A. Fries</name>
    </author>
    <author>
      <name>Conor K. Corbin</name>
    </author>
    <author>
      <name>Stephen R. Pfohl</name>
    </author>
    <author>
      <name>Nigam H. Shah</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01795v1</id>
    <updated>2020-01-06T22:19:17Z</updated>
    <published>2020-01-06T22:19:17Z</published>
    <title>Character-Aware Attention-Based End-to-End Speech Recognition</title>
    <summary>  Predicting words and subword units (WSUs) as the output has shown to be
effective for the attention-based encoder-decoder (AED) model in end-to-end
speech recognition. However, as one input to the decoder recurrent neural
network (RNN), each WSU embedding is learned independently through context and
acoustic information in a purely data-driven fashion. Little effort has been
made to explicitly model the morphological relationships among WSUs. In this
work, we propose a novel character-aware (CA) AED model in which each WSU
embedding is computed by summarizing the embeddings of its constituent
characters using a CA-RNN. This WSU-independent CA-RNN is jointly trained with
the encoder, the decoder and the attention network of a conventional AED to
predict WSUs. With CA-AED, the embeddings of morphologically similar WSUs are
naturally and directly correlated through the CA-RNN in addition to the
semantic and acoustic relations modeled by a traditional AED. Moreover, CA-AED
significantly reduces the model parameters in a traditional AED by replacing
the large pool of WSU embeddings with a much smaller set of character
embeddings. On a 3400 hours Microsoft Cortana dataset, CA-AED achieves up to
11.9% relative WER improvement over a strong AED baseline with 27.1% fewer
model parameters.
</summary>
    <author>
      <name>Zhong Meng</name>
    </author>
    <author>
      <name>Yashesh Gaur</name>
    </author>
    <author>
      <name>Jinyu Li</name>
    </author>
    <author>
      <name>Yifan Gong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, ASRU 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU), Sentosa, Singapore</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01669v1</id>
    <updated>2020-01-06T17:09:21Z</updated>
    <published>2020-01-06T17:09:21Z</published>
    <title>Topic Extraction of Crawled Documents Collection using Correlated Topic
  Model in MapReduce Framework</title>
    <summary>  The tremendous increase in the amount of available research documents impels
researchers to propose topic models to extract the latent semantic themes of a
documents collection. However, how to extract the hidden topics of the
documents collection has become a crucial task for many topic model
applications. Moreover, conventional topic modeling approaches suffer from the
scalability problem when the size of documents collection increases. In this
paper, the Correlated Topic Model with variational Expectation-Maximization
algorithm is implemented in MapReduce framework to solve the scalability
problem. The proposed approach utilizes the dataset crawled from the public
digital library. In addition, the full-texts of the crawled documents are
analysed to enhance the accuracy of MapReduce CTM. The experiments are
conducted to demonstrate the performance of the proposed algorithm. From the
evaluation, the proposed approach has a comparable performance in terms of
topic coherences with LDA implemented in MapReduce framework.
</summary>
    <author>
      <name>Mi Khine Oo</name>
    </author>
    <author>
      <name>May Aye Khine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01622v1</id>
    <updated>2020-01-06T15:11:59Z</updated>
    <published>2020-01-06T15:11:59Z</published>
    <title>Exploring Benefits of Transfer Learning in Neural Machine Translation</title>
    <summary>  Neural machine translation is known to require large numbers of parallel
training sentences, which generally prevent it from excelling on low-resource
language pairs. This thesis explores the use of cross-lingual transfer learning
on neural networks as a way of solving the problem with the lack of resources.
We propose several transfer learning approaches to reuse a model pretrained on
a high-resource language pair. We pay particular attention to the simplicity of
the techniques. We study two scenarios: (a) when we reuse the high-resource
model without any prior modifications to its training process and (b) when we
can prepare the first-stage high-resource model for transfer learning in
advance. For the former scenario, we present a proof-of-concept method by
reusing a model trained by other researchers. In the latter scenario, we
present a method which reaches even larger improvements in translation
performance. Apart from proposed techniques, we focus on an in-depth analysis
of transfer learning techniques and try to shed some light on transfer learning
improvements. We show how our techniques address specific problems of
low-resource languages and are suitable even in high-resource transfer
learning. We evaluate the potential drawbacks and behavior by studying transfer
learning in various situations, for example, under artificially damaged
training corpora, or with fixed various model parts.
</summary>
    <author>
      <name>Tom Kocmi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Defended PhD thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01582v1</id>
    <updated>2020-01-06T13:54:06Z</updated>
    <published>2020-01-06T13:54:06Z</published>
    <title>A Survey on Machine Reading Comprehension Systems</title>
    <summary>  Machine reading comprehension is a challenging task and hot topic in natural
language processing. Its goal is to develop systems to answer the questions
regarding a given context. In this paper, we present a comprehensive survey on
different aspects of machine reading comprehension systems, including their
approaches, structures, input/outputs, and research novelties. We illustrate
the recent trends in this field based on 124 reviewed papers from 2016 to 2018.
Our investigations demonstrate that the focus of research has changed in recent
years from answer extraction to answer generation, from single to
multi-document reading comprehension, and from learning from scratch to using
pre-trained embeddings. We also discuss the popular datasets and the evaluation
metrics in this field. The paper ends with investigating the most cited papers
and their contributions.
</summary>
    <author>
      <name>Razieh Baradaran</name>
    </author>
    <author>
      <name>Razieh Ghiasi</name>
    </author>
    <author>
      <name>Hossein Amirkhani</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01565v1</id>
    <updated>2020-01-06T13:37:51Z</updated>
    <published>2020-01-06T13:37:51Z</published>
    <title>Stance Detection Benchmark: How Robust Is Your Stance Detection?</title>
    <summary>  Stance Detection (StD) aims to detect an author's stance towards a certain
topic or claim and has become a key component in applications like fake news
detection, claim validation, and argument search. However, while stance is
easily detected by humans, machine learning models are clearly falling short of
this task. Given the major differences in dataset sizes and framing of StD
(e.g. number of classes and inputs), we introduce a StD benchmark that learns
from ten StD datasets of various domains in a multi-dataset learning (MDL)
setting, as well as from related tasks via transfer learning. Within this
benchmark setup, we are able to present new state-of-the-art results on five of
the datasets. Yet, the models still perform well below human capabilities and
even simple adversarial attacks severely hurt the performance of MDL models.
Deeper investigation into this phenomenon suggests the existence of biases
inherited from multiple datasets by design. Our analysis emphasizes the need of
focus on robustness and de-biasing strategies in multi-task learning
approaches. The benchmark dataset and code is made available.
</summary>
    <author>
      <name>Benjamin Schiller</name>
    </author>
    <author>
      <name>Johannes Daxenberger</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01447v1</id>
    <updated>2020-01-06T09:18:29Z</updated>
    <published>2020-01-06T09:18:29Z</published>
    <title>Improving Entity Linking by Modeling Latent Entity Type Information</title>
    <summary>  Existing state of the art neural entity linking models employ attention-based
bag-of-words context model and pre-trained entity embeddings bootstrapped from
word embeddings to assess topic level context compatibility. However, the
latent entity type information in the immediate context of the mention is
neglected, which causes the models often link mentions to incorrect entities
with incorrect type. To tackle this problem, we propose to inject latent entity
type information into the entity embeddings based on pre-trained BERT. In
addition, we integrate a BERT-based entity similarity score into the local
context model of a state-of-the-art model to better capture latent entity type
information. Our model significantly outperforms the state-of-the-art entity
linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis
demonstrates that our model corrects most of the type errors produced by the
direct baseline.
</summary>
    <author>
      <name>Shuang Chen</name>
    </author>
    <author>
      <name>Jinpeng Wang</name>
    </author>
    <author>
      <name>Feng Jiang</name>
    </author>
    <author>
      <name>Chin-Yew Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09896v1</id>
    <updated>2020-01-06T00:23:11Z</updated>
    <published>2020-01-06T00:23:11Z</published>
    <title>Semantic Sensitive TF-IDF to Determine Word Relevance in Documents</title>
    <summary>  Keyword extraction has received an increasing attention as an important
research topic which can lead to have advancements in diverse applications such
as document context categorization, text indexing and document classification.
In this paper we propose STF-IDF, a novel semantic method based on TF-IDF, for
scoring word importance of informal documents in a corpus. A set of nearly four
million documents from health-care social media was collected and was trained
in order to draw semantic model and to find the word embeddings. Then, the
features of semantic space were utilized to rearrange the original TF-IDF
scores through an iterative solution so as to improve the moderate performance
of this algorithm on informal texts. After testing the proposed method with 200
randomly chosen documents, our method managed to decrease the TF-IDF mean error
rate by a factor of 50% and reaching the mean error of 13.7%, as opposed to
27.2% of the original TF-IDF.
</summary>
    <author>
      <name>Amir Jalilifard</name>
    </author>
    <author>
      <name>Vinicius Caridá</name>
    </author>
    <author>
      <name>Alex Mansano</name>
    </author>
    <author>
      <name>Rogers Cristo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, 9 references. Work in progress, feedback are very
  welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09896v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09896v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01323v1</id>
    <updated>2020-01-05T22:37:17Z</updated>
    <published>2020-01-05T22:37:17Z</published>
    <title>On Identifying Hashtags in Disaster Twitter Data</title>
    <summary>  Tweet hashtags have the potential to improve the search for information
during disaster events. However, there is a large number of disaster-related
tweets that do not have any user-provided hashtags. Moreover, only a small
number of tweets that contain actionable hashtags are useful for disaster
response. To facilitate progress on automatic identification (or extraction) of
disaster hashtags for Twitter data, we construct a unique dataset of
disaster-related tweets annotated with hashtags useful for filtering actionable
information. Using this dataset, we further investigate Long Short Term
Memory-based models within a Multi-Task Learning framework. The best performing
model achieves an F1-score as high as 92.22%. The dataset, code, and other
resources are available on Github.
</summary>
    <author>
      <name>Jishnu Ray Chowdhury</name>
    </author>
    <author>
      <name>Cornelia Caragea</name>
    </author>
    <author>
      <name>Doina Caragea</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01269v1</id>
    <updated>2020-01-05T16:34:32Z</updated>
    <published>2020-01-05T16:34:32Z</published>
    <title>Generating Word and Document Embeddings for Sentiment Analysis</title>
    <summary>  Sentiments of words differ from one corpus to another. Inducing general
sentiment lexicons for languages and using them cannot, in general, produce
meaningful results for different domains. In this paper, we combine contextual
and supervised information with the general semantic representations of words
occurring in the dictionary. Contexts of words help us capture the
domain-specific information and supervised scores of words are indicative of
the polarities of those words. When we combine supervised features of words
with the features extracted from their dictionary definitions, we observe an
increase in the success rates. We try out the combinations of contextual,
supervised, and dictionary-based approaches, and generate original vectors. We
also combine the word2vec approach with hand-crafted features. We induce
domain-specific sentimental vectors for two corpora, which are the movie domain
and the Twitter datasets in Turkish. When we thereafter generate document
vectors and employ the support vector machines method utilising those vectors,
our approaches perform better than the baseline studies for Turkish with a
significant margin. We evaluated our models on two English corpora as well and
these also outperformed the word2vec approach. It shows that our approaches are
cross-lingual and cross-domain.
</summary>
    <author>
      <name>Cem Rıfkı Aydın</name>
    </author>
    <author>
      <name>Tunga Güngör</name>
    </author>
    <author>
      <name>Ali Erkan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted and presented as a full paper at 20th International
  Conference on Computational Linguistics and Intelligent Text Processing
  (CICLing 2019), April 7-13, 2019, La Rochelle, France</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Springer LNCS Proceedings for CICLing 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01243v1</id>
    <updated>2020-01-05T14:19:11Z</updated>
    <published>2020-01-05T14:19:11Z</published>
    <title>Automatic Business Process Structure Discovery using Ordered Neurons
  LSTM: A Preliminary Study</title>
    <summary>  Automatic process discovery from textual process documentations is highly
desirable to reduce time and cost of Business Process Management (BPM)
implementation in organizations. However, existing automatic process discovery
approaches mainly focus on identifying activities out of the documentations.
Deriving the structural relationships between activities, which is important in
the whole process discovery scope, is still a challenge. In fact, a business
process has latent semantic hierarchical structure which defines different
levels of detail to reflect the complex business logic. Recent findings in
neural machine learning area show that the meaningful linguistic structure can
be induced by joint language modeling and structure learning. Inspired by these
findings, we propose to retrieve the latent hierarchical structure present in
the textual business process documents by building a neural network that
leverages a novel recurrent architecture, Ordered Neurons LSTM (ON-LSTM), with
process-level language model objective. We tested the proposed approach on data
set of Process Description Documents (PDD) from our practical Robotic Process
Automation (RPA) projects. Preliminary experiments showed promising results.
</summary>
    <author>
      <name>Xue Han</name>
    </author>
    <author>
      <name>Lianxue Hu</name>
    </author>
    <author>
      <name>Yabin Dang</name>
    </author>
    <author>
      <name>Shivali Agarwal</name>
    </author>
    <author>
      <name>Lijun Mei</name>
    </author>
    <author>
      <name>Shaochun Li</name>
    </author>
    <author>
      <name>Xin Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01167v1</id>
    <updated>2020-01-05T04:50:38Z</updated>
    <published>2020-01-05T04:50:38Z</published>
    <title>Computationally Efficient NER Taggers with Combined Embeddings and
  Constrained Decoding</title>
    <summary>  Current State-of-the-Art models in Named Entity Recognition (NER) are neural
models with a Conditional Random Field (CRF) as the final network layer, and
pre-trained "contextual embeddings". The CRF layer is used to facilitate global
coherence between labels, and the contextual embeddings provide a better
representation of words in context. However, both of these improvements come at
a high computational cost. In this work, we explore two simple techniques that
substantially improve NER performance over a strong baseline with negligible
cost. First, we use multiple pre-trained embeddings as word representations via
concatenation. Second, we constrain the tagger, trained using a cross-entropy
loss, during decoding to eliminate illegal transitions. While training a tagger
on CoNLL 2003 we find a $786$\% speed-up over a contextual embeddings-based
tagger without sacrificing strong performance. We also show that the
concatenation technique works across multiple tasks and datasets. We analyze
aspects of similarity and coverage between pre-trained embeddings and the
dynamics of tag co-occurrence to explain why these techniques work. We provide
an open source implementation of our tagger using these techniques in three
popular deep learning frameworks --- TensorFlow, Pytorch, and DyNet.
</summary>
    <author>
      <name>Brian Lester</name>
    </author>
    <author>
      <name>Daniel Pressel</name>
    </author>
    <author>
      <name>Amy Hemmeter</name>
    </author>
    <author>
      <name>Sagnik Ray Choudhury</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01140v1</id>
    <updated>2020-01-04T23:27:59Z</updated>
    <published>2020-01-04T23:27:59Z</published>
    <title>Transformer-based language modeling and decoding for conversational
  speech recognition</title>
    <summary>  We propose a way to use a transformer-based language model in conversational
speech recognition. Specifically, we focus on decoding efficiently in a
weighted finite-state transducer framework. We showcase an approach to lattice
re-scoring that allows for longer range history captured by a transfomer-based
language model and takes advantage of a transformer's ability to avoid
computing sequentially.
</summary>
    <author>
      <name>Kareem Nassar</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01126v1</id>
    <updated>2020-01-04T20:56:21Z</updated>
    <published>2020-01-04T20:56:21Z</published>
    <title>Can x2vec Save Lives? Integrating Graph and Language Embeddings for
  Automatic Mental Health Classification</title>
    <summary>  Graph and language embedding models are becoming commonplace in large scale
analyses given their ability to represent complex sparse data densely in
low-dimensional space. Integrating these models' complementary relational and
communicative data may be especially helpful if predicting rare events or
classifying members of hidden populations - tasks requiring huge and sparse
datasets for generalizable analyses. For example, due to social stigma and
comorbidities, mental health support groups often form in amorphous online
groups. Predicting suicidality among individuals in these settings using
standard network analyses is prohibitive due to resource limits (e.g., memory),
and adding auxiliary data like text to such models exacerbates complexity- and
sparsity-related issues. Here, I show how merging graph and language embedding
models (metapath2vec and doc2vec) avoids these limits and extracts unsupervised
clustering data without domain expertise or feature engineering. Graph and
language distances to a suicide support group have little correlation (\r{ho} &lt;
0.23), implying the two models are not embedding redundant information. When
used separately to predict suicidality among individuals, graph and language
data generate relatively accurate results (69% and 76%, respectively); however,
when integrated, both data produce highly accurate predictions (90%, with 10%
false-positives and 12% false-negatives). Visualizing graph embeddings
annotated with predictions of potentially suicidal individuals shows the
integrated model could classify such individuals even if they are positioned
far from the support group. These results extend research on the importance of
simultaneously analyzing behavior and language in massive networks and efforts
to integrate embedding models for different kinds of data when predicting and
classifying, particularly when they involve rare events.
</summary>
    <author>
      <name>Alexander Ruch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages (23 body, 2 supplemental material), 12 figures (10 body, 2
  supplemental material), 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.2.8; H.3.3; H.3.4; H.3.5; H.4.3; I.2.1; I.2.6; I.2.7; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01115v2</id>
    <updated>2020-01-07T16:54:33Z</updated>
    <published>2020-01-04T19:38:00Z</published>
    <title>A Comprehensive Survey of Multilingual Neural Machine Translation</title>
    <summary>  We present a survey on multilingual neural machine translation (MNMT), which
has gained a lot of traction in the recent years. MNMT has been useful in
improving translation quality as a result of translation knowledge transfer
(transfer learning). MNMT is more promising and interesting than its
statistical machine translation counterpart because end-to-end modeling and
distributed representations open new avenues for research on machine
translation. Many approaches have been proposed in order to exploit
multilingual parallel corpora for improving translation quality. However, the
lack of a comprehensive survey makes it difficult to determine which approaches
are promising and hence deserve further exploration. In this paper, we present
an in-depth survey of existing literature on MNMT. We first categorize various
approaches based on their central use-case and then further categorize them
based on resource scenarios, underlying modeling principles, core-issues and
challenges. Wherever possible we address the strengths and weaknesses of
several techniques by comparing them with each other. We also discuss the
future directions that MNMT research might take. This paper is aimed towards
both, beginners and experts in NMT. We hope this paper will serve as a starting
point as well as a source of new ideas for researchers and engineers interested
in MNMT.
</summary>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Chenhui Chu</name>
    </author>
    <author>
      <name>Anoop Kunchukuttan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an extended version of our survey paper on multilingual NMT.
  The previous version [arXiv:1905.05395] is rather condensed and is useful for
  speed-reading whereas this version is more beginner friendly. Under review at
  the computing surveys journal. We have intentionally decided to maintain both
  short and long versions of our survey paper for different reader groups</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01115v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01115v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01047v1</id>
    <updated>2020-01-04T06:31:15Z</updated>
    <published>2020-01-04T06:31:15Z</published>
    <title>Adapting Deep Learning for Sentiment Classification of Code-Switched
  Informal Short Text</title>
    <summary>  Nowadays, an abundance of short text is being generated that uses nonstandard
writing styles influenced by regional languages. Such informal and
code-switched content are under-resourced in terms of labeled datasets and
language models even for popular tasks like sentiment classification. In this
work, we (1) present a labeled dataset called MultiSenti for sentiment
classification of code-switched informal short text, (2) explore the
feasibility of adapting resources from a resource-rich language for an informal
one, and (3) propose a deep learning-based model for sentiment classification
of code-switched informal short text. We aim to achieve this without any
lexical normalization, language translation, or code-switching indication. The
performance of the proposed models is compared with three existing multilingual
sentiment classification models. The results show that the proposed model
performs better in general and adapting character-based embeddings yield
equivalent performance while being computationally more efficient than training
word-based domain-specific embeddings.
</summary>
    <author>
      <name>Muhammad Haroon Shakeel</name>
    </author>
    <author>
      <name>Asim Karim</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01037v2</id>
    <updated>2020-01-22T02:09:36Z</updated>
    <published>2020-01-04T05:15:11Z</published>
    <title>Understanding Image Captioning Models beyond Visualizing Attention</title>
    <summary>  This paper explains predictions of image captioning models with attention
mechanisms beyond visualizing the attention itself. In this paper, we develop
variants of layer-wise relevance backpropagation (LRP) and gradient
backpropagation, tailored to image captioning with attention. The result
provides simultaneously pixel-wise image explanation and linguistic explanation
for each word in the captions. We show that given a word in the caption to be
explained, explanation methods such as LRP reveal supporting and opposing
pixels as well as words. We compare the properties of attention heatmaps
systematically against those computed with explanation methods such as LRP,
Grad-CAM and Guided Grad-CAM. We show that explanation methods, firstly,
correlate to object locations with higher precision than attention, secondly,
are able to identify object words that are unsupported by image content, and
thirdly, provide guidance to debias and improve the model. Results are reported
for image captioning using two different attention models trained with
Flickr30K and MSCOCO2017 datasets. Experimental analyses show the strength of
explanation methods for understanding image captioning attention models.
</summary>
    <author>
      <name>Jiamei Sun</name>
    </author>
    <author>
      <name>Sebastian Lapuschkin</name>
    </author>
    <author>
      <name>Wojciech Samek</name>
    </author>
    <author>
      <name>Alexander Binder</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01037v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01037v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05839v1</id>
    <updated>2020-01-03T20:41:18Z</updated>
    <published>2020-01-03T20:41:18Z</published>
    <title>Discoverability in Satellite Imagery: A Good Sentence is Worth a
  Thousand Pictures</title>
    <summary>  Small satellite constellations provide daily global coverage of the earth's
landmass, but image enrichment relies on automating key tasks like change
detection or feature searches. For example, to extract text annotations from
raw pixels requires two dependent machine learning models, one to analyze the
overhead image and the other to generate a descriptive caption. We evaluate
seven models on the previously largest benchmark for satellite image captions.
We extend the labeled image samples five-fold, then augment, correct and prune
the vocabulary to approach a rough min-max (minimum word, maximum description).
This outcome compares favorably to previous work with large pre-trained image
models but offers a hundred-fold reduction in model size without sacrificing
overall accuracy (when measured with log entropy loss). These smaller models
provide new deployment opportunities, particularly when pushed to edge
processors, on-board satellites, or distributed ground stations. To quantify a
caption's descriptiveness, we introduce a novel multi-class confusion or error
matrix to score both human-labeled test data and never-labeled images that
include bounding box detection but lack full sentence captions. This work
suggests future captioning strategies, particularly ones that can enrich the
class coverage beyond land use applications and that lessen color-centered and
adjacency adjectives ("green", "near", "between", etc.). Many modern language
transformers present novel and exploitable models with world knowledge gleaned
from training from their vast online corpus. One interesting, but easy example
might learn the word association between wind and waves, thus enriching a beach
scene with more than just color descriptions that otherwise might be accessed
from raw pixels without text annotation.
</summary>
    <author>
      <name>David Noever</name>
    </author>
    <author>
      <name>Wes Regian</name>
    </author>
    <author>
      <name>Matt Ciolino</name>
    </author>
    <author>
      <name>Josh Kalin</name>
    </author>
    <author>
      <name>Dom Hambrick</name>
    </author>
    <author>
      <name>Kaye Blankenship</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00926v1</id>
    <updated>2020-01-03T18:40:35Z</updated>
    <published>2020-01-03T18:40:35Z</published>
    <title>Learning Accurate Integer Transformer Machine-Translation Models</title>
    <summary>  We describe a method for training accurate Transformer machine-translation
models to run inference using 8-bit integer (INT8) hardware matrix multipliers,
as opposed to the more costly single-precision floating-point (FP32) hardware.
Unlike previous work, which converted only 85 Transformer matrix
multiplications to INT8, leaving 48 out of 133 of them in FP32 because of
unacceptable accuracy loss, we convert them all to INT8 without compromising
accuracy. Tested on the newstest2014 English-to-German translation task, our
INT8 Transformer Base and Transformer Big models yield BLEU scores that are
99.3% to 100% relative to those of the corresponding FP32 models. Our approach
converts all matrix-multiplication tensors from an existing FP32 model into
INT8 tensors by automatically making range-precision trade-offs during
training. To demonstrate the robustness of this approach, we also include
results from INT6 Transformer models.
</summary>
    <author>
      <name>Ephrem Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01588v1</id>
    <updated>2020-01-03T17:16:28Z</updated>
    <published>2020-01-03T17:16:28Z</published>
    <title>Information Extraction based on Named Entity for Tourism Corpus</title>
    <summary>  Tourism information is scattered around nowadays. To search for the
information, it is usually time consuming to browse through the results from
search engine, select and view the details of each accommodation. In this
paper, we present a methodology to extract particular information from full
text returned from the search engine to facilitate the users. Then, the users
can specifically look to the desired relevant information. The approach can be
used for the same task in other domains. The main steps are 1) building
training data and 2) building recognition model. First, the tourism data is
gathered and the vocabularies are built. The raw corpus is used to train for
creating vocabulary embedding. Also, it is used for creating annotated data.
The process of creating named entity annotation is presented. Then, the
recognition model of a given entity type can be built. From the experiments,
given hotel description, the model can extract the desired entity,i.e, name,
location, facility. The extracted data can further be stored as a structured
information, e.g., in the ontology format, for future querying and inference.
The model for automatic named entity identification, based on machine learning,
yields the error ranging 8%-25%.
</summary>
    <author>
      <name>Chantana Chantrapornchai</name>
    </author>
    <author>
      <name>Aphisit Tunsakul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JCSSE.2019.8864166</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JCSSE.2019.8864166" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">16th International Joint Conference on Computer Science and
  Software Engineering (JCSSE), 2019, pp. 187-192</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2, I.7" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00891v1</id>
    <updated>2020-01-03T17:06:41Z</updated>
    <published>2020-01-03T17:06:41Z</published>
    <title>Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text
  Segmentation</title>
    <summary>  Breaking down the structure of long texts into semantically coherent segments
makes the texts more readable and supports downstream applications like
summarization and retrieval. Starting from an apparent link between text
coherence and segmentation, we introduce a novel supervised model for text
segmentation with simple but explicit coherence modeling. Our model -- a neural
architecture consisting of two hierarchically connected Transformer networks --
is a multi-task learning model that couples the sentence-level segmentation
objective with the coherence objective that differentiates correct sequences of
sentences from corrupt ones. The proposed model, dubbed Coherence-Aware Text
Segmentation (CATS), yields state-of-the-art segmentation performance on a
collection of benchmark datasets. Furthermore, by coupling CATS with
cross-lingual word embeddings, we demonstrate its effectiveness in zero-shot
language transfer: it can successfully segment texts in languages unseen in
training.
</summary>
    <author>
      <name>Goran Glavaš</name>
    </author>
    <author>
      <name>Swapna Somasundaran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00862v1</id>
    <updated>2020-01-03T15:28:52Z</updated>
    <published>2020-01-03T15:28:52Z</published>
    <title>Meaning updating of density matrices</title>
    <summary>  The DisCoCat model of natural language meaning assigns meaning to a sentence
given: (i) the meanings of its words, and, (ii) its grammatical structure. The
recently introduced DisCoCirc model extends this to text consisting of multiple
sentences. While in DisCoCat all meanings are fixed, in DisCoCirc each sentence
updates meanings of words. In this paper we explore different update mechanisms
for DisCoCirc, in the case where meaning is encoded in density matrices---which
come with several advantages as compared to vectors.
  Our starting point are two non-commutative update mechanisms, borrowing one
from quantum foundations research, from Leifer and Spekkens. Unfortunately,
neither of these satisfies any desirable algebraic properties, nor are internal
to the meaning category. By passing to double density matrices we do get an
elegant internal diagrammatic update mechanism.
  We also show that (commutative) spiders can be cast as an instance of the
Leifer-Spekkens update mechanism. This result is of interest to quantum
foundations, as it bridges the work in Categorical Quantum Mechanics (CQM) with
that on conditional quantum states. Our work also underpins implementation of
text-level natural language processing on quantum hardware (a.k.a. QNLP), for
which exponential space-gain and quadratic speed-up have previously been
identified.
</summary>
    <author>
      <name>Bob Coecke</name>
    </author>
    <author>
      <name>Konstantinos Meichanetzidis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, many figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10613v1</id>
    <updated>2020-01-03T11:00:54Z</updated>
    <published>2020-01-03T11:00:54Z</published>
    <title>Predicting Personalized Academic and Career Roads: First Steps Toward a
  Multi-Uses Recommender System</title>
    <summary>  Nobody knows what one's do in the future and everyone will have had a
different answer to the question : how do you see yourself in five years after
your current job/diploma? In this paper we introduce concepts, large categories
of fields of studies or job domains in order to represent the vision of the
future of the user's trajectory. Then, we show how they can influence the
prediction when proposing him a set of next steps to take.
</summary>
    <author>
      <name>Alexandre Nadjem</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Marc El-Bèze</name>
    </author>
    <author>
      <name>Guillaume Marrel</name>
    </author>
    <author>
      <name>Benoît Bonte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, 4 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Digital Tools &amp; Uses Congress (DTUC '18), pp 1--4, 2018, Paris,
  France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.10613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00781v1</id>
    <updated>2020-01-03T10:53:35Z</updated>
    <published>2020-01-03T10:53:35Z</published>
    <title>On the comparability of Pre-trained Language Models</title>
    <summary>  Recent developments in unsupervised representation learning have successfully
established the concept of transfer learning in NLP. Mainly three forces are
driving the improvements in this area of research: More elaborated
architectures are making better use of contextual information. Instead of
simply plugging in static pre-trained representations, these are learned based
on surrounding context in end-to-end trainable models with more intelligently
designed language modelling objectives. Along with this, larger corpora are
used as resources for pre-training large language models in a self-supervised
fashion which are afterwards fine-tuned on supervised tasks. Advances in
parallel computing as well as in cloud computing, made it possible to train
these models with growing capacities in the same or even in shorter time than
previously established models. These three developments agglomerate in new
state-of-the-art (SOTA) results being revealed in a higher and higher
frequency. It is not always obvious where these improvements originate from, as
it is not possible to completely disentangle the contributions of the three
driving forces. We set ourselves to providing a clear and concise overview on
several large pre-trained language models, which achieved SOTA results in the
last two years, with respect to their use of new architectures and resources.
We want to clarify for the reader where the differences between the models are
and we furthermore attempt to gain some insight into the single contributions
of lexical/computational improvements as well as of architectural changes. We
explicitly do not intend to quantify these contributions, but rather see our
work as an overview in order to identify potential starting points for
benchmark comparisons. Furthermore, we tentatively want to point at potential
possibilities for improvement in the field of open-sourcing and reproducible
research.
</summary>
    <author>
      <name>Matthias Aßenmacher</name>
    </author>
    <author>
      <name>Christian Heumann</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00733v1</id>
    <updated>2020-01-03T05:56:13Z</updated>
    <published>2020-01-03T05:56:13Z</published>
    <title>"Love is as Complex as Math": Metaphor Generation System for Social
  Chatbot</title>
    <summary>  As the wide adoption of intelligent chatbot in human daily life, user demands
for such systems evolve from basic task-solving conversations to more casual
and friend-like communication. To meet the user needs and build emotional bond
with users, it is essential for social chatbots to incorporate more human-like
and advanced linguistic features. In this paper, we investigate the usage of a
commonly used rhetorical device by human -- metaphor for social chatbot. Our
work first designs a metaphor generation framework, which generates topic-aware
and novel figurative sentences. By embedding the framework into a chatbot
system, we then enables the chatbot to communicate with users using figurative
language. Human annotators validate the novelty and properness of the generated
metaphors. More importantly, we evaluate the effects of employing metaphors in
human-chatbot conversations. Experiments indicate that our system effectively
arouses user interests in communicating with our chatbot, resulting in
significantly longer human-chatbot conversations.
</summary>
    <author>
      <name>Danning Zheng</name>
    </author>
    <author>
      <name>Ruihua Song</name>
    </author>
    <author>
      <name>Tianran Hu</name>
    </author>
    <author>
      <name>Hao Fu</name>
    </author>
    <author>
      <name>Jin Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00725v2</id>
    <updated>2020-01-06T02:12:26Z</updated>
    <published>2020-01-03T05:15:41Z</published>
    <title>TED: A Pretrained Unsupervised Summarization Model with Theme Modeling
  and Denoising</title>
    <summary>  Text summarization aims to extract essential information from a piece of text
and transform it into a concise version. Existing unsupervised abstractive
summarization models use recurrent neural networks framework and ignore
abundant unlabeled corpora resources. In order to address these issues, we
propose TED, a transformer-based unsupervised summarization system with
pretraining on large-scale data. We first leverage the lead bias in news
articles to pretrain the model on large-scale corpora. Then, we finetune TED on
target domains through theme modeling and a denoising autoencoder to enhance
the quality of summaries. Notably, TED outperforms all unsupervised abstractive
baselines on NYT, CNN/DM and English Gigaword datasets with various document
styles. Further analysis shows that the summaries generated by TED are
abstractive and containing even higher proportions of novel tokens than those
from supervised models.
</summary>
    <author>
      <name>Ziyi Yang</name>
    </author>
    <author>
      <name>Chenguang Zhu</name>
    </author>
    <author>
      <name>Robert Gmyr</name>
    </author>
    <author>
      <name>Michael Zeng</name>
    </author>
    <author>
      <name>Xuedong Huang</name>
    </author>
    <author>
      <name>Eric Darve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00725v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00725v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00572v2</id>
    <updated>2020-01-16T14:27:21Z</updated>
    <published>2020-01-03T03:43:35Z</published>
    <title>Read Beyond the Lines: Understanding the Implied Textual Meaning via a
  Skim and Intensive Reading Model</title>
    <summary>  The nonliteral interpretation of a text is hard to be understood by machine
models due to its high context-sensitivity and heavy usage of figurative
language. In this study, inspired by human reading comprehension, we propose a
novel, simple, and effective deep neural framework, called Skim and Intensive
Reading Model (SIRM), for figuring out implied textual meaning. The proposed
SIRM consists of two main components, namely the skim reading component and
intensive reading component. N-gram features are quickly extracted from the
skim reading component, which is a combination of several convolutional neural
networks, as skim (entire) information. An intensive reading component enables
a hierarchical investigation for both local (sentence) and global (paragraph)
representation, which encapsulates the current embedding and the contextual
information with a dense connection. More specifically, the contextual
information includes the near-neighbor information and the skim information
mentioned above. Finally, besides the normal training loss function, we employ
an adversarial loss function as a penalty over the skim reading component to
eliminate noisy information arisen from special figurative words in the
training data. To verify the effectiveness, robustness, and efficiency of the
proposed architecture, we conduct extensive comparative experiments on several
sarcasm benchmarks and an industrial spam dataset with metaphors. Experimental
results indicate that (1) the proposed model, which benefits from context
modeling and consideration of figurative language, outperforms existing
state-of-the-art solutions, with comparable parameter scale and training speed;
(2) the SIRM yields superior robustness in terms of parameter size sensitivity;
(3) compared with ablation and addition variants of the SIRM, the final
framework is efficient enough.
</summary>
    <author>
      <name>Guoxiu He</name>
    </author>
    <author>
      <name>Zhe Gao</name>
    </author>
    <author>
      <name>Zhuoren Jiang</name>
    </author>
    <author>
      <name>Yangyang Kang</name>
    </author>
    <author>
      <name>Changlong Sun</name>
    </author>
    <author>
      <name>Xiaozhong Liu</name>
    </author>
    <author>
      <name>Wei Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00572v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00572v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00571v1</id>
    <updated>2020-01-03T00:16:46Z</updated>
    <published>2020-01-03T00:16:46Z</published>
    <title>Question Type Classification Methods Comparison</title>
    <summary>  The paper presents a comparative study of state-of-the-art approaches for
question classification task: Logistic Regression, Convolutional Neural
Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent
Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and
trained on human-labeled data. The best accuracy is achieved using CNN model
with five convolutional layers and various kernel sizes stacked in parallel,
followed by one fully connected layer. The model reached 90.7% accuracy on TREC
10 test set. All the model architectures in this paper were developed from
scratch on PyTorch, in few cases based on reliable open-source implementation.
</summary>
    <author>
      <name>Tamirlan Seidakhmetov</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00623v1</id>
    <updated>2020-01-02T21:01:02Z</updated>
    <published>2020-01-02T21:01:02Z</published>
    <title>Mining Disinformation and Fake News: Concepts, Methods, and Recent
  Advancements</title>
    <summary>  In recent years, disinformation including fake news, has became a global
phenomenon due to its explosive growth, particularly on social media. The wide
spread of disinformation and fake news can cause detrimental societal effects.
Despite the recent progress in detecting disinformation and fake news, it is
still non-trivial due to its complexity, diversity, multi-modality, and costs
of fact-checking or annotation. The goal of this chapter is to pave the way for
appreciating the challenges and advancements via: (1) introducing the types of
information disorder on social media and examine their differences and
connections; (2) describing important and emerging tasks to combat
disinformation for characterization, detection and attribution; and (3)
discussing a weak supervision approach to detect disinformation with limited
labeled data. We then provide an overview of the chapters in this book that
represent the recent advancements in three related parts: (1) user engagements
in the dissemination of information disorder; (2) techniques on detecting and
mitigating disinformation; and (3) trending issues such as ethics, blockchain,
clickbaits, etc. We hope this book to be a convenient entry point for
researchers, practitioners, and students to understand the problems and
challenges, learn state-of-the-art solutions for their specific needs, and
quickly identify new research problems in their domains.
</summary>
    <author>
      <name>Kai Shu</name>
    </author>
    <author>
      <name>Suhang Wang</name>
    </author>
    <author>
      <name>Dongwon Lee</name>
    </author>
    <author>
      <name>Huan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted as an introductory chapter for the edited book on "Fake
  News, Disinformation, and Misinformation in Social Media- Emerging Research
  Challenges and Opportunities", Springer Press</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.8" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01595v1</id>
    <updated>2020-01-02T15:23:11Z</updated>
    <published>2020-01-02T15:23:11Z</published>
    <title>Why Molière most likely did write his plays</title>
    <summary>  As for Shakespeare, a hard-fought debate has emerged about Moli\`ere, a
supposedly uneducated actor who, according to some, could not have written the
masterpieces attributed to him. In the past decades, the century-old thesis
according to which Pierre Corneille would be their actual author has become
popular, mostly because of new works in computational linguistics. These
results are reassessed here through state-of-the-art attribution methods. We
study a corpus of comedies in verse by major authors of Moli\`ere and
Corneille's time. Analysis of lexicon, rhymes, word forms, affixes,
morphosyntactic sequences, and function words do not give any clue that another
author among the major playwrights of the time would have written the plays
signed under the name Moli\`ere.
</summary>
    <author>
      <name>Florian Cafiero</name>
    </author>
    <author>
      <name>Jean-Baptiste Camps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1126/sciadv.aax5489</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1126/sciadv.aax5489" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Science Advances, 27 Nov 2019: Vol. 5, no. 11, eaax5489</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01557v1</id>
    <updated>2020-01-02T15:04:08Z</updated>
    <published>2020-01-02T15:04:08Z</published>
    <title>Speaker-aware speech-transformer</title>
    <summary>  Recently, end-to-end (E2E) models become a competitive alternative to the
conventional hybrid automatic speech recognition (ASR) systems. However, they
still suffer from speaker mismatch in training and testing condition. In this
paper, we use Speech-Transformer (ST) as the study platform to investigate
speaker aware training of E2E models. We propose a model called Speaker-Aware
Speech-Transformer (SAST), which is a standard ST equipped with a speaker
attention module (SAM). The SAM has a static speaker knowledge block (SKB) that
is made of i-vectors. At each time step, the encoder output attends to the
i-vectors in the block, and generates a weighted combined speaker embedding
vector, which helps the model to normalize the speaker variations. The SAST
model trained in this way becomes independent of specific training speakers and
thus generalizes better to unseen testing speakers. We investigate different
factors of SAM. Experimental results on the AISHELL-1 task show that SAST
achieves a relative 6.5% CER reduction (CERR) over the speaker-independent (SI)
baseline. Moreover, we demonstrate that SAST still works quite well even if the
i-vectors in SKB all come from a different data source other than the acoustic
training set.
</summary>
    <author>
      <name>Zhiyun Fan</name>
    </author>
    <author>
      <name>Jie Li</name>
    </author>
    <author>
      <name>Shiyu Zhou</name>
    </author>
    <author>
      <name>Bo Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01589v1</id>
    <updated>2020-01-02T10:05:02Z</updated>
    <published>2020-01-02T10:05:02Z</published>
    <title>Morphological Word Segmentation on Agglutinative Languages for Neural
  Machine Translation</title>
    <summary>  Neural machine translation (NMT) has achieved impressive performance on
machine translation task in recent years. However, in consideration of
efficiency, a limited-size vocabulary that only contains the top-N highest
frequency words are employed for model training, which leads to many rare and
unknown words. It is rather difficult when translating from the low-resource
and morphologically-rich agglutinative languages, which have complex morphology
and large vocabulary. In this paper, we propose a morphological word
segmentation method on the source-side for NMT that incorporates morphology
knowledge to preserve the linguistic and semantic information in the word
structure while reducing the vocabulary size at training time. It can be
utilized as a preprocessing tool to segment the words in agglutinative
languages for other natural language processing (NLP) tasks. Experimental
results show that our morphologically motivated word segmentation method is
better suitable for the NMT model, which achieves significant improvements on
Turkish-English and Uyghur-Chinese machine translation tasks on account of
reducing data sparseness and language complexity.
</summary>
    <author>
      <name>Yirong Pan</name>
    </author>
    <author>
      <name>Xiao Li</name>
    </author>
    <author>
      <name>Yating Yang</name>
    </author>
    <author>
      <name>Rui Dong</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01589v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01589v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00583v1</id>
    <updated>2020-01-02T10:04:37Z</updated>
    <published>2020-01-02T10:04:37Z</published>
    <title>On the Mutual Information between Source and Filter Contributions for
  Voice Pathology Detection</title>
    <summary>  This paper addresses the problem of automatic detection of voice pathologies
directly from the speech signal. For this, we investigate the use of the
glottal source estimation as a means to detect voice disorders. Three sets of
features are proposed, depending on whether they are related to the speech or
the glottal signal, or to prosody. The relevancy of these features is assessed
through mutual information-based measures. This allows an intuitive
interpretation in terms of discrimation power and redundancy between the
features, independently of any subsequent classifier. It is discussed which
characteristics are interestingly informative or complementary for detecting
voice pathologies.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thomas Dubuisson</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00372v1</id>
    <updated>2020-01-02T09:51:51Z</updated>
    <published>2020-01-02T09:51:51Z</published>
    <title>Phase-based Information for Voice Pathology Detection</title>
    <summary>  In most current approaches of speech processing, information is extracted
from the magnitude spectrum. However recent perceptual studies have underlined
the importance of the phase component. The goal of this paper is to investigate
the potential of using phase-based features for automatically detecting voice
disorders. It is shown that group delay functions are appropriate for
characterizing irregularities in the phonation. Besides the respect of the
mixed-phase model of speech is discussed. The proposed phase-based features are
evaluated and compared to other parameters derived from the magnitude spectrum.
Both streams are shown to be interestingly complementary. Furthermore
phase-based features turn out to convey a great amount of relevant information,
leading to high discrimination performance.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thomas Dubuisson</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00582v1</id>
    <updated>2020-01-02T09:44:52Z</updated>
    <published>2020-01-02T09:44:52Z</published>
    <title>Excitation-based Voice Quality Analysis and Modification</title>
    <summary>  This paper investigates the differences occuring in the excitation for
different voice qualities. Its goal is two-fold. First a large corpus
containing three voice qualities (modal, soft and loud) uttered by the same
speaker is analyzed and significant differences in characteristics extracted
from the excitation are observed. Secondly rules of modification derived from
the analysis are used to build a voice quality transformation system applied as
a post-process to HMM-based speech synthesis. The system is shown to
effectively achieve the transformations while maintaining the delivered
quality.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <author>
      <name>Baris Bozkurt</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00581v1</id>
    <updated>2020-01-02T09:39:07Z</updated>
    <published>2020-01-02T09:39:07Z</published>
    <title>Eigenresiduals for improved Parametric Speech Synthesis</title>
    <summary>  Statistical parametric speech synthesizers have recently shown their ability
to produce natural-sounding and flexible voices. Unfortunately the delivered
quality suffers from a typical buzziness due to the fact that speech is
vocoded. This paper proposes a new excitation model in order to reduce this
undesirable effect. This model is based on the decomposition of
pitch-synchronous residual frames on an orthonormal basis obtained by Principal
Component Analysis. This basis contains a limited number of eigenresiduals and
is computed on a relatively small speech database. A stream of PCA-based
coefficients is added to our HMM-based synthesizer and allows to generate the
voiced excitation during the synthesis. An improvement compared to the
traditional excitation is reported while the synthesis engine footprint remains
under about 1Mb.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Geoffrey Wilfart</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00579v1</id>
    <updated>2020-01-02T09:25:30Z</updated>
    <published>2020-01-02T09:25:30Z</published>
    <title>A Comparative Evaluation of Pitch Modification Techniques</title>
    <summary>  This paper addresses the problem of pitch modification, as an important
module for an efficient voice transformation system. The Deterministic plus
Stochastic Model of the residual signal we proposed in a previous work is
compared to TDPSOLA, HNM and STRAIGHT. The four methods are compared through an
important subjective test. The influence of the speaker gender and of the pitch
modification ratio is analyzed. Despite its higher compression level, the DSM
technique is shown to give similar or better results than other methods,
especially for male speakers and important ratios of modification. The DSM
turns out to be only outperformed by STRAIGHT for female voices.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00295v1</id>
    <updated>2020-01-02T02:24:53Z</updated>
    <published>2020-01-02T02:24:53Z</published>
    <title>Chemical-induced Disease Relation Extraction with Dependency Information
  and Prior Knowledge</title>
    <summary>  Chemical-disease relation (CDR) extraction is significantly important to
various areas of biomedical research and health care. Nowadays, many
large-scale biomedical knowledge bases (KBs) containing triples about entity
pairs and their relations have been built. KBs are important resources for
biomedical relation extraction. However, previous research pays little
attention to prior knowledge. In addition, the dependency tree contains
important syntactic and semantic information, which helps to improve relation
extraction. So how to effectively use it is also worth studying. In this paper,
we propose a novel convolutional attention network (CAN) for CDR extraction.
Firstly, we extract the shortest dependency path (SDP) between chemical and
disease pairs in a sentence, which includes a sequence of words, dependency
directions, and dependency relation tags. Then the convolution operations are
performed on the SDP to produce deep semantic dependency features. After that,
an attention mechanism is employed to learn the importance/weight of each
semantic dependency vector related to knowledge representations learned from
KBs. Finally, in order to combine dependency information and prior knowledge,
the concatenation of weighted semantic dependency representations and knowledge
representations is fed to the softmax layer for classification. Experiments on
the BioCreative V CDR dataset show that our method achieves comparable
performance with the state-of-the-art systems, and both dependency information
and prior knowledge play important roles in CDR extraction task.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Yunlong Yang</name>
    </author>
    <author>
      <name>Zhuang Liu</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Yingyu Lin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jbi.2018.07.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jbi.2018.07.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on Journal of Biomedical Informatics, 13 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Biomedical Informatics, 2018, 84:171-178</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.00295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00575v1</id>
    <updated>2020-01-01T20:39:22Z</updated>
    <published>2020-01-01T20:39:22Z</published>
    <title>Smart Summarizer for Blind People</title>
    <summary>  In today's world, time is a very important resource. In our busy lives, most
of us hardly have time to read the complete news so what we have to do is just
go through the headlines and satisfy ourselves with that. As a result, we might
miss a part of the news or misinterpret the complete thing. The situation is
even worse for the people who are visually impaired or have lost their ability
to see. The inability of these people to read text has a huge impact on their
lives. There are a number of methods for blind people to read the text. Braille
script, in particular, is one of the examples, but it is a highly inefficient
method as it is really time taking and requires a lot of practice. So, we
present a method for visually impaired people based on the sense of sound which
is obviously better and more accurate than the sense of touch. This paper deals
with an efficient method to summarize news into important keywords so as to
save the efforts to go through the complete text every single time. This paper
deals with many API's and modules like the tesseract, GTTS, and many algorithms
that have been discussed and implemented in detail such as Luhn's Algorithm,
Latent Semantic Analysis Algorithm, Text Ranking Algorithm. And the other
functionality that this paper deals with is converting the summarized text to
speech so that the system can aid even the blind people.
</summary>
    <author>
      <name>Mona teja K</name>
    </author>
    <author>
      <name>Mohan Sai. S</name>
    </author>
    <author>
      <name>H S S S Raviteja D</name>
    </author>
    <author>
      <name>Sai Kushagra P V</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00137v1</id>
    <updated>2020-01-01T04:49:23Z</updated>
    <published>2020-01-01T04:49:23Z</published>
    <title>Stacked DeBERT: All Attention in Incomplete Data for Text Classification</title>
    <summary>  In this paper, we propose Stacked DeBERT, short for Stacked Denoising
Bidirectional Encoder Representations from Transformers. This novel model
improves robustness in incomplete data, when compared to existing systems, by
designing a novel encoding scheme in BERT, a powerful language representation
model solely based on attention mechanisms. Incomplete data in natural language
processing refer to text with missing or incorrect words, and its presence can
hinder the performance of current models that were not implemented to withstand
such noises, but must still perform well even under duress. This is due to the
fact that current approaches are built for and trained with clean and complete
data, and thus are not able to extract features that can adequately represent
incomplete data. Our proposed approach consists of obtaining intermediate input
representations by applying an embedding layer to the input tokens followed by
vanilla transformers. These intermediate features are given as input to novel
denoising transformers which are responsible for obtaining richer input
representations. The proposed approach takes advantage of stacks of multilayer
perceptrons for the reconstruction of missing words' embeddings by extracting
more abstract and meaningful hidden feature vectors, and bidirectional
transformers for improved embedding representation. We consider two datasets
for training and evaluation: the Chatbot Natural Language Understanding
Evaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows
improved F1-scores and better robustness in informal/incorrect texts present in
tweets and in texts with Speech-to-Text error in the sentiment and intent
classification tasks.
</summary>
    <author>
      <name>Gwenaelle Cunha Sergio</name>
    </author>
    <author>
      <name>Minho Lee</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00573v1</id>
    <updated>2019-12-31T23:31:42Z</updated>
    <published>2019-12-31T23:31:42Z</published>
    <title>A Hybrid Framework for Topic Structure using Laughter Occurrences</title>
    <summary>  Conversational discourse coherence depends on both linguistic and
paralinguistic phenomena. In this work we combine both paralinguistic and
linguistic knowledge into a hybrid framework through a multi-level hierarchy.
Thus it outputs the discourse-level topic structures. The laughter occurrences
are used as paralinguistic information from the multiparty meeting transcripts
of ICSI database. A clustering-based algorithm is proposed that chose the best
topic-segment cluster from two independent, optimized clusters, namely,
hierarchical agglomerative clustering and $K$-medoids. Then it is iteratively
hybridized with an existing lexical cohesion based Bayesian topic segmentation
framework. The hybrid approach improves the performance of both of the
stand-alone approaches. This leads to the brief study of interactions between
topic structures with discourse relational structure. This training-free topic
structuring approach can be applicable to online understanding of spoken
dialogs.
</summary>
    <author>
      <name>Sucheta Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00100v1</id>
    <updated>2019-12-31T22:40:30Z</updated>
    <published>2019-12-31T22:40:30Z</published>
    <title>Building chatbots from large scale domain-specific knowledge bases:
  challenges and opportunities</title>
    <summary>  Popular conversational agents frameworks such as Alexa Skills Kit (ASK) and
Google Actions (gActions) offer unprecedented opportunities for facilitating
the development and deployment of voice-enabled AI solutions in various
verticals. Nevertheless, understanding user utterances with high accuracy
remains a challenging task with these frameworks. Particularly, when building
chatbots with large volume of domain-specific entities. In this paper, we
describe the challenges and lessons learned from building a large scale virtual
assistant for understanding and responding to equipment-related complaints. In
the process, we describe an alternative scalable framework for: 1) extracting
the knowledge about equipment components and their associated problem entities
from short texts, and 2) learning to identify such entities in user utterances.
We show through evaluation on a real dataset that the proposed framework,
compared to off-the-shelf popular ones, scales better with large volume of
entities being up to 30% more accurate, and is more effective in understanding
user utterances with domain-specific entities.
</summary>
    <author>
      <name>Walid Shalaby</name>
    </author>
    <author>
      <name>Adriano Arantes</name>
    </author>
    <author>
      <name>Teresa GonzalezDiaz</name>
    </author>
    <author>
      <name>Chetan Gupta</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00056v1</id>
    <updated>2019-12-31T19:54:27Z</updated>
    <published>2019-12-31T19:54:27Z</published>
    <title>Deep Attentive Ranking Networks for Learning to Order Sentences</title>
    <summary>  We present an attention-based ranking framework for learning to order
sentences given a paragraph. Our framework is built on a bidirectional sentence
encoder and a self-attention based transformer network to obtain an input order
invariant representation of paragraphs. Moreover, it allows seamless training
using a variety of ranking based loss functions, such as pointwise, pairwise,
and listwise ranking. We apply our framework on two tasks: Sentence Ordering
and Order Discrimination. Our framework outperforms various state-of-the-art
methods on these tasks on a variety of evaluation metrics. We also show that it
achieves better results when using pairwise and listwise ranking losses, rather
than the pointwise ranking loss, which suggests that incorporating relative
positions of two or more sentences in the loss function contributes to better
learning.
</summary>
    <author>
      <name>Pawan Kumar</name>
    </author>
    <author>
      <name>Dhanajit Brahma</name>
    </author>
    <author>
      <name>Harish Karnick</name>
    </author>
    <author>
      <name>Piyush Rai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00569v1</id>
    <updated>2019-12-31T18:33:03Z</updated>
    <published>2019-12-31T18:33:03Z</published>
    <title>Emergent Behaviors from Folksonomy Driven Interactions</title>
    <summary>  To reflect the evolving knowledge on the Web this paper considers ontologies
based on folksonomies according to a new concept structure called
"Folksodriven" to represent folksonomies. This paper describes a research
program for studying Folksodriven tags interactions leading to Folksodriven
cluster behavior. The goal of the research is to understand the type of simple
local interactions which produce complex and purposive group behaviors on
Folksodriven tags. We describe a synthetic, bottom-up approach to studying
group behavior, consisting of designing and testing a variety of social
interactions and cultural scenarios with Folksodriven tags. We propose a set of
basic interactions which can be used to structure and simplify the process of
both designing and analyzing emergent group behaviors. The presented behavior
repertories was developed and tested on a folksonomy environment.
</summary>
    <author>
      <name>Massimiliano Dal Mas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures; for details see: http://www.maxdalmas.com arXiv
  admin note: text overlap with arXiv:1612.09574</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; G.1.10; G.2.2; H.1.1; H.1.2; H.3.1; H.3.3; H.3.5; H.5.2;&#10;  H.5.3; H.5.4; I.2.1; I.2.4; I.2.7; I.3.6; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13455v1</id>
    <updated>2019-12-31T17:52:05Z</updated>
    <published>2019-12-31T17:52:05Z</published>
    <title>Essential Sentences for Navigating Stack Overflow Answers</title>
    <summary>  Stack Overflow (SO) has become an essential resource for software
development. Despite its success and prevalence, navigating SO remains a
challenge. Ideally, SO users could benefit from highlighted navigational cues
that help them decide if an answer is relevant to their task and context. Such
navigational cues could be in the form of essential sentences that help the
searcher decide whether they want to read the answer or skip over it. In this
paper, we compare four potential approaches for identifying essential
sentences. We adopt two existing approaches and develop two new approaches
based on the idea that contextual information in a sentence (e.g., "if using
windows") could help identify essential sentences. We compare the four
techniques using a survey of 43 participants. Our participants indicate that it
is not always easy to figure out what the best solution for their specific
problem is, given the options, and that they would indeed like to easily spot
contextual information that may narrow down the search. Our quantitative
comparison of the techniques shows that there is no single technique sufficient
for identifying essential sentences that can serve as navigational cues, while
our qualitative analysis shows that participants valued explanations and
specific conditions, and did not value filler sentences or speculations. Our
work sheds light on the importance of navigational cues, and our findings can
be used to guide future research to find the best combination of techniques to
identify such cues.
</summary>
    <author>
      <name>Sarah Nadi</name>
    </author>
    <author>
      <name>Christoph Treude</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear as full paper at SANER 2020, the 27th IEEE International
  Conference on Software Analysis, Evolution and Reengineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13337v1</id>
    <updated>2019-12-31T15:05:54Z</updated>
    <published>2019-12-31T15:05:54Z</published>
    <title>What Does My QA Model Know? Devising Controlled Probes using Expert
  Knowledge</title>
    <summary>  Open-domain question answering (QA) is known to involve several underlying
knowledge and reasoning challenges, but are models actually learning such
knowledge when trained on benchmark tasks? To investigate this, we introduce
several new challenge tasks that probe whether state-of-the-art QA models have
general knowledge about word definitions and general taxonomic reasoning, both
of which are fundamental to more complex forms of reasoning and are widespread
in benchmark datasets. As an alternative to expensive crowd-sourcing, we
introduce a methodology for automatically building datasets from various types
of expert knowledge (e.g., knowledge graphs and lexical taxonomies), allowing
for systematic control over the resulting probes and for a more comprehensive
evaluation. We find automatically constructing probes to be vulnerable to
annotation artifacts, which we carefully control for. Our evaluation confirms
that transformer-based QA models are already predisposed to recognize certain
types of structural lexical knowledge. However, it also reveals a more nuanced
picture: their performance degrades substantially with even a slight increase
in the number of hops in the underlying taxonomic hierarchy, or as more
challenging distractor candidate answers are introduced. Further, even when
these models succeed at the standard instance-level evaluation, they leave much
room for improvement when assessed at the level of clusters of semantically
connected probes (e.g., all Isa questions about a concept).
</summary>
    <author>
      <name>Kyle Richardson</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13321v1</id>
    <updated>2019-12-31T14:36:45Z</updated>
    <published>2019-12-31T14:36:45Z</published>
    <title>OTEANN: Estimating the Transparency of Orthographies with an Artificial
  Neural Network</title>
    <summary>  To transcribe spoken language to written medium, most alphabets enable an
unambiguous sound-to-letter rule. However, some writing systems have distanced
themselves from this simple concept and little work exists on measuring such
distance. In this study, we use an Artificial Neural Network (ANN) model to
evaluate the transparency between written words and their pronunciation, hence
its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on
datasets derived from Wikimedia dictionaries, we trained and tested this model
to score the percentage of false predictions in phoneme-to-grapheme and
grapheme-to-phoneme translation tasks. The scores obtained on 15 orthographies
were in line with the estimations of other studies. Interestingly, the model
also provided insight into typical mistakes made by learners who only consider
the phonemic rule in reading and writing.
</summary>
    <author>
      <name>Xavier Marjou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13318v3</id>
    <updated>2020-02-19T13:00:42Z</updated>
    <published>2019-12-31T14:31:29Z</published>
    <title>LayoutLM: Pre-training of Text and Layout for Document Image
  Understanding</title>
    <summary>  Pre-training techniques have been verified successfully in a variety of NLP
tasks in recent years. Despite the widespread of pre-training models for NLP
applications, they almost focused on text-level manipulation, while neglecting
the layout and style information that is vital for document image
understanding. In this paper, we propose the LayoutLM to jointly model the
interaction between text and layout information across scanned document images,
which is beneficial for a great number of real-world document image
understanding tasks such as information extraction from scanned documents.
Furthermore, we also leverage the image features to incorporate the visual
information of words into LayoutLM. To the best of our knowledge, this is the
first time that text and layout are jointly learned in a single framework for
document-level pre-training. It achieves new state-of-the-art results in
several downstream tasks, including form understanding (from 70.72 to 79.27),
receipt understanding (from 94.02 to 95.24) and document image classification
(from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly
available at https://github.com/microsoft/unilm/tree/master/layoutlm.
</summary>
    <author>
      <name>Yiheng Xu</name>
    </author>
    <author>
      <name>Minghao Li</name>
    </author>
    <author>
      <name>Lei Cui</name>
    </author>
    <author>
      <name>Shaohan Huang</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13318v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13318v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13283v1</id>
    <updated>2019-12-31T12:11:35Z</updated>
    <published>2019-12-31T12:11:35Z</published>
    <title>oLMpics -- On what Language Model Pre-training Captures</title>
    <summary>  Recent success of pre-trained language models (LMs) has spurred widespread
interest in the language capabilities that they possess. However, efforts to
understand whether LM representations are useful for symbolic reasoning tasks
have been limited and scattered. In this work, we propose eight reasoning
tasks, which conceptually require operations such as comparison, conjunction,
and composition. A fundamental challenge is to understand whether the
performance of a LM on a task should be attributed to the pre-trained
representations or to the process of fine-tuning on the task data. To address
this, we propose an evaluation protocol that includes both zero-shot evaluation
(no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to
the learning curve of multiple controls, which paints a rich picture of the LM
capabilities. Our main findings are that: (a) different LMs exhibit
qualitatively different reasoning abilities, e.g., RoBERTa succeeds in
reasoning tasks where BERT fails completely; (b) LMs do not reason in an
abstract manner and are context-dependent, e.g., while RoBERTa can compare
ages, it can do so only when the ages are in the typical range of human ages;
(c) On half of our reasoning tasks all models fail completely. Our findings and
infrastructure can help future work on designing new datasets, models and
objective functions for pre-training.
</summary>
    <author>
      <name>Alon Talmor</name>
    </author>
    <author>
      <name>Yanai Elazar</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <author>
      <name>Jonathan Berant</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13194v1</id>
    <updated>2019-12-31T06:38:57Z</updated>
    <published>2019-12-31T06:38:57Z</published>
    <title>CASE: Context-Aware Semantic Expansion</title>
    <summary>  In this paper, we define and study a new task called Context-Aware Semantic
Expansion (CASE). Given a seed term in a sentential context, we aim to suggest
other terms that well fit the context as the seed. CASE has many interesting
applications such as query suggestion, computer-assisted writing, and word
sense disambiguation, to name a few. Previous explorations, if any, only
involve some similar tasks, and all require human annotations for evaluation.
In this study, we demonstrate that annotations for this task can be harvested
at scale from existing corpora, in a fully automatic manner. On a dataset of
1.8 million sentences thus derived, we propose a network architecture that
encodes the context and seed term separately before suggesting alternative
terms. The context encoder in this architecture can be easily extended by
incorporating seed-aware attention. Our experiments demonstrate that
competitive results are achieved with appropriate choices of context encoder
and attention scoring function.
</summary>
    <author>
      <name>Jialong Han</name>
    </author>
    <author>
      <name>Aixin Sun</name>
    </author>
    <author>
      <name>Haisong Zhang</name>
    </author>
    <author>
      <name>Chenliang Li</name>
    </author>
    <author>
      <name>Shuming Shi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13149v2</id>
    <updated>2020-01-04T14:06:19Z</updated>
    <published>2019-12-31T02:46:29Z</published>
    <title>Revisiting Paraphrase Question Generator using Pairwise Discriminator</title>
    <summary>  In this paper, we propose a method for obtaining sentence-level embeddings.
While the problem of securing word-level embeddings is very well studied, we
propose a novel method for obtaining sentence-level embeddings. This is
obtained by a simple method in the context of solving the paraphrase generation
task. If we use a sequential encoder-decoder model for generating paraphrase,
we would like the generated paraphrase to be semantically close to the original
sentence. One way to ensure this is by adding constraints for true paraphrase
embeddings to be close and unrelated paraphrase candidate sentence embeddings
to be far. This is ensured by using a sequential pair-wise discriminator that
shares weights with the encoder that is trained with a suitable loss function.
Our loss function penalizes paraphrase sentence embedding distances from being
too large. This loss is used in combination with a sequential encoder-decoder
network. We also validated our method by evaluating the obtained embeddings for
a sentiment analysis task. The proposed method results in semantic embeddings
and outperforms the state-of-the-art on the paraphrase generation and sentiment
analysis task on standard datasets. These results are also shown to be
statistically significant.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Dev Chauhan</name>
    </author>
    <author>
      <name>Vinod K. Kurmi</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work is an extension of our COLING-2018 paper arXiv:1806.00807</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13149v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13149v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13109v1</id>
    <updated>2019-12-30T23:01:28Z</updated>
    <published>2019-12-30T23:01:28Z</published>
    <title>"Hinglish" Language -- Modeling a Messy Code-Mixed Language</title>
    <summary>  With a sharp rise in fluency and users of "Hinglish" in linguistically
diverse country, India, it has increasingly become important to analyze social
content written in this language in platforms such as Twitter, Reddit,
Facebook. This project focuses on using deep learning techniques to tackle a
classification problem in categorizing social content written in Hindi-English
into Abusive, Hate-Inducing and Not offensive categories. We utilize
bi-directional sequence models with easy text augmentation techniques such as
synonym replacement, random insertion, random swap, and random deletion to
produce a state of the art classifier that outperforms the previous work done
on analyzing this dataset.
</summary>
    <author>
      <name>Vivek Kumar Gupta</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13106v1</id>
    <updated>2019-12-30T22:41:57Z</updated>
    <published>2019-12-30T22:41:57Z</published>
    <title>An Empirical Study of Factors Affecting Language-Independent Models</title>
    <summary>  Scaling existing applications and solutions to multiple human languages has
traditionally proven to be difficult, mainly due to the language-dependent
nature of preprocessing and feature engineering techniques employed in
traditional approaches. In this work, we empirically investigate the factors
affecting language-independent models built with multilingual representations,
including task type, language set and data resource. On two most representative
NLP tasks -- sentence classification and sequence labeling, we show that
language-independent models can be comparable to or even outperforms the models
trained using monolingual data, and they are generally more effective on
sentence classification. We experiment language-independent models with many
different languages and show that they are more suitable for typologically
similar languages. We also explore the effects of different data sizes when
training and testing language-independent models, and demonstrate that they are
not only suitable for high-resource languages, but also very effective in
low-resource languages.
</summary>
    <author>
      <name>Xiaotong Liu</name>
    </author>
    <author>
      <name>Yingbei Tong</name>
    </author>
    <author>
      <name>Anbang Xu</name>
    </author>
    <author>
      <name>Rama Akkiraju</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13082v2</id>
    <updated>2020-01-01T16:06:48Z</updated>
    <published>2019-12-30T21:03:59Z</published>
    <title>The Shmoop Corpus: A Dataset of Stories with Loosely Aligned Summaries</title>
    <summary>  Understanding stories is a challenging reading comprehension problem for
machines as it requires reading a large volume of text and following long-range
dependencies. In this paper, we introduce the Shmoop Corpus: a dataset of 231
stories that are paired with detailed multi-paragraph summaries for each
individual chapter (7,234 chapters), where the summary is chronologically
aligned with respect to the story chapter. From the corpus, we construct a set
of common NLP tasks, including Cloze-form question answering and a simplified
form of abstractive summarization, as benchmarks for reading comprehension on
stories. We then show that the chronological alignment provides a strong
supervisory signal that learning-based methods can exploit leading to
significant improvements on these tasks. We believe that the unique structure
of this corpus provides an important foothold towards making machine story
comprehension more approachable.
</summary>
    <author>
      <name>Atef Chaudhury</name>
    </author>
    <author>
      <name>Makarand Tapaswi</name>
    </author>
    <author>
      <name>Seung Wook Kim</name>
    </author>
    <author>
      <name>Sanja Fidler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: http://www.cs.toronto.edu/~makarand/shmoop/ Dataset at:
  https://github.com/achaudhury/shmoop-corpus/</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13082v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13082v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13080v1</id>
    <updated>2019-12-30T20:46:38Z</updated>
    <published>2019-12-30T20:46:38Z</published>
    <title>Teaching a New Dog Old Tricks: Resurrecting Multilingual Retrieval Using
  Zero-shot Learning</title>
    <summary>  While billions of non-English speaking users rely on search engines every
day, the problem of ad-hoc information retrieval is rarely studied for
non-English languages. This is primarily due to a lack of data set that are
suitable to train ranking algorithms. In this paper, we tackle the lack of data
by leveraging pre-trained multilingual language models to transfer a retrieval
system trained on English collections to non-English queries and documents. Our
model is evaluated in a zero-shot setting, meaning that we use them to predict
relevance scores for query-document pairs in languages never seen during
training. Our results show that the proposed approach can significantly
outperform unsupervised retrieval techniques for Arabic, Chinese Mandarin, and
Spanish. We also show that augmenting the English training collection with some
examples from the target language can sometimes improve performance.
</summary>
    <author>
      <name>Sean MacAvaney</name>
    </author>
    <author>
      <name>Luca Soldaini</name>
    </author>
    <author>
      <name>Nazli Goharian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2020 (short)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13072v1</id>
    <updated>2019-12-30T20:05:37Z</updated>
    <published>2019-12-30T20:05:37Z</published>
    <title>AraNet: A Deep Learning Toolkit for Arabic Social Media</title>
    <summary>  We describe AraNet, a collection of deep learning Arabic social media
processing tools. Namely, we exploit an extensive host of publicly available
and novel social media datasets to train bidirectional encoders from
transformer models (BERT) to predict age, dialect, gender, emotion, irony, and
sentiment. AraNet delivers state-of-the-art performance on a number of the
cited tasks and competitively on others. In addition, AraNet has the advantage
of being exclusively based on a deep learning framework and hence feature
engineering free. To the best of our knowledge, AraNet is the first to performs
predictions across such a wide range of tasks for Arabic NLP and thus meets a
critical needs. We publicly release AraNet to accelerate research and
facilitate comparisons across the different tasks.
</summary>
    <author>
      <name>Muhammad Abdul-Mageed</name>
    </author>
    <author>
      <name>Chiyu Zhang</name>
    </author>
    <author>
      <name>Azadeh Hashemi</name>
    </author>
    <author>
      <name>El Moatez Billah Nagoudi</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12999v2</id>
    <updated>2020-01-09T13:52:19Z</updated>
    <published>2019-12-30T16:44:41Z</published>
    <title>AutoDiscern: Rating the Quality of Online Health Information with
  Hierarchical Encoder Attention-based Neural Networks</title>
    <summary>  Patients increasingly turn to search engines and online content before, or in
place of, talking with a health professional. Low quality health information,
which is common on the internet, presents risks to the patient in the form of
misinformation and a possibly poorer relationship with their physician. To
address this, the DISCERN criteria (developed at University of Oxford) are used
to evaluate the quality of online health information. However, patients are
unlikely to take the time to apply these criteria to the health websites they
visit. We built an automated implementation of the DISCERN instrument (Brief
version) using machine learning models. We compared the performance of a
traditional model (Random Forest) with that of a hierarchical encoder
attention-based neural network (HEA) model using two language embeddings, BERT
and BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores
across all criteria of 0.75 and 0.74, respectively, outperforming the Random
Forest model (average F1-macro = 0.69). Similarly, as measured by F-micro, HEA
BERT and BioBERT scored on average 0.80 and 0.81 vs. 0.76 for the Random Forest
model. Overall, the neural network based models achieved 81% and 86% average
accuracy at 100% and 80% coverage, respectively, compared to 94% manual rating
accuracy. The attention mechanism implemented in the HEA architectures provided
'model explainability' by identifying reasonable supporting sentences for the
documents fulfilling the Brief DISCERN criteria. Our research suggests that it
is feasible to automate online health information quality assessment, which is
an important step towards empowering patients to become informed partners in
the healthcare process.
</summary>
    <author>
      <name>Laura Kinkead</name>
    </author>
    <author>
      <name>Ahmed Allam</name>
    </author>
    <author>
      <name>Michael Krauthammer</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12999v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12999v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12887v1</id>
    <updated>2019-12-30T11:34:39Z</updated>
    <published>2019-12-30T11:34:39Z</published>
    <title>Using a Pitch-Synchronous Residual Codebook for Hybrid HMM/Frame
  Selection Speech Synthesis</title>
    <summary>  This paper proposes a method to improve the quality delivered by statistical
parametric speech synthesizers. For this, we use a codebook of
pitch-synchronous residual frames, so as to construct a more realistic source
signal. First a limited codebook of typical excitations is built from some
training database. During the synthesis part, HMMs are used to generate filter
and source coefficients. The latter coefficients contain both the pitch and a
compact representation of target residual frames. The source signal is obtained
by concatenating excitation frames picked up from the codebook, based on a
selection criterion and taking target residual coefficients as input.
Subjective results show a relevant improvement compared to the basic technique.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Alexis Moinet</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <author>
      <name>Geoffrey Wilfart</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12843v1</id>
    <updated>2019-12-30T08:12:03Z</updated>
    <published>2019-12-30T08:12:03Z</published>
    <title>Causal-Anticausal Decomposition of Speech using Complex Cepstrum for
  Glottal Source Estimation</title>
    <summary>  Complex cepstrum is known in the literature for linearly separating causal
and anticausal components. Relying on advances achieved by the Zeros of the
Z-Transform (ZZT) technique, we here investigate the possibility of using
complex cepstrum for glottal flow estimation on a large-scale database. Via a
systematic study of the windowing effects on the deconvolution quality, we show
that the complex cepstrum causal-anticausal decomposition can be effectively
used for glottal flow estimation when specific windowing criteria are met. It
is also shown that this complex cepstral decomposition gives similar glottal
estimates as obtained with the ZZT method. However, as complex cepstrum uses
FFT operations instead of requiring the factoring of high-degree polynomials,
the method benefits from a much higher speed. Finally in our tests on a large
corpus of real expressive speech, we show that the proposed method has the
potential to be used for voice quality analysis.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Baris Bozkurt</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12800v1</id>
    <updated>2019-12-30T03:31:17Z</updated>
    <published>2019-12-30T03:31:17Z</published>
    <title>Likelihood Ratios and Generative Classifiers for Unsupervised
  Out-of-Domain Detection In Task Oriented Dialog</title>
    <summary>  The task of identifying out-of-domain (OOD) input examples directly at
test-time has seen renewed interest recently due to increased real world
deployment of models. In this work, we focus on OOD detection for natural
language sentence inputs to task-based dialog systems. Our findings are
three-fold: First, we curate and release ROSTD (Real Out-of-Domain Sentences
From Task-oriented Dialog) - a dataset of 4K OOD examples for the publicly
available dataset from (Schuster et al. 2019). In contrast to existing settings
which synthesize OOD examples by holding out a subset of classes, our examples
were authored by annotators with apriori instructions to be out-of-domain with
respect to the sentences in an existing dataset. Second, we explore likelihood
ratio based approaches as an alternative to currently prevalent paradigms.
Specifically, we reformulate and apply these approaches to natural language
inputs. We find that they match or outperform the latter on all datasets, with
larger improvements on non-artificial OOD benchmarks such as our dataset. Our
ablations validate that specifically using likelihood ratios rather than plain
likelihood is necessary to discriminate well between OOD and in-domain data.
Third, we propose learning a generative classifier and computing a marginal
likelihood (ratio) for OOD detection. This allows us to use a principled
likelihood while at the same time exploiting training-time labels. We find that
this approach outperforms both simple likelihood (ratio) based and other prior
approaches. We are hitherto the first to investigate the use of generative
classifiers for OOD detection at test-time.
</summary>
    <author>
      <name>Varun Gangal</name>
    </author>
    <author>
      <name>Abhinav Arora</name>
    </author>
    <author>
      <name>Arash Einolghozati</name>
    </author>
    <author>
      <name>Sonal Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for AAAI-2020 Main Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00009v1</id>
    <updated>2019-12-30T01:32:42Z</updated>
    <published>2019-12-30T01:32:42Z</published>
    <title>Deep Reinforced Self-Attention Masks for Abstractive Summarization
  (DR.SAS)</title>
    <summary>  We present a novel architectural scheme to tackle the abstractive
summarization problem based on the CNN/DMdataset which fuses Reinforcement
Learning (RL) withUniLM, which is a pre-trained Deep Learning Model, to solve
various natural language tasks. We have tested the limits of learning
fine-grained attention in Transformers to improve the summarization quality.
UniLM applies attention to the entire token space in a global fashion. We
propose DR.SAS which applies the Actor-Critic (AC) algorithm to learn a dynamic
self-attention distribution over the tokens to reduce redundancy and generate
factual and coherent summaries to improve the quality of summarization. After
performing hyperparameter tuning, we achievedbetter ROUGE results compared to
the baseline. Our model tends to be more extractive/factual yet coherent in
detail because of optimization over ROUGE rewards. We present detailed error
analysis with examples of the strengths and limitations of our model. Our
codebase will be publicly available on our GitHub.
</summary>
    <author>
      <name>Ankit Chadha</name>
    </author>
    <author>
      <name>Mohamed Masoud</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12635v2</id>
    <updated>2020-03-06T15:26:59Z</updated>
    <published>2019-12-29T11:31:11Z</published>
    <title>ÆTHEL: Automatically Extracted Typelogical Derivations for Dutch</title>
    <summary>  We present {\AE}THEL, a semantic compositionality dataset for written Dutch.
{\AE}THEL consists of two parts. First, it contains a lexicon of supertags for
about 900 000 words in context. The supertags correspond to types of the simply
typed linear lambda-calculus, enhanced with dependency decorations that capture
grammatical roles supplementary to function-argument structures. On the basis
of these types, {\AE}THEL further provides 72 192 validated derivations,
presented in four formats: natural-deduction and sequent-style proofs, linear
logic proofnets and the associated programs (lambda terms) for meaning
composition. {\AE}THEL's types and derivations are obtained by means of an
extraction algorithm applied to the syntactic analyses of LASSY Small, the gold
standard corpus of written Dutch. We discuss the extraction algorithm and show
how `virtual elements' in the original LASSY annotation of unbounded
dependencies and coordination phenomena give rise to higher-order types. We
suggest some example usecases highlighting the benefits of a type-driven
approach at the syntax semantics interface. The following resources are
open-sourced with {\AE}THEL: the lexical mappings between words and types, a
subset of the dataset consisting of 7 924 semantic parses, and the Python code
that implements the extraction algorithm.
</summary>
    <author>
      <name>Konstantinos Kogkalidis</name>
    </author>
    <author>
      <name>Michael Moortgat</name>
    </author>
    <author>
      <name>Richard Moot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages plus abstract, LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12635v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12635v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12628v1</id>
    <updated>2019-12-29T11:05:47Z</updated>
    <published>2019-12-29T11:05:47Z</published>
    <title>Dirichlet uncertainty wrappers for actionable algorithm accuracy
  accountability and auditability</title>
    <summary>  Nowadays, the use of machine learning models is becoming a utility in many
applications. Companies deliver pre-trained models encapsulated as application
programming interfaces (APIs) that developers combine with third party
components and their own models and data to create complex data products to
solve specific problems. The complexity of such products and the lack of
control and knowledge of the internals of each component used cause unavoidable
effects, such as lack of transparency, difficulty in auditability, and
emergence of potential uncontrolled risks. They are effectively black-boxes.
Accountability of such solutions is a challenge for the auditors and the
machine learning community. In this work, we propose a wrapper that given a
black-box model enriches its output prediction with a measure of uncertainty.
By using this wrapper, we make the black-box auditable for the accuracy risk
(risk derived from low quality or uncertain decisions) and at the same time we
provide an actionable mechanism to mitigate that risk in the form of decision
rejection; we can choose not to issue a prediction when the risk or uncertainty
in that decision is significant. Based on the resulting uncertainty measure, we
advocate for a rejection system that selects the more confident predictions,
discarding those more uncertain, leading to an improvement in the trustability
of the resulting system. We showcase the proposed technique and methodology in
a practical scenario where a simulated sentiment analysis API based on natural
language processing is applied to different domains. Results demonstrate the
effectiveness of the uncertainty computed by the wrapper and its high
correlation to bad quality predictions and misclassifications.
</summary>
    <author>
      <name>José Mena</name>
    </author>
    <author>
      <name>Oriol Pujol</name>
    </author>
    <author>
      <name>Jordi Vitrià</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures and 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T37" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12604v1</id>
    <updated>2019-12-29T08:13:58Z</updated>
    <published>2019-12-29T08:13:58Z</published>
    <title>Glottal Source Processing: from Analysis to Applications</title>
    <summary>  The great majority of current voice technology applications relies on
acoustic features characterizing the vocal tract response, such as the widely
used MFCC of LPC parameters. Nonetheless, the airflow passing through the vocal
folds, and called glottal flow, is expected to exhibit a relevant
complementarity. Unfortunately, glottal analysis from speech recordings
requires specific and more complex processing operations, which explains why it
has been generally avoided. This review gives a general overview of techniques
which have been designed for glottal source processing. Starting from
fundamental analysis tools of pitch tracking, glottal closure instant
detection, glottal flow estimation and modelling, this paper then highlights
how these solutions can be properly integrated within various voice technology
applications.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Paavo Alku</name>
    </author>
    <author>
      <name>Abeer Alwan</name>
    </author>
    <author>
      <name>Bayya Yegnanarayana</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12602v1</id>
    <updated>2019-12-29T07:58:18Z</updated>
    <published>2019-12-29T07:58:18Z</published>
    <title>Complex Cepstrum-based Decomposition of Speech for Glottal Source
  Estimation</title>
    <summary>  Homomorphic analysis is a well-known method for the separation of
non-linearly combined signals. More particularly, the use of complex cepstrum
for source-tract deconvolution has been discussed in various articles. However
there exists no study which proposes a glottal flow estimation methodology
based on cepstrum and reports effective results. In this paper, we show that
complex cepstrum can be effectively used for glottal flow estimation by
separating the causal and anticausal components of a windowed speech signal as
done by the Zeros of the Z-Transform (ZZT) decomposition. Based on exactly the
same principles presented for ZZT decomposition, windowing should be applied
such that the windowed speech signals exhibit mixed-phase characteristics which
conform the speech production model that the anticausal component is mainly due
to the glottal flow open phase. The advantage of the complex cepstrum-based
approach compared to the ZZT decomposition is its much higher speed.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Baris Bozkurt</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01000v1</id>
    <updated>2019-12-29T07:52:37Z</updated>
    <published>2019-12-29T07:52:37Z</published>
    <title>The Deterministic plus Stochastic Model of the Residual Signal and its
  Applications</title>
    <summary>  The modeling of speech production often relies on a source-filter approach.
Although methods parameterizing the filter have nowadays reached a certain
maturity, there is still a lot to be gained for several speech processing
applications in finding an appropriate excitation model. This manuscript
presents a Deterministic plus Stochastic Model (DSM) of the residual signal.
The DSM consists of two contributions acting in two distinct spectral bands
delimited by a maximum voiced frequency. Both components are extracted from an
analysis performed on a speaker-dependent dataset of pitch-synchronous residual
frames. The deterministic part models the low-frequency contents and arises
from an orthonormal decomposition of these frames. As for the stochastic
component, it is a high-frequency noise modulated both in time and frequency.
Some interesting phonetic and computational properties of the DSM are also
highlighted. The applicability of the DSM in two fields of speech processing is
then studied. First, it is shown that incorporating the DSM vocoder in
HMM-based speech synthesis enhances the delivered quality. The proposed
approach turns out to significantly outperform the traditional pulse excitation
and provides a quality equivalent to STRAIGHT. In a second application, the
potential of glottal signatures derived from the proposed DSM is investigated
for speaker identification purpose. Interestingly, these signatures are shown
to lead to better recognition rates than other glottal-based methods.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.01000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12598v1</id>
    <updated>2019-12-29T07:27:23Z</updated>
    <published>2019-12-29T07:27:23Z</published>
    <title>ORB: An Open Reading Benchmark for Comprehensive Evaluation of Machine
  Reading Comprehension</title>
    <summary>  Reading comprehension is one of the crucial tasks for furthering research in
natural language understanding. A lot of diverse reading comprehension datasets
have recently been introduced to study various phenomena in natural language,
ranging from simple paraphrase matching and entity typing to entity tracking
and understanding the implications of the context. Given the availability of
many such datasets, comprehensive and reliable evaluation is tedious and
time-consuming for researchers working on this problem. We present an
evaluation server, ORB, that reports performance on seven diverse reading
comprehension datasets, encouraging and facilitating testing a single model's
capability in understanding a wide variety of reading phenomena. The evaluation
server places no restrictions on how models are trained, so it is a suitable
test bed for exploring training paradigms and representation learning for
general reading facility. As more suitable datasets are released, they will be
added to the evaluation server. We also collect and include synthetic
augmentations for these datasets, testing how well models can handle
out-of-domain questions.
</summary>
    <author>
      <name>Dheeru Dua</name>
    </author>
    <author>
      <name>Ananth Gottumukkala</name>
    </author>
    <author>
      <name>Alon Talmor</name>
    </author>
    <author>
      <name>Sameer Singh</name>
    </author>
    <author>
      <name>Matt Gardner</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00842v1</id>
    <updated>2019-12-29T07:26:47Z</updated>
    <published>2019-12-29T07:26:47Z</published>
    <title>A Deterministic plus Stochastic Model of the Residual Signal for
  Improved Parametric Speech Synthesis</title>
    <summary>  Speech generated by parametric synthesizers generally suffers from a typical
buzziness, similar to what was encountered in old LPC-like vocoders. In order
to alleviate this problem, a more suited modeling of the excitation should be
adopted. For this, we hereby propose an adaptation of the Deterministic plus
Stochastic Model (DSM) for the residual. In this model, the excitation is
divided into two distinct spectral bands delimited by the maximum voiced
frequency. The deterministic part concerns the low-frequency contents and
consists of a decomposition of pitch-synchronous residual frames on an
orthonormal basis obtained by Principal Component Analysis. The stochastic
component is a high-pass filtered noise whose time structure is modulated by an
energy-envelope, similarly to what is done in the Harmonic plus Noise Model
(HNM). The proposed residual model is integrated within a HMM-based speech
synthesizer and is compared to the traditional excitation through a subjective
test. Results show a significative improvement for both male and female voices.
In addition the proposed model requires few computational load and memory,
which is essential for its integration in commercial applications.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Geoffrey Wilfart</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12520v2</id>
    <updated>2020-01-20T03:03:09Z</updated>
    <published>2019-12-28T21:20:25Z</published>
    <title>Weak Supervision for Fake News Detection via Reinforcement Learning</title>
    <summary>  Today social media has become the primary source for news. Via social media
platforms, fake news travel at unprecedented speeds, reach global audiences and
put users and communities at great risk. Therefore, it is extremely important
to detect fake news as early as possible. Recently, deep learning based
approaches have shown improved performance in fake news detection. However, the
training of such models requires a large amount of labeled data, but manual
annotation is time-consuming and expensive. Moreover, due to the dynamic nature
of news, annotated samples may become outdated quickly and cannot represent the
news articles on newly emerged events. Therefore, how to obtain fresh and
high-quality labeled samples is the major challenge in employing deep learning
models for fake news detection. In order to tackle this challenge, we propose a
reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which
can leverage users' reports as weak supervision to enlarge the amount of
training data for fake news detection. The proposed framework consists of three
main components: the annotator, the reinforced selector and the fake news
detector. The annotator can automatically assign weak labels for unlabeled news
based on users' reports. The reinforced selector using reinforcement learning
techniques chooses high-quality samples from the weakly labeled data and
filters out those low-quality ones that may degrade the detector's prediction
performance. The fake news detector aims to identify fake news based on the
news content. We tested the proposed framework on a large collection of news
articles published via WeChat official accounts and associated user reports.
Extensive experiments on this dataset show that the proposed WeFEND model
achieves the best performance compared with the state-of-the-art methods.
</summary>
    <author>
      <name>Yaqing Wang</name>
    </author>
    <author>
      <name>Weifeng Yang</name>
    </author>
    <author>
      <name>Fenglong Ma</name>
    </author>
    <author>
      <name>Jin Xu</name>
    </author>
    <author>
      <name>Bin Zhong</name>
    </author>
    <author>
      <name>Qiang Deng</name>
    </author>
    <author>
      <name>Jing Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12520v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12520v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00840v1</id>
    <updated>2019-12-28T20:40:08Z</updated>
    <published>2019-12-28T20:40:08Z</published>
    <title>A Comparative Study of Glottal Source Estimation Techniques</title>
    <summary>  Source-tract decomposition (or glottal flow estimation) is one of the basic
problems of speech processing. For this, several techniques have been proposed
in the literature. However studies comparing different approaches are almost
nonexistent. Besides, experiments have been systematically performed either on
synthetic speech or on sustained vowels. In this study we compare three of the
main representative state-of-the-art methods of glottal flow estimation:
closed-phase inverse filtering, iterative and adaptive inverse filtering, and
mixed-phase decomposition. These techniques are first submitted to an objective
assessment test on synthetic speech signals. Their sensitivity to various
factors affecting the estimation quality, as well as their robustness to noise
are studied. In a second experiment, their ability to label voice quality
(tensed, modal, soft) is studied on a large corpus of real connected speech. It
is shown that changes of voice quality are reflected by significant
modifications in glottal feature distributions. Techniques based on the
mixed-phase decomposition and on a closed-phase inverse filtering process turn
out to give the best results on both clean synthetic and real speech signals.
On the other hand, iterative and adaptive inverse filtering is recommended in
noisy environments for its high robustness.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Baris Bozkurt</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12514v1</id>
    <updated>2019-12-28T20:11:33Z</updated>
    <published>2019-12-28T20:11:33Z</published>
    <title>Tha3aroon at NSURL-2019 Task 8: Semantic Question Similarity in Arabic</title>
    <summary>  In this paper, we describe our team's effort on the semantic text question
similarity task of NSURL 2019. Our top performing system utilizes several
innovative data augmentation techniques to enlarge the training data. Then, it
takes ELMo pre-trained contextual embeddings of the data and feeds them into an
ON-LSTM network with self-attention. This results in sequence representation
vectors that are used to predict the relation between the question pairs. The
model is ranked in the 1st place with 96.499 F1-score (same as the second place
F1-score) and the 2nd place with 94.848 F1-score (differs by 1.076 F1-score
from the first place) on the public and private leaderboards, respectively.
</summary>
    <author>
      <name>Ali Fadel</name>
    </author>
    <author>
      <name>Ibraheem Tuffaha</name>
    </author>
    <author>
      <name>Mahmoud Al-Ayyoub</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12514v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12514v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00841v1</id>
    <updated>2019-12-28T19:27:45Z</updated>
    <published>2019-12-28T19:27:45Z</published>
    <title>Glottal Closure and Opening Instant Detection from Speech Signals</title>
    <summary>  This paper proposes a new procedure to detect Glottal Closure and Opening
Instants (GCIs and GOIs) directly from speech waveforms. The procedure is
divided into two successive steps. First a mean-based signal is computed, and
intervals where speech events are expected to occur are extracted from it.
Secondly, at each interval a precise position of the speech event is assigned
by locating a discontinuity in the Linear Prediction residual. The proposed
method is compared to the DYPSA algorithm on the CMU ARCTIC database. A
significant improvement as well as a better noise robustness are reported.
Besides, results of GOI identification accuracy are promising for the glottal
source characterization.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12481v1</id>
    <updated>2019-12-28T16:18:33Z</updated>
    <published>2019-12-28T16:18:33Z</published>
    <title>Robust Cross-lingual Embeddings from Parallel Sentences</title>
    <summary>  Recent advances in cross-lingual word embeddings have primarily relied on
mapping-based methods, which project pretrained word embeddings from different
languages into a shared space through a linear transformation. However, these
approaches assume word embedding spaces are isomorphic between different
languages, which has been shown not to hold in practice (S{\o}gaard et al.,
2018), and fundamentally limits their performance. This motivates investigating
joint learning methods which can overcome this impediment, by simultaneously
learning embeddings across languages via a cross-lingual term in the training
objective. Given the abundance of parallel data available (Tiedemann, 2012), we
propose a bilingual extension of the CBOW method which leverages
sentence-aligned corpora to obtain robust cross-lingual word and sentence
representations. Our approach significantly improves cross-lingual sentence
retrieval performance over all other approaches, as well as convincingly
outscores mapping methods while maintaining parity with jointly trained methods
on word-translation. It also achieves parity with a deep RNN method on a
zero-shot cross-lingual document classification task, requiring far fewer
computational resources for training and inference. As an additional advantage,
our bilingual method also improves the quality of monolingual word vectors
despite training on much smaller datasets. We make our code and models publicly
available.
</summary>
    <author>
      <name>Ali Sabet</name>
    </author>
    <author>
      <name>Prakhar Gupta</name>
    </author>
    <author>
      <name>Jean-Baptiste Cordonnier</name>
    </author>
    <author>
      <name>Robert West</name>
    </author>
    <author>
      <name>Martin Jaggi</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00473v1</id>
    <updated>2019-12-28T14:12:16Z</updated>
    <published>2019-12-28T14:12:16Z</published>
    <title>Detection of Glottal Closure Instants from Speech Signals: a
  Quantitative Review</title>
    <summary>  The pseudo-periodicity of voiced speech can be exploited in several speech
processing applications. This requires however that the precise locations of
the Glottal Closure Instants (GCIs) are available. The focus of this paper is
the evaluation of automatic methods for the detection of GCIs directly from the
speech waveform. Five state-of-the-art GCI detection algorithms are compared
using six different databases with contemporaneous electroglottographic
recordings as ground truth, and containing many hours of speech by multiple
speakers. The five techniques compared are the Hilbert Envelope-based detection
(HE), the Zero Frequency Resonator-based method (ZFR), the Dynamic Programming
Phase Slope Algorithm (DYPSA), the Speech Event Detection using the Residual
Excitation And a Mean-based Signal (SEDREAMS) and the Yet Another GCI Algorithm
(YAGA). The efficacy of these methods is first evaluated on clean speech, both
in terms of reliabililty and accuracy. Their robustness to additive noise and
to reverberation is also assessed. A further contribution of the paper is the
evaluation of their performance on a concrete application of speech processing:
the causal-anticausal decomposition of speech. It is shown that for clean
speech, SEDREAMS and YAGA are the best performing techniques, both in terms of
identification rate and accuracy. ZFR and SEDREAMS also show a superior
robustness to additive noise and reverberation.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Mark Thomas</name>
    </author>
    <author>
      <name>Jon Gudnason</name>
    </author>
    <author>
      <name>Patrick Naylor</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00459v1</id>
    <updated>2019-12-28T13:45:29Z</updated>
    <published>2019-12-28T13:45:29Z</published>
    <title>Joint Robust Voicing Detection and Pitch Estimation Based on Residual
  Harmonics</title>
    <summary>  This paper focuses on the problem of pitch tracking in noisy conditions. A
method using harmonic information in the residual signal is presented. The
proposed criterion is used both for pitch estimation, as well as for
determining the voicing segments of speech. In the experiments, the method is
compared to six state-of-the-art pitch trackers on the Keele and CSTR
databases. The proposed technique is shown to be particularly robust to
additive noise, leading to a significant improvement in adverse conditions.
</summary>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Abeer Alwan</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12422v2</id>
    <updated>2020-01-01T10:18:26Z</updated>
    <published>2019-12-28T07:52:00Z</published>
    <title>TextScanner: Reading Characters in Order for Robust Scene Text
  Recognition</title>
    <summary>  Driven by deep learning and the large volume of data, scene text recognition
has evolved rapidly in recent years. Formerly, RNN-attention based methods have
dominated this field, but suffer from the problem of \textit{attention drift}
in certain situations. Lately, semantic segmentation based algorithms have
proven effective at recognizing text of different forms (horizontal, oriented
and curved). However, these methods may produce spurious characters or miss
genuine characters, as they rely heavily on a thresholding procedure operated
on segmentation maps. To tackle these challenges, we propose in this paper an
alternative approach, called TextScanner, for scene text recognition.
TextScanner bears three characteristics: (1) Basically, it belongs to the
semantic segmentation family, as it generates pixel-wise, multi-channel
segmentation maps for character class, position and order; (2) Meanwhile, akin
to RNN-attention based methods, it also adopts RNN for context modeling; (3)
Moreover, it performs paralleled prediction for character position and class,
and ensures that characters are transcripted in correct order. The experiments
on standard benchmark datasets demonstrate that TextScanner outperforms the
state-of-the-art methods. Moreover, TextScanner shows its superiority in
recognizing more difficult text such Chinese transcripts and aligning with
target characters.
</summary>
    <author>
      <name>Zhaoyi Wan</name>
    </author>
    <author>
      <name>Minghang He</name>
    </author>
    <author>
      <name>Haoran Chen</name>
    </author>
    <author>
      <name>Xiang Bai</name>
    </author>
    <author>
      <name>Cong Yao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12422v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12422v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12397v1</id>
    <updated>2019-12-28T04:05:15Z</updated>
    <published>2019-12-28T04:05:15Z</published>
    <title>Natural language processing of MIMIC-III clinical notes for identifying
  diagnosis and procedures with neural networks</title>
    <summary>  Coding diagnosis and procedures in medical records is a crucial process in
the healthcare industry, which includes the creation of accurate billings,
receiving reimbursements from payers, and creating standardized patient care
records. In the United States, Billing and Insurance related activities cost
around $471 billion in 2012 which constitutes about 25% of all the U.S hospital
spending. In this paper, we report the performance of a natural language
processing model that can map clinical notes to medical codes, and predict
final diagnosis from unstructured entries of history of present illness,
symptoms at the time of admission, etc. Previous studies have demonstrated that
deep learning models perform better at such mapping when compared to
conventional machine learning models. Therefore, we employed state-of-the-art
deep learning method, ULMFiT on the largest emergency department clinical notes
dataset MIMIC III which has 1.2M clinical notes to select for the top-10 and
top-50 diagnosis and procedure codes. Our models were able to predict the
top-10 diagnoses and procedures with 80.3% and 80.5% accuracy, whereas the
top-50 ICD-9 codes of diagnosis and procedures are predicted with 70.7% and
63.9% accuracy. Prediction of diagnosis and procedures from unstructured
clinical notes benefit human coders to save time, eliminate errors and minimize
costs. With promising scores from our present model, the next step would be to
deploy this on a small-scale real-world scenario and compare it with human
coders as the gold standard. We believe that further research of this approach
can create highly accurate predictions that can ease the workflow in a clinical
setting.
</summary>
    <author>
      <name>Siddhartha Nuthakki</name>
    </author>
    <author>
      <name>Sunil Neela</name>
    </author>
    <author>
      <name>Judy W. Gichoya</name>
    </author>
    <author>
      <name>Saptarshi Purkayastha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a shortened version of the Capstone Project that was accepted
  by the Faculty of Indiana University, in partial fulfillment of the
  requirements for the degree of Master of Science in Health Informatics in Dec
  2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12394v2</id>
    <updated>2020-01-15T23:10:55Z</updated>
    <published>2019-12-28T03:51:52Z</published>
    <title>All-in-One Image-Grounded Conversational Agents</title>
    <summary>  As single-task accuracy on individual language and image tasks has improved
substantially in the last few years, the long-term goal of a generally skilled
agent that can both see and talk becomes more feasible to explore. In this
work, we focus on leveraging individual language and image tasks, along with
resources that incorporate both vision and language towards that objective. We
design an architecture that combines state-of-the-art Transformer and ResNeXt
modules fed into a novel attentive multimodal module to produce a combined
model trained on many tasks. We provide a thorough analysis of the components
of the model, and transfer performance when training on one, some, or all of
the tasks. Our final models provide a single system that obtains good results
on all vision and language tasks considered, and improves the state-of-the-art
in image-grounded conversational applications.
</summary>
    <author>
      <name>Da Ju</name>
    </author>
    <author>
      <name>Kurt Shuster</name>
    </author>
    <author>
      <name>Y-Lan Boureau</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12394v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12394v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00003v3</id>
    <updated>2020-01-11T14:00:55Z</updated>
    <published>2019-12-28T03:15:43Z</published>
    <title>Learning Numeral Embeddings</title>
    <summary>  Word embedding is an essential building block for deep learning methods for
natural language processing. Although word embedding has been extensively
studied over the years, the problem of how to effectively embed numerals, a
special subset of words, is still underexplored. Existing word embedding
methods do not learn numeral embeddings well because there are an infinite
number of numerals and their individual appearances in training corpora are
highly scarce. In this paper, we propose two novel numeral embedding methods
that can handle the out-of-vocabulary (OOV) problem for numerals. We first
induce a finite set of prototype numerals using either a self-organizing map or
a Gaussian mixture model. We then represent the embedding of a numeral as a
weighted average of the prototype number embeddings. Numeral embeddings
represented in this manner can be plugged into existing word embedding learning
approaches such as skip-gram for training. We evaluated our methods and showed
its effectiveness on four intrinsic and extrinsic tasks: word similarity,
embedding numeracy, numeral prediction, and sequence labeling.
</summary>
    <author>
      <name>Chengyue Jiang</name>
    </author>
    <author>
      <name>Zhonglin Nian</name>
    </author>
    <author>
      <name>Kaihao Guo</name>
    </author>
    <author>
      <name>Shanbo Chu</name>
    </author>
    <author>
      <name>Yinggong Zhao</name>
    </author>
    <author>
      <name>Libin Shen</name>
    </author>
    <author>
      <name>Kewei Tu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00003v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00003v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12380v1</id>
    <updated>2019-12-28T01:12:15Z</updated>
    <published>2019-12-28T01:12:15Z</published>
    <title>Knowledge-guided Text Structuring in Clinical Trials</title>
    <summary>  Clinical trial records are variable resources or the analysis of patients and
diseases. Information extraction from free text such as eligibility criteria
and summary of results and conclusions in clinical trials would better support
computer-based eligibility query formulation and electronic patient screening.
Previous research has focused on extracting information from eligibility
criteria, with usually a single pair of medical entity and attribute, but
seldom considering other kinds of free text with multiple entities, attributes
and relations that are more complex for parsing. In this paper, we propose a
knowledge-guided text structuring framework with an automatically generated
knowledge base as training corpus and word dependency relations as context
information to transfer free text into formal, computer-interpretable
representations. Experimental results show that our method can achieve overall
high precision and recall, demonstrating the effectiveness and efficiency of
the proposed method.
</summary>
    <author>
      <name>Yingcheng Sun</name>
    </author>
    <author>
      <name>Kenneth Loparo</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 19th Industrial Conference on Data Mining</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.12380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12362v1</id>
    <updated>2019-12-27T23:15:49Z</updated>
    <published>2019-12-27T23:15:49Z</published>
    <title>Structural characterization of musical harmonies</title>
    <summary>  Understanding the structural characteristics of harmony is essential for an
effective use of music as a communication medium. Of the three expressive axes
of music (melody, rhythm, harmony), harmony is the foundation on which the
emotional content is built, and its understanding is important in areas such as
multimedia and affective computing. The common tool for studying this kind of
structure in computing science is the formal grammar but, in the case of music,
grammars run into problems due to the ambiguous nature of some of the concepts
defined in music theory. In this paper, we consider one of such constructs:
modulation, that is, the change of key in the middle of a musical piece, an
important tool used by many authors to enhance the capacity of music to express
emotions. We develop a hybrid method in which an evidence-gathering numerical
method detects modulation and then, based on the detected tonalities, a
non-ambiguous grammar can be used for analyzing the structure of each tonal
component. Experiments with music from the XVII and XVIII centuries show that
we can detect the precise point of modulation with an error of at most two
chords in almost 97% of the cases. Finally, we show examples of complete
modulation and structural analysis of musical harmonies.
</summary>
    <author>
      <name>Maria Rojo González</name>
    </author>
    <author>
      <name>Simone Santini</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12333v1</id>
    <updated>2019-12-27T20:59:38Z</updated>
    <published>2019-12-27T20:59:38Z</published>
    <title>Encoding word order in complex embeddings</title>
    <summary>  Sequential word order is important when processing text. Currently, neural
networks (NNs) address this by modeling word position using position
embeddings. The problem is that position embeddings capture the position of
individual words, but not the ordered relationship (e.g., adjacency or
precedence) between individual word positions. We present a novel and
principled solution for modeling both the global absolute positions of words
and their order relationships. Our solution generalizes word embeddings,
previously defined as independent vectors, to continuous word functions over a
variable (position). The benefit of continuous functions over variable
positions is that word representations shift smoothly with increasing
positions. Hence, word representations in different positions can correlate
with each other in a continuous function. The general solution of these
functions is extended to complex-valued domain due to richer representations.
We extend CNN, RNN and Transformer NNs to complex-valued versions to
incorporate our complex embedding (we make all code available). Experiments on
text classification, machine translation and language modeling show gains over
both classical word embeddings and position-enriched word embeddings. To our
knowledge, this is the first work in NLP to link imaginary numbers in
complex-valued representations to concrete meanings (i.e., word order).
</summary>
    <author>
      <name>Benyou Wang</name>
    </author>
    <author>
      <name>Donghao Zhao</name>
    </author>
    <author>
      <name>Christina Lioma</name>
    </author>
    <author>
      <name>Qiuchi Li</name>
    </author>
    <author>
      <name>Peng Zhang</name>
    </author>
    <author>
      <name>Jakob Grue Simonsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures, ICLR 2020 spotlight paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12333v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12333v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12214v2</id>
    <updated>2020-01-31T09:36:49Z</updated>
    <published>2019-12-27T16:13:43Z</published>
    <title>Job Prediction: From Deep Neural Network Models to Applications</title>
    <summary>  Determining the job is suitable for a student or a person looking for work
based on their job's descriptions such as knowledge and skills that are
difficult, as well as how employers must find ways to choose the candidates
that match the job they require. In this paper, we focus on studying the job
prediction using different deep neural network models including TextCNN,
Bi-GRU-LSTM-CNN, and Bi-GRU-CNN with various pre-trained word embeddings on the
IT Job dataset. In addition, we also proposed a simple and effective ensemble
model combining different deep neural network models. The experimental results
illustrated that our proposed ensemble model achieved the highest result with
an F1 score of 72.71%. Moreover, we analyze these experimental results to have
insights about this problem to find better solutions in the future.
</summary>
    <author>
      <name>Tin Van Huynh</name>
    </author>
    <author>
      <name>Kiet Van Nguyen</name>
    </author>
    <author>
      <name>Ngan Luu-Thuy Nguyen</name>
    </author>
    <author>
      <name>Anh Gia-Tuan Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IEEE RIVF 2020 Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12214v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12214v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12068v1</id>
    <updated>2019-12-27T12:10:10Z</updated>
    <published>2019-12-27T12:10:10Z</published>
    <title>A Multi-cascaded Model with Data Augmentation for Enhanced Paraphrase
  Detection in Short Texts</title>
    <summary>  Paraphrase detection is an important task in text analytics with numerous
applications such as plagiarism detection, duplicate question identification,
and enhanced customer support helpdesks. Deep models have been proposed for
representing and classifying paraphrases. These models, however, require large
quantities of human-labeled data, which is expensive to obtain. In this work,
we present a data augmentation strategy and a multi-cascaded model for improved
paraphrase detection in short texts. Our data augmentation strategy considers
the notions of paraphrases and non-paraphrases as binary relations over the set
of texts. Subsequently, it uses graph theoretic concepts to efficiently
generate additional paraphrase and non-paraphrase pairs in a sound manner. Our
multi-cascaded model employs three supervised feature learners (cascades) based
on CNN and LSTM networks with and without soft-attention. The learned features,
together with hand-crafted linguistic features, are then forwarded to a
discriminator network for final classification. Our model is both wide and deep
and provides greater robustness across clean and noisy short texts. We evaluate
our approach on three benchmark datasets and show that it produces a comparable
or state-of-the-art performance on all three.
</summary>
    <author>
      <name>Muhammad Haroon Shakeel</name>
    </author>
    <author>
      <name>Asim Karim</name>
    </author>
    <author>
      <name>Imdadullah Khan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ipm.2020.102204</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ipm.2020.102204" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Processing &amp; Management, Volume 57, Issue 3, May 2020,
  102204</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.12068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12014v1</id>
    <updated>2019-12-27T07:46:29Z</updated>
    <published>2019-12-27T07:46:29Z</published>
    <title>Visual Agreement Regularized Training for Multi-Modal Machine
  Translation</title>
    <summary>  Multi-modal machine translation aims at translating the source sentence into
a different language in the presence of the paired image. Previous work
suggests that additional visual information only provides dispensable help to
translation, which is needed in several very special cases such as translating
ambiguous words. To make better use of visual information, this work presents
visual agreement regularized training. The proposed approach jointly trains the
source-to-target and target-to-source translation models and encourages them to
share the same focus on the visual information when generating semantically
equivalent visual words (e.g. "ball" in English and "ballon" in French).
Besides, a simple yet effective multi-head co-attention model is also
introduced to capture interactions between visual and textual features. The
results show that our approaches can outperform competitive baselines by a
large margin on the Multi30k dataset. Further analysis demonstrates that the
proposed regularized training can effectively improve the agreement of
attention on the image, leading to better use of visual information.
</summary>
    <author>
      <name>Pengcheng Yang</name>
    </author>
    <author>
      <name>Boxing Chen</name>
    </author>
    <author>
      <name>Pei Zhang</name>
    </author>
    <author>
      <name>Xu Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12010v1</id>
    <updated>2019-12-27T07:28:11Z</updated>
    <published>2019-12-27T07:28:11Z</published>
    <title>Synthesising Expressiveness in Peking Opera via Duration Informed
  Attention Network</title>
    <summary>  This paper presents a method that generates expressive singing voice of
Peking opera. The synthesis of expressive opera singing usually requires pitch
contours to be extracted as the training data, which relies on techniques and
is not able to be manually labeled. With the Duration Informed Attention
Network (DurIAN), this paper makes use of musical note instead of pitch
contours for expressive opera singing synthesis. The proposed method enables
human annotation being combined with automatic extracted features to be used as
training data thus the proposed method gives extra flexibility in data
collection for Peking opera singing synthesis. Comparing with the expressive
singing voice of Peking opera synthesised by pitch contour based system, the
proposed musical note based system produces comparable singing voice in Peking
opera with expressiveness in various aspects.
</summary>
    <author>
      <name>Yusong Wu</name>
    </author>
    <author>
      <name>Shengchen Li</name>
    </author>
    <author>
      <name>Chengzhu Yu</name>
    </author>
    <author>
      <name>Heng Lu</name>
    </author>
    <author>
      <name>Chao Weng</name>
    </author>
    <author>
      <name>Liqiang Zhang</name>
    </author>
    <author>
      <name>Dong Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1912.12010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11980v1</id>
    <updated>2019-12-27T04:14:06Z</updated>
    <published>2019-12-27T04:14:06Z</published>
    <title>Explicit Sentence Compression for Neural Machine Translation</title>
    <summary>  State-of-the-art Transformer-based neural machine translation (NMT) systems
still follow a standard encoder-decoder framework, in which source sentence
representation can be well done by an encoder with self-attention mechanism.
Though Transformer-based encoder may effectively capture general information in
its resulting source sentence representation, the backbone information, which
stands for the gist of a sentence, is not specifically focused on. In this
paper, we propose an explicit sentence compression method to enhance the source
sentence representation for NMT. In practice, an explicit sentence compression
goal used to learn the backbone information in a sentence. We propose three
ways, including backbone source-side fusion, target-side fusion, and both-side
fusion, to integrate the compressed sentence into NMT. Our empirical tests on
the WMT English-to-French and English-to-German translation tasks show that the
proposed sentence compression method significantly improves the translation
performances over strong baselines.
</summary>
    <author>
      <name>Zuchao Li</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
    <author>
      <name>Kehai Chen</name>
    </author>
    <author>
      <name>Masao Utiyama</name>
    </author>
    <author>
      <name>Eiichiro Sumita</name>
    </author>
    <author>
      <name>Zhuosheng Zhang</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working in progress, part of this work is accepted in AAAI-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11975v1</id>
    <updated>2019-12-27T03:40:31Z</updated>
    <published>2019-12-27T03:40:31Z</published>
    <title>Clinical XLNet: Modeling Sequential Clinical Notes and Predicting
  Prolonged Mechanical Ventilation</title>
    <summary>  Clinical notes contain rich data, which is unexploited in predictive modeling
compared to structured data. In this work, we developed a new text
representation Clinical XLNet for clinical notes which also leverages the
temporal information of the sequence of the notes. We evaluated our models on
prolonged mechanical ventilation prediction problem and our experiments
demonstrated that Clinical XLNet outperforms the best baselines consistently.
</summary>
    <author>
      <name>Kexin Huang</name>
    </author>
    <author>
      <name>Abhishek Singh</name>
    </author>
    <author>
      <name>Sitong Chen</name>
    </author>
    <author>
      <name>Edward T. Moseley</name>
    </author>
    <author>
      <name>Chih-ying Deng</name>
    </author>
    <author>
      <name>Naomi George</name>
    </author>
    <author>
      <name>Charlotta Lindvall</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11973v2</id>
    <updated>2020-01-23T12:55:41Z</updated>
    <published>2019-12-27T03:20:48Z</published>
    <title>Language Independent Sentiment Analysis</title>
    <summary>  Social media platforms and online forums generate rapid and increasing amount
of textual data. Businesses, government agencies, and media organizations seek
to perform sentiment analysis on this rich text data. The results of these
analytics are used for adapting marketing strategies, customizing products,
security and various other decision makings. Sentiment analysis has been
extensively studied and various methods have been developed for it with great
success. These methods, however apply to texts written in a specific language.
This limits applicability to a limited demographic and a specific geographic
region. In this paper we propose a general approach for sentiment analysis on
data containing texts from multiple languages. This enables all the
applications to utilize the results of sentiment analysis in a language
oblivious or language-independent fashion.
</summary>
    <author>
      <name>Muhammad Haroon Shakeel</name>
    </author>
    <author>
      <name>Turki Alghamidi</name>
    </author>
    <author>
      <name>Safi Faizullah</name>
    </author>
    <author>
      <name>Imdadullah Khan</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11973v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11973v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11959v2</id>
    <updated>2019-12-30T09:01:18Z</updated>
    <published>2019-12-27T02:01:13Z</published>
    <title>Is Attention All What You Need? -- An Empirical Investigation on
  Convolution-Based Active Memory and Self-Attention</title>
    <summary>  The key to a Transformer model is the self-attention mechanism, which allows
the model to analyze an entire sequence in a computationally efficient manner.
Recent work has suggested the possibility that general attention mechanisms
used by RNNs could be replaced by active-memory mechanisms. In this work, we
evaluate whether various active-memory mechanisms could replace self-attention
in a Transformer. Our experiments suggest that active-memory alone achieves
comparable results to the self-attention mechanism for language modelling, but
optimal results are mostly achieved by using both active-memory and
self-attention mechanisms together. We also note that, for some specific
algorithmic tasks, active-memory mechanisms alone outperform both
self-attention and a combination of the two.
</summary>
    <author>
      <name>Thomas Dowdell</name>
    </author>
    <author>
      <name>Hongyu Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11959v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11959v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13161v1</id>
    <updated>2019-12-26T15:41:35Z</updated>
    <published>2019-12-26T15:41:35Z</published>
    <title>Amharic-Arabic Neural Machine Translation</title>
    <summary>  Many automatic translation works have been addressed between major European
language pairs, by taking advantage of large scale parallel corpora, but very
few research works are conducted on the Amharic-Arabic language pair due to its
parallel data scarcity. Two Long Short-Term Memory (LSTM) and Gated Recurrent
Units (GRU) based Neural Machine Translation (NMT) models are developed using
Attention-based Encoder-Decoder architecture which is adapted from the
open-source OpenNMT system. In order to perform the experiment, a small
parallel Quranic text corpus is constructed by modifying the existing
monolingual Arabic text and its equivalent translation of Amharic language text
corpora available on Tanzile. LSTM and GRU based NMT models and Google
Translation system are compared and found that LSTM based OpenNMT outperforms
GRU based OpenNMT and Google Translation system, with a BLEU score of 12%, 11%,
and 6% respectively.
</summary>
    <author>
      <name>Ibrahim Gashaw</name>
    </author>
    <author>
      <name>H L Shashirekha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13362v1</id>
    <updated>2019-12-26T08:38:49Z</updated>
    <published>2019-12-26T08:38:49Z</published>
    <title>Text Classification for Azerbaijani Language Using Machine Learning and
  Embedding</title>
    <summary>  Text classification systems will help to solve the text clustering problem in
the Azerbaijani language. There are some text-classification applications for
foreign languages, but we tried to build a newly developed system to solve this
problem for the Azerbaijani language. Firstly, we tried to find out potential
practice areas. The system will be useful in a lot of areas. It will be mostly
used in news feed categorization. News websites can automatically categorize
news into classes such as sports, business, education, science, etc. The system
is also used in sentiment analysis for product reviews. For example, the
company shares a photo of a new product on Facebook and the company receives a
thousand comments for new products. The systems classify the comments into
categories like positive or negative. The system can also be applied in
recommended systems, spam filtering, etc. Various machine learning techniques
such as Naive Bayes, SVM, Decision Trees have been devised to solve the text
classification problem in Azerbaijani language.
</summary>
    <author>
      <name>Umid Suleymanov</name>
    </author>
    <author>
      <name>Behnam Kiani Kalejahi</name>
    </author>
    <author>
      <name>Elkhan Amrahov</name>
    </author>
    <author>
      <name>Rashid Badirkhanli</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11739v2</id>
    <updated>2020-01-14T03:16:24Z</updated>
    <published>2019-12-26T01:12:31Z</published>
    <title>Coursera Corpus Mining and Multistage Fine-Tuning for Improving Lectures
  Translation</title>
    <summary>  Lectures translation is a case of spoken language translation and there is a
lack of publicly available parallel corpora for this purpose. To address this,
we examine a language independent framework for parallel corpus mining which is
a quick and effective way to mine a parallel corpus from publicly available
lectures at Coursera. Our approach determines sentence alignments, relying on
machine translation and cosine similarity over continuous-space sentence
representations. We also show how to use the resulting corpora in a multistage
fine-tuning based domain adaptation for high-quality lectures translation. For
Japanese--English lectures translation, we extracted parallel data of
approximately 40,000 lines and created development and test sets through manual
filtering for benchmarking translation performance. We demonstrate that the
mined corpus greatly enhances the quality of translation when used in
conjunction with out-of-domain parallel corpora via multistage training. This
paper also suggests some guidelines to gather and clean corpora, mine parallel
sentences, address noise in the mined data, and create high-quality evaluation
splits. For the sake of reproducibility, we will release our code for parallel
data creation.
</summary>
    <author>
      <name>Haiyue Song</name>
    </author>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Atsushi Fujita</name>
    </author>
    <author>
      <name>Sadao Kurohashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, 9 tables, under review by LREC2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11739v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11739v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11720v1</id>
    <updated>2019-12-25T22:01:59Z</updated>
    <published>2019-12-25T22:01:59Z</published>
    <title>Convolutional Quantum-Like Language Model with Mutual-Attention for
  Product Rating Prediction</title>
    <summary>  Recommender systems are designed to help mitigate information overload users
experience during online shopping. Recent work explores neural language models
to learn user and item representations from user reviews and combines such
representations with rating information. Most existing convolutional-based
neural models take pooling immediately after convolution and loses the
interaction information between the latent dimension of convolutional feature
vectors along the way. Moreover, these models usually take all feature vectors
at higher levels as equal and do not take into consideration that some features
are more relevant to this specific user-item context. To bridge these gaps,
this paper proposes a convolutional quantum-like language model with
mutual-attention for rating prediction (ConQAR). By introducing a quantum-like
density matrix layer, interactions between latent dimensions of convolutional
feature vectors are well captured. With the attention weights learned from the
mutual-attention layer, final representations of a user and an item absorb
information from both itself and its counterparts for making rating prediction.
Experiments on two large datasets show that our model outperforms multiple
state-of-the-art CNN-based models. We also perform an ablation test to analyze
the independent effects of the two components of our model. Moreover, we
conduct a case study and present visualizations of the quantum probabilistic
distributions in one user and one item review document to show that the learned
distributions capture meaningful information about this user and item, and can
be potentially used as textual profiling of the user and item.
</summary>
    <author>
      <name>Qing Ping</name>
    </author>
    <author>
      <name>Chaomei Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at MAISON workshop at ICTIR 19'</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11701v1</id>
    <updated>2019-12-25T17:48:09Z</updated>
    <published>2019-12-25T17:48:09Z</published>
    <title>Hybrid MemNet for Extractive Summarization</title>
    <summary>  Extractive text summarization has been an extensive research problem in the
field of natural language understanding. While the conventional approaches rely
mostly on manually compiled features to generate the summary, few attempts have
been made in developing data-driven systems for extractive summarization. To
this end, we present a fully data-driven end-to-end deep network which we call
as Hybrid MemNet for single document summarization task. The network learns the
continuous unified representation of a document before generating its summary.
It jointly captures local and global sentential information along with the
notion of summary worthy sentences. Experimental results on two different
corpora confirm that our model shows significant performance gains compared
with the state-of-the-art baselines.
</summary>
    <author>
      <name>Abhishek Kumar Singh</name>
    </author>
    <author>
      <name>Manish Gupta</name>
    </author>
    <author>
      <name>Vasudeva Varma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3132847.3133127</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3132847.3133127" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in CIKM '17 Proceedings of the 2017 ACM on Conference on
  Information and Knowledge Management</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 2017 ACM on Conference on Information and
  Knowledge Management (CIKM '17). ACM, New York, NY, USA, pages 2303-2306</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.11701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11688v1</id>
    <updated>2019-12-25T16:25:29Z</updated>
    <published>2019-12-25T16:25:29Z</published>
    <title>Unity in Diversity: Learning Distributed Heterogeneous Sentence
  Representation for Extractive Summarization</title>
    <summary>  Automated multi-document extractive text summarization is a widely studied
research problem in the field of natural language understanding. Such
extractive mechanisms compute in some form the worthiness of a sentence to be
included into the summary. While the conventional approaches rely on human
crafted document-independent features to generate a summary, we develop a
data-driven novel summary system called HNet, which exploits the various
semantic and compositional aspects latent in a sentence to capture document
independent features. The network learns sentence representation in a way that,
salient sentences are closer in the vector space than non-salient sentences.
This semantic and compositional feature vector is then concatenated with the
document-dependent features for sentence ranking. Experiments on the DUC
benchmark datasets (DUC-2001, DUC-2002 and DUC-2004) indicate that our model
shows significant performance gain of around 1.5-2 points in terms of ROUGE
score compared with the state-of-the-art baselines.
</summary>
    <author>
      <name>Abhishek Kumar Singh</name>
    </author>
    <author>
      <name>Manish Gupta</name>
    </author>
    <author>
      <name>Vasudeva Varma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in AAAI Conference on Artificial Intelligence, 2018.
  Retrieved from
  https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16977</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11668v1</id>
    <updated>2019-12-25T13:43:44Z</updated>
    <published>2019-12-25T13:43:44Z</published>
    <title>Learning to Answer Ambiguous Questions with Knowledge Graph</title>
    <summary>  In the task of factoid question answering over knowledge base, many questions
have more than one plausible interpretation. Previous works on SimpleQuestions
assume only one interpretation as the ground truth for each question, so they
lack the ability to answer ambiguous questions correctly. In this paper, we
present a new way to utilize the dataset that takes into account the existence
of ambiguous questions. Then we introduce a simple and effective model which
combines local knowledge subgraph with attention mechanism. Our experimental
results show that our approach achieves outstanding performance in this task.
</summary>
    <author>
      <name>Yikai Zhu</name>
    </author>
    <author>
      <name>Jianhao Shen</name>
    </author>
    <author>
      <name>Ming Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11637v1</id>
    <updated>2019-12-25T10:59:31Z</updated>
    <published>2019-12-25T10:59:31Z</published>
    <title>Explicit Sparse Transformer: Concentrated Attention Through Explicit
  Selection</title>
    <summary>  Self-attention based Transformer has demonstrated the state-of-the-art
performances in a number of natural language processing tasks. Self-attention
is able to model long-term dependencies, but it may suffer from the extraction
of irrelevant information in the context. To tackle the problem, we propose a
novel model called \textbf{Explicit Sparse Transformer}. Explicit Sparse
Transformer is able to improve the concentration of attention on the global
context through an explicit selection of the most relevant segments. Extensive
experimental results on a series of natural language processing and computer
vision tasks, including neural machine translation, image captioning, and
language modeling, all demonstrate the advantages of Explicit Sparse
Transformer in model performance. We also show that our proposed sparse
attention method achieves comparable or better results than the previous sparse
attention method, but significantly reduces training and testing time. For
example, the inference speed is twice that of sparsemax in Transformer model.
Code will be available at
\url{https://github.com/lancopku/Explicit-Sparse-Transformer}
</summary>
    <author>
      <name>Guangxiang Zhao</name>
    </author>
    <author>
      <name>Junyang Lin</name>
    </author>
    <author>
      <name>Zhiyuan Zhang</name>
    </author>
    <author>
      <name>Xuancheng Ren</name>
    </author>
    <author>
      <name>Qi Su</name>
    </author>
    <author>
      <name>Xu Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11625v1</id>
    <updated>2019-12-25T08:50:45Z</updated>
    <published>2019-12-25T08:50:45Z</published>
    <title>A Study of Multilingual Neural Machine Translation</title>
    <summary>  Multilingual neural machine translation (NMT) has recently been investigated
from different aspects (e.g., pivot translation, zero-shot translation,
fine-tuning, or training from scratch) and in different settings (e.g., rich
resource and low resource, one-to-many, and many-to-one translation). This
paper concentrates on a deep understanding of multilingual NMT and conducts a
comprehensive study on a multilingual dataset with more than 20 languages. Our
results show that (1) low-resource language pairs benefit much from
multilingual training, while rich-resource language pairs may get hurt under
limited model capacity and training with similar languages benefits more than
dissimilar languages; (2) fine-tuning performs better than training from
scratch in the one-to-many setting while training from scratch performs better
in the many-to-one setting; (3) the bottom layers of the encoder and top layers
of the decoder capture more language-specific information, and just fine-tuning
these parts can achieve good accuracy for low-resource language pairs; (4)
direct translation is better than pivot translation when the source language is
similar to the target language (e.g., in the same language branch), even when
the size of direct training data is much smaller; (5) given a fixed training
data budget, it is better to introduce more languages into multilingual
training for zero-shot translation.
</summary>
    <author>
      <name>Xu Tan</name>
    </author>
    <author>
      <name>Yichong Leng</name>
    </author>
    <author>
      <name>Jiale Chen</name>
    </author>
    <author>
      <name>Yi Ren</name>
    </author>
    <author>
      <name>Tao Qin</name>
    </author>
    <author>
      <name>Tie-Yan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11612v1</id>
    <updated>2019-12-25T07:31:44Z</updated>
    <published>2019-12-25T07:31:44Z</published>
    <title>N-gram Statistical Stemmer for Bangla Corpus</title>
    <summary>  Stemming is a process that can be utilized to trim inflected words to stem or
root form. It is useful for enhancing the retrieval effectiveness, especially
for text search in order to solve the mismatch problems. Previous research on
Bangla stemming mostly relied on eliminating multiple suffixes from a solitary
word through a recursive rule based procedure to recover progressively
applicable relative root. Our proposed system has enhanced the aforementioned
exploration by actualizing one of the stemming algorithms called N-gram
stemming. By utilizing an affiliation measure called dice coefficient, related
sets of words are clustered depending on their character structure. The
smallest word in one cluster may be considered as the stem. We additionally
analyzed Affinity Propagation clustering algorithms with coefficient similarity
as well as with median similarity. Our result indicates N-gram stemming
techniques to be effective in general which gave us around 87% accurate
clusters.
</summary>
    <author>
      <name>Rabeya Sadia</name>
    </author>
    <author>
      <name>Md Ataur Rahman</name>
    </author>
    <author>
      <name>Md Hanif Seddiqui</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11602v2</id>
    <updated>2020-01-07T04:04:03Z</updated>
    <published>2019-12-25T06:05:44Z</published>
    <title>Make Lead Bias in Your Favor: A Simple and Effective Method for News
  Summarization</title>
    <summary>  Lead bias is a common phenomenon in news summarization, where early parts of
an article often contain the most salient information. While many algorithms
exploit this fact in summary generation, it has a detrimental effect on
teaching the model to discriminate and extract important information. We
propose that the lead bias can be leveraged in a simple and effective way in
our favor to pretrain abstractive news summarization models on large-scale
unlabeled corpus: predicting the leading sentences using the rest of an
article. Via careful data cleaning and filtering, our transformer-based
pretrained model without any finetuning achieves remarkable results over
various news summarization tasks. With further finetuning, our model
outperforms many competitive baseline models. Human evaluations further show
the effectiveness of our method.
</summary>
    <author>
      <name>Chenguang Zhu</name>
    </author>
    <author>
      <name>Ziyi Yang</name>
    </author>
    <author>
      <name>Robert Gmyr</name>
    </author>
    <author>
      <name>Michael Zeng</name>
    </author>
    <author>
      <name>Xuedong Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11602v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11602v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11600v1</id>
    <updated>2019-12-25T05:59:29Z</updated>
    <published>2019-12-25T05:59:29Z</published>
    <title>A statistical test for correspondence of texts to the Zipf-Mandelbrot
  law</title>
    <summary>  We analyse correspondence of a text to a simple probabilistic model. The
model assumes that the words are selected independently from an infinite
dictionary. The probability distribution correspond to the Zipf---Mandelbrot
law. We count sequentially the numbers of different words in the text and get
the process of the numbers of different words. Then we estimate
Zipf---Mandelbrot law parameters using the same sequence and construct an
estimate of the expectation of the number of different words in the text. Then
we subtract the corresponding values of the estimate from the sequence and
normalize along the coordinate axes, obtaining a random process on a segment
from 0 to 1. We prove that this process (the empirical text bridge) converges
weakly in the uniform metric on $C (0,1)$ to a centered Gaussian process with
continuous a.s. paths. We develop and implement an algorithm for approximate
calculation of eigenvalues of the covariance function of the limit Gaussian
process, and then an algorithm for calculating the probability distribution of
the integral of the square of this process. We use the algorithm to analyze
uniformity of texts in English, French, Russian and Chinese.
</summary>
    <author>
      <name>Anik Chakrabarty</name>
    </author>
    <author>
      <name>Mikhail Chebunin</name>
    </author>
    <author>
      <name>Artyom Kovalevskii</name>
    </author>
    <author>
      <name>Ilya Pupyshev</name>
    </author>
    <author>
      <name>Natalia Zakrevskaya</name>
    </author>
    <author>
      <name>Qianqian Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11585v1</id>
    <updated>2019-12-25T03:44:31Z</updated>
    <published>2019-12-25T03:44:31Z</published>
    <title>THUEE system description for NIST 2019 SRE CTS Challenge</title>
    <summary>  This paper describes the systems submitted by the department of electronic
engineering, institute of microelectronics of Tsinghua university and
TsingMicro Co. Ltd. (THUEE) to the NIST 2019 speaker recognition evaluation CTS
challenge. Six subsystems, including etdnn/ams, ftdnn/as, eftdnn/ams, resnet,
multitask and c-vector are developed in this evaluation.
</summary>
    <author>
      <name>Yi Liu</name>
    </author>
    <author>
      <name>Tianyu Liang</name>
    </author>
    <author>
      <name>Can Xu</name>
    </author>
    <author>
      <name>Xianwei Zhang</name>
    </author>
    <author>
      <name>Xianhong Chen</name>
    </author>
    <author>
      <name>Wei-Qiang Zhang</name>
    </author>
    <author>
      <name>Liang He</name>
    </author>
    <author>
      <name>Dandan song</name>
    </author>
    <author>
      <name>Ruyun Li</name>
    </author>
    <author>
      <name>Yangcheng Wu</name>
    </author>
    <author>
      <name>Peng Ouyang</name>
    </author>
    <author>
      <name>Shouyi Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the system description of THUEE submitted to NIST SRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00051v1</id>
    <updated>2019-12-24T17:09:54Z</updated>
    <published>2019-12-24T17:09:54Z</published>
    <title>Simultaneous Identification of Tweet Purpose and Position</title>
    <summary>  Tweet classification has attracted considerable attention recently. Most of
the existing work on tweet classification focuses on topic classification,
which classifies tweets into several predefined categories, and sentiment
classification, which classifies tweets into positive, negative and neutral.
Since tweets are different from conventional text in that they generally are of
limited length and contain informal, irregular or new words, so it is difficult
to determine user intention to publish a tweet and user attitude towards
certain topic. In this paper, we aim to simultaneously classify tweet purpose,
i.e., the intention for user to publish a tweet, and position, i.e.,
supporting, opposing or being neutral to a given topic. By transforming this
problem to a multi-label classification problem, a multi-label classification
method with post-processing is proposed. Experiments on real-world data sets
demonstrate the effectiveness of this method and the results outperform the
individual classification methods.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Yulong Pei</name>
    </author>
    <author>
      <name>Katia Sycara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11270v4</id>
    <updated>2020-02-12T18:32:14Z</updated>
    <published>2019-12-24T09:53:27Z</published>
    <title>FALCON 2.0: An Entity and Relation Linking Tool over Wikidata</title>
    <summary>  Natural Language Processing (NLP) tools and frameworks have significantly
contributed with solutions to the problems of extracting entities and relations
and linking them to the related knowledge graphs. Albeit effective, the
majority of existing tools are available for only one knowledge graph. In this
paper, we present Falcon 2.0, a rule-based tool capable of accurately mapping
entities and relations in short texts to resources in both DBpedia and Wikidata
following the same approach in both cases. The input of Falcon 2.0 is a short
natural language text in the English language. Falcon 2.0 resorts to
fundamental principles of the English morphology (e.g., N-Gram tiling and
N-Gram splitting) and background knowledge of labels alignments obtained from
studied knowledge graph to return as an output; the resulting entity and
relation resources are either in the DBpedia or Wikidata knowledge graphs. We
have empirically studied the impact using only Wikidata on Falcon 2.0, and
observed it is knowledge graph agnostic, i.e., Falcon 2.0 performance and
behavior are not affected by the knowledge graph used as background knowledge.
Falcon 2.0 is public and can be reused by the community. Additionally, Falcon
2.0 and its background knowledge bases are available as resources at
https://labs.tib.eu/falcon/falcon2/.
</summary>
    <author>
      <name>Ahmad Sakor</name>
    </author>
    <author>
      <name>Kuldeep Singh</name>
    </author>
    <author>
      <name>Anery Patel</name>
    </author>
    <author>
      <name>Maria-Esther Vidal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11270v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11270v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11046v1</id>
    <updated>2019-12-24T03:34:58Z</updated>
    <published>2019-12-24T03:34:58Z</published>
    <title>Improving Abstractive Text Summarization with History Aggregation</title>
    <summary>  Recent neural sequence to sequence models have provided feasible solutions
for abstractive summarization. However, such models are still hard to tackle
long text dependency in the summarization task. A high-quality summarization
system usually depends on strong encoder which can refine important information
from long input texts so that the decoder can generate salient summaries from
the encoder's memory. In this paper, we propose an aggregation mechanism based
on the Transformer model to address the challenge of long text representation.
Our model can review history information to make encoder hold more memory
capacity. Empirically, we apply our aggregation mechanism to the Transformer
model and experiment on CNN/DailyMail dataset to achieve higher quality
summaries compared to several strong baseline models on the ROUGE metrics.
</summary>
    <author>
      <name>Pengcheng Liao</name>
    </author>
    <author>
      <name>Chuang Zhang</name>
    </author>
    <author>
      <name>Xiaojun Chen</name>
    </author>
    <author>
      <name>Xiaofei Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13413v1</id>
    <updated>2019-12-23T18:01:32Z</updated>
    <published>2019-12-23T18:01:32Z</published>
    <title>Semantics- and Syntax-related Subvectors in the Skip-gram Embeddings</title>
    <summary>  We show that the skip-gram embedding of any word can be decomposed into two
subvectors which roughly correspond to semantic and syntactic roles of the
word.
</summary>
    <author>
      <name>Maxat Tezekbayev</name>
    </author>
    <author>
      <name>Zhenisbek Assylbekov</name>
    </author>
    <author>
      <name>Rustem Takhanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, Student Abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13413v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13413v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10915v1</id>
    <updated>2019-12-23T15:25:45Z</updated>
    <published>2019-12-23T15:25:45Z</published>
    <title>Probing the phonetic and phonological knowledge of tones in Mandarin TTS
  models</title>
    <summary>  This study probes the phonetic and phonological knowledge of lexical tones in
TTS models through two experiments. Controlled stimuli for testing tonal
coarticulation and tone sandhi in Mandarin were fed into Tacotron 2 and
WaveGlow to generate speech samples, which were subject to acoustic analysis
and human evaluation. Results show that both baseline Tacotron 2 and Tacotron 2
with BERT embeddings capture the surface tonal coarticulation patterns well but
fail to consistently apply the Tone-3 sandhi rule to novel sentences.
Incorporating pre-trained BERT embeddings into Tacotron 2 improves the
naturalness and prosody performance, and yields better generalization of Tone-3
sandhi rules to novel complex sentences, although the overall accuracy for
Tone-3 sandhi was still low. Given that TTS models do capture some linguistic
phenomena, it is argued that they can be used to generate and validate certain
linguistic hypotheses. On the other hand, it is also suggested that
linguistically informed stimuli should be included in the training and the
evaluation of TTS models.
</summary>
    <author>
      <name>Jian Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Speech Prosody 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10846v1</id>
    <updated>2019-12-23T14:46:46Z</updated>
    <published>2019-12-23T14:46:46Z</published>
    <title>BioConceptVec: creating and evaluating literature-based biomedical
  concept embeddings on a large scale</title>
    <summary>  Capturing the semantics of related biological concepts, such as genes and
mutations, is of significant importance to many research tasks in computational
biology such as protein-protein interaction detection, gene-drug association
prediction, and biomedical literature-based discovery. Here, we propose to
leverage state-of-the-art text mining tools and machine learning models to
learn the semantics via vector representations (aka. embeddings) of over
400,000 biological concepts mentioned in the entire PubMed abstracts. Our
learned embeddings, namely BioConceptVec, can capture related concepts based on
their surrounding contextual information in the literature, which is beyond
exact term match or co-occurrence-based methods. BioConceptVec has been
thoroughly evaluated in multiple bioinformatics tasks consisting of over 25
million instances from nine different biological datasets. The evaluation
results demonstrate that BioConceptVec has better performance than existing
methods in all tasks. Finally, BioConceptVec is made freely available to the
research community and general public via
https://github.com/ncbi-nlp/BioConceptVec.
</summary>
    <author>
      <name>Qingyu Chen</name>
    </author>
    <author>
      <name>Kyubum Lee</name>
    </author>
    <author>
      <name>Shankai Yan</name>
    </author>
    <author>
      <name>Sun Kim</name>
    </author>
    <author>
      <name>Chih-Hsuan Wei</name>
    </author>
    <author>
      <name>Zhiyong Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 6 figures, 7 tables, accepted by PLOS Computational Biology</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10785v2</id>
    <updated>2020-01-20T01:47:29Z</updated>
    <published>2019-12-23T13:14:40Z</published>
    <title>Discovering Protagonist of Sentiment with Aspect Reconstructed Capsule
  Network</title>
    <summary>  Most recent existing aspect-term level sentiment analysis (ATSA) approaches
combined various neural network models with delicately carved attention
mechanisms built upon given aspect and context to generate refined sentence
representations for better predictions. In these methods, aspect terms are
always provided in both training and testing process which may degrade
aspect-level analysis into sentence-level prediction. However, the annotated
aspect term might be unavailable in real-world scenarios which may challenge
the applicability of the existing methods. In this paper, we aim to improve
ATSA by discovering the potential aspect terms of the predicted sentiment
polarity when the aspect terms of a test sentence are unknown. We access this
goal by proposing a capsule network based model named CAPSAR. In CAPSAR,
sentiment categories are denoted by capsules and aspect term information is
injected into sentiment capsules through a sentiment-aspect reconstruction
procedure during the training. As a result, coherent patterns between aspects
and sentimental expressions are encapsulated by these sentiment capsules.
Experiments on three widely used benchmarks demonstrate these patterns have
potential in exploring aspect terms from test sentence when only feeding the
sentence to the model. Meanwhile, the proposed CAPSAR can clearly outperform
SOTA methods in standard ATSA tasks.
</summary>
    <author>
      <name>Chi Xu</name>
    </author>
    <author>
      <name>Hao Feng</name>
    </author>
    <author>
      <name>Guoxin Yu</name>
    </author>
    <author>
      <name>Min Yang</name>
    </author>
    <author>
      <name>Xiting Wang</name>
    </author>
    <author>
      <name>Xiang Ao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7pages, 3figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10785v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10785v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10729v1</id>
    <updated>2019-12-23T10:51:58Z</updated>
    <published>2019-12-23T10:51:58Z</published>
    <title>TextNAS: A Neural Architecture Search Space tailored for Text
  Representation</title>
    <summary>  Learning text representation is crucial for text classification and other
language related tasks. There are a diverse set of text representation networks
in the literature, and how to find the optimal one is a non-trivial problem.
Recently, the emerging Neural Architecture Search (NAS) techniques have
demonstrated good potential to solve the problem. Nevertheless, most of the
existing works of NAS focus on the search algorithms and pay little attention
to the search space. In this paper, we argue that the search space is also an
important human prior to the success of NAS in different applications. Thus, we
propose a novel search space tailored for text representation. Through
automatic search, the discovered network architecture outperforms
state-of-the-art models on various public datasets on text classification and
natural language inference tasks. Furthermore, some of the design principles
found in the automatic network agree well with human intuition.
</summary>
    <author>
      <name>Yujing Wang</name>
    </author>
    <author>
      <name>Yaming Yang</name>
    </author>
    <author>
      <name>Yiren Chen</name>
    </author>
    <author>
      <name>Jing Bai</name>
    </author>
    <author>
      <name>Ce Zhang</name>
    </author>
    <author>
      <name>Guinan Su</name>
    </author>
    <author>
      <name>Xiaoyu Kou</name>
    </author>
    <author>
      <name>Yunhai Tong</name>
    </author>
    <author>
      <name>Mao Yang</name>
    </author>
    <author>
      <name>Lidong Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10616v2</id>
    <updated>2020-01-21T06:48:40Z</updated>
    <published>2019-12-23T04:38:00Z</published>
    <title>Siamese Networks for Large-Scale Author Identification</title>
    <summary>  Authorship attribution is the process of identifying the author of a text.
Classification-based approaches work well for small numbers of candidate
authors, but only similarity-based methods are applicable for larger numbers of
authors or for authors beyond the training set. While deep learning methods
have been applied to classification-based approaches, applications to
similarity-based applications have been limited, and most similarity-based
methods only embody static notions of similarity. Siamese networks have been
used to develop learned notions of similarity in one-shot image tasks, and also
for tasks of mostly semantic relatedness in NLP. We examine their application
to the stylistic task of authorship attribution on datasets with large numbers
of authors, looking at multiple energy functions and neural network
architectures, and show that they can substantially outperform both
classification- and existing similarity-based approaches. We also find an
unexpected relationship between choice of energy function and number of
authors, in terms of performance.
</summary>
    <author>
      <name>Chakaveh Saedi</name>
    </author>
    <author>
      <name>Mark Dras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10616v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10616v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10604v1</id>
    <updated>2019-12-23T03:34:13Z</updated>
    <published>2019-12-23T03:34:13Z</published>
    <title>Combining Context and Knowledge Representations for Chemical-Disease
  Relation Extraction</title>
    <summary>  Automatically extracting the relationships between chemicals and diseases is
significantly important to various areas of biomedical research and health
care. Biomedical experts have built many large-scale knowledge bases (KBs) to
advance the development of biomedical research. KBs contain huge amounts of
structured information about entities and relationships, therefore plays a
pivotal role in chemical-disease relation (CDR) extraction. However, previous
researches pay less attention to the prior knowledge existing in KBs. This
paper proposes a neural network-based attention model (NAM) for CDR extraction,
which makes full use of context information in documents and prior knowledge in
KBs. For a pair of entities in a document, an attention mechanism is employed
to select important context words with respect to the relation representations
learned from KBs. Experiments on the BioCreative V CDR dataset show that
combining context and knowledge representations through the attention
mechanism, could significantly improve the CDR extraction performance while
achieve comparable results with state-of-the-art systems.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Yunlong Yang</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Zhuang Liu</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Yingyu Lin</name>
    </author>
    <author>
      <name>Degen Huang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCBB.2018.2838661</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCBB.2018.2838661" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on IEEE/ACM Transactions on Computational Biology and
  Bioinformatics, 11 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE/ACM TCBB,2018,16(6):1879-1889</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10590v1</id>
    <updated>2019-12-23T02:28:10Z</updated>
    <published>2019-12-23T02:28:10Z</published>
    <title>Knowledge-guided Convolutional Networks for Chemical-Disease Relation
  Extraction</title>
    <summary>  Background: Automatic extraction of chemical-disease relations (CDR) from
unstructured text is of essential importance for disease treatment and drug
development. Meanwhile, biomedical experts have built many highly-structured
knowledge bases (KBs), which contain prior knowledge about chemicals and
diseases. Prior knowledge provides strong support for CDR extraction. How to
make full use of it is worth studying. Results: This paper proposes a novel
model called "Knowledge-guided Convolutional Networks (KCN)" to leverage prior
knowledge for CDR extraction. The proposed model first learns knowledge
representations including entity embeddings and relation embeddings from KBs.
Then, entity embeddings are used to control the propagation of context features
towards a chemical-disease pair with gated convolutions. After that, relation
embeddings are employed to further capture the weighted context features by a
shared attention pooling. Finally, the weighted context features containing
additional knowledge information are used for CDR extraction. Experiments on
the BioCreative V CDR dataset show that the proposed KCN achieves 71.28%
F1-score, which outperforms most of the state-of-the-art systems. Conclusions:
This paper proposes a novel CDR extraction model KCN to make full use of prior
knowledge. Experimental results demonstrate that KCN could effectively
integrate prior knowledge and contexts for the performance improvement.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Zhuang Liu</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Yingyu Lin</name>
    </author>
    <author>
      <name>Lei Du</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/s12859-019-2873-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/s12859-019-2873-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on BMC Bioinformatics, 16 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">BMC Bioinformatics, 2019, 20(1):260</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10554v2</id>
    <updated>2020-01-31T15:41:03Z</updated>
    <published>2019-12-22T22:39:04Z</published>
    <title>Harnessing Evolution of Multi-Turn Conversations for Effective Answer
  Retrieval</title>
    <summary>  With the improvements in speech recognition and voice generation technologies
over the last years, a lot of companies have sought to develop conversation
understanding systems that run on mobile phones or smart home devices through
natural language interfaces. Conversational assistants, such as Google
Assistant and Microsoft Cortana, can help users to complete various types of
tasks. This requires an accurate understanding of the user's information need
as the conversation evolves into multiple turns. Finding relevant context in a
conversation's history is challenging because of the complexity of natural
language and the evolution of a user's information need. In this work, we
present an extensive analysis of language, relevance, dependency of user
utterances in a multi-turn information-seeking conversation. To this aim, we
have annotated relevant utterances in the conversations released by the TREC
CaST 2019 track. The annotation labels determine which of the previous
utterances in a conversation can be used to improve the current one.
Furthermore, we propose a neural utterance relevance model based on BERT
fine-tuning, outperforming competitive baselines. We study and compare the
performance of multiple retrieval models, utilizing different strategies to
incorporate the user's context. The experimental results on both classification
and retrieval tasks show that our proposed approach can effectively identify
and incorporate the conversation context. We show that processing the current
utterance using the predicted relevant utterance leads to a 38% relative
improvement in terms of nDCG@20. Finally, to foster research in this area, we
have released the dataset of the annotations.
</summary>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Manajit Chakraborty</name>
    </author>
    <author>
      <name>Esteban Andrés Ríssola</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3343413.3377968</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3343413.3377968" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ACM CHIIR 2020, Vancouver, BC, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10554v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10554v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10546v1</id>
    <updated>2019-12-22T21:47:05Z</updated>
    <published>2019-12-22T21:47:05Z</published>
    <title>Hybrid Machine Learning Models of Classifying Residential Requests for
  Smart Dispatching</title>
    <summary>  This paper presents a hybrid machine learning method of classifying
residential requests in natural language to responsible departments that
provide timely responses back to residents under the vision of digital
government services in smart cities. Residential requests in natural language
descriptions cover almost every aspect of a city's daily operation. Hence the
responsible departments are fine-grained to even the level of local
communities. There are no specific general categories or labels for each
request sample. This causes two issues for supervised classification solutions,
namely (1) the request sample data is unbalanced and (2) lack of specific
labels for training. To solve these issues, we investigate a hybrid machine
learning method that generates meta-class labels by means of unsupervised
clustering algorithms; applies two-word embedding methods with three
classifiers (including two hierarchical classifiers and one residual
convolutional neural network); and selects the best performing classifier as
the classification result. We demonstrate our approach performing better
classification tasks compared to two benchmarking machine learning models,
Naive Bayes classifier and a Multiple Layer Perceptron (MLP). In addition, the
hierarchical classification method provides insights into the source of
classification errors.
</summary>
    <author>
      <name>T. Chen</name>
    </author>
    <author>
      <name>J. Sun</name>
    </author>
    <author>
      <name>H. Lin</name>
    </author>
    <author>
      <name>Y. Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, Cyberspace Data and Intelligence, and Cyber-Living,
  Syndrome, and Health. Springer, Singapore, 2019. 357-378</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10514v1</id>
    <updated>2019-12-22T19:20:10Z</updated>
    <published>2019-12-22T19:20:10Z</published>
    <title>Tag-less Back-Translation</title>
    <summary>  An effective method to generate a large number of parallel sentences for
training improved neural machine translation (NMT) systems is the use of
back-translations of the target-side monolingual data. Tagging, or using gates,
has been used to enable translation models to distinguish between synthetic and
natural data. This improves standard back-translation and also enables the use
of iterative back-translation on language pairs that underperformed using
standard back-translation. This work presents a simplified approach of
differentiating between the two data using pretraining and finetuning. The
approach - tag-less back-translation - trains the model on the synthetic data
and finetunes it on the natural data. Preliminary experiments have shown the
approach to continuously outperform the tagging approach on low resource
English-Vietnamese neural machine translation. While the need for tagging
(noising) the dataset has been removed, the approach outperformed the tagged
back-translation approach by an average of 0.4 BLEU.
</summary>
    <author>
      <name>Idris Abdulmumin</name>
    </author>
    <author>
      <name>Bashir Shehu Galadanci</name>
    </author>
    <author>
      <name>Aliyu Garba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to 2020 International Conference on Computer and
  Information Sciences, 5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10514v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10514v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10458v1</id>
    <updated>2019-12-22T14:43:14Z</updated>
    <published>2019-12-22T14:43:14Z</published>
    <title>Emotion Recognition from Speech</title>
    <summary>  In this work, we conduct an extensive comparison of various approaches to
speech based emotion recognition systems. The analyses were carried out on
audio recordings from Ryerson Audio-Visual Database of Emotional Speech and
Song (RAVDESS). After pre-processing the raw audio files, features such as
Log-Mel Spectrogram, Mel-Frequency Cepstral Coefficients (MFCCs), pitch and
energy were considered. The significance of these features for emotion
classification was compared by applying methods such as Long Short Term Memory
(LSTM), Convolutional Neural Networks (CNNs), Hidden Markov Models (HMMs) and
Deep Neural Networks (DNNs). On the 14-class (2 genders x 7 emotions)
classification task, an accuracy of 68% was achieved with a 4-layer 2
dimensional CNN using the Log-Mel Spectrogram features. We also observe that,
in emotion recognition, the choice of audio features impacts the results much
more than the model complexity.
</summary>
    <author>
      <name>Kannan Venkataramanan</name>
    </author>
    <author>
      <name>Haresh Rengaraj Rajamohan</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10375v1</id>
    <updated>2019-12-22T03:02:42Z</updated>
    <published>2019-12-22T03:02:42Z</published>
    <title>AdvCodec: Towards A Unified Framework for Adversarial Text Generation</title>
    <summary>  While there has been great interest in generating imperceptible adversarial
examples in continuous data domain (e.g. image and audio) to explore the model
vulnerabilities, generating \emph{adversarial text} in the discrete domain is
still challenging. The main contribution of this paper is to propose a general
targeted attack framework AdvCodec for adversarial text generation which
addresses the challenge of discrete input space and is easily adapted to
general natural language processing (NLP) tasks. In particular, we propose a
tree-based autoencoder to encode discrete text data into continuous vector
space, upon which we optimize the adversarial perturbation. A tree-based
decoder is then applied to ensure the grammar correctness of the generated
text. It also enables the flexibility of making manipulations on different
levels of text, such as sentence (AdvCodec(sent)) and word (AdvCodec(word))
levels. We consider multiple attacking scenarios, including appending an
adversarial sentence or adding unnoticeable words to a given paragraph, to
achieve the arbitrary targeted attack. To demonstrate the effectiveness of the
proposed method, we consider two most representative NLP tasks: sentiment
analysis and question answering (QA). Extensive experimental results and human
studies show that AdvCodec generated adversarial text can successfully attack
the neural models without misleading the human. In particular, our attack
causes a BERT-based sentiment classifier accuracy to drop from 0.703$ to 0.006,
and a BERT-based QA model's F1 score to drop from 88.62 to 33.21 (with best
targeted attack F1 score as 46.54). Furthermore, we show that the white-box
generated adversarial texts can transfer across other black-box models,
shedding light on an effective way to examine the robustness of existing NLP
models.
</summary>
    <author>
      <name>Boxin Wang</name>
    </author>
    <author>
      <name>Hengzhi Pei</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <author>
      <name>Bo Li</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10337v1</id>
    <updated>2019-12-21T21:11:35Z</updated>
    <published>2019-12-21T21:11:35Z</published>
    <title>Recurrent Hierarchical Topic-Guided Neural Language Models</title>
    <summary>  To simultaneously capture syntax and global semantics from a text corpus, we
propose a new larger-context recurrent neural network (RNN) based language
model, which extracts recurrent hierarchical semantic structure via a dynamic
deep topic model to guide natural language generation. Moving beyond a
conventional RNN based language model that ignores long-range word dependencies
and sentence order, the proposed model captures not only intra-sentence word
dependencies, but also temporal transitions between sentences and
inter-sentence topic dependences. For inference, we develop a hybrid of
stochastic-gradient MCMC and recurrent autoencoding variational Bayes.
Experimental results on a variety of real-world text corpora demonstrate that
the proposed model not only outperforms state-of-the-art larger-context
RNN-based language models, but also learns interpretable recurrent multilayer
topics and generates diverse sentences and paragraphs that are syntactically
correct and semantically coherent.
</summary>
    <author>
      <name>Dandan Guo</name>
    </author>
    <author>
      <name>Bo Chen</name>
    </author>
    <author>
      <name>Ruiying Lu</name>
    </author>
    <author>
      <name>Mingyuan Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10308v1</id>
    <updated>2019-12-21T18:14:32Z</updated>
    <published>2019-12-21T18:14:32Z</published>
    <title>Candidate Fusion: Integrating Language Modelling into a
  Sequence-to-Sequence Handwritten Word Recognition Architecture</title>
    <summary>  Sequence-to-sequence models have recently become very popular for tackling
handwritten word recognition problems. However, how to effectively integrate an
external language model into such recognizer is still a challenging problem.
The main challenge faced when training a language model is to deal with the
language model corpus which is usually different to the one used for training
the handwritten word recognition system. Thus, the bias between both word
corpora leads to incorrectness on the transcriptions, providing similar or even
worse performances on the recognition task. In this work, we introduce
Candidate Fusion, a novel way to integrate an external language model to a
sequence-to-sequence architecture. Moreover, it provides suggestions from an
external language knowledge, as a new input to the sequence-to-sequence
recognizer. Hence, Candidate Fusion provides two improvements. On the one hand,
the sequence-to-sequence recognizer has the flexibility not only to combine the
information from itself and the language model, but also to choose the
importance of the information provided by the language model. On the other
hand, the external language model has the ability to adapt itself to the
training corpus and even learn the most commonly errors produced from the
recognizer. Finally, by conducting comprehensive experiments, the Candidate
Fusion proves to outperform the state-of-the-art language models for
handwritten word recognition tasks.
</summary>
    <author>
      <name>Lei Kang</name>
    </author>
    <author>
      <name>Pau Riba</name>
    </author>
    <author>
      <name>Mauricio Villegas</name>
    </author>
    <author>
      <name>Alicia Fornés</name>
    </author>
    <author>
      <name>Marçal Rusiñol</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10306v1</id>
    <updated>2019-12-21T17:49:13Z</updated>
    <published>2019-12-21T17:49:13Z</published>
    <title>Predicting Heart Failure Readmission from Clinical Notes Using Deep
  Learning</title>
    <summary>  Heart failure hospitalization is a severe burden on healthcare. How to
predict and therefore prevent readmission has been a significant challenge in
outcomes research. To address this, we propose a deep learning approach to
predict readmission from clinical notes. Unlike conventional methods that use
structured data for prediction, we leverage the unstructured clinical notes to
train deep learning models based on convolutional neural networks (CNN). We
then use the trained models to classify and predict potentially high-risk
admissions/patients. For evaluation, we trained CNNs using the discharge
summary notes in the MIMIC III database. We also trained regular machine
learning models based on random forest using the same datasets. The result
shows that deep learning models outperform the regular models in prediction
tasks. CNN method achieves a F1 score of 0.756 in general readmission
prediction and 0.733 in 30-day readmission prediction, while random forest only
achieves a F1 score of 0.674 and 0.656 respectively. We also propose a
chi-square test based method to interpret key features associated with deep
learning predicted readmissions. It reveals clinical insights about readmission
embedded in the clinical notes. Collectively, our method can make the human
evaluation process more efficient and potentially facilitate the reduction of
readmission rates.
</summary>
    <author>
      <name>Xiong Liu</name>
    </author>
    <author>
      <name>Yu Chen</name>
    </author>
    <author>
      <name>Jay Bae</name>
    </author>
    <author>
      <name>Hu Li</name>
    </author>
    <author>
      <name>Joseph Johnston</name>
    </author>
    <author>
      <name>Todd Sanger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE BIBM 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE International Conference on Bioinformatics and
  Biomedicine (BIBM)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10204v1</id>
    <updated>2019-12-21T05:47:58Z</updated>
    <published>2019-12-21T05:47:58Z</published>
    <title>A Machine Learning Framework for Authorship Identification From Texts</title>
    <summary>  Authorship identification is a process in which the author of a text is
identified. Most known literary texts can easily be attributed to a certain
author because they are, for example, signed. Yet sometimes we find unfinished
pieces of work or a whole bunch of manuscripts with a wide variety of possible
authors. In order to assess the importance of such a manuscript, it is vital to
know who wrote it. In this work, we aim to develop a machine learning framework
to effectively determine authorship. We formulate the task as a single-label
multi-class text categorization problem and propose a supervised machine
learning framework incorporating stylometric features. This task is highly
interdisciplinary in that it takes advantage of machine learning, information
retrieval, and natural language processing. We present an approach and a model
which learns the differences in writing style between $50$ different authors
and is able to predict the author of a new text with high accuracy. The
accuracy is seen to increase significantly after introducing certain linguistic
stylometric features along with text features.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Carolyn Penstein Rose</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00059v1</id>
    <updated>2019-12-21T05:05:22Z</updated>
    <published>2019-12-21T05:05:22Z</published>
    <title>Pre-trained Contextual Embedding of Source Code</title>
    <summary>  The source code of a program not only serves as a formal description of an
executable task, but it also serves to communicate developer intent in a
human-readable form. To facilitate this, developers use meaningful identifier
names and natural-language documentation. This makes it possible to
successfully apply sequence-modeling approaches, shown to be effective in
natural-language processing, to source code. A major advancement in
natural-language understanding has been the use of pre-trained token
embeddings; BERT and other works have further shown that pre-trained contextual
embeddings can be extremely powerful and can be fine-tuned effectively for a
variety of downstream supervised tasks. Inspired by these developments, we
present the first attempt to replicate this success on source code. We curate a
massive corpus of Python programs from GitHub to pre-train a BERT model, which
we call Code Understanding BERT (CuBERT). We also pre-train Word2Vec embeddings
on the same dataset. We create a benchmark of five classification tasks and
compare fine-tuned CuBERT against sequence models trained with and without the
Word2Vec embeddings. Our results show that CuBERT outperforms the baseline
methods by a margin of 2.9-22%. We also show its superiority when fine-tuned
with smaller datasets, and over fewer epochs. We further evaluate CuBERT's
effectiveness on a joint classification, localization and repair task involving
prediction of two pointers.
</summary>
    <author>
      <name>Aditya Kanade</name>
    </author>
    <author>
      <name>Petros Maniatis</name>
    </author>
    <author>
      <name>Gogul Balakrishnan</name>
    </author>
    <author>
      <name>Kensen Shi</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10132v1</id>
    <updated>2019-12-20T22:56:54Z</updated>
    <published>2019-12-20T22:56:54Z</published>
    <title>Exploring Context, Attention and Audio Features for Audio Visual
  Scene-Aware Dialog</title>
    <summary>  We are witnessing a confluence of vision, speech and dialog system
technologies that are enabling the IVAs to learn audio-visual groundings of
utterances and have conversations with users about the objects, activities and
events surrounding them. Recent progress in visual grounding techniques and
Audio Understanding are enabling machines to understand shared semantic
concepts and listen to the various sensory events in the environment. With
audio and visual grounding methods, end-to-end multimodal SDS are trained to
meaningfully communicate with us in natural language about the real dynamic
audio-visual sensory world around us. In this work, we explore the role of
`topics' as the context of the conversation along with multimodal attention
into such an end-to-end audio-visual scene-aware dialog system architecture. We
also incorporate an end-to-end audio classification ConvNet, AclNet, into our
models. We develop and test our approaches on the Audio Visual Scene-Aware
Dialog (AVSD) dataset released as a part of the DSTC7. We present the analysis
of our experiments and show that some of our model variations outperform the
baseline system released for AVSD.
</summary>
    <author>
      <name>Shachi H Kumar</name>
    </author>
    <author>
      <name>Eda Okur</name>
    </author>
    <author>
      <name>Saurav Sahay</name>
    </author>
    <author>
      <name>Jonathan Huang</name>
    </author>
    <author>
      <name>Lama Nachman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the Visual Question Answering and Dialog Workshop, CVPR
  2019, Long Beach, USA. arXiv admin note: substantial text overlap with
  arXiv:1912.10131</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10131v1</id>
    <updated>2019-12-20T22:55:40Z</updated>
    <published>2019-12-20T22:55:40Z</published>
    <title>Leveraging Topics and Audio Features with Multimodal Attention for Audio
  Visual Scene-Aware Dialog</title>
    <summary>  With the recent advancements in Artificial Intelligence (AI), Intelligent
Virtual Assistants (IVA) such as Alexa, Google Home, etc., have become a
ubiquitous part of many homes. Currently, such IVAs are mostly audio-based, but
going forward, we are witnessing a confluence of vision, speech and dialog
system technologies that are enabling the IVAs to learn audio-visual groundings
of utterances. This will enable agents to have conversations with users about
the objects, activities and events surrounding them. In this work, we present
three main architectural explorations for the Audio Visual Scene-Aware Dialog
(AVSD): 1) investigating `topics' of the dialog as an important contextual
feature for the conversation, 2) exploring several multimodal attention
mechanisms during response generation, 3) incorporating an end-to-end audio
classification ConvNet, AclNet, into our architecture. We discuss detailed
analysis of the experimental results and show that our model variations
outperform the baseline system presented for the AVSD task.
</summary>
    <author>
      <name>Shachi H Kumar</name>
    </author>
    <author>
      <name>Eda Okur</name>
    </author>
    <author>
      <name>Saurav Sahay</name>
    </author>
    <author>
      <name>Jonathan Huang</name>
    </author>
    <author>
      <name>Lama Nachman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 3rd Visually Grounded Interaction and Language
  (ViGIL) Workshop, NeurIPS 2019, Vancouver, Canada. arXiv admin note:
  substantial text overlap with arXiv:1812.08407, arXiv:1912.10132</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10130v1</id>
    <updated>2019-12-20T22:53:18Z</updated>
    <published>2019-12-20T22:53:18Z</published>
    <title>Modeling Intent, Dialog Policies and Response Adaptation for
  Goal-Oriented Interactions</title>
    <summary>  Building a machine learning driven spoken dialog system for goal-oriented
interactions involves careful design of intents and data collection along with
development of intent recognition models and dialog policy learning algorithms.
The models should be robust enough to handle various user distractions during
the interaction flow and should steer the user back into an engaging
interaction for successful completion of the interaction. In this work, we have
designed a goal-oriented interaction system where children can engage with
agents for a series of interactions involving `Meet \&amp; Greet' and `Simon Says'
game play. We have explored various feature extractors and models for improved
intent recognition and looked at leveraging previous user and system
interactions in novel ways with attention models. We have also looked at dialog
adaptation methods for entrained response selection. Our bootstrapped models
from limited training data perform better than many baseline approaches we have
looked at for intent recognition and dialog action prediction.
</summary>
    <author>
      <name>Saurav Sahay</name>
    </author>
    <author>
      <name>Shachi H Kumar</name>
    </author>
    <author>
      <name>Eda Okur</name>
    </author>
    <author>
      <name>Haroon Syed</name>
    </author>
    <author>
      <name>Lama Nachman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented as a full-paper at the 23rd Workshop on the Semantics and
  Pragmatics of Dialogue (SemDial 2019 - LondonLogue), Sep 4-6, 2019, London,
  UK</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 23rd Workshop on the Semantics and Pragmatics
  of Dialogue (SEMDIAL), pp. 146-155, London, United Kingdom, September 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10128v1</id>
    <updated>2019-12-20T22:45:23Z</updated>
    <published>2019-12-20T22:45:23Z</published>
    <title>Learning Singing From Speech</title>
    <summary>  We propose an algorithm that is capable of synthesizing high quality target
speaker's singing voice given only their normal speech samples. The proposed
algorithm first integrate speech and singing synthesis into a unified
framework, and learns universal speaker embeddings that are shareable between
speech and singing synthesis tasks. Specifically, the speaker embeddings
learned from normal speech via the speech synthesis objective are shared with
those learned from singing samples via the singing synthesis objective in the
unified training framework. This makes the learned speaker embedding a
transferable representation for both speaking and singing. We evaluate the
proposed algorithm on singing voice conversion task where the content of
original singing is covered with the timbre of another speaker's voice learned
purely from their normal speech samples. Our experiments indicate that the
proposed algorithm generates high-quality singing voices that sound highly
similar to target speaker's voice given only his or her normal speech samples.
We believe that proposed algorithm will open up new opportunities for singing
synthesis and conversion for broader users and applications.
</summary>
    <author>
      <name>Liqiang Zhang</name>
    </author>
    <author>
      <name>Chengzhu Yu</name>
    </author>
    <author>
      <name>Heng Lu</name>
    </author>
    <author>
      <name>Chao Weng</name>
    </author>
    <author>
      <name>Yusong Wu</name>
    </author>
    <author>
      <name>Xiang Xie</name>
    </author>
    <author>
      <name>Zijin Li</name>
    </author>
    <author>
      <name>Dong Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ICASSP-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04345v1</id>
    <updated>2019-12-20T22:12:47Z</updated>
    <published>2019-12-20T22:12:47Z</published>
    <title>Shareable Representations for Search Query Understanding</title>
    <summary>  Understanding search queries is critical for shopping search engines to
deliver a satisfying customer experience. Popular shopping search engines
receive billions of unique queries yearly, each of which can depict any of
hundreds of user preferences or intents. In order to get the right results to
customers it must be known queries like "inexpensive prom dresses" are intended
to not only surface results of a certain product type but also products with a
low price. Referred to as query intents, examples also include preferences for
author, brand, age group, or simply a need for customer service. Recent works
such as BERT have demonstrated the success of a large transformer encoder
architecture with language model pre-training on a variety of NLP tasks. We
adapt such an architecture to learn intents for search queries and describe
methods to account for the noisiness and sparseness of search query data. We
also describe cost effective ways of hosting transformer encoder models in
context with low latency requirements. With the right domain-specific training
we can build a shareable deep learning model whose internal representation can
be reused for a variety of query understanding tasks including query intent
identification. Model sharing allows for fewer large models needed to be served
at inference time and provides a platform to quickly build and roll out new
search query classifiers.
</summary>
    <author>
      <name>Mukul Kumar</name>
    </author>
    <author>
      <name>Youna Hu</name>
    </author>
    <author>
      <name>Will Headden</name>
    </author>
    <author>
      <name>Rahul Goutam</name>
    </author>
    <author>
      <name>Heran Lin</name>
    </author>
    <author>
      <name>Bing Yin</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13415v1</id>
    <updated>2019-12-20T19:47:56Z</updated>
    <published>2019-12-20T19:47:56Z</published>
    <title>End-to-end Named Entity Recognition and Relation Extraction using
  Pre-trained Language Models</title>
    <summary>  Named entity recognition (NER) and relation extraction (RE) are two important
tasks in information extraction and retrieval (IE \&amp; IR). Recent work has
demonstrated that it is beneficial to learn these tasks jointly, which avoids
the propagation of error inherent in pipeline-based systems and improves
performance. However, state-of-the-art joint models typically rely on external
natural language processing (NLP) tools, such as dependency parsers, limiting
their usefulness to domains (e.g. news) where those tools perform well. The few
neural, end-to-end models that have been proposed are trained almost completely
from scratch. In this paper, we propose a neural, end-to-end model for jointly
extracting entities and their relations which does not rely on external NLP
tools and which integrates a large, pre-trained language model. Because the
bulk of our model's parameters are pre-trained and we eschew recurrence for
self-attention, our model is fast to train. On 5 datasets across 3 domains, our
model matches or exceeds state-of-the-art performance, sometimes by a large
margin.
</summary>
    <author>
      <name>John Giorgi</name>
    </author>
    <author>
      <name>Xindi Wang</name>
    </author>
    <author>
      <name>Nicola Sahar</name>
    </author>
    <author>
      <name>Won Young Shin</name>
    </author>
    <author>
      <name>Gary D. Bader</name>
    </author>
    <author>
      <name>Bo Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00471v1</id>
    <updated>2019-12-20T18:58:25Z</updated>
    <published>2019-12-20T18:58:25Z</published>
    <title>A Voice Interactive Multilingual Student Support System using IBM Watson</title>
    <summary>  Systems powered by artificial intelligence are being developed to be more
user-friendly by communicating with users in a progressively human-like
conversational way. Chatbots, also known as dialogue systems, interactive
conversational agents, or virtual agents are an example of such systems used in
a wide variety of applications ranging from customer support in the business
domain to companionship in the healthcare sector. It is becoming increasingly
important to develop chatbots that can best respond to the personalized needs
of their users so that they can be as helpful to the user as possible in a real
human way. This paper investigates and compares three popular existing chatbots
API offerings and then propose and develop a voice interactive and multilingual
chatbot that can effectively respond to users mood, tone, and language using
IBM Watson Assistant, Tone Analyzer, and Language Translator. The chatbot was
evaluated using a use case that was targeted at responding to users needs
regarding exam stress based on university students survey data generated using
Google Forms. The results of measuring the chatbot effectiveness at analyzing
responses regarding exam stress indicate that the chatbot responding
appropriately to the user queries regarding how they are feeling about exams
76.5%. The chatbot could also be adapted for use in other application areas
such as student info-centers, government kiosks, and mental health support
systems.
</summary>
    <author>
      <name>Kennedy Ralston</name>
    </author>
    <author>
      <name>Yuhao Chen</name>
    </author>
    <author>
      <name>Haruna Isah</name>
    </author>
    <author>
      <name>Farhana Zulkernine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10011v1</id>
    <updated>2019-12-20T18:41:32Z</updated>
    <published>2019-12-20T18:41:32Z</published>
    <title>A Hierarchical Model for Data-to-Text Generation</title>
    <summary>  Transcribing structured data into natural language descriptions has emerged
as a challenging task, referred to as "data-to-text". These structures
generally regroup multiple elements, as well as their attributes. Most attempts
rely on translation encoder-decoder methods which linearize elements into a
sequence. This however loses most of the structure contained in the data. In
this work, we propose to overpass this limitation with a hierarchical model
that encodes the data-structure at the element-level and the structure level.
Evaluations on RotoWire show the effectiveness of our model w.r.t. qualitative
and quantitative metrics.
</summary>
    <author>
      <name>Clément Rebuffel</name>
    </author>
    <author>
      <name>Laure Soulier</name>
    </author>
    <author>
      <name>Geoffrey Scoutheeten</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 42nd European Conference on IR Research, ECIR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10000v2</id>
    <updated>2020-02-13T10:38:54Z</updated>
    <published>2019-12-20T18:31:33Z</published>
    <title>Probability Calibration for Knowledge Graph Embedding Models</title>
    <summary>  Knowledge graph embedding research has overlooked the problem of probability
calibration. We show popular embedding models are indeed uncalibrated. That
means probability estimates associated to predicted triples are unreliable. We
present a novel method to calibrate a model when ground truth negatives are not
available, which is the usual case in knowledge graphs. We propose to use Platt
scaling and isotonic regression alongside our method. Experiments on three
datasets with ground truth negatives show our contribution leads to
well-calibrated models when compared to the gold standard of using negatives.
We get significantly better results than the uncalibrated models from all
calibration methods. We show isotonic regression offers the best the
performance overall, not without trade-offs. We also show that calibrated
models reach state-of-the-art accuracy without the need to define
relation-specific decision thresholds.
</summary>
    <author>
      <name>Pedro Tabacof</name>
    </author>
    <author>
      <name>Luca Costabello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10000v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10000v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10847v1</id>
    <updated>2019-12-20T18:28:29Z</updated>
    <published>2019-12-20T18:28:29Z</published>
    <title>What do Asian Religions Have in Common? An Unsupervised Text Analytics
  Exploration</title>
    <summary>  The main source of various religious teachings is their sacred texts which
vary from religion to religion based on different factors like the geographical
location or time of the birth of a particular religion. Despite these
differences, there could be similarities between the sacred texts based on what
lessons it teaches to its followers. This paper attempts to find the similarity
using text mining techniques. The corpus consisting of Asian (Tao Te Ching,
Buddhism, Yogasutra, Upanishad) and non-Asian (four Bible texts) is used to
explore findings of similarity measures like Euclidean, Manhattan, Jaccard and
Cosine on raw Document Term Frequency [DTM], normalized DTM which reveals
similarity based on word usage. The performance of Supervised learning
algorithms like K-Nearest Neighbor [KNN], Support Vector Machine [SVM] and
Random Forest is measured based on its accuracy to predict correct scared text
for any given chapter in the corpus. The K-means clustering visualizations on
Euclidean distances of raw DTM reveals that there exists a pattern of
similarity among these sacred texts with Upanishads and Tao Te Ching is the
most similar text in the corpus.
</summary>
    <author>
      <name>Preeti Sah</name>
    </author>
    <author>
      <name>Ernest Fokoué</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 22 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09913v1</id>
    <updated>2019-12-20T16:24:23Z</updated>
    <published>2019-12-20T16:24:23Z</published>
    <title>Hierarchical Character Embeddings: Learning Phonological and Semantic
  Representations in Languages of Logographic Origin using Recursive Neural
  Networks</title>
    <summary>  Logographs (Chinese characters) have recursive structures (i.e. hierarchies
of sub-units in logographs) that contain phonological and semantic information,
as developmental psychology literature suggests that native speakers leverage
on the structures to learn how to read. Exploiting these structures could
potentially lead to better embeddings that can benefit many downstream tasks.
We propose building hierarchical logograph (character) embeddings from
logograph recursive structures using treeLSTM, a recursive neural network.
Using recursive neural network imposes a prior on the mapping from logographs
to embeddings since the network must read in the sub-units in logographs
according to the order specified by the recursive structures. Based on human
behavior in language learning and reading, we hypothesize that modeling
logographs' structures using recursive neural network should be beneficial. To
verify this claim, we consider two tasks (1) predicting logographs' Cantonese
pronunciation from logographic structures and (2) language modeling. Empirical
results show that the proposed hierarchical embeddings outperform baseline
approaches. Diagnostic analysis suggests that hierarchical embeddings
constructed using treeLSTM is less sensitive to distractors, thus is more
robust, especially on complex logographs.
</summary>
    <author>
      <name>Minh Nguyen</name>
    </author>
    <author>
      <name>Gia H. Ngo</name>
    </author>
    <author>
      <name>Nancy F. Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TASLP.2019.2955246</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TASLP.2019.2955246" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IEEE Transactions on Audio, Speech and Language
  Processing. Copyright 2019 IEEE</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09879v1</id>
    <updated>2019-12-20T15:25:57Z</updated>
    <published>2019-12-20T15:25:57Z</published>
    <title>When to Talk: Chatbot Controls the Timing of Talking during Multi-turn
  Open-domain Dialogue Generation</title>
    <summary>  Despite the multi-turn open-domain dialogue systems have attracted more and
more attention and made great progress, the existing dialogue systems are still
very boring. Nearly all the existing dialogue models only provide a response
when the user's utterance is accepted. But during daily conversations, humans
always decide whether to continue to utter an utterance based on the context.
Intuitively, a dialogue model that can control the timing of talking
autonomously based on the conversation context can chat with humans more
naturally. In this paper, we explore the dialogue system that automatically
controls the timing of talking during the conversation. Specifically, we adopt
the decision module for the existing dialogue models. Furthermore, modeling
conversation context effectively is very important for controlling the timing
of talking. So we also adopt the graph neural networks to process the context
with the natural graph structure. Extensive experiments on two benchmarks show
that controlling the timing of talking can effectively improve the quality of
dialogue generation, and the proposed methods significantly improve the
accuracy of the timing of talking. In addition, we have publicly released the
codes of our proposed model.
</summary>
    <author>
      <name>Tian Lan</name>
    </author>
    <author>
      <name>Xianling Mao</name>
    </author>
    <author>
      <name>Heyan Huang</name>
    </author>
    <author>
      <name>Wei Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10858v1</id>
    <updated>2019-12-20T14:37:27Z</updated>
    <published>2019-12-20T14:37:27Z</published>
    <title>"The Squawk Bot": Joint Learning of Time Series and Text Data Modalities
  for Automated Financial Information Filtering</title>
    <summary>  Multimodal analysis that uses numerical time series and textual corpora as
input data sources is becoming a promising approach, especially in the
financial industry. However, the main focus of such analysis has been on
achieving high prediction accuracy while little effort has been spent on the
important task of understanding the association between the two data
modalities. Performance on the time series hence receives little explanation
though human-understandable textual information is available. In this work, we
address the problem of given a numerical time series, and a general corpus of
textual stories collected in the same period of the time series, the task is to
timely discover a succinct set of textual stories associated with that time
series. Towards this goal, we propose a novel multi-modal neural model called
MSIN that jointly learns both numerical time series and categorical text
articles in order to unearth the association between them. Through multiple
steps of data interrelation between the two data modalities, MSIN learns to
focus on a small subset of text articles that best align with the performance
in the time series. This succinct set is timely discovered and presented as
recommended documents, acting as automated information filtering, for the given
time series. We empirically evaluate the performance of our model on
discovering relevant news articles for two stock time series from Apple and
Google companies, along with the daily news articles collected from the Thomson
Reuters over a period of seven consecutive years. The experimental results
demonstrate that MSIN achieves up to 84.9% and 87.2% in recalling the ground
truth articles respectively to the two examined time series, far more superior
to state-of-the-art algorithms that rely on conventional attention mechanism in
deep learning.
</summary>
    <author>
      <name>Xuan-Hong Dang</name>
    </author>
    <author>
      <name>Syed Yousaf Shah</name>
    </author>
    <author>
      <name>Petros Zerfos</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09723v2</id>
    <updated>2019-12-23T10:44:08Z</updated>
    <published>2019-12-20T09:44:42Z</published>
    <title>SberQuAD - Russian Reading Comprehension Dataset: Description and
  Analysis</title>
    <summary>  SberQuAD - a large scale analog of Stanford SQuAD in the Russian language -
is a valuable resource that has not been properly presented to the scientific
community. We fill this gap by providing a description, a thorough analysis,
and baseline experimental results.
</summary>
    <author>
      <name>Pavel Efimov</name>
    </author>
    <author>
      <name>Leonid Boytsov</name>
    </author>
    <author>
      <name>Pavel Braslavski</name>
    </author>
    <link href="http://arxiv.org/abs/1912.09723v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09723v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09713v1</id>
    <updated>2019-12-20T09:32:41Z</updated>
    <published>2019-12-20T09:32:41Z</published>
    <title>Measuring Compositional Generalization: A Comprehensive Method on
  Realistic Data</title>
    <summary>  State-of-the-art machine learning methods exhibit limited compositional
generalization. At the same time, there is a lack of realistic benchmarks that
comprehensively measure this ability, which makes it challenging to find and
evaluate improvements. We introduce a novel method to systematically construct
such benchmarks by maximizing compound divergence while guaranteeing a small
atom divergence between train and test sets, and we quantitatively compare this
method to other approaches for creating compositional generalization
benchmarks. We present a large and realistic natural language question
answering dataset that is constructed according to this method, and we use it
to analyze the compositional generalization ability of three machine learning
architectures. We find that they fail to generalize compositionally and that
there is a surprisingly strong negative correlation between compound divergence
and accuracy. We also demonstrate how our method can be used to create new
compositionality benchmarks on top of the existing SCAN dataset, which confirms
these findings.
</summary>
    <author>
      <name>Daniel Keysers</name>
    </author>
    <author>
      <name>Nathanael Schärli</name>
    </author>
    <author>
      <name>Nathan Scales</name>
    </author>
    <author>
      <name>Hylke Buisman</name>
    </author>
    <author>
      <name>Daniel Furrer</name>
    </author>
    <author>
      <name>Sergii Kashubin</name>
    </author>
    <author>
      <name>Nikola Momchev</name>
    </author>
    <author>
      <name>Danila Sinopalnikov</name>
    </author>
    <author>
      <name>Lukasz Stafiniak</name>
    </author>
    <author>
      <name>Tibor Tihon</name>
    </author>
    <author>
      <name>Dmitry Tsarkov</name>
    </author>
    <author>
      <name>Xiao Wang</name>
    </author>
    <author>
      <name>Marc van Zee</name>
    </author>
    <author>
      <name>Olivier Bousquet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09637v1</id>
    <updated>2019-12-20T04:25:48Z</updated>
    <published>2019-12-20T04:25:48Z</published>
    <title>Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language
  Model</title>
    <summary>  Recent breakthroughs of pretrained language models have shown the
effectiveness of self-supervised learning for a wide range of natural language
processing (NLP) tasks. In addition to standard syntactic and semantic NLP
tasks, pretrained models achieve strong improvements on tasks that involve
real-world knowledge, suggesting that large-scale language modeling could be an
implicit method to capture knowledge. In this work, we further investigate the
extent to which pretrained models such as BERT capture knowledge using a
zero-shot fact completion task. Moreover, we propose a simple yet effective
weakly supervised pretraining objective, which explicitly forces the model to
incorporate knowledge about real-world entities. Models trained with our new
objective yield significant improvements on the fact completion task. When
applied to downstream tasks, our model consistently outperforms BERT on four
entity-related question answering datasets (i.e., WebQuestions, TriviaQA,
SearchQA and Quasar-T) with an average 2.7 F1 improvements and a standard
fine-grained entity typing dataset (i.e., FIGER) with 5.7 accuracy gains.
</summary>
    <author>
      <name>Wenhan Xiong</name>
    </author>
    <author>
      <name>Jingfei Du</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <author>
      <name>Veselin Stoyanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10806v1</id>
    <updated>2019-12-20T02:52:27Z</updated>
    <published>2019-12-20T02:52:27Z</published>
    <title>DP-LSTM: Differential Privacy-inspired LSTM for Stock Prediction Using
  Financial News</title>
    <summary>  Stock price prediction is important for value investments in the stock
market. In particular, short-term prediction that exploits financial news
articles is promising in recent years. In this paper, we propose a novel deep
neural network DP-LSTM for stock price prediction, which incorporates the news
articles as hidden information and integrates difference news sources through
the differential privacy mechanism. First, based on the autoregressive moving
average model (ARMA), a sentiment-ARMA is formulated by taking into
consideration the information of financial news articles in the model. Then, an
LSTM-based deep neural network is designed, which consists of three components:
LSTM, VADER model and differential privacy (DP) mechanism. The proposed DP-LSTM
scheme can reduce prediction errors and increase the robustness. Extensive
experiments on S&amp;P 500 stocks show that (i) the proposed DP-LSTM achieves 0.32%
improvement in mean MPA of prediction result, and (ii) for the prediction of
the market index S&amp;P 500, we achieve up to 65.79% improvement in MSE.
</summary>
    <author>
      <name>Xinyi Li</name>
    </author>
    <author>
      <name>Yinchuan Li</name>
    </author>
    <author>
      <name>Hongyang Yang</name>
    </author>
    <author>
      <name>Liuqing Yang</name>
    </author>
    <author>
      <name>Xiao-Yang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1908.01112</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09582v1</id>
    <updated>2019-12-19T22:59:26Z</updated>
    <published>2019-12-19T22:59:26Z</published>
    <title>BERTje: A Dutch BERT Model</title>
    <summary>  The transformer-based pre-trained language model BERT has helped to improve
state-of-the-art performance on many natural language processing (NLP) tasks.
Using the same architecture and parameters, we developed and evaluated a
monolingual Dutch BERT model called BERTje. Compared to the multilingual BERT
model, which includes Dutch but is only based on Wikipedia text, BERTje is
based on a large and diverse dataset of 2.4 billion tokens. BERTje consistently
outperforms the equally-sized multilingual BERT model on downstream NLP tasks
(part-of-speech tagging, named-entity recognition, semantic role labeling, and
sentiment analysis). Our pre-trained Dutch BERT model is made available at
https://github.com/wietsedv/bertje.
</summary>
    <author>
      <name>Wietse de Vries</name>
    </author>
    <author>
      <name>Andreas van Cranenburgh</name>
    </author>
    <author>
      <name>Arianna Bisazza</name>
    </author>
    <author>
      <name>Tommaso Caselli</name>
    </author>
    <author>
      <name>Gertjan van Noord</name>
    </author>
    <author>
      <name>Malvina Nissim</name>
    </author>
    <link href="http://arxiv.org/abs/1912.09582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09558v2</id>
    <updated>2019-12-25T11:36:04Z</updated>
    <published>2019-12-19T21:47:08Z</published>
    <title>RIMAX: Ranking Semantic Rhymes by calculating Definition Similarity</title>
    <summary>  This paper presents RIMAX, a new system for detecting semantic rhymes, using
a Comprehensive Mexican Spanish Dictionary (DEM) and its Rhyming Dictionary
(REM). We use the Vector Space Model to calculate the similarity of the
definition of a query with the definitions corresponding to the assonant and
consonant rhymes of the query. The preliminary results using a manual
evaluation are very encouraging.
</summary>
    <author>
      <name>Alfonso Medina-Urrea</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09558v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09558v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09551v1</id>
    <updated>2019-12-19T21:29:22Z</updated>
    <published>2019-12-19T21:29:22Z</published>
    <title>Deep Exemplar Networks for VQA and VQG</title>
    <summary>  In this paper, we consider the problem of solving semantic tasks such as
`Visual Question Answering' (VQA), where one aims to answers related to an
image and `Visual Question Generation' (VQG), where one aims to generate a
natural question pertaining to an image. Solutions for VQA and VQG tasks have
been proposed using variants of encoder-decoder deep learning based frameworks
that have shown impressive performance. Humans however often show
generalization by relying on exemplar based approaches. For instance, the work
by Tversky and Kahneman suggests that humans use exemplars when making
categorizations and decisions. In this work, we propose the incorporation of
exemplar based approaches towards solving these problems. Specifically, we
incorporate exemplar based approaches and show that an exemplar based module
can be incorporated in almost any of the deep learning architectures proposed
in the literature and the addition of such a block results in improved
performance for solving these tasks. Thus, just as the incorporation of
attention is now considered de facto useful for solving these tasks, similarly,
incorporating exemplars also can be considered to improve any proposed
architecture for solving this task. We provide extensive empirical analysis for
the same through various architectures, ablations, and state of the art
comparisons.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work is an extension of CVPR-2018 accepted paper
  arXiv:1804.00298 and EMNLP-2018 accepted paper arXiv:1808.03986</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10839v1</id>
    <updated>2019-12-19T15:55:42Z</updated>
    <published>2019-12-19T15:55:42Z</published>
    <title>Gaussianity and typicality in matrix distributional semantics</title>
    <summary>  Constructions in type-driven compositional distributional semantics associate
large collections of matrices of size $D$ to linguistic corpora. We develop the
proposal of analysing the statistical characteristics of this data in the
framework of permutation invariant matrix models. The observables in this
framework are permutation invariant polynomial functions of the matrix entries,
which correspond to directed graphs. Using the general 13-parameter permutation
invariant Gaussian matrix models recently solved, we find, using a dataset of
matrices constructed via standard techniques in distributional semantics, that
the expectation values of a large class of cubic and quartic observables show
high gaussianity at levels between 90 to 99 percent. Beyond expectation values,
which are averages over words, the dataset allows the computation of standard
deviations for each observable, which can be viewed as a measure of typicality
for each observable. There is a wide range of magnitudes in the measures of
typicality. The permutation invariant matrix models, considered as functions of
random couplings, give a very good prediction of the magnitude of the
typicality for different observables. We find evidence that observables with
similar matrix model characteristics of Gaussianity and typicality also have
high degrees of correlation between the ranked lists of words associated to
these observables.
</summary>
    <author>
      <name>Sanjaye Ramgoolam</name>
    </author>
    <author>
      <name>Mehrnoosh Sadrzadeh</name>
    </author>
    <author>
      <name>Lewis Sword</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09297v2</id>
    <updated>2020-02-02T05:16:12Z</updated>
    <published>2019-12-19T15:32:19Z</published>
    <title>An End-to-End Dialogue State Tracking System with Machine Reading
  Comprehension and Wide &amp; Deep Classification</title>
    <summary>  This paper describes our approach in DSTC 8 Track 4: Schema-Guided Dialogue
State Tracking. The goal of this task is to predict the intents and slots in
each user turn to complete the dialogue state tracking (DST) based on the
information provided by the task's schema. Different from traditional
stage-wise DST, we propose an end-to-end DST system to avoid error accumulation
between the dialogue turns. The DST system consists of a machine reading
comprehension (MRC) model for non-categorical slots and a Wide &amp; Deep model for
categorical slots. As far as we know, this is the first time that MRC and Wide
&amp; Deep model are applied to DST problem in a fully end-to-end way. Experimental
results show that our framework achieves an excellent performance on the test
dataset including 50% zero-shot services with a joint goal accuracy of 0.8652
and a slot tagging F1-Score of 0.9835.
</summary>
    <author>
      <name>Yue Ma</name>
    </author>
    <author>
      <name>Zengfeng Zeng</name>
    </author>
    <author>
      <name>Dawei Zhu</name>
    </author>
    <author>
      <name>Xuan Li</name>
    </author>
    <author>
      <name>Yiying Yang</name>
    </author>
    <author>
      <name>Xiaoyuan Yao</name>
    </author>
    <author>
      <name>Kaijie Zhou</name>
    </author>
    <author>
      <name>Jianping Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The Thirty-Fourth AAAI Conference on Artificial Intelligence DSTC 8
  Workshop (AAAI-20, DSTC 8 Workshop)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09297v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09297v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09257v2</id>
    <updated>2020-02-17T14:08:42Z</updated>
    <published>2019-12-19T15:09:07Z</published>
    <title>Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems</title>
    <summary>  Recent advances in text-to-speech (TTS) led to the development of flexible
multi-speaker end-to-end TTS systems. We extend state-of-the-art
attention-based automatic speech recognition (ASR) systems with synthetic audio
generated by a TTS system trained only on the ASR corpora itself. ASR and TTS
systems are built separately to show that text-only data can be used to enhance
existing end-to-end ASR systems without the necessity of parameter or
architecture changes. We compare our method with language model integration of
the same text data and with simple data augmentation methods like SpecAugment
and show that performance improvements are mostly independent. We achieve
improvements of up to 33% relative in word-error-rate (WER) over a strong
baseline with data-augmentation in a low-resource environment
(LibriSpeech-100h), closing the gap to a comparable oracle experiment by more
than 50\%. We also show improvements of up to 5% relative WER over our most
recent ASR baseline on LibriSpeech-960h.
</summary>
    <author>
      <name>Nick Rossenbach</name>
    </author>
    <author>
      <name>Albert Zeyer</name>
    </author>
    <author>
      <name>Ralf Schlüter</name>
    </author>
    <author>
      <name>Hermann Ney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09257v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09257v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09253v3</id>
    <updated>2020-01-11T17:26:25Z</updated>
    <published>2019-12-19T15:04:24Z</published>
    <title>Towards a Philological Metric through a Topological Data Analysis
  Approach</title>
    <summary>  The canon of the baroque Spanish literature has been thoroughly studied with
philological techniques. The major representatives of the poetry of this epoch
are Francisco de Quevedo and Luis de G\'ongora y Argote. They are commonly
classified by the literary experts in two different streams: Quevedo belongs to
the Conceptismo and G\'ongora to the Culteranismo. Besides, traditionally, even
if Quevedo is considered the most representative of the Conceptismo, Lope de
Vega is also considered to be, at least, closely related to this literary
trend. In this paper, we use Topological Data Analysis techniques to provide a
first approach to a metric distance between the literary style of these poets.
As a consequence, we reach results that are under the literary experts'
criteria, locating the literary style of Lope de Vega, closer to the one of
Quevedo than to the one of G\'ongora.
</summary>
    <author>
      <name>Eduardo Paluzo-Hidalgo</name>
    </author>
    <author>
      <name>Rocio Gonzalez-Diaz</name>
    </author>
    <author>
      <name>Miguel A. Gutiérrez-Naranjo</name>
    </author>
    <link href="http://arxiv.org/abs/1912.09253v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09253v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09156v1</id>
    <updated>2019-12-19T12:17:38Z</updated>
    <published>2019-12-19T12:17:38Z</published>
    <title>CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial
  Reading Comprehension</title>
    <summary>  We present a Chinese judicial reading comprehension (CJRC) dataset which
contains approximately 10K documents and almost 50K questions with answers. The
documents come from judgment documents and the questions are annotated by law
experts. The CJRC dataset can help researchers extract elements by reading
comprehension technology. Element extraction is an important task in the legal
field. However, it is difficult to predefine the element types completely due
to the diversity of document types and causes of action. By contrast, machine
reading comprehension technology can quickly extract elements by answering
various questions from the long document. We build two strong baseline models
based on BERT and BiDAF. The experimental results show that there is enough
space for improvement compared to human annotators.
</summary>
    <author>
      <name>Xingyi Duan</name>
    </author>
    <author>
      <name>Baoxin Wang</name>
    </author>
    <author>
      <name>Ziyue Wang</name>
    </author>
    <author>
      <name>Wentao Ma</name>
    </author>
    <author>
      <name>Yiming Cui</name>
    </author>
    <author>
      <name>Dayong Wu</name>
    </author>
    <author>
      <name>Shijin Wang</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Tianxiang Huo</name>
    </author>
    <author>
      <name>Zhen Hu</name>
    </author>
    <author>
      <name>Heng Wang</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32381-3_36</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32381-3_36" rel="related"/>
    <link href="http://arxiv.org/abs/1912.09156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09152v1</id>
    <updated>2019-12-19T12:05:36Z</updated>
    <published>2019-12-19T12:05:36Z</published>
    <title>Annotating and normalizing biomedical NEs with limited knowledge</title>
    <summary>  Named entity recognition (NER) is the very first step in the linguistic
processing of any new domain. It is currently a common process in BioNLP on
English clinical text. However, it is still in its infancy in other major
languages, as it is the case for Spanish. Presented under the umbrella of the
PharmaCoNER shared task, this paper describes a very simple method for the
annotation and normalization of pharmacological, chemical and, ultimately,
biomedical named entities in clinical cases. The system developed for the
shared task is based on limited knowledge, collected, structured and munged in
a way that clearly outperforms scores obtained by similar dictionary-based
systems for English in the past. Along with this recovering of the
knowledge-based methods for NER in subdomains, the paper also highlights the
key contribution of resource-based systems in the validation and consolidation
of both the annotation guidelines and the human annotation practices. In this
sense, some of the authors discoverings on the overall quality of human
annotated datasets question the above-mentioned `official' results obtained by
this system, that ranked second (0.91 F1-score) and first (0.916 F1-score),
respectively, in the two PharmaCoNER subtasks.
</summary>
    <author>
      <name>Fernando Sánchez León</name>
    </author>
    <author>
      <name>Ana González Ledesma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; unpublished contribution to the PharmaCoNER shared task held
  as part of BioNLP-OST 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09084v1</id>
    <updated>2019-12-19T09:40:19Z</updated>
    <published>2019-12-19T09:40:19Z</published>
    <title>Neural Simile Recognition with Cyclic Multitask Learning and Local
  Attention</title>
    <summary>  Simile recognition is to detect simile sentences and to extract simile
components, i.e., tenors and vehicles. It involves two subtasks: {\it simile
sentence classification} and {\it simile component extraction}. Recent work has
shown that standard multitask learning is effective for Chinese simile
recognition, but it is still uncertain whether the mutual effects between the
subtasks have been well captured by simple parameter sharing. We propose a
novel cyclic multitask learning framework for neural simile recognition, which
stacks the subtasks and makes them into a loop by connecting the last to the
first. It iteratively performs each subtask, taking the outputs of the previous
subtask as additional inputs to the current one, so that the interdependence
between the subtasks can be better explored. Extensive experiments show that
our framework significantly outperforms the current state-of-the-art model and
our carefully designed baselines, and the gains are still remarkable using
BERT.
</summary>
    <author>
      <name>Jiali Zeng</name>
    </author>
    <author>
      <name>Linfeng Song</name>
    </author>
    <author>
      <name>Jinsong Su</name>
    </author>
    <author>
      <name>Jun Xie</name>
    </author>
    <author>
      <name>Wei Song</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09008v1</id>
    <updated>2019-12-19T03:48:05Z</updated>
    <published>2019-12-19T03:48:05Z</published>
    <title>Discriminative Sentence Modeling for Story Ending Prediction</title>
    <summary>  Story Ending Prediction is a task that needs to select an appropriate ending
for the given story, which requires the machine to understand the story and
sometimes needs commonsense knowledge. To tackle this task, we propose a new
neural network called Diff-Net for better modeling the differences of each
ending in this task. The proposed model could discriminate two endings in three
semantic levels: contextual representation, story-aware representation, and
discriminative representation. Experimental results on the Story Cloze Test
dataset show that the proposed model siginificantly outperforms various systems
by a large margin, and detailed ablation studies are given for better
understanding our model. We also carefully examine the traditional and
BERT-based models on both SCT v1.0 and v1.5 with interesting findings that may
potentially help future studies.
</summary>
    <author>
      <name>Yiming Cui</name>
    </author>
    <author>
      <name>Wanxiang Che</name>
    </author>
    <author>
      <name>Wei-Nan Zhang</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Shijin Wang</name>
    </author>
    <author>
      <name>Guoping Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, accepted as a conference paper at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09003v1</id>
    <updated>2019-12-19T03:20:33Z</updated>
    <published>2019-12-19T03:20:33Z</published>
    <title>LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge</title>
    <summary>  This paper presents a novel Dialect Identification (DID) system developed for
the Fifth Edition of the Multi-Genre Broadcast challenge, the task of
Fine-grained Arabic Dialect Identification (MGB-5 ADI Challenge). The system
improves upon traditional DNN x-vector performance by employing a Convolutional
and Long Short Term Memory-Recurrent (CLSTM) architecture to combine the
benefits of a convolutional neural network front-end for feature extraction and
a back-end recurrent neural to capture longer temporal dependencies.
Furthermore we investigate intensive augmentation of one low resource dialect
in the highly unbalanced training set using time-scale modification (TSM). This
converts an utterance to several time-stretched or time-compressed versions,
subsequently used to train the CLSTM system without using any other corpus. In
this paper, we also investigate speech augmentation using MUSAN and the RIR
datasets to increase the quantity and diversity of the existing training data
in the normal way. Results show firstly that the CLSTM architecture outperforms
a traditional DNN x-vector implementation. Secondly, adopting TSM-based speed
perturbation yields a small performance improvement for the unbalanced data,
finally that traditional data augmentation techniques yield further benefit, in
line with evidence from related speaker and language recognition tasks. Our
system achieved 2nd place ranking out of 15 entries in the MGB-5 ADI challenge,
presented at ASRU 2019.
</summary>
    <author>
      <name>Xiaoxiao Miao</name>
    </author>
    <author>
      <name>Ian McLoughlin</name>
    </author>
    <link href="http://arxiv.org/abs/1912.09003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08981v1</id>
    <updated>2019-12-19T01:45:36Z</updated>
    <published>2019-12-19T01:45:36Z</published>
    <title>Identifying Adversarial Sentences by Analyzing Text Complexity</title>
    <summary>  Attackers create adversarial text to deceive both human perception and the
current AI systems to perform malicious purposes such as spam product reviews
and fake political posts. We investigate the difference between the adversarial
and the original text to prevent the risk. We prove that the text written by a
human is more coherent and fluent. Moreover, the human can express the idea
through the flexible text with modern words while a machine focuses on
optimizing the generated text by the simple and common words. We also suggest a
method to identify the adversarial text by extracting the features related to
our findings. The proposed method achieves high performance with 82.0% of
accuracy and 18.4% of equal error rate, which is better than the existing
methods whose the best accuracy is 77.0% corresponding to the error rate 22.8%.
</summary>
    <author>
      <name>Hoang-Quoc Nguyen-Son</name>
    </author>
    <author>
      <name>Tran Phuong Thao</name>
    </author>
    <author>
      <name>Seira Hidano</name>
    </author>
    <author>
      <name>Shinsaku Kiyomoto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PACLIC 2019, 9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08981v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08981v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08960v1</id>
    <updated>2019-12-19T00:27:40Z</updated>
    <published>2019-12-19T00:27:40Z</published>
    <title>Going Beneath the Surface: Evaluating Image Captioning for
  Grammaticality, Truthfulness and Diversity</title>
    <summary>  Image captioning as a multimodal task has drawn much interest in recent
years. However, evaluation for this task remains a challenging problem.
Existing evaluation metrics focus on surface similarity between a candidate
caption and a set of reference captions, and do not check the actual relation
between a caption and the underlying visual content. We introduce a new
diagnostic evaluation framework for the task of image captioning, with the goal
of directly assessing models for grammaticality, truthfulness and diversity
(GTD) of generated captions. We demonstrate the potential of our evaluation
framework by evaluating existing image captioning models on a wide ranging set
of synthetic datasets that we construct for diagnostic evaluation. We
empirically show how the GTD evaluation framework, in combination with
diagnostic datasets, can provide insights into model capabilities and
limitations to supplement standard evaluations.
</summary>
    <author>
      <name>Huiyuan Xie</name>
    </author>
    <author>
      <name>Tom Sherborne</name>
    </author>
    <author>
      <name>Alexander Kuhnle</name>
    </author>
    <author>
      <name>Ann Copestake</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04346v1</id>
    <updated>2019-12-18T23:48:42Z</updated>
    <published>2019-12-18T23:48:42Z</published>
    <title>Asymmetrical Hierarchical Networks with Attentive Interactions for
  Interpretable Review-Based Recommendation</title>
    <summary>  Recently, recommender systems have been able to emit substantially improved
recommendations by leveraging user-provided reviews. Existing methods typically
merge all reviews of a given user or item into a long document, and then
process user and item documents in the same manner. In practice, however, these
two sets of reviews are notably different: users' reviews reflect a variety of
items that they have bought and are hence very heterogeneous in their topics,
while an item's reviews pertain only to that single item and are thus topically
homogeneous. In this work, we develop a novel neural network model that
properly accounts for this important difference by means of asymmetric
attentive modules. The user module learns to attend to only those signals that
are relevant with respect to the target item, whereas the item module learns to
extract the most salient contents with regard to properties of the item. Our
multi-hierarchical paradigm accounts for the fact that neither are all reviews
equally useful, nor are all sentences within each review equally pertinent.
Extensive experimental results on a variety of real datasets demonstrate the
effectiveness of our method.
</summary>
    <author>
      <name>Xin Dong</name>
    </author>
    <author>
      <name>Jingchao Ni</name>
    </author>
    <author>
      <name>Wei Cheng</name>
    </author>
    <author>
      <name>Zhengzhang Chen</name>
    </author>
    <author>
      <name>Bo Zong</name>
    </author>
    <author>
      <name>Dongjin Song</name>
    </author>
    <author>
      <name>Yanchi Liu</name>
    </author>
    <author>
      <name>Haifeng Chen</name>
    </author>
    <author>
      <name>Gerard de Melo</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08904v1</id>
    <updated>2019-12-18T21:51:22Z</updated>
    <published>2019-12-18T21:51:22Z</published>
    <title>Macaw: An Extensible Conversational Information Seeking Platform</title>
    <summary>  Conversational information seeking (CIS) has been recognized as a major
emerging research area in information retrieval. Such research will require
data and tools, to allow the implementation and study of conversational
systems. This paper introduces Macaw, an open-source framework with a modular
architecture for CIS research. Macaw supports multi-turn, multi-modal, and
mixed-initiative interactions, and enables research for tasks such as document
retrieval, question answering, recommendation, and structured data exploration.
It has a modular design to encourage the study of new CIS algorithms, which can
be evaluated in batch mode. It can also integrate with a user interface, which
allows user studies and data collection in an interactive mode, where the back
end can be fully algorithmic or a wizard of oz setup. Macaw is distributed
under the MIT License.
</summary>
    <author>
      <name>Hamed Zamani</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08868v1</id>
    <updated>2019-12-18T20:11:03Z</updated>
    <published>2019-12-18T20:11:03Z</published>
    <title>Topic subject creation using unsupervised learning for topic modeling</title>
    <summary>  We describe the use of Non-Negative Matrix Factorization (NMF) and Latent
Dirichlet Allocation (LDA) algorithms to perform topic mining and labelling
applied to retail customer communications in attempt to characterize the
subject of customers inquiries. In this paper we compare both algorithms in the
topic mining performance and propose methods to assign topic subject labels in
an automated way.
</summary>
    <author>
      <name>Rashid Mehdiyev</name>
    </author>
    <author>
      <name>Jean Nava</name>
    </author>
    <author>
      <name>Karan Sodhi</name>
    </author>
    <author>
      <name>Saurav Acharya</name>
    </author>
    <author>
      <name>Annie Ibrahim Rana</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08830v1</id>
    <updated>2019-12-18T19:00:49Z</updated>
    <published>2019-12-18T19:00:49Z</published>
    <title>ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language</title>
    <summary>  We introduce the new task of 3D object localization in RGB-D scans using
natural language descriptions. As input, we assume a point cloud of a scanned
3D scene along with a free-form description of a specified target object. To
address this task, we propose ScanRefer, where the core idea is to learn a
fused descriptor from 3D object proposals and encoded sentence embeddings. This
learned descriptor then correlates the language expressions with the underlying
geometric features of the 3D scan and facilitates the regression of the 3D
bounding box of the target object. In order to train and benchmark our method,
we introduce a new ScanRefer dataset, containing 46,173 descriptions of 9,943
objects from 703 ScanNet scenes. ScanRefer is the first large-scale effort to
perform object localization via natural language expression directly in 3D.
</summary>
    <author>
      <name>Dave Zhenyu Chen</name>
    </author>
    <author>
      <name>Angel X. Chang</name>
    </author>
    <author>
      <name>Matthias Nießner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Video: https://youtu.be/T9J5t-UEcNA</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08777v1</id>
    <updated>2019-12-18T18:16:20Z</updated>
    <published>2019-12-18T18:16:20Z</published>
    <title>PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive
  Summarization</title>
    <summary>  Recent work pre-training Transformers with self-supervised objectives on
large text corpora has shown great success when fine-tuned on downstream NLP
tasks including text summarization. However, pre-training objectives tailored
for abstractive text summarization have not been explored. Furthermore there is
a lack of systematic evaluation across diverse domains. In this work, we
propose pre-training large Transformer-based encoder-decoder models on massive
text corpora with a new self-supervised objective. In PEGASUS, important
sentences are removed/masked from an input document and are generated together
as one output sequence from the remaining sentences, similar to an extractive
summary. We evaluated our best PEGASUS model on 12 downstream summarization
tasks spanning news, science, stories, instructions, emails, patents, and
legislative bills. Experiments demonstrate it achieves state-of-the-art
performance on all 12 downstream datasets measured by ROUGE scores. Our model
also shows surprising performance on low-resource summarization, surpassing
previous state-of-the-art results on 6 datasets with only 1000 examples.
</summary>
    <author>
      <name>Jingqing Zhang</name>
    </author>
    <author>
      <name>Yao Zhao</name>
    </author>
    <author>
      <name>Mohammad Saleh</name>
    </author>
    <author>
      <name>Peter J. Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10166v1</id>
    <updated>2019-12-18T17:42:31Z</updated>
    <published>2019-12-18T17:42:31Z</published>
    <title>MedCAT -- Medical Concept Annotation Tool</title>
    <summary>  Biomedical documents such as Electronic Health Records (EHRs) contain a large
amount of information in an unstructured format. The data in EHRs is a hugely
valuable resource documenting clinical narratives and decisions, but whilst the
text can be easily understood by human doctors it is challenging to use in
research and clinical applications. To uncover the potential of biomedical
documents we need to extract and structure the information they contain. The
task at hand is Named Entity Recognition and Linking (NER+L). The number of
entities, ambiguity of words, overlapping and nesting make the biomedical area
significantly more difficult than many others. To overcome these difficulties,
we have developed the Medical Concept Annotation Tool (MedCAT), an open-source
unsupervised approach to NER+L. MedCAT uses unsupervised machine learning to
disambiguate entities. It was validated on MIMIC-III (a freely accessible
critical care database) and MedMentions (Biomedical papers annotated with
mentions from the Unified Medical Language System). In case of NER+L, the
comparison with existing tools shows that MedCAT improves the previous best
with only unsupervised learning (F1=0.848 vs 0.691 for disease detection;
F1=0.710 vs. 0.222 for general concept detection). A qualitative analysis of
the vector embeddings learnt by MedCAT shows that it captures latent medical
knowledge available in EHRs (MIMIC-III). Unsupervised learning can improve the
performance of large scale entity extraction, but it has some limitations when
working with only a couple of entities and a small dataset. In that case
options are supervised learning or active learning, both of which are supported
in MedCAT via the MedCATtrainer extension. Our approach can detect and link
millions of different biomedical concepts with state-of-the-art performance,
whilst being lightweight, fast and easy to use.
</summary>
    <author>
      <name>Zeljko Kraljevic</name>
    </author>
    <author>
      <name>Daniel Bean</name>
    </author>
    <author>
      <name>Aurelie Mascio</name>
    </author>
    <author>
      <name>Lukasz Roguski</name>
    </author>
    <author>
      <name>Amos Folarin</name>
    </author>
    <author>
      <name>Angus Roberts</name>
    </author>
    <author>
      <name>Rebecca Bendayan</name>
    </author>
    <author>
      <name>Richard Dobson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint, 25 pages, 5 figures and 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08633v1</id>
    <updated>2019-12-18T14:33:05Z</updated>
    <published>2019-12-18T14:33:05Z</published>
    <title>Semantic integration of disease-specific knowledge</title>
    <summary>  Biomedical researchers working on a specific disease need up-to-date and
unified access to knowledge relevant to the disease of their interest.
Knowledge is continuously accumulated in scientific literature and other
resources such as biomedical ontologies. Identifying the specific information
needed is a challenging task and computational tools can be valuable. In this
study, we propose a pipeline to automatically retrieve and integrate relevant
knowledge based on a semantic graph representation, the iASiS Open Data Graph.
  Results: The disease-specific semantic graph can provide easy access to
resources relevant to specific concepts and individual aspects of these
concepts, in the form of concept relations and attributes. The proposed
approach is applied to three different case studies: Two prevalent diseases,
Lung Cancer and Dementia, for which a lot of knowledge is available, and one
rare disease, Duchenne Muscular Dystrophy, for which knowledge is less abundant
and difficult to locate. Results from exemplary queries are presented,
investigating the potential of this approach in integrating and accessing
knowledge as an automatically generated semantic graph.
</summary>
    <author>
      <name>Anastasios Nentidis</name>
    </author>
    <author>
      <name>Konstantinos Bougiatiotis</name>
    </author>
    <author>
      <name>Anastasia Krithara</name>
    </author>
    <author>
      <name>Georgios Paliouras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08582v1</id>
    <updated>2019-12-18T13:13:29Z</updated>
    <published>2019-12-18T13:13:29Z</published>
    <title>Towards an automatic recognition of mixed languages: The
  Ukrainian-Russian hybrid language Surzhyk</title>
    <summary>  Language interference is common in today's multilingual societies where more
languages are being in contact and as a global final result leads to the
creation of hybrid languages. These, together with doubts on their right to be
officially recognised made emerge in the area of computational linguistics the
problem of their automatic identification and further elaboration. In this
paper, we propose a first attempt to identify the elements of a
Ukrainian-Russian hybrid language, Surzhyk, through the adoption of the
example-based rules created with the instruments of programming language R. Our
example-based study consists of: 1) analysis of spoken samples of Surzhyk
registered by Del Gaudio (2010) in Kyiv area and creation of the written
corpus; 2) production of specific rules on the identification of Surzhyk
patterns and their implementation; 3) testing the code and analysing the
effectiveness.
</summary>
    <author>
      <name>Nataliya Sira</name>
    </author>
    <author>
      <name>Giorgio Maria Di Nunzio</name>
    </author>
    <author>
      <name>Viviana Nosilia</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11151v1</id>
    <updated>2019-12-18T12:26:38Z</updated>
    <published>2019-12-18T12:26:38Z</published>
    <title>A Cycle-GAN Approach to Model Natural Perturbations in Speech for ASR
  Applications</title>
    <summary>  Naturally introduced perturbations in audio signal, caused by emotional and
physical states of the speaker, can significantly degrade the performance of
Automatic Speech Recognition (ASR) systems. In this paper, we propose a
front-end based on Cycle-Consistent Generative Adversarial Network (CycleGAN)
which transforms naturally perturbed speech into normal speech, and hence
improves the robustness of an ASR system. The CycleGAN model is trained on
non-parallel examples of perturbed and normal speech. Experiments on
spontaneous laughter-speech and creaky-speech datasets show that the
performance of four different ASR systems improve by using speech obtained from
CycleGAN based front-end, as compared to directly using the original perturbed
speech. Visualization of the features of the laughter perturbed speech and
those generated by the proposed front-end further demonstrates the
effectiveness of our approach.
</summary>
    <author>
      <name>Sri Harsha Dumpala</name>
    </author>
    <author>
      <name>Imran Sheikh</name>
    </author>
    <author>
      <name>Rupayan Chakraborty</name>
    </author>
    <author>
      <name>Sunil Kumar Kopparapu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, ICASSP-2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08555v1</id>
    <updated>2019-12-18T12:13:30Z</updated>
    <published>2019-12-18T12:13:30Z</published>
    <title>Curriculum Learning Strategies for IR: An Empirical Study on
  Conversation Response Ranking</title>
    <summary>  Neural ranking models are traditionally trained on a series of random
batches, sampled uniformly from the entire training set. Curriculum learning
has recently been shown to improve neural models' effectiveness by sampling
batches non-uniformly, going from easy to difficult instances during training.
In the context of neural Information Retrieval (IR) curriculum learning has not
been explored yet, and so it remains unclear (1) how to measure the difficulty
of training instances and (2) how to transition from easy to difficult
instances during training. To address both challenges and determine whether
curriculum learning is beneficial for neural ranking models, we need
large-scale datasets and a retrieval task that allows us to conduct a wide
range of experiments. For this purpose, we resort to the task of conversation
response ranking: ranking responses given the conversation history. In order to
deal with challenge (1), we explore scoring functions to measure the difficulty
of conversations based on different input spaces. To address challenge (2) we
evaluate different pacing functions, which determine the velocity in which we
go from easy to difficult instances. We find that, overall, by just
intelligently sorting the training data (i.e., by performing curriculum
learning) we can improve the retrieval effectiveness by up to 2%.
</summary>
    <author>
      <name>Gustavo Penha</name>
    </author>
    <author>
      <name>Claudia Hauff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the 42nd European Conference on
  Information Retrieval (ECIR'20)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08555v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08555v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08494v1</id>
    <updated>2019-12-18T10:07:20Z</updated>
    <published>2019-12-18T10:07:20Z</published>
    <title>A Survey on Document-level Machine Translation: Methods and Evaluation</title>
    <summary>  Machine translation (MT) is an important task in natural language processing
(NLP) as it automates the translation process and reduces the reliance on human
translators. With the advent of neural networks, the translation quality
surpasses that of the translations obtained using statistical techniques. Up
until three years ago, all neural translation models translated sentences
independently, without incorporating any extra-sentential information. The aim
of this paper is to highlight the major works that have been undertaken in the
space of document-level machine translation before and after the neural
revolution so that researchers can recognise where we started from and which
direction we are heading in. When talking about the literature in statistical
machine translation (SMT), we focus on works which have tried to improve the
translation of specific discourse phenomena, while in neural machine
translation (NMT), we focus on works which use the wider context explicitly. In
addition to this, we also cover the evaluation strategies that have been
introduced to account for the improvements in this domain.
</summary>
    <author>
      <name>Sameen Maruf</name>
    </author>
    <author>
      <name>Fahimeh Saleh</name>
    </author>
    <author>
      <name>Gholamreza Haffari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This article is under-review at an international journal. This arXiv
  version has been made available to solicit feedback</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08492v1</id>
    <updated>2019-12-18T10:05:49Z</updated>
    <published>2019-12-18T10:05:49Z</published>
    <title>Generating summaries tailored to target characteristics</title>
    <summary>  Recently, research efforts have gained pace to cater to varied user
preferences while generating text summaries. While there have been attempts to
incorporate a few handpicked characteristics such as length or entities, a
holistic view around these preferences is missing and crucial insights on why
certain characteristics should be incorporated in a specific manner are absent.
With this objective, we provide a categorization around these characteristics
relevant to the task of text summarization: one, focusing on what content needs
to be generated and second, focusing on the stylistic aspects of the output
summaries. We use our insights to provide guidelines on appropriate methods to
incorporate various classes characteristics in sequence-to-sequence
summarization framework. Our experiments with incorporating topics, readability
and simplicity indicate the viability of the proposed prescriptions
</summary>
    <author>
      <name>Kushal Chawla</name>
    </author>
    <author>
      <name>Hrituraj Singh</name>
    </author>
    <author>
      <name>Arijit Pramanik</name>
    </author>
    <author>
      <name>Mithlesh Kumar</name>
    </author>
    <author>
      <name>Balaji Vasan Srinivasan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appeared in CiCLing 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08462v2</id>
    <updated>2019-12-25T17:14:07Z</updated>
    <published>2019-12-18T09:08:05Z</published>
    <title>End-to-end training of time domain audio separation and recognition</title>
    <summary>  The rising interest in single-channel multi-speaker speech separation sparked
development of End-to-End (E2E) approaches to multi-speaker speech recognition.
However, up until now, state-of-the-art neural network-based time domain source
separation has not yet been combined with E2E speech recognition. We here
demonstrate how to combine a separation module based on a Convolutional Time
domain Audio Separation Network (Conv-TasNet) with an E2E speech recognizer and
how to train such a model jointly by distributing it over multiple GPUs or by
approximating truncated back-propagation for the convolutional front-end. To
put this work into perspective and illustrate the complexity of the design
space, we provide a compact overview of single-channel multi-speaker
recognition systems. Our experiments show a word error rate of 11.0% on
WSJ0-2mix and indicate that our joint time domain model can yield substantial
improvements over cascade DNN-HMM and monolithic E2E frequency domain systems
proposed so far.
</summary>
    <author>
      <name>Thilo von Neumann</name>
    </author>
    <author>
      <name>Keisuke Kinoshita</name>
    </author>
    <author>
      <name>Lukas Drude</name>
    </author>
    <author>
      <name>Christoph Boeddeker</name>
    </author>
    <author>
      <name>Marc Delcroix</name>
    </author>
    <author>
      <name>Tomohiro Nakatani</name>
    </author>
    <author>
      <name>Reinhold Haeb-Umbach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, to appear in ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08462v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08462v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08442v1</id>
    <updated>2019-12-18T08:14:10Z</updated>
    <published>2019-12-18T08:14:10Z</published>
    <title>MALA: Cross-Domain Dialogue Generation with Action Learning</title>
    <summary>  Response generation for task-oriented dialogues involves two basic
components: dialogue planning and surface realization. These two components,
however, have a discrepancy in their objectives, i.e., task completion and
language quality. To deal with such discrepancy, conditioned response
generation has been introduced where the generation process is factorized into
action decision and language generation via explicit action representations. To
obtain action representations, recent studies learn latent actions in an
unsupervised manner based on the utterance lexical similarity. Such an action
learning approach is prone to diversities of language surfaces, which may
impinge task completion and language quality. To address this issue, we propose
multi-stage adaptive latent action learning (MALA) that learns semantic latent
actions by distinguishing the effects of utterances on dialogue progress. We
model the utterance effect using the transition of dialogue states caused by
the utterance and develop a semantic similarity measurement that estimates
whether utterances have similar effects. For learning semantic actions on
domains without dialogue states, MsALA extends the semantic similarity
measurement across domains progressively, i.e., from aligning shared actions to
learning domain-specific actions. Experiments using multi-domain datasets, SMD
and MultiWOZ, show that our proposed model achieves consistent improvements
over the baselines models in terms of both task completion and language
quality.
</summary>
    <author>
      <name>Xinting Huang</name>
    </author>
    <author>
      <name>Jianzhong Qi</name>
    </author>
    <author>
      <name>Yu Sun</name>
    </author>
    <author>
      <name>Rui Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08441v2</id>
    <updated>2019-12-19T02:12:09Z</updated>
    <published>2019-12-18T08:13:43Z</published>
    <title>Multi-channel Reverse Dictionary Model</title>
    <summary>  A reverse dictionary takes the description of a target word as input and
outputs the target word together with other words that match the description.
Existing reverse dictionary methods cannot deal with highly variable input
queries and low-frequency target words successfully. Inspired by the
description-to-word inference process of humans, we propose the multi-channel
reverse dictionary model, which can mitigate the two problems simultaneously.
Our model comprises a sentence encoder and multiple predictors. The predictors
are expected to identify different characteristics of the target word from the
input query. We evaluate our model on English and Chinese datasets including
both dictionary definitions and human-written descriptions. Experimental
results show that our model achieves the state-of-the-art performance, and even
outperforms the most popular commercial reverse dictionary system on the
human-written description dataset. We also conduct quantitative analyses and a
case study to demonstrate the effectiveness and robustness of our model. All
the code and data of this work can be obtained on
https://github.com/thunlp/MultiRD.
</summary>
    <author>
      <name>Lei Zhang</name>
    </author>
    <author>
      <name>Fanchao Qi</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <author>
      <name>Yasheng Wang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI Conference on Artificial Intelligence 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08441v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08441v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08404v1</id>
    <updated>2019-12-18T06:25:12Z</updated>
    <published>2019-12-18T06:25:12Z</published>
    <title>Collective Embedding-based Entity Alignment via Adaptive Features</title>
    <summary>  Entity alignment (EA) identifies entities that refer to the same real-world
object but locate in different knowledge graphs (KGs), and has been harnessed
for KG construction and integration. When generating EA results, current
embedding-based solutions treat entities independently and fail to take into
account the interdependence between entities. In addition, most of
embedding-based EA methods either fuse different features on
representation-level and generate unified entity embedding for alignment, which
potentially causes information loss, or aggregate features on outcome-level
with hand-tuned weights, which is not practical with increasing numbers of
features. To tackle these deficiencies, we propose a collective embedding-based
EA framework with adaptive feature fusion mechanism. We first employ three
representative features, i.e., structural, semantic and string signals, for
capturing different aspects of the similarity between entities in heterogeneous
KGs. These features are then integrated at outcome-level, with dynamically
assigned weights generated by our carefully devised adaptive feature fusion
strategy. Eventually, in order to make collective EA decisions, we formulate EA
as the classical stable matching problem between entities to be aligned, with
preference lists constructed using fused feature matrix. It is further
effectively solved by deferred acceptance algorithm. Our proposal is evaluated
on both cross-lingual and mono-lingual EA benchmarks against state-of-the-art
solutions, and the empirical results verify its effectiveness and superiority.
We also perform ablation study to gain insights into framework modules.
</summary>
    <author>
      <name>Wexin Zeng</name>
    </author>
    <author>
      <name>Xiang Zhao</name>
    </author>
    <author>
      <name>Jiuyang Tang</name>
    </author>
    <author>
      <name>Xuemin Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08374v3</id>
    <updated>2020-01-24T03:49:50Z</updated>
    <published>2019-12-18T04:32:18Z</published>
    <title>Uncovering Relations for Marketing Knowledge Representation</title>
    <summary>  Online behaviors of consumers and marketers generate massive marketing data,
which ever more sophisticated models attempt to turn into insights and aid
decisions by marketers. Yet, in making decisions human managers bring to bear
marketing knowledge which reside outside of data and models. Thus, it behooves
creation of an automated marketing knowledge base that can interact with data
and models. Currently, marketing knowledge is dispersed in large corpora, but
no definitive knowledge base for marketing exists. Out of the two broad aspects
of marketing knowledge - representation and reasoning - this treatise focuses
on the former. Specifically, we focus on creation of marketing knowledge graph
from corpora, which requires identification of entities and relations. The
relation identification task is particularly challenging in marketing, because
of the non-factoid nature of much marketing knowledge, and the difficulty of
forming rules that govern relations. Specifically, we define a set of relations
to capture marketing knowledge, propose a pipeline for creating the knowledge
graph from text and propose a rule-guided semi-supervised relation prediction
algorithm to extract relations between marketing entities from sentences.
</summary>
    <author>
      <name>Somak Aditya</name>
    </author>
    <author>
      <name>Atanu Sinha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, 8 tables (2 page Appendix)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08374v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08374v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08360v1</id>
    <updated>2019-12-18T03:09:12Z</updated>
    <published>2019-12-18T03:09:12Z</published>
    <title>DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog</title>
    <summary>  Visual Dialog is a vision-language task that requires an AI agent to engage
in a conversation with humans grounded in an image. It remains a challenging
task since it requires the agent to fully understand a given question before
making an appropriate response not only from the textual dialog history, but
also from the visually-grounded information. While previous models typically
leverage single-hop reasoning or single-channel reasoning to deal with this
complex multimodal reasoning task, which is intuitively insufficient. In this
paper, we thus propose a novel and more powerful Dual-channel Multi-hop
Reasoning Model for Visual Dialog, named DMRM. DMRM synchronously captures
information from the dialog history and the image to enrich the semantic
representation of the question by exploiting dual-channel reasoning.
Specifically, DMRM maintains a dual channel to obtain the question- and
history-aware image features and the question- and image-aware dialog history
features by a mulit-hop reasoning process in each channel. Additionally, we
also design an effective multimodal attention to further enhance the decoder to
generate more accurate responses. Experimental results on the VisDial v0.9 and
v1.0 datasets demonstrate that the proposed model is effective and outperforms
compared models by a significant margin.
</summary>
    <author>
      <name>Feilong Chen</name>
    </author>
    <author>
      <name>Fandong Meng</name>
    </author>
    <author>
      <name>Jiaming Xu</name>
    </author>
    <author>
      <name>Peng Li</name>
    </author>
    <author>
      <name>Bo Xu</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08320v1</id>
    <updated>2019-12-17T23:49:19Z</updated>
    <published>2019-12-17T23:49:19Z</published>
    <title>Garbage In, Garbage Out? Do Machine Learning Application Papers in
  Social Computing Report Where Human-Labeled Training Data Comes From?</title>
    <summary>  Many machine learning projects for new application areas involve teams of
humans who label data for a particular purpose, from hiring crowdworkers to the
paper's authors labeling the data themselves. Such a task is quite similar to
(or a form of) structured content analysis, which is a longstanding methodology
in the social sciences and humanities, with many established best practices. In
this paper, we investigate to what extent a sample of machine learning
application papers in social computing --- specifically papers from ArXiv and
traditional publications performing an ML classification task on Twitter data
--- give specific details about whether such best practices were followed. Our
team conducted multiple rounds of structured content analysis of each paper,
making determinations such as: Does the paper report who the labelers were,
what their qualifications were, whether they independently labeled the same
items, whether inter-rater reliability metrics were disclosed, what level of
training and/or instructions were given to labelers, whether compensation for
crowdworkers is disclosed, and if the training data is publicly available. We
find a wide divergence in whether such practices were followed and documented.
Much of machine learning research and education focuses on what is done once a
"gold standard" of training data is available, but we discuss issues around the
equally-important aspect of whether such data is reliable in the first place.
</summary>
    <author>
      <name>R. Stuart Geiger</name>
    </author>
    <author>
      <name>Kevin Yu</name>
    </author>
    <author>
      <name>Yanlai Yang</name>
    </author>
    <author>
      <name>Mindy Dai</name>
    </author>
    <author>
      <name>Jie Qiu</name>
    </author>
    <author>
      <name>Rebekah Tang</name>
    </author>
    <author>
      <name>Jenny Huang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3351095.3372862</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3351095.3372862" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, includes appendix</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc ACM FAT* 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.08320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10824v1</id>
    <updated>2019-12-17T23:01:54Z</updated>
    <published>2019-12-17T23:01:54Z</published>
    <title>Differentiable Reasoning on Large Knowledge Bases and Natural Language</title>
    <summary>  Reasoning with knowledge expressed in natural language and Knowledge Bases
(KBs) is a major challenge for Artificial Intelligence, with applications in
machine reading, dialogue, and question answering. General neural architectures
that jointly learn representations and transformations of text are very
data-inefficient, and it is hard to analyse their reasoning process. These
issues are addressed by end-to-end differentiable reasoning systems such as
Neural Theorem Provers (NTPs), although they can only be used with small-scale
symbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension
to NTPs addressing their complexity and scalability limitations, thus making
them applicable to real-world datasets. This result is achieved by dynamically
constructing the computation graph of NTPs and including only the most
promising proof paths during inference, thus obtaining orders of magnitude more
efficient models. Then, we propose a novel approach for jointly reasoning over
KBs and textual mentions, by embedding logic facts and natural language
sentences in a shared embedding space. We show that GNTPs perform on par with
NTPs at a fraction of their cost while achieving competitive link prediction
results on large datasets, providing explanations for predictions, and inducing
interpretable models. Source code, datasets, and supplementary material are
available online at https://github.com/uclnlp/gntp.
</summary>
    <author>
      <name>Pasquale Minervini</name>
    </author>
    <author>
      <name>Matko Bošnjak</name>
    </author>
    <author>
      <name>Tim Rocktäschel</name>
    </author>
    <author>
      <name>Sebastian Riedel</name>
    </author>
    <author>
      <name>Edward Grefenstette</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 34th AAAI Conference on Artificial Intelligence
  (AAAI-20)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08290v1</id>
    <updated>2019-12-17T21:58:51Z</updated>
    <published>2019-12-17T21:58:51Z</published>
    <title>The performance evaluation of Multi-representation in the Deep Learning
  models for Relation Extraction Task</title>
    <summary>  Single implementing, concatenating, adding or replacing of the
representations has yielded significant improvements on many NLP tasks. Mainly
in Relation Extraction where static, contextualized and others representations
that are capable of explaining word meanings through the linguistic features
that these incorporates. In this work addresses the question of how is improved
the relation extraction using different types of representations generated by
pretrained language representation models. We benchmarked our approach using
popular word representation models, replacing and concatenating static,
contextualized and others representations of hand-extracted features. The
experiments show that representation is a crucial element to choose when DL
approach is applied. Word embeddings from Flair and BERT can be well
interpreted by a deep learning model for RE task, and replacing static word
embeddings with contextualized word representations could lead to significant
improvements. While, the hand-created representations requires is
time-consuming and not is ensure a improve in combination with others
representations.
</summary>
    <author>
      <name>Jefferson A. Peña Torres</name>
    </author>
    <author>
      <name>Raul Ernesto Gutierrez</name>
    </author>
    <author>
      <name>Victor A. Bucheli</name>
    </author>
    <author>
      <name>Fabio A. Gonzalez O</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 tables, 4 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50, 68T35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08282v1</id>
    <updated>2019-12-17T21:38:22Z</updated>
    <published>2019-12-17T21:38:22Z</published>
    <title>Chinese Named Entity Recognition Augmented with Lexicon Memory</title>
    <summary>  Inspired by a concept of content-addressable retrieval from cognitive
science, we propose a novel fragment-based model augmented with a lexicon-based
memory for Chinese NER, in which both the character-level and word-level
features are combined to generate better feature representations for possible
name candidates. It is observed that locating the boundary information of
entity names is useful in order to classify them into pre-defined categories.
Position-dependent features, including prefix and suffix are introduced for NER
in the form of distributed representation. The lexicon-based memory is used to
help generate such position-dependent features and deal with the problem of
out-of-vocabulary words. Experimental results showed that the proposed model,
called LEMON, achieved state-of-the-art on four datasets.
</summary>
    <author>
      <name>Yi Zhou</name>
    </author>
    <author>
      <name>Xiaoqing Zheng</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08259v1</id>
    <updated>2019-12-17T20:15:34Z</updated>
    <published>2019-12-17T20:15:34Z</published>
    <title>Open Set Authorship Attribution toward Demystifying Victorian
  Periodicals</title>
    <summary>  Existing research in computational authorship attribution (AA) has primarily
focused on attribution tasks with a limited number of authors in a closed-set
configuration. This restricted set-up is far from being realistic in dealing
with highly entangled real-world AA tasks that involve a large number of
candidate authors for attribution during test time. In this paper, we study AA
in historical texts using anew data set compiled from the Victorian literature.
We investigate the predictive capacity of most common English words in
distinguishing writings of most prominent Victorian novelists. We challenged
the closed-set classification assumption and discussed the limitations of
standard machine learning techniques in dealing with the open set AA task. Our
experiments suggest that a linear classifier can achieve near perfect
attribution accuracy under closed set assumption yet, the need for more robust
approaches becomes evident once a large candidate pool has to be considered in
the open-set classification setting.
</summary>
    <author>
      <name>Sarkhan Badirli</name>
    </author>
    <author>
      <name>Mary Borgo Ton</name>
    </author>
    <author>
      <name>Abdulmecit Gungor</name>
    </author>
    <author>
      <name>Murat Dundar</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08226v1</id>
    <updated>2019-12-17T19:03:23Z</updated>
    <published>2019-12-17T19:03:23Z</published>
    <title>M$^2$: Meshed-Memory Transformer for Image Captioning</title>
    <summary>  Transformer-based architectures represent the state of the art in sequence
modeling tasks like machine translation and language understanding. Their
applicability to multi-modal contexts like image captioning, however, is still
largely under-explored. With the aim of filling this gap, we present M$^2$ - a
Meshed Transformer with Memory for Image Captioning. The architecture improves
both the image encoding and the language generation steps: it learns a
multi-level representation of the relationships between image regions
integrating learned a priori knowledge, and uses a mesh-like connectivity at
decoding stage to exploit low- and high-level features. Experimentally, we
investigate the performance of the M$^2$ Transformer and different
fully-attentive models in comparison with recurrent ones. When tested on COCO,
our proposal achieves a new state of the art in single-model and ensemble
configurations on the "Karpathy" test split and on the online test server. We
also assess its performances when describing objects unseen in the training
set. Trained models and code for reproducing the experiments are publicly
available at: https://github.com/aimagelab/meshed-memory-transformer.
</summary>
    <author>
      <name>Marcella Cornia</name>
    </author>
    <author>
      <name>Matteo Stefanini</name>
    </author>
    <author>
      <name>Lorenzo Baraldi</name>
    </author>
    <author>
      <name>Rita Cucchiara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Source code: https://github.com/aimagelab/meshed-memory-transformer</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08011v2</id>
    <updated>2019-12-19T12:40:45Z</updated>
    <published>2019-12-17T13:45:13Z</published>
    <title>Application of Word2vec in Phoneme Recognition</title>
    <summary>  In this paper, we present how to hybridize a Word2vec model and an
attention-based end-to-end speech recognition model. We build a phoneme
recognition system based on Listen, Attend and Spell model. And the phoneme
recognition model uses a word2vec model to initialize the embedding matrix for
the improvement of the performance, which can increase the distance among the
phoneme vectors. At the same time, in order to solve the problem of overfitting
in the 61 phoneme recognition model on TIMIT dataset, we propose a new training
method. A 61-39 phoneme mapping comparison table is used to inverse map the
phonemes of the dataset to generate more 61 phoneme training data. At the end
of training, replace the dataset with a standard dataset for corrective
training. Our model can achieve the best result under the TIMIT dataset which
is 16.5% PER (Phoneme Error Rate).
</summary>
    <author>
      <name>Xin Feng</name>
    </author>
    <author>
      <name>Lei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08011v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08011v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07976v3</id>
    <updated>2020-02-12T09:20:28Z</updated>
    <published>2019-12-17T12:47:33Z</published>
    <title>A Multi-task Learning Model for Chinese-oriented Aspect Polarity
  Classification and Aspect Term Extraction</title>
    <summary>  Aspect-based sentiment analysis (ABSA) task is a multi-grained task of
natural language processing and consists of two subtasks: aspect term
extraction (ATE) and aspect polarity classification (APC). Most of the existing
work focuses on the subtask of aspect term polarity inferring and ignores the
significance of aspect term extraction. Besides, the existing researches do not
pay attention to the research of the Chinese-oriented ABSA task. Based on the
local context focus (LCF) mechanism, this paper firstly proposes a multi-task
learning model for Chinese-oriented aspect-based sentiment analysis, namely
LCF-ATEPC. Compared with existing models, this model equips the capability of
extracting aspect term and inferring aspect term polarity synchronously,
moreover, this model is effective to analyze both Chinese and English comments
simultaneously and the experiment on a multilingual mixed dataset proved its
availability. By integrating the domain-adapted BERT model, the LCF-ATEPC model
achieved the state-of-the-art performance of aspect term extraction and aspect
polarity classification in four Chinese review datasets. Besides, the
experimental results on the most commonly used SemEval-2014 task4 Restaurant
and Laptop datasets outperform the state-of-the-art performance on the ATE and
APC subtask.
</summary>
    <author>
      <name>Heng Yang</name>
    </author>
    <author>
      <name>Biqing Zeng</name>
    </author>
    <author>
      <name>JianHao Yang</name>
    </author>
    <author>
      <name>Youwei Song</name>
    </author>
    <author>
      <name>Ruyang Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Elsevier</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07976v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07976v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07946v2</id>
    <updated>2020-02-25T16:17:59Z</updated>
    <published>2019-12-17T11:59:41Z</published>
    <title>In Nomine Function: Naming Functions in Stripped Binaries with Neural
  Networks</title>
    <summary>  In this paper we investigate the problem of automatically naming pieces of
assembly code. Where by naming we mean assigning to an assembly function a
string of words that would likely be assigned by a human reverse engineer. We
formally and precisely define the framework in which our investigation takes
place. That is we define the problem, we provide reasonable justifications for
the choices that we made for the design of training and the tests. We performed
an analysis on a large real-world corpora constituted by nearly 9 millions of
functions taken from more than 22k softwares. In such framework we test
baselines coming from the field of Natural Language Processing (e.g., Seq2Seq
networks and Transformer). Interestingly, our evaluation shows promising
results beating the state-of-the-art and reaching good performance. We
investigate the applicability of tine-tuning (i.e., taking a model already
trained on a large generic corpora and retraining it for a specific task). Such
technique is popular and well-known in the NLP field. Our results confirm that
fine-tuning is effective even when neural networks are applied to binaries. We
show that a model, pre-trained on the aforementioned corpora, when fine-tuned
has higher performances on specific domains (such as predicting names in system
utilites, malware, etc).
</summary>
    <author>
      <name>Fiorella Artuso</name>
    </author>
    <author>
      <name>Giuseppe Antonio Di Luna</name>
    </author>
    <author>
      <name>Luca Massarelli</name>
    </author>
    <author>
      <name>Leonardo Querzoni</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07946v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07946v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07943v1</id>
    <updated>2019-12-17T11:49:13Z</updated>
    <published>2019-12-17T11:49:13Z</published>
    <title>Pioneer dataset and automatic recognition of Urdu handwritten characters
  using a deep autoencoder and convolutional neural network</title>
    <summary>  Automatic recognition of Urdu handwritten digits and characters, is a
challenging task. It has applications in postal address reading, bank's cheque
processing, and digitization and preservation of handwritten manuscripts from
old ages. While there exists a significant work for automatic recognition of
handwritten English characters and other major languages of the world, the work
done for Urdu lan-guage is extremely insufficient. This paper has two goals.
Firstly, we introduce a pioneer dataset for handwritten digits and characters
of Urdu, containing samples from more than 900 individuals. Secondly, we report
results for automatic recog-nition of handwritten digits and characters as
achieved by using deep auto-encoder network and convolutional neural network.
More specifically, we use a two-layer and a three-layer deep autoencoder
network and convolutional neural network and evaluate the two frameworks in
terms of recognition accuracy. The proposed framework of deep autoencoder can
successfully recognize digits and characters with an accuracy of 97% for digits
only, 81% for characters only and 82% for both digits and characters
simultaneously. In comparison, the framework of convolutional neural network
has accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for
both digits and characters simultaneously. These frameworks can serve as
baselines for future research on Urdu handwritten text.
</summary>
    <author>
      <name>Hazrat Ali</name>
    </author>
    <author>
      <name>Ahsan Ullah</name>
    </author>
    <author>
      <name>Talha Iqbal</name>
    </author>
    <author>
      <name>Shahid Khattak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s42452-019-1914-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s42452-019-1914-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SN Applied Sciences, December 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07942v2</id>
    <updated>2020-01-14T13:28:16Z</updated>
    <published>2019-12-17T11:46:08Z</published>
    <title>Analyzing Privacy Loss in Updates of Natural Language Models</title>
    <summary>  To continuously improve quality and reflect changes in data, machine
learning-based services have to regularly re-train and update their core
models. In the setting of language models, we show that a comparative analysis
of model snapshots before and after an update can reveal a surprising amount of
detailed information about the changes in the data used for training before and
after the update. We discuss the privacy implications of our findings, propose
mitigation strategies and evaluate their effect.
</summary>
    <author>
      <name>Shruti Tople</name>
    </author>
    <author>
      <name>Marc Brockschmidt</name>
    </author>
    <author>
      <name>Boris Köpf</name>
    </author>
    <author>
      <name>Olga Ohrimenko</name>
    </author>
    <author>
      <name>Santiago Zanella-Béguelin</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07940v1</id>
    <updated>2019-12-17T11:43:17Z</updated>
    <published>2019-12-17T11:43:17Z</published>
    <title>To What Extent are Name Variants Used as Named Entities in Turkish
  Tweets?</title>
    <summary>  Social media texts differ from regular texts in various aspects. One of the
main differences is the common use of informal name variants instead of
well-formed named entities in social media compared to regular texts. These
name variants may come in the form of abbreviations, nicknames, contractions,
and hypocoristic uses, in addition to names distorted due to capitalization and
writing errors. In this paper, we present an analysis of the named entities in
a publicly-available tweet dataset in Turkish with respect to their being name
variants belonging to different categories. We also provide finer-grained
annotations of the named entities as well-formed names and different categories
of name variants, where these annotations are made publicly-available. The
analysis presented and the accompanying annotations will contribute to related
research on the treatment of named entities in social media.
</summary>
    <author>
      <name>Dilek Küçük</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07915v1</id>
    <updated>2019-12-17T10:33:17Z</updated>
    <published>2019-12-17T10:33:17Z</published>
    <title>Knowledge-Enhanced Attentive Learning for Answer Selection in Community
  Question Answering Systems</title>
    <summary>  In the community question answering (CQA) system, the answer selection task
aims to identify the best answer for a specific question, and thus is playing a
key role in enhancing the service quality through recommending appropriate
answers for new questions. Recent advances in CQA answer selection focus on
enhancing the performance by incorporating the community information,
particularly the expertise (previous answers) and authority (position in the
social network) of an answerer. However, existing approaches for incorporating
such information are limited in (a) only considering either the expertise or
the authority, but not both; (b) ignoring the domain knowledge to differentiate
topics of previous answers; and (c) simply using the authority information to
adjust the similarity score, instead of fully utilizing it in the process of
measuring the similarity between segments of the question and the answer. We
propose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which
enhances the performance through (a) considering both the expertise and the
authority of the answerer; (b) utilizing the human-labeled tags, the taxonomy
of the tags, and the votes as the domain knowledge to infer the expertise of
the answer; (c) using matrix decomposition of the social network (formed by
following-relationship) to infer the authority of the answerer and
incorporating such information in the process of evaluating the similarity
between segments. Besides, for vertical community, we incorporate an external
knowledge graph to capture more professional information for vertical CQA
systems. Then we adopt the attention mechanism to integrate the analysis of the
text of questions and answers and the aforementioned community information.
Experiments with both vertical and general CQA sites demonstrate the superior
performance of the proposed KAAS model.
</summary>
    <author>
      <name>Fengshi Jing</name>
    </author>
    <author>
      <name>Qingpeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07911v1</id>
    <updated>2019-12-17T10:29:26Z</updated>
    <published>2019-12-17T10:29:26Z</published>
    <title>A Heterogeneous Graphical Model to Understand User-Level Sentiments in
  Social Media</title>
    <summary>  Social Media has seen a tremendous growth in the last decade and is
continuing to grow at a rapid pace. With such adoption, it is increasingly
becoming a rich source of data for opinion mining and sentiment analysis. The
detection and analysis of sentiment in social media is thus a valuable topic
and attracts a lot of research efforts. Most of the earlier efforts focus on
supervised learning approaches to solve this problem, which require expensive
human annotations and therefore limits their practical use. In our work, we
propose a semi-supervised approach to predict user-level sentiments for
specific topics. We define and utilize a heterogeneous graph built from the
social networks of the users with the knowledge that connected users in social
networks typically share similar sentiments. Compared with the previous works,
we have several novelties: (1) we incorporate the influences/authoritativeness
of the users into the model, 2) we include comment-based and like-based
user-user links to the graph, 3) we superimpose multiple heterogeneous graphs
into one thereby allowing multiple types of links to exist between two users.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Jing Chen</name>
    </author>
    <author>
      <name>Haonan Sun</name>
    </author>
    <author>
      <name>Keyang Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10434v1</id>
    <updated>2019-12-17T09:01:30Z</updated>
    <published>2019-12-17T09:01:30Z</published>
    <title>Analyzing Structures in the Semantic Vector Space: A Framework for
  Decomposing Word Embeddings</title>
    <summary>  Word embeddings are rich word representations, which in combination with deep
neural networks, lead to large performance gains for many NLP tasks. However,
word embeddings are represented by dense, real-valued vectors and they are
therefore not directly interpretable. Thus, computational operations based on
them are also not well understood. In this paper, we present an approach for
analyzing structures in the semantic vector space to get a better understanding
of the underlying semantic encoding principles. We present a framework for
decomposing word embeddings into smaller meaningful units which we call
sub-vectors. The framework opens up a wide range of possibilities analyzing
phenomena in vector space semantics, as well as solving concrete NLP problems:
We introduce the category completion task and show that a sub-vector based
approach is superior to supervised techniques; We present a sub-vector based
method for solving the word analogy task, which substantially outperforms
different variants of the traditional vector-offset method.
</summary>
    <author>
      <name>Andreas Hanselowski</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07875v1</id>
    <updated>2019-12-17T08:47:30Z</updated>
    <published>2019-12-17T08:47:30Z</published>
    <title>Libri-Light: A Benchmark for ASR with Limited or No Supervision</title>
    <summary>  We introduce a new collection of spoken English audio suitable for training
speech recognition systems under limited or no supervision. It is derived from
open-source audio books from the LibriVox project. It contains over 60K hours
of audio, which is, to our knowledge, the largest freely-available corpus of
speech. The audio has been segmented using voice activity detection and is
tagged with SNR, speaker ID and genre descriptions. Additionally, we provide
baseline systems and evaluation metrics working under three settings: (1) the
zero resource/unsupervised setting (ABX), (2) the semi-supervised setting (PER,
CER) and (3) the distant supervision setting (WER). Settings (2) and (3) use
limited textual resources (10 minutes to 10 hours) aligned with the speech.
Setting (3) uses large amounts of unaligned text. They are evaluated on the
standard LibriSpeech dev and test sets for comparison with the supervised
state-of-the-art.
</summary>
    <author>
      <name>Jacob Kahn</name>
    </author>
    <author>
      <name>Morgane Rivière</name>
    </author>
    <author>
      <name>Weiyi Zheng</name>
    </author>
    <author>
      <name>Evgeny Kharitonov</name>
    </author>
    <author>
      <name>Qiantong Xu</name>
    </author>
    <author>
      <name>Pierre-Emmanuel Mazaré</name>
    </author>
    <author>
      <name>Julien Karadayi</name>
    </author>
    <author>
      <name>Vitaliy Liptchinsky</name>
    </author>
    <author>
      <name>Ronan Collobert</name>
    </author>
    <author>
      <name>Christian Fuegen</name>
    </author>
    <author>
      <name>Tatiana Likhomanenko</name>
    </author>
    <author>
      <name>Gabriel Synnaeve</name>
    </author>
    <author>
      <name>Armand Joulin</name>
    </author>
    <author>
      <name>Abdelrahman Mohamed</name>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07840v2</id>
    <updated>2020-02-15T18:48:42Z</updated>
    <published>2019-12-17T06:53:05Z</published>
    <title>Cross-Lingual Ability of Multilingual BERT: An Empirical Study</title>
    <summary>  Recent work has exhibited the surprising cross-lingual abilities of
multilingual BERT (M-BERT) -- surprising since it is trained without any
cross-lingual objective and with no aligned data. In this work, we provide a
comprehensive study of the contribution of different components in M-BERT to
its cross-lingual ability. We study the impact of linguistic properties of the
languages, the architecture of the model, and the learning objectives. The
experimental study is done in the context of three typologically different
languages -- Spanish, Hindi, and Russian -- and using two conceptually
different NLP tasks, textual entailment and named entity recognition. Among our
key conclusions is the fact that the lexical overlap between languages plays a
negligible role in the cross-lingual success, while the depth of the network is
an integral part of it. All our models and implementations can be found on our
project page: http://cogcomp.org/page/publication_view/900 .
</summary>
    <author>
      <name>Karthikeyan K</name>
    </author>
    <author>
      <name>Zihan Wang</name>
    </author>
    <author>
      <name>Stephen Mayhew</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07747v1</id>
    <updated>2019-12-16T23:04:03Z</updated>
    <published>2019-12-16T23:04:03Z</published>
    <title>Pipelines for Procedural Information Extraction from Scientific
  Literature: Towards Recipes using Machine Learning and Data Science</title>
    <summary>  This paper describes a machine learning and data science pipeline for
structured information extraction from documents, implemented as a suite of
open-source tools and extensions to existing tools. It centers around a
methodology for extracting procedural information in the form of recipes,
stepwise procedures for creating an artifact (in this case synthesizing a
nanomaterial), from published scientific literature. From our overall goal of
producing recipes from free text, we derive the technical objectives of a
system consisting of pipeline stages: document acquisition and filtering,
payload extraction, recipe step extraction as a relationship extraction task,
recipe assembly, and presentation through an information retrieval interface
with question answering (QA) functionality. This system meets computational
information and knowledge management (CIKM) requirements of metadata-driven
payload extraction, named entity extraction, and relationship extraction from
text. Functional contributions described in this paper include semi-supervised
machine learning methods for PDF filtering and payload extraction tasks,
followed by structured extraction and data transformation tasks beginning with
section extraction, recipe steps as information tuples, and finally assembled
recipes. Measurable objective criteria for extraction quality include precision
and recall of recipe steps, ordering constraints, and QA accuracy, precision,
and recall. Results, key novel contributions, and significant open problems
derived from this work center around the attribution of these holistic quality
measures to specific machine learning and inference stages of the pipeline,
each with their performance measures. The desired recipes contain identified
preconditions, material inputs, and operations, and constitute the overall
output generated by our computational information and knowledge management
(CIKM) system.
</summary>
    <author>
      <name>Huichen Yang</name>
    </author>
    <author>
      <name>Carlos A. Aguirre</name>
    </author>
    <author>
      <name>Maria F. De La Torre</name>
    </author>
    <author>
      <name>Derek Christensen</name>
    </author>
    <author>
      <name>Luis Bobadilla</name>
    </author>
    <author>
      <name>Emily Davich</name>
    </author>
    <author>
      <name>Jordan Roth</name>
    </author>
    <author>
      <name>Lei Luo</name>
    </author>
    <author>
      <name>Yihong Theis</name>
    </author>
    <author>
      <name>Alice Lam</name>
    </author>
    <author>
      <name>T. Yong-Jin Han</name>
    </author>
    <author>
      <name>David Buttler</name>
    </author>
    <author>
      <name>William H. Hsu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICDARW.2019.10037</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICDARW.2019.10037" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15th International Conference on Document Analysis and Recognition
  Workshops (ICDARW 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7, I.2.6, H.3.3, H.3.4, I.2.10, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.6; H.3.3; H.3.4; I.2.10; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07575v1</id>
    <updated>2019-12-16T18:41:49Z</updated>
    <published>2019-12-16T18:41:49Z</published>
    <title>Predicting detection filters for small footprint open-vocabulary keyword
  spotting</title>
    <summary>  In many scenarios, detecting keywords from natural language queries is
sufficient to understand the intent of the user. In this paper, we propose a
fully-neural approach to open-vocabulary keyword spotting, allowing a user to
include a voice interface to its device without having to retrain a model on
task-specific data. We present a keyword detection neural network weighing less
than 550KB, in which the topmost layer performing keyword detection is
predicted by an auxiliary network, that may be run offline to generate a
detector for any keyword.
</summary>
    <author>
      <name>Theodore Bluche</name>
    </author>
    <author>
      <name>Thibault Gisselbrecht</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07538v2</id>
    <updated>2019-12-22T21:22:34Z</updated>
    <published>2019-12-16T17:45:01Z</published>
    <title>Towards Causal VQA: Revealing and Reducing Spurious Correlations by
  Invariant and Covariant Semantic Editing</title>
    <summary>  Despite significant success in Visual Question Answering (VQA), VQA models
have been shown to be notoriously brittle to linguistic variations in the
questions. Due to deficiencies in models and datasets, today's models often
rely on correlations rather than predictions that are causal w.r.t. data. In
this paper, we propose a novel way to analyze and measure the robustness of the
state of the art models w.r.t semantic visual variations as well as propose
ways to make models more robust against spurious correlations. Our method
performs automated semantic image manipulations and tests for consistency in
model predictions to quantify the model robustness as well as generate
synthetic data to counter these problems. We perform our analysis on three
diverse, state of the art VQA models and diverse question types with a
particular focus on challenging counting questions. In addition, we show that
models can be made significantly more robust against inconsistent predictions
using our edited data. Finally, we show that results also translate to
real-world error cases of state of the art models, which results in improved
overall performance
</summary>
    <author>
      <name>Vedika Agarwal</name>
    </author>
    <author>
      <name>Rakshith Shetty</name>
    </author>
    <author>
      <name>Mario Fritz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07538v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07538v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07506v1</id>
    <updated>2019-12-16T17:12:00Z</updated>
    <published>2019-12-16T17:12:00Z</published>
    <title>Scale-dependent Relationships in Natural Language</title>
    <summary>  Natural language exhibits statistical dependencies at a wide range of scales.
For instance, the mutual information between words in natural language decays
like a power law with the temporal lag between them. However, many statistical
learning models applied to language impose a sampling scale while extracting
statistical structure. For instance, Word2Vec constructs a vector embedding
that maximizes the prediction between a target word and the context words that
appear nearby in the corpus. The size of the context is chosen by the user and
defines a strong scale; relationships over much larger temporal scales would be
invisible to the algorithm. This paper examines the family of Word2Vec
embeddings generated while systematically manipulating the sampling scale used
to define the context around each word. The primary result is that different
linguistic relationships are preferentially encoded at different scales.
Different scales emphasize different syntactic and semantic relations between
words.Moreover, the neighborhoods of a given word in the embeddings change
significantly depending on the scale. These results suggest that any individual
scale can only identify a subset of the meaningful relationships a word might
have, and point toward the importance of developing scale-free models of
semantic meaning.
</summary>
    <author>
      <name>Aakash Sarkar</name>
    </author>
    <author>
      <name>Marc Howard</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07491v1</id>
    <updated>2019-12-16T16:39:01Z</updated>
    <published>2019-12-16T16:39:01Z</published>
    <title>Improving Knowledge-aware Dialogue Generation via Knowledge Base
  Question Answering</title>
    <summary>  Neural network models usually suffer from the challenge of incorporating
commonsense knowledge into the open-domain dialogue systems. In this paper, we
propose a novel knowledge-aware dialogue generation model (called TransDG),
which transfers question representation and knowledge matching abilities from
knowledge base question answering (KBQA) task to facilitate the utterance
understanding and factual knowledge selection for dialogue generation. In
addition, we propose a response guiding attention and a multi-step decoding
strategy to steer our model to focus on relevant features for response
generation. Experiments on two benchmark datasets demonstrate that our model
has robust superiority over compared methods in generating informative and
fluent dialogues. Our code is available at https://github.com/siat-nlp/TransDG.
</summary>
    <author>
      <name>Jian Wang</name>
    </author>
    <author>
      <name>Junhao Liu</name>
    </author>
    <author>
      <name>Wei Bi</name>
    </author>
    <author>
      <name>Xiaojiang Liu</name>
    </author>
    <author>
      <name>Kejing He</name>
    </author>
    <author>
      <name>Ruifeng Xu</name>
    </author>
    <author>
      <name>Min Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07478v1</id>
    <updated>2019-12-16T16:21:13Z</updated>
    <published>2019-12-16T16:21:13Z</published>
    <title>Image Manipulation with Natural Language using Two-sidedAttentive
  Conditional Generative Adversarial Network</title>
    <summary>  Altering the content of an image with photo editing tools is a tedious task
for an inexperienced user. Especially, when modifying the visual attributes of
a specific object in an image without affecting other constituents such as
background etc. To simplify the process of image manipulation and to provide
more control to users, it is better to utilize a simpler interface like natural
language. Therefore, in this paper, we address the challenge of manipulating
images using natural language description. We propose the Two-sidEd Attentive
conditional Generative Adversarial Network (TEA-cGAN) to generate semantically
manipulated images while preserving other contents such as background intact.
TEA-cGAN uses fine-grained attention both in the generator and discriminator of
Generative Adversarial Network (GAN) based framework at different scales.
Experimental results show that TEA-cGAN which generates 128x128 and 256x256
resolution images outperforms existing methods on CUB and Oxford-102 datasets
both quantitatively and qualitatively.
</summary>
    <author>
      <name>Dawei Zhu</name>
    </author>
    <author>
      <name>Aditya Mogadala</name>
    </author>
    <author>
      <name>Dietrich Klakow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10819v1</id>
    <updated>2019-12-16T15:42:30Z</updated>
    <published>2019-12-16T15:42:30Z</published>
    <title>Predicting the Outcome of Judicial Decisions made by the European Court
  of Human Rights</title>
    <summary>  In this study, machine learning models were constructed to predict whether
judgments made by the European Court of Human Rights (ECHR) would lead to a
violation of an Article in the Convention on Human Rights. The problem is
framed as a binary classification task where a judgment can lead to a
"violation" or "non-violation" of a particular Article. Using auto-sklearn, an
automated algorithm selection package, models were constructed for 12 Articles
in the Convention. To train these models, textual features were obtained from
the ECHR Judgment documents using N-grams, word embeddings and paragraph
embeddings. Additional documents, from the ECHR, were incorporated into the
models through the creation of a word embedding (echr2vec) and a doc2vec model.
The features obtained using the echr2vec embedding provided the highest
cross-validation accuracy for 5 of the Articles. The overall test accuracy,
across the 12 Articles, was 68.83%. As far as we could tell, this is the first
estimate of the accuracy of such machine learning models using a realistic test
set. This provides an important benchmark for future work. As a baseline, a
simple heuristic of always predicting the most common outcome in the past was
used. The heuristic achieved an overall test accuracy of 86.68% which is 29.7%
higher than the models. Again, this was seemingly the first study that included
such a heuristic with which to compare model results. The higher accuracy
achieved by the heuristic highlights the importance of including such a
baseline.
</summary>
    <author>
      <name>Conor O'Sullivan</name>
    </author>
    <author>
      <name>Joeran Beel</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">27th AIAI Irish Conference on Artificial Intelligence and
  Cognitive Science. 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07421v1</id>
    <updated>2019-12-16T14:45:56Z</updated>
    <published>2019-12-16T14:45:56Z</published>
    <title>Semantic Similarity To Improve Question Understanding in a Virtual
  Patient</title>
    <summary>  In medicine, a communicating virtual patient or doctor allows students to
train in medical diagnosis and develop skills to conduct a medical
consultation. In this paper, we describe a conversational virtual standardized
patient system to allow medical students to simulate a diagnosis strategy of an
abdominal surgical emergency. We exploited the semantic properties captured by
distributed word representations to search for similar questions in the virtual
patient dialogue system. We created two dialogue systems that were evaluated on
datasets collected during tests with students. The first system based on
hand-crafted rules obtains $92.29\%$ as $F1$-score on the studied clinical case
while the second system that combines rules and semantic similarity achieves
$94.88\%$. It represents an error reduction of $9.70\%$ as compared to the
rules-only-based system.
</summary>
    <author>
      <name>Fréjus A. A. Laleye</name>
    </author>
    <author>
      <name>Antonia Blanié</name>
    </author>
    <author>
      <name>Antoine Brouquet</name>
    </author>
    <author>
      <name>Dan Behnamou</name>
    </author>
    <author>
      <name>Gaël de Chalendar</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07419v1</id>
    <updated>2019-12-16T14:43:11Z</updated>
    <published>2019-12-16T14:43:11Z</published>
    <title>Optimized Tracking of Topic Evolution</title>
    <summary>  Topic evolution modeling has been researched for a long time and has gained
considerable interest. A state-of-the-art method has been recently using word
modeling algorithms in combination with community detection mechanisms to
achieve better results in a more effective way. We analyse results of this
approach and discuss the two major challenges that this approach still faces.
Although the topics that have resulted from the recent algorithm are good in
general, they are very noisy due to many topics that are very unimportant
because of their size, words, or ambiguity. Additionally, the number of words
defining each topic is too large, making it difficult to analyse them in their
unsorted state. In this paper, we propose approaches to tackle these challenges
by adding topic filtering and network analysis metrics to define the importance
of a topic. We test different combinations of these metrics to see which
combination yields the best results. Furthermore, we add word filtering and
ranking to each topic to identify the words with the highest novelty
automatically. We evaluate our enhancement methods in two ways: human
qualitative evaluation and automatic quantitative evaluation. Moreover, we
created two case studies to test the quality of the clusters and words. In the
quantitative evaluation, we use the pairwise mutual information score to test
the coherency of topics. The quantitative evaluation also includes an analysis
of execution times for each part of the program. The results of the
experimental evaluations show that the two evaluation methods agree on the
positive feasibility of the algorithm. We then show possible extensions in the
form of usability and future improvements to the algorithm.
</summary>
    <author>
      <name>Patrick Kiss</name>
    </author>
    <author>
      <name>Elaheh Momeni</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07240v1</id>
    <updated>2019-12-16T08:22:43Z</updated>
    <published>2019-12-16T08:22:43Z</published>
    <title>Synchronous Speech Recognition and Speech-to-Text Translation with
  Interactive Decoding</title>
    <summary>  Speech-to-text translation (ST), which translates source language speech into
target language text, has attracted intensive attention in recent years.
Compared to the traditional pipeline system, the end-to-end ST model has
potential benefits of lower latency, smaller model size, and less error
propagation. However, it is notoriously difficult to implement such a model
without transcriptions as intermediate. Existing works generally apply
multi-task learning to improve translation quality by jointly training
end-to-end ST along with automatic speech recognition (ASR). However, different
tasks in this method cannot utilize information from each other, which limits
the improvement. Other works propose a two-stage model where the second model
can use the hidden state from the first one, but its cascade manner greatly
affects the efficiency of training and inference process. In this paper, we
propose a novel interactive attention mechanism which enables ASR and ST to
perform synchronously and interactively in a single model. Specifically, the
generation of transcriptions and translations not only relies on its previous
outputs but also the outputs predicted in the other task. Experiments on TED
speech translation corpora have shown that our proposed model can outperform
strong baselines on the quality of speech translation and achieve better speech
recognition performances as well.
</summary>
    <author>
      <name>Yuchen Liu</name>
    </author>
    <author>
      <name>Jiajun Zhang</name>
    </author>
    <author>
      <name>Hao Xiong</name>
    </author>
    <author>
      <name>Long Zhou</name>
    </author>
    <author>
      <name>Zhongjun He</name>
    </author>
    <author>
      <name>Hua Wu</name>
    </author>
    <author>
      <name>Haifeng Wang</name>
    </author>
    <author>
      <name>Chengqing Zong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07239v1</id>
    <updated>2019-12-16T08:21:28Z</updated>
    <published>2019-12-16T08:21:28Z</published>
    <title>Iterative Dual Domain Adaptation for Neural Machine Translation</title>
    <summary>  Previous studies on the domain adaptation for neural machine translation
(NMT) mainly focus on the one-pass transferring out-of-domain translation
knowledge to in-domain NMT model. In this paper, we argue that such a strategy
fails to fully extract the domain-shared translation knowledge, and repeatedly
utilizing corpora of different domains can lead to better distillation of
domain-shared translation knowledge. To this end, we propose an iterative dual
domain adaptation framework for NMT. Specifically, we first pre-train in-domain
and out-of-domain NMT models using their own training corpora respectively, and
then iteratively perform bidirectional translation knowledge transfer (from
in-domain to out-of-domain and then vice versa) based on knowledge distillation
until the in-domain NMT model convergences. Furthermore, we extend the proposed
framework to the scenario of multiple out-of-domain training corpora, where the
above-mentioned transfer is performed sequentially between the in-domain and
each out-of-domain NMT models in the ascending order of their domain
similarities. Empirical results on Chinese-English and English-German
translation tasks demonstrate the effectiveness of our framework.
</summary>
    <author>
      <name>Jiali Zeng</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Jinsong Su</name>
    </author>
    <author>
      <name>Yubin Ge</name>
    </author>
    <author>
      <name>Yaojie Lu</name>
    </author>
    <author>
      <name>Yongjing Yin</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07225v1</id>
    <updated>2019-12-16T07:23:21Z</updated>
    <published>2019-12-16T07:23:21Z</published>
    <title>Graph-based Neural Sentence Ordering</title>
    <summary>  Sentence ordering is to restore the original paragraph from a set of
sentences. It involves capturing global dependencies among sentences regardless
of their input order. In this paper, we propose a novel and flexible
graph-based neural sentence ordering model, which adopts graph recurrent
network \cite{Zhang:acl18} to accurately learn semantic representations of the
sentences. Instead of assuming connections between all pairs of input
sentences, we use entities that are shared among multiple sentences to make
more expressive graph representations with less noise. Experimental results
show that our proposed model outperforms the existing state-of-the-art systems
on several benchmark datasets, demonstrating the effectiveness of our model. We
also conduct a thorough analysis on how entities help the performance.
</summary>
    <author>
      <name>Yongjing Yin</name>
    </author>
    <author>
      <name>Linfeng Song</name>
    </author>
    <author>
      <name>Jinsong Su</name>
    </author>
    <author>
      <name>Jiali Zeng</name>
    </author>
    <author>
      <name>Chulun Zhou</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCAI2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07199v1</id>
    <updated>2019-12-16T05:25:07Z</updated>
    <published>2019-12-16T05:25:07Z</published>
    <title>Characterizing the dynamics of learning in repeated reference games</title>
    <summary>  The language we use over the course of conversation changes as we establish
common ground and learn what our partner finds meaningful. Here we draw upon
recent advances in natural language processing to provide a finer-grained
characterization of the dynamics of this learning process. We release an open
corpus (&gt;15,000 utterances) of extended dyadic interactions in a classic
repeated reference game task where pairs of participants had to coordinate on
how to refer to initially difficult-to-describe tangram stimuli. We find that
different pairs discover a wide variety of idiosyncratic but efficient and
stable solutions to the problem of reference. Furthermore, these conventions
are shaped by the communicative context: words that are more discriminative in
the initial context (i.e. that are used for one target more than others) are
more likely to persist through the final repetition. Finally, we find
systematic structure in how a speaker's referring expressions become more
efficient over time: syntactic units drop out in clusters following positive
feedback from the listener, eventually leaving short labels containing
open-class parts of speech. These findings provide a higher resolution look at
the quantitative dynamics of ad hoc convention formation and support further
development of computational models of learning in communication.
</summary>
    <author>
      <name>Robert D. Hawkins</name>
    </author>
    <author>
      <name>Michael C. Frank</name>
    </author>
    <author>
      <name>Noah D. Goodman</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10818v1</id>
    <updated>2019-12-15T19:48:48Z</updated>
    <published>2019-12-15T19:48:48Z</published>
    <title>Artificial mental phenomena: Psychophysics as a framework to detect
  perception biases in AI models</title>
    <summary>  Detecting biases in artificial intelligence has become difficult because of
the impenetrable nature of deep learning. The central difficulty is in relating
unobservable phenomena deep inside models with observable, outside quantities
that we can measure from inputs and outputs. For example, can we detect
gendered perceptions of occupations (e.g., female librarian, male electrician)
using questions to and answers from a word embedding-based system? Current
techniques for detecting biases are often customized for a task, dataset, or
method, affecting their generalization. In this work, we draw from
Psychophysics in Experimental Psychology---meant to relate quantities from the
real world (i.e., "Physics") into subjective measures in the mind (i.e.,
"Psyche")---to propose an intellectually coherent and generalizable framework
to detect biases in AI. Specifically, we adapt the two-alternative forced
choice task (2AFC) to estimate potential biases and the strength of those
biases in black-box models. We successfully reproduce previously-known biased
perceptions in word embeddings and sentiment analysis predictions. We discuss
how concepts in experimental psychology can be naturally applied to
understanding artificial mental phenomena, and how psychophysics can form a
useful methodological foundation to study fairness in AI.
</summary>
    <author>
      <name>Lizhen Liang</name>
    </author>
    <author>
      <name>Daniel E. Acuna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3351095.3375623</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3351095.3375623" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">FAT Conference 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07095v1</id>
    <updated>2019-12-15T19:33:25Z</updated>
    <published>2019-12-15T19:33:25Z</published>
    <title>Robust Named Entity Recognition with Truecasing Pretraining</title>
    <summary>  Although modern named entity recognition (NER) systems show impressive
performance on standard datasets, they perform poorly when presented with noisy
data. In particular, capitalization is a strong signal for entities in many
languages, and even state of the art models overfit to this feature, with
drastically lower performance on uncapitalized text. In this work, we address
the problem of robustness of NER systems in data with noisy or uncertain
casing, using a pretraining objective that predicts casing in text, or a
truecaser, leveraging unlabeled data. The pretrained truecaser is combined with
a standard BiLSTM-CRF model for NER by appending output distributions to
character embeddings. In experiments over several datasets of varying domain
and casing quality, we show that our new model improves performance in uncased
text, even adding value to uncased BERT embeddings. Our method achieves a new
state of the art on the WNUT17 shared task dataset.
</summary>
    <author>
      <name>Stephen Mayhew</name>
    </author>
    <author>
      <name>Nitish Gupta</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07076v1</id>
    <updated>2019-12-15T17:50:56Z</updated>
    <published>2019-12-15T17:50:56Z</published>
    <title>Multilingual is not enough: BERT for Finnish</title>
    <summary>  Deep learning-based language models pretrained on large unannotated text
corpora have been demonstrated to allow efficient transfer learning for natural
language processing, with recent approaches such as the transformer-based BERT
model advancing the state of the art across a variety of tasks. While most work
on these models has focused on high-resource languages, in particular English,
a number of recent efforts have introduced multilingual models that can be
fine-tuned to address tasks in a large number of different languages. However,
we still lack a thorough understanding of the capabilities of these models, in
particular for lower-resourced languages. In this paper, we focus on Finnish
and thoroughly evaluate the multilingual BERT model on a range of tasks,
comparing it with a new Finnish BERT model trained from scratch. The new
language-specific model is shown to systematically and clearly outperform the
multilingual. While the multilingual model largely fails to reach the
performance of previously proposed methods, the custom Finnish BERT model
establishes new state-of-the-art results on all corpora for all reference
tasks: part-of-speech tagging, named entity recognition, and dependency
parsing. We release the model and all related resources created for this study
with open licenses at https://turkunlp.org/finbert .
</summary>
    <author>
      <name>Antti Virtanen</name>
    </author>
    <author>
      <name>Jenna Kanerva</name>
    </author>
    <author>
      <name>Rami Ilo</name>
    </author>
    <author>
      <name>Jouni Luoma</name>
    </author>
    <author>
      <name>Juhani Luotolahti</name>
    </author>
    <author>
      <name>Tapio Salakoski</name>
    </author>
    <author>
      <name>Filip Ginter</name>
    </author>
    <author>
      <name>Sampo Pyysalo</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07050v1</id>
    <updated>2019-12-15T14:38:58Z</updated>
    <published>2019-12-15T14:38:58Z</published>
    <title>Computational Induction of Prosodic Structure</title>
    <summary>  The present study has two goals relating to the grammar of prosody,
understood as the rhythms and melodies of speech. First, an overview is
provided of the computable grammatical and phonetic approaches to prosody
analysis which use hypothetico-deductive methods and are based on learned
hermeneutic intuitions about language. Second, a proposal is presented for an
inductive grounding in the physical signal, in which prosodic structure is
inferred using a language-independent method from the low-frequency spectrum of
the speech signal. The overview includes a discussion of computational aspects
of standard generative and post-generative models, and suggestions for
reformulating these to form inductive approaches. Also included is a discussion
of linguistic phonetic approaches to analysis of annotations (pairs of speech
unit labels with time-stamps) of recorded spoken utterances. The proposal
introduces the inductive approach of Rhythm Formant Theory (RFT) and the
associated Rhythm Formant Analysis (RFA) method are introduced, with the aim of
completing a gap in the linguistic hypothetico-deductive cycle by grounding in
a language-independent inductive procedure of speech signal analysis. The
validity of the method is demonstrated and applied to rhythm patterns in
read-aloud Mandarin Chinese, finding differences from English which are related
to lexical and grammatical differences between the languages, as well as
individual variation. The overall conclusions are (1) that normative
language-to-language phonological or phonetic comparisons of rhythm, for
example of Mandarin and English, are too simplistic, in view of diverse
language-internal factors due to genre and style differences as well as
utterance dynamics, and (2) that language-independent empirical grounding of
rhythm in the physical signal is called for.
</summary>
    <author>
      <name>Dafydd Gibbon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 10 figures, code appendix, to appear in "Studies in
  Prosodic Grammar"</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10170v1</id>
    <updated>2019-12-15T14:37:06Z</updated>
    <published>2019-12-15T14:37:06Z</published>
    <title>NaïveRole: Author-Contribution Extraction and Parsing from Biomedical
  Manuscripts</title>
    <summary>  Information about the contributions of individual authors to scientific
publications is important for assessing authors' achievements. Some biomedical
publications have a short section that describes authors' roles and
contributions. It is usually written in natural language and hence author
contributions cannot be trivially extracted in a machine-readable format. In
this paper, we present 1) A statistical analysis of roles in author
contributions sections, and 2) Na\"iveRole, a novel approach to extract
structured authors' roles from author contribution sections. For the first
part, we used co-clustering techniques, as well as Open Information Extraction,
to semi-automatically discover the popular roles within a corpus of 2,000
contributions sections from PubMed Central. The discovered roles were used to
automatically build a training set for Na\"iveRole, our role extractor
approach, based on Na\"ive Bayes. Na\"iveRole extracts roles with a
micro-averaged precision of 0.68, recall of 0.48 and F1 of 0.57. It is, to the
best of our knowledge, the first attempt to automatically extract author roles
from research papers. This paper is an extended version of a previous poster
published at JCDL 2018.
</summary>
    <author>
      <name>Dominika Tkaczyk</name>
    </author>
    <author>
      <name>Andrew Collins</name>
    </author>
    <author>
      <name>Joeran Beel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1802.01174</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">27th AIAI Irish Conference on Artificial Intelligence and
  Cognitive Science, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.10170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10169v1</id>
    <updated>2019-12-15T11:42:32Z</updated>
    <published>2019-12-15T11:42:32Z</published>
    <title>A Comparison of Architectures and Pretraining Methods for Contextualized
  Multilingual Word Embeddings</title>
    <summary>  The lack of annotated data in many languages is a well-known challenge within
the field of multilingual natural language processing (NLP). Therefore, many
recent studies focus on zero-shot transfer learning and joint training across
languages to overcome data scarcity for low-resource languages. In this work we
(i) perform a comprehensive comparison of state-ofthe-art multilingual word and
sentence encoders on the tasks of named entity recognition (NER) and part of
speech (POS) tagging; and (ii) propose a new method for creating multilingual
contextualized word embeddings, compare it to multiple baselines and show that
it performs at or above state-of-theart level in zero-shot transfer settings.
Finally, we show that our method allows for better knowledge sharing across
languages in a joint training setting.
</summary>
    <author>
      <name>Niels van der Heijden</name>
    </author>
    <author>
      <name>Samira Abnar</name>
    </author>
    <author>
      <name>Ekaterina Shutova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07025v1</id>
    <updated>2019-12-15T11:42:27Z</updated>
    <published>2019-12-15T11:42:27Z</published>
    <title>Indiscapes: Instance Segmentation Networks for Layout Parsing of
  Historical Indic Manuscripts</title>
    <summary>  Historical palm-leaf manuscript and early paper documents from Indian
subcontinent form an important part of the world's literary and cultural
heritage. Despite their importance, large-scale annotated Indic manuscript
image datasets do not exist. To address this deficiency, we introduce
Indiscapes, the first ever dataset with multi-regional layout annotations for
historical Indic manuscripts. To address the challenge of large diversity in
scripts and presence of dense, irregular layout elements (e.g. text lines,
pictures, multiple documents per image), we adapt a Fully Convolutional Deep
Neural Network architecture for fully automatic, instance-level spatial layout
parsing of manuscript images. We demonstrate the effectiveness of proposed
architecture on images from the Indiscapes dataset. For annotation flexibility
and keeping the non-technical nature of domain experts in mind, we also
contribute a custom, web-based GUI annotation tool and a dashboard-style
analytics portal. Overall, our contributions set the stage for enabling
downstream applications such as OCR and word-spotting in historical Indic
manuscripts at scale.
</summary>
    <author>
      <name>Abhishek Prusty</name>
    </author>
    <author>
      <name>Sowmya Aitha</name>
    </author>
    <author>
      <name>Abhishek Trivedi</name>
    </author>
    <author>
      <name>Ravi Kiran Sarvadevabhatla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Oral presentation at International Conference on Document Analysis
  and Recognition (ICDAR) - 2019. For dataset, pre-trained networks and
  additional details, visit project page at http://ihdia.iiit.ac.in/</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.07025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06979v1</id>
    <updated>2019-12-15T05:34:45Z</updated>
    <published>2019-12-15T05:34:45Z</published>
    <title>Breaking Speech Recognizers to Imagine Lyrics</title>
    <summary>  We introduce a new method for generating text, and in particular song lyrics,
based on the speech-like acoustic qualities of a given audio file. We repurpose
a vocal source separation algorithm and an acoustic model trained to recognize
isolated speech, instead inputting instrumental music or environmental sounds.
Feeding the "mistakes" of the vocal separator into the recognizer, we obtain a
transcription of words \emph{imagined} to be spoken in the input audio. We
describe the key components of our approach, present initial analysis, and
discuss the potential of the method for machine-in-the-loop collaboration in
creative applications.
</summary>
    <author>
      <name>Jon Gillick</name>
    </author>
    <author>
      <name>David Bamman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019 Workshop on Machine Learning for Creativity and
  Design</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.06979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06927v1</id>
    <updated>2019-12-14T20:57:29Z</updated>
    <published>2019-12-14T20:57:29Z</published>
    <title>#MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo
  Movement</title>
    <summary>  In this paper, we present a dataset containing 9,973 tweets related to the
MeToo movement that were manually annotated for five different linguistic
aspects: relevance, stance, hate speech, sarcasm, and dialogue acts. We present
a detailed account of the data collection and annotation processes. The
annotations have a very high inter-annotator agreement (0.79 to 0.93 k-alpha)
due to the domain expertise of the annotators and clear annotation
instructions. We analyze the data in terms of geographical distribution, label
correlations, and keywords. Lastly, we present some potential use cases of this
dataset. We expect this dataset would be of great interest to psycholinguists,
socio-linguists, and computational linguists to study the discursive space of
digitally mobilized social movements on sensitive issues like sexual
harassment.
</summary>
    <author>
      <name>Akash Gautam</name>
    </author>
    <author>
      <name>Puneet Mathur</name>
    </author>
    <author>
      <name>Rakesh Gosangi</name>
    </author>
    <author>
      <name>Debanjan Mahata</name>
    </author>
    <author>
      <name>Ramit Sawhney</name>
    </author>
    <author>
      <name>Rajiv Ratn Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of paper accepted at ICWSM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06905v1</id>
    <updated>2019-12-14T19:13:44Z</updated>
    <published>2019-12-14T19:13:44Z</published>
    <title>Long-length Legal Document Classification</title>
    <summary>  One of the principal tasks of machine learning with major applications is
text classification. This paper focuses on the legal domain and, in particular,
on the classification of lengthy legal documents. The main challenge that this
study addresses is the limitation that current models impose on the length of
the input text. In addition, the present paper shows that dividing the text
into segments and later combining the resulting embeddings with a BiLSTM
architecture to form a single document embedding can improve results. These
advancements are achieved by utilising a simpler structure, rather than an
increasingly complex one, which is often the case in NLP research. The dataset
used in this paper is obtained from an online public database containing
lengthy legal documents with highly domain-specific vocabulary and thus, the
comparison of our results to the ones produced by models implemented on the
commonly used datasets would be unjustified. This work provides the foundation
for future work in document classification in the legal field.
</summary>
    <author>
      <name>Lulu Wan</name>
    </author>
    <author>
      <name>George Papageorgiou</name>
    </author>
    <author>
      <name>Michael Seddon</name>
    </author>
    <author>
      <name>Mirko Bernardoni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, 4 equations, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06900v1</id>
    <updated>2019-12-14T18:28:02Z</updated>
    <published>2019-12-14T18:28:02Z</published>
    <title>Efficient Convolutional Neural Networks for Diacritic Restoration</title>
    <summary>  Diacritic restoration has gained importance with the growing need for
machines to understand written texts. The task is typically modeled as a
sequence labeling problem and currently Bidirectional Long Short Term Memory
(BiLSTM) models provide state-of-the-art results. Recently, Bai et al. (2018)
show the advantages of Temporal Convolutional Neural Networks (TCN) over
Recurrent Neural Networks (RNN) for sequence modeling in terms of performance
and computational resources. As diacritic restoration benefits from both
previous as well as subsequent timesteps, we further apply and evaluate a
variant of TCN, Acausal TCN (A-TCN), which incorporates context from both
directions (previous and future) rather than strictly incorporating previous
context as in the case of TCN. A-TCN yields significant improvement over TCN
for diacritization in three different languages: Arabic, Yoruba, and
Vietnamese. Furthermore, A-TCN and BiLSTM have comparable performance, making
A-TCN an efficient alternative over BiLSTM since convolutions can be trained in
parallel. A-TCN is significantly faster than BiLSTM at inference time
(270%-334% improvement in the amount of text diacritized per minute).
</summary>
    <author>
      <name>Sawsan Alqahtani</name>
    </author>
    <author>
      <name>Ajay Mishra</name>
    </author>
    <author>
      <name>Mona Diab</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/D19-1151</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/D19-1151" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted in EMNLP 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.06900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06889v2</id>
    <updated>2020-01-23T17:19:46Z</updated>
    <published>2019-12-14T17:38:46Z</published>
    <title>Integrating Lexical Knowledge in Word Embeddings using Sprinkling and
  Retrofitting</title>
    <summary>  Neural network based word embeddings, such as Word2Vec and GloVe, are purely
data driven in that they capture the distributional information about words
from the training corpus. Past works have attempted to improve these embeddings
by incorporating semantic knowledge from lexical resources like WordNet. Some
techniques like retrofitting modify word embeddings in the post-processing
stage while some others use a joint learning approach by modifying the
objective function of neural networks. In this paper, we discuss two novel
approaches for incorporating semantic knowledge into word embeddings. In the
first approach, we take advantage of Levy et al's work which showed that using
SVD based methods on co-occurrence matrix provide similar performance to neural
network based embeddings. We propose a 'sprinkling' technique to add semantic
relations to the co-occurrence matrix directly before factorization. In the
second approach, WordNet similarity scores are used to improve the retrofitting
method. We evaluate the proposed methods in both intrinsic and extrinsic tasks
and observe significant improvements over the baselines in many of the
datasets.
</summary>
    <author>
      <name>Aakash Srinivasan</name>
    </author>
    <author>
      <name>Harshavardhan Kamarthi</name>
    </author>
    <author>
      <name>Devi Ganesan</name>
    </author>
    <author>
      <name>Sutanu Chakraborti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06889v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06889v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06872v1</id>
    <updated>2019-12-14T16:03:15Z</updated>
    <published>2019-12-14T16:03:15Z</published>
    <title>Towards Robust Toxic Content Classification</title>
    <summary>  Toxic content detection aims to identify content that can offend or harm its
recipients. Automated classifiers of toxic content need to be robust against
adversaries who deliberately try to bypass filters. We propose a method of
generating realistic model-agnostic attacks using a lexicon of toxic tokens,
which attempts to mislead toxicity classifiers by diluting the toxicity signal
either by obfuscating toxic tokens through character-level perturbations, or by
injecting non-toxic distractor tokens. We show that these realistic attacks
reduce the detection recall of state-of-the-art neural toxicity detectors,
including those using ELMo and BERT, by more than 50% in some cases. We explore
two approaches for defending against such attacks. First, we examine the effect
of training on synthetically noised data. Second, we propose the Contextual
Denoising Autoencoder (CDAE): a method for learning robust representations that
uses character-level and contextual information to denoise perturbed tokens. We
show that the two approaches are complementary, improving robustness to both
character-level perturbations and distractors, recovering a considerable
portion of the lost accuracy. Finally, we analyze the robustness
characteristics of the most competitive methods and outline practical
considerations for improving toxicity detectors.
</summary>
    <author>
      <name>Keita Kurita</name>
    </author>
    <author>
      <name>Anna Belova</name>
    </author>
    <author>
      <name>Antonios Anastasopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at EDSMLS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06859v1</id>
    <updated>2019-12-14T14:59:38Z</updated>
    <published>2019-12-14T14:59:38Z</published>
    <title>Knowledge-based Conversational Search</title>
    <summary>  Conversational interfaces that allow for intuitive and comprehensive access
to digitally stored information remain an ambitious goal. In this thesis, we
lay foundations for designing conversational search systems by analyzing the
requirements and proposing concrete solutions for automating some of the basic
components and tasks that such systems should support. We describe several
interdependent studies that were conducted to analyse the design requirements
for more advanced conversational search systems able to support complex
human-like dialogue interactions and provide access to vast knowledge
repositories. In the first two research chapters, we focus on analyzing the
structures common to information-seeking dialogues by capturing recurrent
patterns in terms of both domain-independent functional relations between
utterances as well as domain-specific implicit semantic relations from shared
background knowledge.
  Our results show that question answering is one of the key components
required for efficient information access but it is not the only type of
dialogue interactions that a conversational search system should support. In
the third research chapter, we propose a novel approach for complex question
answering from a knowledge graph that surpasses the current state-of-the-art
results in terms of both efficacy and efficiency. In the last research chapter,
we turn our attention towards an alternative interaction mode, which we termed
conversational browsing, in which, unlike question answering, the
conversational system plays a more pro-active role in the course of a dialogue
interaction. We show that this approach helps users to discover relevant items
that are difficult to retrieve using only question answering due to the
vocabulary mismatch problem.
</summary>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06858v1</id>
    <updated>2019-12-14T14:55:59Z</updated>
    <published>2019-12-14T14:55:59Z</published>
    <title>LScDC-new large scientific dictionary</title>
    <summary>  In this paper, we present a scientific corpus of abstracts of academic papers
in English -- Leicester Scientific Corpus (LSC). The LSC contains 1,673,824
abstracts of research articles and proceeding papers indexed by Web of Science
(WoS) in which publication year is 2014. Each abstract is assigned to at least
one of 252 subject categories. Paper metadata include these categories and the
number of citations. We then develop scientific dictionaries named Leicester
Scientific Dictionary (LScD) and Leicester Scientific Dictionary-Core (LScDC),
where words are extracted from the LSC. The LScD is a list of 974,238 unique
words (lemmas). The LScDC is a core list (sub-list) of the LScD with 104,223
lemmas. It was created by removing LScD words appearing in not greater than 10
texts in the LSC. LScD and LScDC are available online. Both the corpus and
dictionaries are developed to be later used for quantification of meaning in
academic texts.
  Finally, the core list LScDC was analysed by comparing its words and word
frequencies with a classic academic word list 'New Academic Word List (NAWL)'
containing 963 word families, which is also sampled from an academic corpus.
The major sources of the corpus where NAWL is extracted are Cambridge English
Corpus (CEC), oral sources and textbooks. We investigate whether two
dictionaries are similar in terms of common words and ranking of words. Our
comparison leads us to main conclusion: most of words of NAWL (99.6%) are
present in the LScDC but two lists differ in word ranking. This difference is
measured.
</summary>
    <author>
      <name>Neslihan Suzen</name>
    </author>
    <author>
      <name>Evgeny M. Mirkes</name>
    </author>
    <author>
      <name>Alexander N. Gorban</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">63 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06825v1</id>
    <updated>2019-12-14T11:02:17Z</updated>
    <published>2019-12-14T11:02:17Z</published>
    <title>Knowledge forest: a novel model to organize knowledge fragments</title>
    <summary>  With the rapid growth of knowledge, it shows a steady trend of knowledge
fragmentization. Knowledge fragmentization manifests as that the knowledge
related to a specific topic in a course is scattered in isolated and autonomous
knowledge sources. We term the knowledge of a facet in a specific topic as a
knowledge fragment. The problem of knowledge fragmentization brings two
challenges: First, knowledge is scattered in various knowledge sources, which
exerts users' considerable efforts to search for the knowledge of their
interested topics, thereby leading to information overload. Second, learning
dependencies which refer to the precedence relationships between topics in the
learning process are concealed by the isolation and autonomy of knowledge
sources, thus causing learning disorientation. To solve the knowledge
fragmentization problem, we propose a novel knowledge organization model,
knowledge forest, which consists of facet trees and learning dependencies.
Facet trees can organize knowledge fragments with facet hyponymy to alleviate
information overload. Learning dependencies can organize disordered topics to
cope with learning disorientation. We conduct extensive experiments on three
manually constructed datasets from the Data Structure, Data Mining, and
Computer Network courses, and the experimental results show that knowledge
forest can effectively organize knowledge fragments, and alleviate information
overload and learning disorientation.
</summary>
    <author>
      <name>Qinghua Zheng</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <author>
      <name>Hongwei Zeng</name>
    </author>
    <author>
      <name>Zhaotong Guo</name>
    </author>
    <author>
      <name>Bei Wu</name>
    </author>
    <author>
      <name>Bifan Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figures, Accepted for publication in Science China
  Information Science</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08084v1</id>
    <updated>2019-12-14T10:29:13Z</updated>
    <published>2019-12-14T10:29:13Z</published>
    <title>A Context-Aware Approach for Detecting Check-Worthy Claims in Political
  Debates</title>
    <summary>  In the context of investigative journalism, we address the problem of
automatically identifying which claims in a given document are most worthy and
should be prioritized for fact-checking. Despite its importance, this is a
relatively understudied problem. Thus, we create a new dataset of political
debates, containing statements that have been fact-checked by nine reputable
sources, and we train machine learning models to predict which claims should be
prioritized for fact-checking, i.e., we model the problem as a ranking task.
Unlike previous work, which has looked primarily at sentences in isolation, in
this paper we focus on a rich input representation modeling the context:
relationship between the target statement and the larger context of the debate,
interaction between the opponents, and reaction by the moderator and by the
public. Our experiments show state-of-the-art results, outperforming a strong
rivaling system by a margin, while also confirming the importance of the
contextual information.
</summary>
    <author>
      <name>Pepa Gencheva</name>
    </author>
    <author>
      <name>Ivan Koychev</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Check-worthiness; Fact-Checking; Veracity; Neural Networks. arXiv
  admin note: substantial text overlap with arXiv:1908.01328</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">RANLP-2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.08084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06813v1</id>
    <updated>2019-12-14T09:30:52Z</updated>
    <published>2019-12-14T09:30:52Z</published>
    <title>Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using
  Transformer with Text-to-Speech Pretraining</title>
    <summary>  We introduce a novel sequence-to-sequence (seq2seq) voice conversion (VC)
model based on the Transformer architecture with text-to-speech (TTS)
pretraining. Seq2seq VC models are attractive owing to their ability to convert
prosody. While seq2seq models based on recurrent neural networks (RNNs) and
convolutional neural networks (CNNs) have been successfully applied to VC, the
use of the Transformer network, which has shown promising results in various
speech processing tasks, has not yet been investigated. Nonetheless, their
data-hungry property and the mispronunciation of converted speech make seq2seq
models far from practical. To this end, we propose a simple yet effective
pretraining technique to transfer knowledge from learned TTS models, which
benefit from large-scale, easily accessible TTS corpora. VC models initialized
with such pretrained model parameters are able to generate effective hidden
representations for high-fidelity, highly intelligible converted speech.
Experimental results show that such a pretraining scheme can facilitate
data-efficient training and outperform an RNN-based seq2seq VC model in terms
of intelligibility, naturalness, and similarity.
</summary>
    <author>
      <name>Wen-Chin Huang</name>
    </author>
    <author>
      <name>Tomoki Hayashi</name>
    </author>
    <author>
      <name>Yi-Chiao Wu</name>
    </author>
    <author>
      <name>Hirokazu Kameoka</name>
    </author>
    <author>
      <name>Tomoki Toda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06810v1</id>
    <updated>2019-12-14T08:58:01Z</updated>
    <published>2019-12-14T08:58:01Z</published>
    <title>Proppy: A System to Unmask Propaganda in Online News</title>
    <summary>  We present proppy, the first publicly available real-world, real-time
propaganda detection system for online news, which aims at raising awareness,
thus potentially limiting the impact of propaganda and helping fight
disinformation. The system constantly monitors a number of news sources,
deduplicates and clusters the news into events, and organizes the articles
about an event on the basis of the likelihood that they contain propagandistic
content. The system is trained on known propaganda sources using a variety of
stylistic features. The evaluation results on a standard dataset show
state-of-the-art results for propaganda detection.
</summary>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Giovanni Da San Martino</name>
    </author>
    <author>
      <name>Israa Jaradat</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">propaganda, disinformation, fake news</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Thirty-Third AAAI Conference on Artificial Intelligence
  (AAAI-2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.06810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06806v1</id>
    <updated>2019-12-14T08:44:18Z</updated>
    <published>2019-12-14T08:44:18Z</published>
    <title>SemEval-2013 Task 2: Sentiment Analysis in Twitter</title>
    <summary>  In recent years, sentiment analysis in social media has attracted a lot of
research interest and has been used for a number of applications.
Unfortunately, research has been hindered by the lack of suitable datasets,
complicating the comparison between approaches. To address this issue, we have
proposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two
subtasks: A, an expression-level subtask, and B, a message-level subtask. We
used crowdsourcing on Amazon Mechanical Turk to label a large Twitter training
dataset along with additional test sets of Twitter and SMS messages for both
subtasks. All datasets used in the evaluation are released to the research
community. The task attracted significant interest and a total of 149
submissions from 44 teams. The best-performing team achieved an F1 of 88.9% and
69% for subtasks A and B, respectively.
</summary>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <author>
      <name>Alan Ritter</name>
    </author>
    <author>
      <name>Sara Rosenthal</name>
    </author>
    <author>
      <name>Veselin Stoyanov</name>
    </author>
    <author>
      <name>Theresa Wilson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Sentiment analysis, microblog sentiment analysis, Twitter opinion
  mining, SMS</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.06806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10435v1</id>
    <updated>2019-12-14T06:44:12Z</updated>
    <published>2019-12-14T06:44:12Z</published>
    <title>BERTQA -- Attention on Steroids</title>
    <summary>  In this work, we extend the Bidirectional Encoder Representations from
Transformers (BERT) with an emphasis on directed coattention to obtain an
improved F1 performance on the SQUAD2.0 dataset. The Transformer architecture
on which BERT is based places hierarchical global attention on the
concatenation of the context and query. Our additions to the BERT architecture
augment this attention with a more focused context to query (C2Q) and query to
context (Q2C) attention via a set of modified Transformer encoder units. In
addition, we explore adding convolution-based feature extraction within the
coattention architecture to add localized information to self-attention. We
found that coattention significantly improves the no answer F1 by 4 points in
the base and 1 point in the large architecture. After adding skip connections
the no answer F1 improved further without causing an additional loss in has
answer F1. The addition of localized feature extraction added to attention
produced an overall dev F1 of 77.03 in the base architecture. We applied our
findings to the large BERT model which contains twice as many layers and
further used our own augmented version of the SQUAD 2.0 dataset created by back
translation, which we have named SQUAD 2.Q. Finally, we performed
hyperparameter tuning and ensembled our best models for a final F1/EM of
82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).
</summary>
    <author>
      <name>Ankit Chadha</name>
    </author>
    <author>
      <name>Rewa Sood</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06745v1</id>
    <updated>2019-12-13T23:32:38Z</updated>
    <published>2019-12-13T23:32:38Z</published>
    <title>An Unsupervised Domain-Independent Framework for Automated Detection of
  Persuasion Tactics in Text</title>
    <summary>  With the increasing growth of social media, people have started relying
heavily on the information shared therein to form opinions and make decisions.
While such a reliance is motivation for a variety of parties to promote
information, it also makes people vulnerable to exploitation by slander,
misinformation, terroristic and predatorial advances. In this work, we aim to
understand and detect such attempts at persuasion. Existing works on detecting
persuasion in text make use of lexical features for detecting persuasive
tactics, without taking advantage of the possible structures inherent in the
tactics used. We formulate the task as a multi-class classification problem and
propose an unsupervised, domain-independent machine learning framework for
detecting the type of persuasion used in text, which exploits the inherent
sentence structure present in the different persuasion tactics. Our work shows
promising results as compared to existing work.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Katia Sycara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 8 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06728v1</id>
    <updated>2019-12-13T22:06:59Z</updated>
    <published>2019-12-13T22:06:59Z</published>
    <title>Associating Natural Language Comment and Source Code Entities</title>
    <summary>  Comments are an integral part of software development; they are natural
language descriptions associated with source code elements. Understanding
explicit associations can be useful in improving code comprehensibility and
maintaining the consistency between code and comments. As an initial step
towards this larger goal, we address the task of associating entities in
Javadoc comments with elements in Java source code. We propose an approach for
automatically extracting supervised data using revision histories of open
source projects and present a manually annotated evaluation dataset for this
task. We develop a binary classifier and a sequence labeling model by crafting
a rich feature set which encompasses various aspects of code, comments, and the
relationships between them. Experiments show that our systems outperform
several baselines learning from the proposed supervision.
</summary>
    <author>
      <name>Sheena Panthaplackel</name>
    </author>
    <author>
      <name>Milos Gligoric</name>
    </author>
    <author>
      <name>Raymond J. Mooney</name>
    </author>
    <author>
      <name>Junyi Jessy Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06721v1</id>
    <updated>2019-12-13T21:49:30Z</updated>
    <published>2019-12-13T21:49:30Z</published>
    <title>Long-Term Planning and Situational Awareness in OpenAI Five</title>
    <summary>  Understanding how knowledge about the world is represented within model-free
deep reinforcement learning methods is a major challenge given the black box
nature of its learning process within high-dimensional observation and action
spaces. AlphaStar and OpenAI Five have shown that agents can be trained without
any explicit hierarchical macro-actions to reach superhuman skill in games that
require taking thousands of actions before reaching the final goal. Assessing
the agent's plans and game understanding becomes challenging given the lack of
hierarchy or explicit representations of macro-actions in these models, coupled
with the incomprehensible nature of the internal representations.
  In this paper, we study the distributed representations learned by OpenAI
Five to investigate how game knowledge is gradually obtained over the course of
training. We also introduce a general technique for learning a model from the
agent's hidden states to identify the formation of plans and subgoals. We show
that the agent can learn situational similarity across actions, and find
evidence of planning towards accomplishing subgoals minutes before they are
executed. We perform a qualitative analysis of these predictions during the
games against the DotA 2 world champions OG in April 2019.
</summary>
    <author>
      <name>Jonathan Raiman</name>
    </author>
    <author>
      <name>Susan Zhang</name>
    </author>
    <author>
      <name>Filip Wolski</name>
    </author>
    <link href="http://arxiv.org/abs/1912.06721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06719v1</id>
    <updated>2019-12-13T21:41:39Z</updated>
    <published>2019-12-13T21:41:39Z</published>
    <title>Neural Network Surgery with Sets</title>
    <summary>  The cost to train machine learning models has been increasing exponentially,
making exploration and research into the correct features and architecture a
costly or intractable endeavor at scale. However, using a technique named
"surgery" OpenAI Five was continuously trained to play the game DotA 2 over the
course of 10 months through 20 major changes in features and architecture.
Surgery transfers trained weights from one network to another after a selection
process to determine which sections of the model are unchanged and which must
be re-initialized. In the past, the selection process relied on heuristics,
manual labor, or pre-existing boundaries in the structure of the model,
limiting the ability to salvage experiments after modifications of the feature
set or input reorderings.
  We propose a solution to automatically determine which components of a neural
network model should be salvaged and which require retraining. We achieve this
by allowing the model to operate over discrete sets of features and use
set-based operations to determine the exact relationship between inputs and
outputs, and how they change across tweaks in model architecture. In this
paper, we introduce the methodology for enabling neural networks to operate on
sets, derive two methods for detecting feature-parameter interaction maps, and
show their equivalence. We empirically validate that we can surgery weights
across feature and architecture changes to the OpenAI Five model.
</summary>
    <author>
      <name>Jonathan Raiman</name>
    </author>
    <author>
      <name>Susan Zhang</name>
    </author>
    <author>
      <name>Christy Dennison</name>
    </author>
    <link href="http://arxiv.org/abs/1912.06719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06670v2</id>
    <updated>2020-03-05T20:37:08Z</updated>
    <published>2019-12-13T19:22:44Z</published>
    <title>Common Voice: A Massively-Multilingual Speech Corpus</title>
    <summary>  The Common Voice corpus is a massively-multilingual collection of transcribed
speech intended for speech technology research and development. Common Voice is
designed for Automatic Speech Recognition purposes but can be useful in other
domains (e.g. language identification). To achieve scale and sustainability,
the Common Voice project employs crowdsourcing for both data collection and
data validation. The most recent release includes 29 languages, and as of
November 2019 there are a total of 38 languages collecting data. Over 50,000
individuals have participated so far, resulting in 2,500 hours of collected
audio. To our knowledge this is the largest audio corpus in the public domain
for speech recognition, both in terms of number of hours and number of
languages. As an example use case for Common Voice, we present speech
recognition experiments using Mozilla's DeepSpeech Speech-to-Text toolkit. By
applying transfer learning from a source English model, we find an average
Character Error Rate improvement of 5.99 +/- 5.48 for twelve target languages
(German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton,
Tatar, Chuvash, and Kabyle). For most of these languages, these are the first
ever published results on end-to-end Automatic Speech Recognition.
</summary>
    <author>
      <name>Rosana Ardila</name>
    </author>
    <author>
      <name>Megan Branson</name>
    </author>
    <author>
      <name>Kelly Davis</name>
    </author>
    <author>
      <name>Michael Henretty</name>
    </author>
    <author>
      <name>Michael Kohler</name>
    </author>
    <author>
      <name>Josh Meyer</name>
    </author>
    <author>
      <name>Reuben Morais</name>
    </author>
    <author>
      <name>Lindsay Saunders</name>
    </author>
    <author>
      <name>Francis M. Tyers</name>
    </author>
    <author>
      <name>Gregor Weber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06670v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06670v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06638v2</id>
    <updated>2020-02-18T19:08:58Z</updated>
    <published>2019-12-13T18:15:37Z</published>
    <title>WaLDORf: Wasteless Language-model Distillation On Reading-comprehension</title>
    <summary>  Transformer based Very Large Language Models (VLLMs) like BERT, XLNet and
RoBERTa, have recently shown tremendous performance on a large variety of
Natural Language Understanding (NLU) tasks. However, due to their size, these
VLLMs are extremely resource intensive and cumbersome to deploy at production
time. Several recent publications have looked into various ways to distil
knowledge from a transformer based VLLM (most commonly BERT-Base) into a
smaller model which can run much faster at inference time. Here, we propose a
novel set of techniques which together produce a task-specific hybrid
convolutional and transformer model, WaLDORf, that achieves state-of-the-art
inference speed while still being more accurate than previous distilled models.
</summary>
    <author>
      <name>James Yi Tian</name>
    </author>
    <author>
      <name>Alexander P. Kreuzer</name>
    </author>
    <author>
      <name>Pai-Hung Chen</name>
    </author>
    <author>
      <name>Hans-Martin Will</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added Figure, minor edits for clarity</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06638v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06638v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06615v1</id>
    <updated>2019-12-13T17:26:34Z</updated>
    <published>2019-12-13T17:26:34Z</published>
    <title>Lessons from reinforcement learning for biological representations of
  space</title>
    <summary>  Neuroscientists postulate 3D representations in the brain in a variety of
different coordinate frames (e.g. 'head-centred', 'hand-centred' and
'world-based'). Recent advances in reinforcement learning demonstrate a quite
different approach that may provide a more promising model for biological
representations underlying spatial perception and navigation. In this paper, we
focus on reinforcement learning methods that reward an agent for arriving at a
target image without any attempt to build up a 3D 'map'. We test the ability of
this type of representation to support geometrically consistent spatial tasks,
such as interpolating between learned locations, and compare its performance to
that of a hand-crafted representation which has, by design, a high degree of
geometric consistency. Our comparison of these two models demonstrates that it
is advantageous to include information about the persistence of features as the
camera translates (e.g. distant features persist). It is likely that
non-Cartesian representations of this sort will be increasingly important in
the search for robust models of human spatial perception and navigation.
</summary>
    <author>
      <name>Alex Muryy</name>
    </author>
    <author>
      <name>N. Siddharth</name>
    </author>
    <author>
      <name>Nantas Nardelli</name>
    </author>
    <author>
      <name>Andrew Glennerster</name>
    </author>
    <author>
      <name>Philip H. S. Torr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages including Appendix, 5 figures plus 3 figures in Appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06598v2</id>
    <updated>2020-03-10T12:19:52Z</updated>
    <published>2019-12-13T16:49:16Z</published>
    <title>Document Sub-structure in Neural Machine Translation</title>
    <summary>  Current approaches to machine translation (MT) either translate sentences in
isolation, disregarding the context they appear in, or model context at the
level of the full document, without a notion of any internal structure the
document may have. In this work we consider the fact that documents are rarely
homogeneous blocks of text, but rather consist of parts covering different
topics. Some documents, such as biographies and encyclopedia entries, have
highly predictable, regular structures in which sections are characterised by
different topics. We draw inspiration from Louis and Webber (2014) who use this
information to improve statistical MT and transfer their proposal into the
framework of neural MT. We compare two different methods of including
information about the topic of the section within which each sentence is found:
one using side constraints and the other using a cache-based model. We create
and release the data on which we run our experiments - parallel corpora for
three language pairs (Chinese-English, French-English, Bulgarian-English) from
Wikipedia biographies, which we extract automatically, preserving the
boundaries of sections within the articles.
</summary>
    <author>
      <name>Radina Dobreva</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <author>
      <name>Rachel Bawden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06311v2</id>
    <updated>2020-01-10T18:03:11Z</updated>
    <published>2019-12-13T03:38:14Z</published>
    <title>Short-duration Speaker Verification (SdSV) Challenge 2020: the Challenge
  Evaluation Plan</title>
    <summary>  This document describes the Short-duration Speaker Verification (SdSV)
Challenge 2020. The main goal of the challenge is to evaluate new technologies
for text-dependent (TD) and text-independent (TI) speaker verification (SV) in
a short duration scenario. The proposed challenge evaluates SdSV with varying
degree of phonetic overlap between the enrollment and test utterances
(cross-lingual). It is the first challenge with a broad focus on systematic
benchmark and analysis on varying degrees of phonetic variability on
short-duration speaker recognition. We expect that modern methods (deep neural
networks in particular) will play a key role.
</summary>
    <author>
      <name>Hossein Zeinali</name>
    </author>
    <author>
      <name>Kong Aik Lee</name>
    </author>
    <author>
      <name>Jahangir Alam</name>
    </author>
    <author>
      <name>Lukas Burget</name>
    </author>
    <link href="http://arxiv.org/abs/1912.06311v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06311v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06262v2</id>
    <updated>2019-12-23T19:10:03Z</updated>
    <published>2019-12-12T23:18:16Z</published>
    <title>Extracting clinical concepts from user queries</title>
    <summary>  Clinical concept extraction often begins with clinical Named Entity
Recognition (NER). Often trained on annotated clinical notes, clinical NER
models tend to struggle with tagging clinical entities in user queries because
of the structural differences between clinical notes and user queries. User
queries, unlike clinical notes, are often ungrammatical and incoherent. In many
cases, user queries are compounded of multiple clinical entities, without comma
or conjunction words separating them. By using as dataset a mixture of
annotated clinical notes and synthesized user queries, we adapt a clinical NER
model based on the BiLSTM-CRF architecture for tagging clinical entities in
user queries. Our contribution are the following: 1) We found that when trained
on a mixture of synthesized user queries and clinical notes, the NER model
performs better on both user queries and clinical notes. 2) We provide an
end-to-end and easy-to-implement framework for clinical concept extraction from
user queries.
</summary>
    <author>
      <name>Yue Zhao</name>
    </author>
    <author>
      <name>John Handley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures. Added references. Corrected wording and typos,
  results unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06262v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06262v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10168v1</id>
    <updated>2019-12-12T21:21:45Z</updated>
    <published>2019-12-12T21:21:45Z</published>
    <title>Two Way Adversarial Unsupervised Word Translation</title>
    <summary>  Word translation is a problem in machine translation that seeks to build
models that recover word level correspondence between languages. Recent
approaches to this problem have shown that word translation models can learned
with very small seeding dictionaries, and even without any starting
supervision. In this paper we propose a method to jointly find translations
between a pair of languages. Not only does our method learn translations in
both directions but it improves accuracy of those translations over past
methods.
</summary>
    <author>
      <name>Blaine Cole</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06214v1</id>
    <updated>2019-12-12T21:11:56Z</updated>
    <published>2019-12-12T21:11:56Z</published>
    <title>Context-aware Entity Linking with Attentive Neural Networks on Wikidata
  Knowledge Graph</title>
    <summary>  The Entity Linking (EL) approaches have been a long-standing research field
and find applicability in various use cases such as semantic search, text
annotation, question answering, etc. Although effective and robust, current
approaches are still limited to particular knowledge repositories (e.g.
Wikipedia) or specific knowledge graphs (e.g. Freebase, DBpedia, and YAGO). The
collaborative knowledge graphs such as Wikidata excessively rely on the crowd
to author the information. Since the crowd is not bound to a standard protocol
for assigning entity titles, the knowledge graph is populated by non-standard,
noisy, long or even sometimes awkward titles. The issue of long, implicit, and
nonstandard entity representations is a challenge in EL approaches for gaining
high precision and recall. In this paper, we advance the state-of-the-art
approaches by developing a context-aware attentive neural network approach for
entity linking on Wikidata. Our approach contributes by exploiting the
sufficient context from a Knowledge Graph as a source of background knowledge,
which is then fed into the neural network. This approach demonstrates merit to
address challenges associated with entity titles (multi-word, long, implicit,
case-sensitive). Our experimental study shows $\approx$8\% improvements over
the baseline approach, and significantly outperform an end to end approach for
Wikidata entity linking. This work, first of its kind, opens a new direction
for the research community to pay attention to developing context-aware EL
approaches for collaborative knowledge graphs.
</summary>
    <author>
      <name>Isaiah Onando Mulang</name>
    </author>
    <author>
      <name>Kuldeep Singh</name>
    </author>
    <author>
      <name>Akhilesh Vyas</name>
    </author>
    <author>
      <name>Saeedeh Shekarpour</name>
    </author>
    <author>
      <name>Ahmad Sakor</name>
    </author>
    <author>
      <name>Maria Esther Vidal</name>
    </author>
    <author>
      <name>Soren Auer</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06208v1</id>
    <updated>2019-12-12T20:56:59Z</updated>
    <published>2019-12-12T20:56:59Z</published>
    <title>Shaping representations through communication: community size effect in
  artificial learning systems</title>
    <summary>  Motivated by theories of language and communication that explain why
communities with large numbers of speakers have, on average, simpler languages
with more regularity, we cast the representation learning problem in terms of
learning to communicate. Our starting point sees the traditional autoencoder
setup as a single encoder with a fixed decoder partner that must learn to
communicate. Generalizing from there, we introduce community-based autoencoders
in which multiple encoders and decoders collectively learn representations by
being randomly paired up on successive training iterations. We find that
increasing community sizes reduce idiosyncrasies in the learned codes,
resulting in representations that better encode concept categories and
correlate with human feature norms.
</summary>
    <author>
      <name>Olivier Tieleman</name>
    </author>
    <author>
      <name>Angeliki Lazaridou</name>
    </author>
    <author>
      <name>Shibl Mourad</name>
    </author>
    <author>
      <name>Charles Blundell</name>
    </author>
    <author>
      <name>Doina Precup</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019 workshop on visually grounded interaction and language</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06203v1</id>
    <updated>2019-12-12T20:48:52Z</updated>
    <published>2019-12-12T20:48:52Z</published>
    <title>ManiGAN: Text-Guided Image Manipulation</title>
    <summary>  The goal of our paper is to semantically edit parts of an image to match a
given text that describes desired attributes (e.g., texture, colour, and
background), while preserving other contents that are irrelevant to the text.
To achieve this, we propose a novel generative adversarial network (ManiGAN),
which contains two key components: text-image affine combination module (ACM)
and detail correction module (DCM). The ACM selects image regions relevant to
the given text and then correlates the regions with corresponding semantic
words for effective manipulation. Meanwhile, it encodes original image features
to help reconstruct text-irrelevant contents. The DCM rectifies mismatched
attributes and completes missing contents of the synthetic image. Finally, we
suggest a new metric for evaluating image manipulation results, in terms of
both the generation of new attributes and the reconstruction of text-irrelevant
contents. Extensive experiments on the CUB and COCO datasets demonstrate the
superior performance of the proposed method.
</summary>
    <author>
      <name>Bowen Li</name>
    </author>
    <author>
      <name>Xiaojuan Qi</name>
    </author>
    <author>
      <name>Thomas Lukasiewicz</name>
    </author>
    <author>
      <name>Philip H. S. Torr</name>
    </author>
    <link href="http://arxiv.org/abs/1912.06203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06174v1</id>
    <updated>2019-12-12T19:32:41Z</updated>
    <published>2019-12-12T19:32:41Z</published>
    <title>Training without training data: Improving the generalizability of
  automated medical abbreviation disambiguation</title>
    <summary>  Abbreviation disambiguation is important for automated clinical note
processing due to the frequent use of abbreviations in clinical settings.
Current models for automated abbreviation disambiguation are restricted by the
scarcity and imbalance of labeled training data, decreasing their
generalizability to orthogonal sources. In this work we propose a novel data
augmentation technique that utilizes information from related medical concepts,
which improves our model's ability to generalize. Furthermore, we show that
incorporating the global context information within the whole medical note (in
addition to the traditional local context window), can significantly improve
the model's representation for abbreviations. We train our model on a public
dataset (MIMIC III) and test its performance on datasets from different sources
(CASI, i2b2). Together, these two techniques boost the accuracy of abbreviation
disambiguation by almost 14% on the CASI dataset and 4% on i2b2.
</summary>
    <author>
      <name>Marta Skreta</name>
    </author>
    <author>
      <name>Aryan Arbabi</name>
    </author>
    <author>
      <name>Jixuan Wang</name>
    </author>
    <author>
      <name>Michael Brudno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS Machine Learning for Healthcare 2019 Conference Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05957v2</id>
    <updated>2019-12-15T15:46:55Z</updated>
    <published>2019-12-12T13:54:09Z</published>
    <title>Text as Environment: A Deep Reinforcement Learning Text Readability
  Assessment Model</title>
    <summary>  Evaluating the readability of a text can significantly facilitate the precise
expression of information in a written form. The formulation of text
readability assessment demands the identification of meaningful properties of
the text and correct conversion of features to the right readability level.
Sophisticated features and models are being used to evaluate the
comprehensibility of texts accurately. Still, these models are challenging to
implement, heavily language-dependent, and do not perform well on short texts.
Deep reinforcement learning models are demonstrated to be helpful in further
improvement of state-of-the-art text readability assessment models. The main
contributions of the proposed approach are the automation of feature
extraction, loosening the tight language dependency of text readability
assessment task, and efficient use of text by finding the minimum portion of a
text required to assess its readability. The experiments on Weebit, Cambridge
Exams, and Persian readability datasets display the model's state-of-the-art
precision, efficiency, and the capability to be applied to other languages.
</summary>
    <author>
      <name>Hamid Mohammadi</name>
    </author>
    <author>
      <name>Seyed Hossein Khasteh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, 6 equations, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05957v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05957v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05898v1</id>
    <updated>2019-12-12T12:45:34Z</updated>
    <published>2019-12-12T12:45:34Z</published>
    <title>Improving Interpretability of Word Embeddings by Generating Definition
  and Usage</title>
    <summary>  Word Embeddings, which encode semantic and syntactic features, have achieved
success in many natural language processing tasks recently. However, the
lexical semantics captured by these embeddings are difficult to interpret due
to the dense vector representations. In order to improve the interpretability
of word vectors, we explore definition modeling task and propose a novel
framework (Semantics-Generator) to generate more reasonable and understandable
context-dependent definitions. Moreover, we introduce usage modeling and study
whether it is possible to utilize distributed representations to generate
example sentences of words. These ways of semantics generation are a more
direct and explicit expression of embedding's semantics. Two multi-task
learning methods are used to combine usage modeling and definition modeling. To
verify our approach, we construct Oxford-2019 dataset, where each entry
contains word, context, example sentence and corresponding definition.
Experimental results show that Semantics-Generator achieves the
state-of-the-art result in definition modeling and the multi-task learning
methods are helpful for two tasks to improve the performance.
</summary>
    <author>
      <name>Haitong Zhang</name>
    </author>
    <author>
      <name>Yongping Du</name>
    </author>
    <author>
      <name>Jiaxin Sun</name>
    </author>
    <author>
      <name>Qingxiao Li</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05881v1</id>
    <updated>2019-12-12T11:17:30Z</updated>
    <published>2019-12-12T11:17:30Z</published>
    <title>Singing Synthesis: with a little help from my attention</title>
    <summary>  We present a novel system for singing synthesis, based on attention. Starting
from a musical score with notes and lyrics, we build a phoneme-level multi
stream note embedding. The embedding contains the information encoded in the
score regarding pitch, duration and the phonemes to be pronounced on each note.
This note representation is used to condition an attention-based
sequence-to-sequence architecture, in order to generate mel-spectrograms. Our
model demonstrates attention can be successfully applied to the singing
synthesis field. The system requires considerably less explicit modelling of
voice features such as F0 patterns, vibratos, and note and phoneme durations,
than most models in the literature. However, we observe that completely
dispensing with any duration modelling introduces occasional instabilities in
the generated spectrograms. We train an autoregressive WaveNet to be used as a
neural vocoder to synthesise the mel-spectrograms produced by the
sequence-to-sequence architecture, using a combination of speech and singing
data.
</summary>
    <author>
      <name>Orazio Angelini</name>
    </author>
    <author>
      <name>Alexis Moinet</name>
    </author>
    <author>
      <name>Kayoko Yanagisawa</name>
    </author>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05877v1</id>
    <updated>2019-12-12T11:02:30Z</updated>
    <published>2019-12-12T11:02:30Z</published>
    <title>Extending Machine Language Models toward Human-Level Language
  Understanding</title>
    <summary>  Language is central to human intelligence. We review recent breakthroughs in
machine language processing and consider what remains to be achieved. Recent
approaches rely on domain general principles of learning and representation
captured in artificial neural networks. Most current models, however, focus too
closely on language itself. In humans, language is part of a larger system for
acquiring, representing, and communicating about objects and situations in the
physical and social world, and future machine language models should emulate
such a system. We describe existing machine models linking language to concrete
situations, and point toward extensions to address more abstract cases. Human
language processing exploits complementary learning systems, including a deep
neural network-like learning system that learns gradually as machine systems
do, as well as a fast-learning system that supports learning new information
quickly. Adding such a system to machine language models will be an important
further step toward truly human-like language understanding.
</summary>
    <author>
      <name>James L. McClelland</name>
    </author>
    <author>
      <name>Felix Hill</name>
    </author>
    <author>
      <name>Maja Rudolph</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05846v1</id>
    <updated>2019-12-12T09:30:02Z</updated>
    <published>2019-12-12T09:30:02Z</published>
    <title>The Benefits of Close-Domain Fine-Tuning for Table Detection in Document
  Images</title>
    <summary>  A correct localisation of tables in a document is instrumental for
determining their structure and extracting their contents; therefore, table
detection is a key step in table understanding. Nowadays, the most successful
methods for table detection in document images employ deep learning algorithms;
and, particularly, a technique known as fine-tuning. In this context, such a
technique exports the knowledge acquired to detect objects in natural images to
detect tables in document images. However, there is only a vague relation
between natural and document images, and fine-tuning works better when there is
a close relation between the source and target task. In this paper, we show
that it is more beneficial to employ fine-tuning from a closer domain. To this
aim, we train different object detection algorithms (namely, Mask R-CNN,
RetinaNet, SSD and YOLO) using the TableBank dataset (a dataset of images of
academic documents designed for table detection and recognition), and fine-tune
them for several heterogeneous table detection datasets. Using this approach,
we considerably improve the accuracy of the detection models fine-tuned from
natural images (in mean a 17%, and, in the best case, up to a 60%).
</summary>
    <author>
      <name>Ángela Casado-García</name>
    </author>
    <author>
      <name>César Domínguez</name>
    </author>
    <author>
      <name>Jónathan Heras</name>
    </author>
    <author>
      <name>Eloy Mata</name>
    </author>
    <author>
      <name>Vico Pascual</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05728v1</id>
    <updated>2019-12-12T02:04:44Z</updated>
    <published>2019-12-12T02:04:44Z</published>
    <title>AliMe KBQA: Question Answering over Structured Knowledge for E-commerce
  Customer Service</title>
    <summary>  With the rise of knowledge graph (KG), question answering over knowledge base
(KBQA) has attracted increasing attention in recent years. Despite much
research has been conducted on this topic, it is still challenging to apply
KBQA technology in industry because business knowledge and real-world questions
can be rather complicated. In this paper, we present AliMe-KBQA, a bold attempt
to apply KBQA in the E-commerce customer service field. To handle real
knowledge and questions, we extend the classic "subject-predicate-object (SPO)"
structure with property hierarchy, key-value structure and compound value type
(CVT), and enhance traditional KBQA with constraints recognition and reasoning
ability. We launch AliMe-KBQA in the Marketing Promotion scenario for merchants
during the "Double 11" period in 2018 and other such promotional events
afterwards. Online results suggest that AliMe-KBQA is not only able to gain
better resolution and improve customer satisfaction, but also becomes the
preferred knowledge management method by business knowledge staffs since it
offers a more convenient and efficient management experience.
</summary>
    <author>
      <name>Feng-Lin Li</name>
    </author>
    <author>
      <name>Weijia Chen</name>
    </author>
    <author>
      <name>Qi Huang</name>
    </author>
    <author>
      <name>Yikun Guo</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05676v1</id>
    <updated>2019-12-11T22:39:51Z</updated>
    <published>2019-12-11T22:39:51Z</published>
    <title>Biases for Emergent Communication in Multi-agent Reinforcement Learning</title>
    <summary>  We study the problem of emergent communication, in which language arises
because speakers and listeners must communicate information in order to solve
tasks. In temporally extended reinforcement learning domains, it has proved
hard to learn such communication without centralized training of agents, due in
part to a difficult joint exploration problem. We introduce inductive biases
for positive signalling and positive listening, which ease this problem. In a
simple one-step environment, we demonstrate how these biases ease the learning
problem. We also apply our methods to a more extended environment, showing that
agents with these inductive biases achieve better performance, and analyse the
resulting communication protocols.
</summary>
    <author>
      <name>Tom Eccles</name>
    </author>
    <author>
      <name>Yoram Bachrach</name>
    </author>
    <author>
      <name>Guy Lever</name>
    </author>
    <author>
      <name>Angeliki Lazaridou</name>
    </author>
    <author>
      <name>Thore Graepel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05533v1</id>
    <updated>2019-12-11T18:58:58Z</updated>
    <published>2019-12-11T18:58:58Z</published>
    <title>SpecAugment on Large Scale Datasets</title>
    <summary>  Recently, SpecAugment, an augmentation scheme for automatic speech
recognition that acts directly on the spectrogram of input utterances, has
shown to be highly effective in enhancing the performance of end-to-end
networks on public datasets. In this paper, we demonstrate its effectiveness on
tasks with large scale datasets by investigating its application to the Google
Multidomain Dataset (Narayanan et al., 2018). We achieve improvement across all
test domains by mixing raw training data augmented with SpecAugment and
noise-perturbed training data when training the acoustic model. We also
introduce a modification of SpecAugment that adapts the time mask size and/or
multiplicity depending on the length of the utterance, which can potentially
benefit large scale tasks. By using adaptive masking, we are able to further
improve the performance of the Listen, Attend and Spell model on LibriSpeech to
2.2% WER on test-clean and 5.2% WER on test-other.
</summary>
    <author>
      <name>Daniel S. Park</name>
    </author>
    <author>
      <name>Yu Zhang</name>
    </author>
    <author>
      <name>Chung-Cheng Chiu</name>
    </author>
    <author>
      <name>Youzheng Chen</name>
    </author>
    <author>
      <name>Bo Li</name>
    </author>
    <author>
      <name>William Chan</name>
    </author>
    <author>
      <name>Quoc V. Le</name>
    </author>
    <author>
      <name>Yonghui Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 tables; submitted to ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05525v1</id>
    <updated>2019-12-11T18:48:05Z</updated>
    <published>2019-12-11T18:48:05Z</published>
    <title>Learning to Request Guidance in Emergent Communication</title>
    <summary>  Previous research into agent communication has shown that a pre-trained guide
can speed up the learning process of an imitation learning agent. The guide
achieves this by providing the agent with discrete messages in an emerged
language about how to solve the task. We extend this one-directional
communication by a one-bit communication channel from the learner back to the
guide: It is able to ask the guide for help, and we limit the guidance by
penalizing the learner for these requests. During training, the agent learns to
control this gate based on its current observation. We find that the amount of
requested guidance decreases over time and guidance is requested in situations
of high uncertainty. We investigate the agent's performance in cases of open
and closed gates and discuss potential motives for the observed gating
behavior.
</summary>
    <author>
      <name>Benjamin Kolb</name>
    </author>
    <author>
      <name>Leon Lang</name>
    </author>
    <author>
      <name>Henning Bartsch</name>
    </author>
    <author>
      <name>Arwin Gansekoele</name>
    </author>
    <author>
      <name>Raymond Koopmanschap</name>
    </author>
    <author>
      <name>Leonardo Romor</name>
    </author>
    <author>
      <name>David Speck</name>
    </author>
    <author>
      <name>Mathijs Mul</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05493v1</id>
    <updated>2019-12-11T17:47:29Z</updated>
    <published>2019-12-11T17:47:29Z</published>
    <title>Quality of syntactic implication of RL-based sentence summarization</title>
    <summary>  Work on summarization has explored both reinforcement learning (RL)
optimization using ROUGE as a reward and syntax-aware models, such as models
those input is enriched with part-of-speech (POS)-tags and dependency
information. However, it is not clear what is the respective impact of these
approaches beyond the standard ROUGE evaluation metric. Especially, RL-based
for summarization is becoming more and more popular. In this paper, we provide
a detailed comparison of these two approaches and of their combination along
several dimensions that relate to the perceived quality of the generated
summaries: number of repeated words, distribution of part-of-speech tags,
impact of sentence length, relevance and grammaticality. Using the standard
Gigaword sentence summarization task, we compare an RL self-critical sequence
training (SCST) method with syntax-aware models that leverage POS tags and
Dependency information. We show that on all qualitative evaluations, the
combined model gives the best results, but also that only training with RL and
without any syntactic information already gives nearly as good results as
syntax-aware models with less parameters and faster training convergence.
</summary>
    <author>
      <name>Hoa T. Le</name>
    </author>
    <author>
      <name>Christophe Cerisara</name>
    </author>
    <author>
      <name>Claire Gardent</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI-20 Workshop on Engineering Dependable and Secure Machine
  Learning Systems (EDSMLS 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05493v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05493v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05467v1</id>
    <updated>2019-12-11T17:05:18Z</updated>
    <published>2019-12-11T17:05:18Z</published>
    <title>MetaMT,a MetaLearning Method Leveraging Multiple Domain Data for Low
  Resource Machine Translation</title>
    <summary>  Manipulating training data leads to robust neural models for MT.
</summary>
    <author>
      <name>Rumeng Li</name>
    </author>
    <author>
      <name>Xun Wang</name>
    </author>
    <author>
      <name>Hong Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05372v3</id>
    <updated>2020-01-09T23:22:38Z</updated>
    <published>2019-12-11T14:59:32Z</published>
    <title>FlauBERT: Unsupervised Language Model Pre-training for French</title>
    <summary>  Language models have become a key step to achieve state-of-the art results in
many different Natural Language Processing (NLP) tasks. Leveraging the huge
amount of unlabeled texts nowadays available, they provide an efficient way to
pre-train continuous word representations that can be fine-tuned for a
downstream task, along with their contextualization at the sentence level. This
has been widely demonstrated for English using contextualized representations
(Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al.,
2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and
share FlauBERT, a model learned on a very large and heterogeneous French
corpus. Models of different sizes are trained using the new CNRS (French
National Centre for Scientific Research) Jean Zay supercomputer. We apply our
French language models to diverse NLP tasks (text classification, paraphrasing,
natural language inference, parsing, word sense disambiguation) and show that
most of the time they outperform other pre-training approaches. Different
versions of FlauBERT as well as a unified evaluation protocol for the
downstream tasks, called FLUE (French Language Understanding Evaluation), are
shared to the research community for further reproducible experiments in French
NLP.
</summary>
    <author>
      <name>Hang Le</name>
    </author>
    <author>
      <name>Loïc Vial</name>
    </author>
    <author>
      <name>Jibril Frej</name>
    </author>
    <author>
      <name>Vincent Segonne</name>
    </author>
    <author>
      <name>Maximin Coavoux</name>
    </author>
    <author>
      <name>Benjamin Lecouteux</name>
    </author>
    <author>
      <name>Alexandre Allauzen</name>
    </author>
    <author>
      <name>Benoît Crabbé</name>
    </author>
    <author>
      <name>Laurent Besacier</name>
    </author>
    <author>
      <name>Didier Schwab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Additional references</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05372v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05372v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05320v2</id>
    <updated>2019-12-18T10:33:05Z</updated>
    <published>2019-12-11T14:02:59Z</published>
    <title>CoSimLex: A Resource for Evaluating Graded Word Similarity in Context</title>
    <summary>  State of the art natural language processing tools are built on
context-dependent word embeddings, but no direct method for evaluating these
representations currently exists. Standard tasks and datasets for intrinsic
evaluation of embeddings are based on judgements of similarity, but ignore
context; standard tasks for word sense disambiguation take account of context
but do not provide continuous measures of meaning similarity. This paper
describes an effort to build a new dataset, CoSimLex, intended to fill this
gap. Building on the standard pairwise similarity task of SimLex-999, it
provides context-dependent similarity measures; covers not only discrete
differences in word sense but more subtle, graded changes in meaning; and
covers not only a well-resourced language (English) but a number of
less-resourced languages. We define the task and evaluation metrics, outline
the dataset collection methodology, and describe the status of the dataset so
far.
</summary>
    <author>
      <name>Carlos Santos Armendariz</name>
    </author>
    <author>
      <name>Matthew Purver</name>
    </author>
    <author>
      <name>Matej Ulčar</name>
    </author>
    <author>
      <name>Senja Pollak</name>
    </author>
    <author>
      <name>Nikola Ljubešić</name>
    </author>
    <author>
      <name>Marko Robnik-Šikonja</name>
    </author>
    <author>
      <name>Mark Granroth-Wilding</name>
    </author>
    <author>
      <name>Kristiina Vaik</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05320v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05320v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05289v2</id>
    <updated>2020-01-17T20:43:49Z</updated>
    <published>2019-12-11T13:34:43Z</published>
    <title>Voice Conversion for Whispered Speech Synthesis</title>
    <summary>  We present an approach to synthesize whisper by applying a handcrafted signal
processing recipe and Voice Conversion (VC) techniques to convert normally
phonated speech to whispered speech. We investigate using Gaussian Mixture
Models (GMM) and Deep Neural Networks (DNN) to model the mapping between
acoustic features of normal speech and those of whispered speech. We evaluate
naturalness and speaker similarity of the converted whisper on an internal
corpus and on the publicly available wTIMIT corpus. We show that applying VC
techniques is significantly better than using rule-based signal processing
methods and it achieves results that are indistinguishable from copy-synthesis
of natural whisper recordings. We investigate the ability of the DNN model to
generalize on unseen speakers, when trained with data from multiple speakers.
We show that excluding the target speaker from the training set has little or
no impact on the perceived naturalness and speaker similarity of the converted
whisper. The proposed DNN method is used in the newly released Whisper Mode of
Amazon Alexa.
</summary>
    <author>
      <name>Marius Cotescu</name>
    </author>
    <author>
      <name>Thomas Drugman</name>
    </author>
    <author>
      <name>Goeric Huybrechts</name>
    </author>
    <author>
      <name>Jaime Lorenzo-Trueba</name>
    </author>
    <author>
      <name>Alexis Moinet</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2019.2961213</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2019.2961213" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Signal Processing Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05289v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05289v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05274v1</id>
    <updated>2019-12-11T12:50:48Z</updated>
    <published>2019-12-11T12:50:48Z</published>
    <title>Two Birds with One Stone: Investigating Invertible Neural Networks for
  Inverse Problems in Morphology</title>
    <summary>  Most problems in natural language processing can be approximated as inverse
problems such as analysis and generation at variety of levels from
morphological (e.g., cat+Plural &lt;-&gt; cats) to semantic (e.g., (call + 1 2) &lt;-&gt;
"Calculate one plus two."). Although the tasks in both directions are closely
related, general approach in the field has been to design separate models
specific for each task. However, having one shared model for both tasks, would
help the researchers exploit the common knowledge among these problems with
reduced time and memory requirements. We investigate a specific class of neural
networks, called Invertible Neural Networks (INNs) (Ardizzone et al. 2019) that
enable simultaneous optimization in both directions, hence allow addressing of
inverse problems via a single model. In this study, we investigate INNs on
morphological problems casted as inverse problems. We apply INNs to various
morphological tasks with varying ambiguity and show that they provide
competitive performance in both directions. We show that they are able to
recover the morphological input parameters, i.e., predicting the lemma (e.g.,
cat) or the morphological tags (e.g., Plural) when run in the reverse
direction, without any significant performance drop in the forward direction,
i.e., predicting the surface form (e.g., cats).
</summary>
    <author>
      <name>Gözde Gül Şahin</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05238v1</id>
    <updated>2019-12-11T11:27:06Z</updated>
    <published>2019-12-11T11:27:06Z</published>
    <title>BERT has a Moral Compass: Improvements of ethical and moral values of
  machines</title>
    <summary>  Allowing machines to choose whether to kill humans would be devastating for
world peace and security. But how do we equip machines with the ability to
learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying
machine learning to human texts can extract deontological ethical reasoning
about "right" and "wrong" conduct by calculating a moral bias score on a
sentence level using sentence embeddings. The machine learned that it is
objectionable to kill living beings, but it is fine to kill time; It is
essential to eat, yet one might not eat dirt; it is important to spread
information, yet one should not spread misinformation. However, the evaluated
moral bias was restricted to simple actions -- one verb -- and a ranking of
actions with surrounding context. Recently BERT ---and variants such as RoBERTa
and SBERT--- has set a new state-of-the-art performance for a wide range of NLP
tasks. But has BERT also a better moral compass? In this paper, we discuss and
show that this is indeed the case. Thus, recent improvements of language
representations also improve the representation of the underlying ethical and
moral values of the machine. We argue that through an advanced semantic
representation of text, BERT allows one to get better insights of moral and
ethical values implicitly represented in text. This enables the Moral Choice
Machine (MCM) to extract more accurate imprints of moral choices and ethical
values.
</summary>
    <author>
      <name>Patrick Schramowski</name>
    </author>
    <author>
      <name>Cigdem Turan</name>
    </author>
    <author>
      <name>Sophie Jentzsch</name>
    </author>
    <author>
      <name>Constantin Rothkopf</name>
    </author>
    <author>
      <name>Kristian Kersting</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05200v2</id>
    <updated>2019-12-12T16:05:41Z</updated>
    <published>2019-12-11T09:33:21Z</published>
    <title>Automatic Spanish Translation of the SQuAD Dataset for Multilingual
  Question Answering</title>
    <summary>  Recently, multilingual question answering became a crucial research topic,
and it is receiving increased interest in the NLP community. However, the
unavailability of large-scale datasets makes it challenging to train
multilingual QA systems with performance comparable to the English ones. In
this work, we develop the Translate Align Retrieve (TAR) method to
automatically translate the Stanford Question Answering Dataset (SQuAD) v1.1 to
Spanish. We then used this dataset to train Spanish QA systems by fine-tuning a
Multilingual-BERT model. Finally, we evaluated our QA models with the recently
proposed MLQA and XQuAD benchmarks for cross-lingual Extractive QA.
Experimental results show that our models outperform the previous
Multilingual-BERT baselines achieving the new state-of-the-art value of 68.1 F1
points on the Spanish MLQA corpus and 77.6 F1 and 61.8 Exact Match points on
the Spanish XQuAD corpus. The resulting, synthetically generated SQuAD-es v1.1
corpora, with almost 100% of data contained in the original English version, to
the best of our knowledge, is the first large-scale QA training resource for
Spanish.
</summary>
    <author>
      <name>Casimiro Pio Carrino</name>
    </author>
    <author>
      <name>Marta R. Costa-jussà</name>
    </author>
    <author>
      <name>José A. R. Fonollosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05200v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05200v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05156v1</id>
    <updated>2019-12-11T07:56:31Z</updated>
    <published>2019-12-11T07:56:31Z</published>
    <title>Lifelong learning for text retrieval and recognition in historical
  handwritten document collections</title>
    <summary>  This chapter provides an overview of the problems that need to be dealt with
when constructing a lifelong-learning retrieval, recognition and indexing
engine for large historical document collections in multiple scripts and
languages, the Monk system. This application is highly variable over time,
since the continuous labeling by end users changes the concept of what a
'ground truth' constitutes. Although current advances in deep learning provide
a huge potential in this application domain, the scale of the problem, i.e.,
more than 520 hugely diverse books, documents and manuscripts precludes the
current meticulous and painstaking human effort which is required in designing
and developing successful deep-learning systems. The ball-park principle is
introduced, which describes the evolution from the sparsely-labeled stage that
can only be addressed by traditional methods or nearest-neighbor methods on
embedded vectors of pre-trained neural networks, up to the other end of the
spectrum where massive labeling allows reliable training of deep-learning
methods. Contents: Introduction, Expectation management, Deep learning, The
ball-park principle, Technical realization, Work flow, Quality and quantity of
material, Industrialization and scalability, Human effort, Algorithms, Object
of recognition, Processing pipeline, Performance,Compositionality, Conclusion.
</summary>
    <author>
      <name>Lambert Schomaker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear as chapter in book: Handwritten Historical Document
  Analysis, Recognition, and Retrieval -- State of the Art and Future Trends,
  in the book series: Series in Machine Perception and Artificial Intelligence
  World Scientific, ISSN (print): 1793-0839 Original version deposited at
  Zenodo: https://zenodo.org/record/2346885#.XfCfsq5ytpg on December 17, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11552v1</id>
    <updated>2019-12-11T07:37:45Z</updated>
    <published>2019-12-11T07:37:45Z</published>
    <title>Unwanted Advances in Higher Education: Uncovering Sexual Harassment
  Experiences in Academia with Text Mining</title>
    <summary>  Sexual harassment in academia is often a hidden problem because victims are
usually reluctant to report their experiences. Recently, a web survey was
developed to provide an opportunity to share thousands of sexual harassment
experiences in academia. Using an efficient approach, this study collected and
investigated more than 2,000 sexual harassment experiences to better understand
these unwanted advances in higher education. This paper utilized text mining to
disclose hidden topics and explore their weight across three variables:
harasser gender, institution type, and victim's field of study. We mapped the
topics on five themes drawn from the sexual harassment literature and found
that more than 50% of the topics were assigned to the unwanted sexual attention
theme. Fourteen percent of the topics were in the gender harassment theme, in
which insulting, sexist, or degrading comments or behavior was directed towards
women. Five percent of the topics involved sexual coercion (a benefit is
offered in exchange for sexual favors), 5% involved sex discrimination, and 7%
of the topics discussed retaliation against the victim for reporting the
harassment, or for simply not complying with the harasser. Findings highlight
the power differential between faculty and students, and the toll on students
when professors abuse their power. While some topics did differ based on type
of institution, there were no differences between the topics based on gender of
harasser or field of study. This research can be beneficial to researchers in
further investigation of this paper's dataset, and to policymakers in improving
existing policies to create a safe and supportive environment in academia.
</summary>
    <author>
      <name>Amir Karami</name>
    </author>
    <author>
      <name>Cynthia Nicole White</name>
    </author>
    <author>
      <name>Kayla Ford</name>
    </author>
    <author>
      <name>Suzanne Swan</name>
    </author>
    <author>
      <name>Melek Yildiz Spinel</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05147v1</id>
    <updated>2019-12-11T07:29:59Z</updated>
    <published>2019-12-11T07:29:59Z</published>
    <title>Improving Neural Protein-Protein Interaction Extraction with Knowledge
  Selection</title>
    <summary>  Protein-protein interaction (PPI) extraction from published scientific
literature provides additional support for precision medicine efforts.
Meanwhile, knowledge bases (KBs) contain huge amounts of structured information
of protein entities and their relations, which can be encoded in entity and
relation embeddings to help PPI extraction. However, the prior knowledge of
protein-protein pairs must be selectively used so that it is suitable for
different contexts. This paper proposes a Knowledge Selection Model (KSM) to
fuse the selected prior knowledge and context information for PPI extraction.
Firstly, two Transformers encode the context sequence of a protein pair
according to each protein embedding, respectively. Then, the two outputs are
fed to a mutual attention to capture the important context features towards the
protein pair. Next, the context features are used to distill the relation
embedding by a knowledge selector. Finally, the selected relation embedding and
the context features are concatenated for PPI extraction. Experiments on the
BioCreative VI PPI dataset show that KSM achieves a new state-of-the-art
performance (38.08% F1-score) by adding knowledge selection.
</summary>
    <author>
      <name>Huiwei Zhou</name>
    </author>
    <author>
      <name>Xuefei Li</name>
    </author>
    <author>
      <name>Weihong Yao</name>
    </author>
    <author>
      <name>Zhuang Liu</name>
    </author>
    <author>
      <name>Shixian Ning</name>
    </author>
    <author>
      <name>Chengkun Lang</name>
    </author>
    <author>
      <name>Lei Du</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compbiolchem.2019.107146</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compbiolchem.2019.107146" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Computational Biology and Chemistry; 14 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Biology and Chemistry, 2019, 83: 107146</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.05147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05134v1</id>
    <updated>2019-12-11T06:21:16Z</updated>
    <published>2019-12-11T06:21:16Z</published>
    <title>Unsupervised Neural Dialect Translation with Commonality and Diversity
  Modeling</title>
    <summary>  As a special machine translation task, dialect translation has two main
characteristics: 1) lack of parallel training corpus; and 2) possessing similar
grammar between two sides of the translation. In this paper, we investigate how
to exploit the commonality and diversity between dialects thus to build
unsupervised translation models merely accessing to monolingual data.
Specifically, we leverage pivot-private embedding, layer coordination, as well
as parameter sharing to sufficiently model commonality and diversity among
source and target, ranging from lexical, through syntactic, to semantic levels.
In order to examine the effectiveness of the proposed models, we collect 20
million monolingual corpus for each of Mandarin and Cantonese, which are
official language and the most widely used dialect in China. Experimental
results reveal that our methods outperform rule-based simplified and
traditional Chinese conversion and conventional unsupervised translation models
over 12 BLEU scores.
</summary>
    <author>
      <name>Yu Wan</name>
    </author>
    <author>
      <name>Baosong Yang</name>
    </author>
    <author>
      <name>Derek F. Wong</name>
    </author>
    <author>
      <name>Lidia S. Chao</name>
    </author>
    <author>
      <name>Haihua Du</name>
    </author>
    <author>
      <name>Ben C. H. Ao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05124v1</id>
    <updated>2019-12-11T05:44:04Z</updated>
    <published>2019-12-11T05:44:04Z</published>
    <title>Small-footprint Keyword Spotting with Graph Convolutional Network</title>
    <summary>  Despite the recent successes of deep neural networks, it remains challenging
to achieve high precision keyword spotting task (KWS) on resource-constrained
devices. In this study, we propose a novel context-aware and compact
architecture for keyword spotting task. Based on residual connection and
bottleneck structure, we design a compact and efficient network for KWS task.
To leverage the long range dependencies and global context of the convolutional
feature maps, the graph convolutional network is introduced to encode the
non-local relations. By evaluated on the Google Speech Command Dataset, the
proposed method achieves state-of-the-art performance and outperforms the prior
works by a large margin with lower computational cost.
</summary>
    <author>
      <name>Xi Chen</name>
    </author>
    <author>
      <name>Shouyi Yin</name>
    </author>
    <author>
      <name>Dandan Song</name>
    </author>
    <author>
      <name>Peng Ouyang</name>
    </author>
    <author>
      <name>Leibo Liu</name>
    </author>
    <author>
      <name>Shaojun Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the IEEE Automatic Speech Recognition and Understanding
  Workshop(ASRU 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05082v1</id>
    <updated>2019-12-11T02:03:31Z</updated>
    <published>2019-12-11T02:03:31Z</published>
    <title>A Collaborative Ecosystem for Digital Coptic Studies</title>
    <summary>  Scholarship on underresourced languages bring with them a variety of
challenges which make access to the full spectrum of source materials and their
evaluation difficult. For Coptic in particular, large scale analyses and any
kind of quantitative work become difficult due to the fragmentation of
manuscripts, the highly fusional nature of an incorporational morphology, and
the complications of dealing with influences from Hellenistic era Greek, among
other concerns. Many of these challenges, however, can be addressed using
Digital Humanities tools and standards. In this paper, we outline some of the
latest developments in Coptic Scriptorium, a DH project dedicated to bringing
Coptic resources online in uniform, machine readable, and openly available
formats. Collaborative web-based tools create online 'virtual departments' in
which scholars dispersed sparsely across the globe can collaborate, and natural
language processing tools counterbalance the scarcity of trained editors by
enabling machine processing of Coptic text to produce searchable, annotated
corpora.
</summary>
    <author>
      <name>Caroline T. Schroeder</name>
    </author>
    <author>
      <name>Amir Zeldes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages; paper presented at the Stanford University CESTA Workshop
  "Collecting, Preserving and Disseminating Endangered Cultural Heritage for
  New Understandings Through Multilingual Approaches"</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05066v1</id>
    <updated>2019-12-11T00:30:24Z</updated>
    <published>2019-12-11T00:30:24Z</published>
    <title>Event Outcome Prediction using Sentiment Analysis and Crowd Wisdom in
  Microblog Feeds</title>
    <summary>  Sentiment Analysis of microblog feeds has attracted considerable interest in
recent times. Most of the current work focuses on tweet sentiment
classification. But not much work has been done to explore how reliable the
opinions of the mass (crowd wisdom) in social network microblogs such as
twitter are in predicting outcomes of certain events such as election debates.
In this work, we investigate whether crowd wisdom is useful in predicting such
outcomes and whether their opinions are influenced by the experts in the field.
We work in the domain of multi-label classification to perform sentiment
classification of tweets and obtain the opinion of the crowd. This learnt
sentiment is then used to predict outcomes of events such as: US Presidential
Debate winners, Grammy Award winners, Super Bowl Winners. We find that in most
of the cases, the wisdom of the crowd does indeed match with that of the
experts, and in cases where they don't (particularly in the case of debates),
we see that the crowd's opinion is actually influenced by that of the experts.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Ronghuo Zheng</name>
    </author>
    <author>
      <name>Yuezhang Li</name>
    </author>
    <author>
      <name>Katia Sycara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages, 5 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04979v1</id>
    <updated>2019-12-10T20:59:24Z</updated>
    <published>2019-12-10T20:59:24Z</published>
    <title>Advances in Online Audio-Visual Meeting Transcription</title>
    <summary>  This paper describes a system that generates speaker-annotated transcripts of
meetings by using a microphone array and a 360-degree camera. The hallmark of
the system is its ability to handle overlapped speech, which has been an
unsolved problem in realistic settings for over a decade. We show that this
problem can be addressed by using a continuous speech separation approach. In
addition, we describe an online audio-visual speaker diarization method that
leverages face tracking and identification, sound source localization, speaker
identification, and, if available, prior speaker information for robustness to
various real world challenges. All components are integrated in a meeting
transcription framework called SRD, which stands for "separate, recognize, and
diarize". Experimental results using recordings of natural meetings involving
up to 11 attendees are reported. The continuous speech separation improves a
word error rate (WER) by 16.1% compared with a highly tuned beamformer. When a
complete list of meeting attendees is available, the discrepancy between WER
and speaker-attributed WER is only 1.0%, indicating accurate word-to-speaker
association. This increases marginally to 1.6% when 50% of the attendees are
unknown to the system.
</summary>
    <author>
      <name>Takuya Yoshioka</name>
    </author>
    <author>
      <name>Igor Abramovski</name>
    </author>
    <author>
      <name>Cem Aksoylar</name>
    </author>
    <author>
      <name>Zhuo Chen</name>
    </author>
    <author>
      <name>Moshe David</name>
    </author>
    <author>
      <name>Dimitrios Dimitriadis</name>
    </author>
    <author>
      <name>Yifan Gong</name>
    </author>
    <author>
      <name>Ilya Gurvich</name>
    </author>
    <author>
      <name>Xuedong Huang</name>
    </author>
    <author>
      <name>Yan Huang</name>
    </author>
    <author>
      <name>Aviv Hurvitz</name>
    </author>
    <author>
      <name>Li Jiang</name>
    </author>
    <author>
      <name>Sharon Koubi</name>
    </author>
    <author>
      <name>Eyal Krupka</name>
    </author>
    <author>
      <name>Ido Leichter</name>
    </author>
    <author>
      <name>Changliang Liu</name>
    </author>
    <author>
      <name>Partha Parthasarathy</name>
    </author>
    <author>
      <name>Alon Vinnikov</name>
    </author>
    <author>
      <name>Lingfeng Wu</name>
    </author>
    <author>
      <name>Xiong Xiao</name>
    </author>
    <author>
      <name>Wayne Xiong</name>
    </author>
    <author>
      <name>Huaming Wang</name>
    </author>
    <author>
      <name>Zhenghao Wang</name>
    </author>
    <author>
      <name>Jun Zhang</name>
    </author>
    <author>
      <name>Yong Zhao</name>
    </author>
    <author>
      <name>Tianyan Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proc. IEEE ASRU Workshop 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04971v2</id>
    <updated>2020-02-15T19:26:05Z</updated>
    <published>2019-12-10T20:36:07Z</published>
    <title>Neural Module Networks for Reasoning over Text</title>
    <summary>  Answering compositional questions that require multiple steps of reasoning
against text is challenging, especially when they involve discrete, symbolic
operations. Neural module networks (NMNs) learn to parse such questions as
executable programs composed of learnable modules, performing well on synthetic
visual QA domains. However, we find that it is challenging to learn these
models for non-synthetic questions on open-domain text, where a model needs to
deal with the diversity of natural language and perform a broader range of
reasoning. We extend NMNs by: (a) introducing modules that reason over a
paragraph of text, performing symbolic reasoning (such as arithmetic, sorting,
counting) over numbers and dates in a probabilistic and differentiable manner;
and (b) proposing an unsupervised auxiliary loss to help extract arguments
associated with the events in text. Additionally, we show that a limited amount
of heuristically-obtained question program and intermediate module output
supervision provides sufficient inductive bias for accurate learning. Our
proposed model significantly outperforms state-of-the-art models on a subset of
the DROP dataset that poses a variety of reasoning challenges that are covered
by our modules.
</summary>
    <author>
      <name>Nitish Gupta</name>
    </author>
    <author>
      <name>Kevin Lin</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <author>
      <name>Sameer Singh</name>
    </author>
    <author>
      <name>Matt Gardner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in ICLR 2020 (International Conference on Learning
  Representations, 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04971v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04971v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04965v1</id>
    <updated>2019-12-10T20:20:40Z</updated>
    <published>2019-12-10T20:20:40Z</published>
    <title>An Ensemble Method for Producing Word Representations for the Greek
  Language</title>
    <summary>  In this paper we present a new ensemble method, Continuous Bag-of-Skip-grams
(CBOS), that produces high-quality word representations for the Greek language.
The CBOS method combines the pioneering approaches for learning word
representations: Continuous Bag-of-Words (CBOW) and Continuous Skip-gram. These
methods are compared through a word analogy task on three different sources of
data: the English Wikipedia corpus, the Greek Wikipedia corpus, and the Greek
Web Content corpus. By comparing these methods across different datasets, it is
evident that the CBOS method achieves state-of-the-art performance.
</summary>
    <author>
      <name>Michalis Lioudakis</name>
    </author>
    <author>
      <name>Stamatis Outsios</name>
    </author>
    <author>
      <name>Michalis Vazirgiannis</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04961v2</id>
    <updated>2020-01-03T04:03:31Z</updated>
    <published>2019-12-10T20:18:39Z</published>
    <title>Medication Regimen Extraction From Medical Conversations</title>
    <summary>  Extracting relevant information from medical conversations and providing it
to doctors and patients might help in addressing doctor burnout and patient
forgetfulness. In this paper, we focus on extracting the Medication Regimen
(dosage and frequency for medications) discussed in a medical conversation. We
frame the problem as a Question Answering (QA) task and perform comparative
analysis over: a QA approach, a new combined QA and Information Extraction
approach, and other baselines. We use a small corpus of 6,692 annotated
doctor-patient conversations for the task. Clinical conversation corpora are
costly to create, difficult to handle (because of data privacy concerns), and
thus scarce. We address this data scarcity challenge through data augmentation
methods, using publicly available embeddings and pretrain part of the network
on a related task (summarization) to improve the model's performance. Compared
to the baseline, our best-performing models improve the dosage and frequency
extractions' ROUGE-1 F1 scores from 54.28 and 37.13 to 89.57 and 45.94,
respectively. Using our best-performing model, we present the first fully
automated system that can extract Medication Regimen tags from spontaneous
doctor-patient conversations with about ~71% accuracy.
</summary>
    <author>
      <name>Sai P. Selvaraj</name>
    </author>
    <author>
      <name>Sandeep Konam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of International Workshop on Health
  Intelligence (W3PHIAI) of the 34th AAAI Conference on Artificial
  Intelligence, 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04961v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04961v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10167v1</id>
    <updated>2019-12-10T19:50:35Z</updated>
    <published>2019-12-10T19:50:35Z</published>
    <title>Machine Translation with Cross-lingual Word Embeddings</title>
    <summary>  Learning word embeddings using distributional information is a task that has
been studied by many researchers, and a lot of studies are reported in the
literature. On the contrary, less studies were done for the case of multiple
languages. The idea is to focus on a single representation for a pair of
languages such that semantically similar words are closer to one another in the
induced representation irrespective of the language. In this way, when data are
missing for a particular language, classifiers from another language can be
used.
</summary>
    <author>
      <name>Marco Berlot</name>
    </author>
    <author>
      <name>Evan Kaplan</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04853v1</id>
    <updated>2019-12-10T17:46:43Z</updated>
    <published>2019-12-10T17:46:43Z</published>
    <title>Embedding Comparator: Visualizing Differences in Global Structure and
  Local Neighborhoods via Small Multiples</title>
    <summary>  Embeddings -- mappings from high-dimensional discrete input to
lower-dimensional continuous vector spaces -- have been widely adopted in
machine learning, linguistics, and computational biology as they often surface
interesting and unexpected domain semantics. Through semi-structured interviews
with embedding model researchers and practitioners, we find that current tools
poorly support a central concern: comparing different embeddings when
developing fairer, more robust models. In response, we present the Embedding
Comparator, an interactive system that balances gaining an overview of the
embedding spaces with making fine-grained comparisons of local neighborhoods.
For a pair of models, we compute the similarity of the k-nearest neighbors of
every embedded object, and visualize the results as Local Neighborhood
Dominoes: small multiples that facilitate rapid comparisons. Using case
studies, we illustrate the types of insights the Embedding Comparator reveals
including how fine-tuning embeddings changes semantics, how language changes
over time, and how training data differences affect two seemingly similar
models.
</summary>
    <author>
      <name>Angie Boggust</name>
    </author>
    <author>
      <name>Brandon Carter</name>
    </author>
    <author>
      <name>Arvind Satyanarayan</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04853v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04853v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10165v1</id>
    <updated>2019-12-10T17:01:34Z</updated>
    <published>2019-12-10T17:01:34Z</published>
    <title>Zero-shot Text Classification With Generative Language Models</title>
    <summary>  This work investigates the use of natural language to enable zero-shot model
adaptation to new tasks. We use text and metadata from social commenting
platforms as a source for a simple pretraining task. We then provide the
language model with natural language descriptions of classification tasks as
input and train it to generate the correct answer in natural language via a
language modeling objective. This allows the model to generalize to new
classification tasks without the need for multiple multitask classification
heads. We show the zero-shot performance of these generative language models,
trained with weak supervision, on six benchmark text classification datasets
from the torchtext library. Despite no access to training data, we achieve up
to a 45% absolute improvement in classification accuracy over random or
majority class baselines. These results show that natural language can serve as
simple and powerful descriptors for task adaptation. We believe this points the
way to new metalearning strategies for text problems.
</summary>
    <author>
      <name>Raul Puri</name>
    </author>
    <author>
      <name>Bryan Catanzaro</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05308v1</id>
    <updated>2019-12-10T16:08:26Z</updated>
    <published>2019-12-10T16:08:26Z</published>
    <title>Unsupervised Transfer Learning via BERT Neuron Selection</title>
    <summary>  Recent advancements in language representation models such as BERT have led
to a rapid improvement in numerous natural language processing tasks. However,
language models usually consist of a few hundred million trainable parameters
with embedding space distributed across multiple layers, thus making them
challenging to be fine-tuned for a specific task or to be transferred to a new
domain. To determine whether there are task-specific neurons that can be
exploited for unsupervised transfer learning, we introduce a method for
selecting the most important neurons to solve a specific classification task.
This algorithm is further extended to multi-source transfer learning by
computing the importance of neurons for several single-source transfer learning
scenarios between different subsets of data sources. Besides, a task-specific
fingerprint for each data source is obtained based on the percentage of the
selected neurons in each layer. We perform extensive experiments in
unsupervised transfer learning for sentiment analysis, natural language
inference and sentence similarity, and compare our results with the existing
literature and baselines. Significantly, we found that the source and target
data sources with higher degrees of similarity between their task-specific
fingerprints demonstrate a better transferability property. We conclude that
our method can lead to better performance using just a few hundred
task-specific and interpretable neurons.
</summary>
    <author>
      <name>Mehrdad Valipour</name>
    </author>
    <author>
      <name>En-Shiun Annie Lee</name>
    </author>
    <author>
      <name>Jaime R. Jamacaro</name>
    </author>
    <author>
      <name>Carolina Bessega</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04784v1</id>
    <updated>2019-12-10T15:53:59Z</updated>
    <published>2019-12-10T15:53:59Z</published>
    <title>A Novel Topology for End-to-end Temporal Classification and Segmentation
  with Recurrent Neural Network</title>
    <summary>  Connectionist temporal classification (CTC) has matured as an alignment free
to sequence transduction and shows competitive for end-to-end speech
recognition. In the CTC topology, the blank symbol occupies more than half of
the state trellis, which results the spike phenomenon of the non-blank symbols.
For classification task, the spikes work quite well, but as to the segmentation
task it does not provide boundaries information. In this paper, a novel
topology is introduced to combine the temporal classification and segmentation
ability in one framework.
</summary>
    <author>
      <name>Taiyang Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages,3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04778v1</id>
    <updated>2019-12-10T15:50:50Z</updated>
    <published>2019-12-10T15:50:50Z</published>
    <title>GeBioToolkit: Automatic Extraction of Gender-Balanced Multilingual
  Corpus of Wikipedia Biographies</title>
    <summary>  We introduce GeBioToolkit, a tool for extracting multilingual parallel
corpora at sentence level, with document and gender information from Wikipedia
biographies. Despite thegender inequalitiespresent in Wikipedia, the toolkit
has been designed to extract corpus balanced in gender. While our toolkit is
customizable to any number of languages (and different domains), in this work
we present a corpus of 2,000 sentences in English, Spanish and Catalan, which
has been post-edited by native speakers to become a high-quality dataset for
machinetranslation evaluation. While GeBioCorpus aims at being one of the first
non-synthetic gender-balanced test datasets, GeBioToolkit aims at paving the
path to standardize procedures to produce gender-balanced datasets
</summary>
    <author>
      <name>Marta R. Costa-jussà</name>
    </author>
    <author>
      <name>Pau Li Lin</name>
    </author>
    <author>
      <name>Cristina España-Bonet</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04748v1</id>
    <updated>2019-12-10T15:07:48Z</updated>
    <published>2019-12-10T15:07:48Z</published>
    <title>Fraud detection in telephone conversations for financial services using
  linguistic features</title>
    <summary>  Detecting the elements of deception in a conversation is one of the most
challenging problems for the AI community. It becomes even more difficult to
design a transparent system, which is fully explainable and satisfies the need
for financial and legal services to be deployed. This paper presents an
approach for fraud detection in transcribed telephone conversations using
linguistic features. The proposed approach exploits the syntactic and semantic
information of the transcription to extract both the linguistic markers and the
sentiment of the customer's response. We demonstrate the results on real-world
financial services data using simple, robust and explainable classifiers such
as Naive Bayes, Decision Tree, Nearest Neighbours, and Support Vector Machines.
</summary>
    <author>
      <name>Nikesh Bajaj</name>
    </author>
    <author>
      <name>Tracy Goodluck Constance</name>
    </author>
    <author>
      <name>Marvin Rajwadi</name>
    </author>
    <author>
      <name>Julie Wall</name>
    </author>
    <author>
      <name>Mansour Moniri</name>
    </author>
    <author>
      <name>Cornelius Glackin</name>
    </author>
    <author>
      <name>Nigel Cannings</name>
    </author>
    <author>
      <name>Chris Woodruff</name>
    </author>
    <author>
      <name>James Laird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published - 33rd Conference on Neural Information Processing Systems
  (NeurIPS 2019), AI for Social Good Workshop, Vancouver, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04664v1</id>
    <updated>2019-12-10T12:27:45Z</updated>
    <published>2019-12-10T12:27:45Z</published>
    <title>How to Evaluate the Next System: Automatic Dialogue Evaluation from the
  Perspective of Continual Learning</title>
    <summary>  Automatic dialogue evaluation plays a crucial role in open-domain dialogue
research. Previous works train neural networks with limited annotation for
conducting automatic dialogue evaluation, which would naturally affect the
evaluation fairness as dialogue systems close to the scope of training corpus
would have more preference than the other ones. In this paper, we study
alleviating this problem from the perspective of continual learning: given an
existing neural dialogue evaluator and the next system to be evaluated, we
fine-tune the learned neural evaluator by selectively forgetting/updating its
parameters, to jointly fit dialogue systems have been and will be evaluated.
Our motivation is to seek for a lifelong and low-cost automatic evaluation for
dialogue systems, rather than to reconstruct the evaluator over and over again.
Experimental results show that our continual evaluator achieves comparable
performance with reconstructing new evaluators, while requires significantly
lower resources.
</summary>
    <author>
      <name>Lu Li</name>
    </author>
    <author>
      <name>Zhongheng He</name>
    </author>
    <author>
      <name>Xiangyang Zhou</name>
    </author>
    <author>
      <name>Dianhai Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04639v1</id>
    <updated>2019-12-10T10:59:47Z</updated>
    <published>2019-12-10T10:59:47Z</published>
    <title>Introducing MANtIS: a novel Multi-Domain Information Seeking Dialogues
  Dataset</title>
    <summary>  Conversational search is an approach to information retrieval (IR), where
users engage in a dialogue with an agent in order to satisfy their information
needs. Previous conceptual work described properties and actions a good agent
should exhibit. Unlike them, we present a novel conceptual model defined in
terms of conversational goals, which enables us to reason about current
research practices in conversational search. Based on the literature, we elicit
how existing tasks and test collections from the fields of IR, natural language
processing (NLP) and dialogue systems (DS) fit into this model. We describe a
set of characteristics that an ideal conversational search dataset should have.
Lastly, we introduce MANtIS (the code and dataset are available at
https://guzpenha.github.io/MANtIS/), a large-scale dataset containing
multi-domain and grounded information seeking dialogues that fulfill all of our
dataset desiderata. We provide baseline results for the conversation response
ranking and user intent prediction tasks.
</summary>
    <author>
      <name>Gustavo Penha</name>
    </author>
    <author>
      <name>Alexandru Balan</name>
    </author>
    <author>
      <name>Claudia Hauff</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04479v1</id>
    <updated>2019-12-10T03:45:42Z</updated>
    <published>2019-12-10T03:45:42Z</published>
    <title>Homograph Disambiguation Through Selective Diacritic Restoration</title>
    <summary>  Lexical ambiguity, a challenging phenomenon in all natural languages, is
particularly prevalent for languages with diacritics that tend to be omitted in
writing, such as Arabic. Omitting diacritics leads to an increase in the number
of homographs: different words with the same spelling. Diacritic restoration
could theoretically help disambiguate these words, but in practice, the
increase in overall sparsity leads to performance degradation in NLP
applications. In this paper, we propose approaches for automatically marking a
subset of words for diacritic restoration, which leads to selective homograph
disambiguation. Compared to full or no diacritic restoration, these approaches
yield selectively-diacritized datasets that balance sparsity and lexical
disambiguation. We evaluate the various selection strategies extrinsically on
several downstream applications: neural machine translation, part-of-speech
tagging, and semantic textual similarity. Our experiments on Arabic show
promising results, where our devised strategies on selective diacritization
lead to a more balanced and consistent performance in downstream applications.
</summary>
    <author>
      <name>Sawsan Alqahtani</name>
    </author>
    <author>
      <name>Hanan Aldarmaki</name>
    </author>
    <author>
      <name>Mona Diab</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/W19-4606</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/W19-4606" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted in WANLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04471v1</id>
    <updated>2019-12-10T03:23:05Z</updated>
    <published>2019-12-10T03:23:05Z</published>
    <title>Duet at TREC 2019 Deep Learning Track</title>
    <summary>  This report discusses three submissions based on the Duet architecture to the
Deep Learning track at TREC 2019. For the document retrieval task, we adapt the
Duet model to ingest a "multiple field" view of documents---we refer to the new
architecture as Duet with Multiple Fields (DuetMF). A second submission
combines the DuetMF model with other neural and traditional relevance
estimators in a learning-to-rank framework and achieves improved performance
over the DuetMF baseline. For the passage retrieval task, we submit a single
run based on an ensemble of eight Duet models.
</summary>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04419v1</id>
    <updated>2019-12-09T23:18:13Z</updated>
    <published>2019-12-09T23:18:13Z</published>
    <title>Analysis of the Ethiopic Twitter Dataset for Abusive Speech in Amharic</title>
    <summary>  In this paper, we present an analysis of the first Ethiopic Twitter Dataset
for the Amharic language targeted for recognizing abusive speech. The dataset
has been collected since 2014 that is written in Fidel script. Since several
languages can be written using the Fidel script, we have used the existing
Amharic, Tigrinya and Ge'ez corpora to retain only the Amharic tweets. We have
analyzed the tweets for abusive speech content with the following targets:
Analyze the distribution and tendency of abusive speech content over time and
compare the abusive speech content between a Twitter and general reference
Amharic corpus.
</summary>
    <author>
      <name>Seid Muhie Yimam</name>
    </author>
    <author>
      <name>Abinew Ali Ayele</name>
    </author>
    <author>
      <name>Chris Biemann</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03884v1</id>
    <updated>2019-12-09T07:44:32Z</updated>
    <published>2019-12-09T07:44:32Z</published>
    <title>MITAS: A Compressed Time-Domain Audio Separation Network with Parameter
  Sharing</title>
    <summary>  Deep learning methods have brought substantial advancements in speech
separation (SS). Nevertheless, it remains challenging to deploy
deep-learning-based models on edge devices. Thus, identifying an effective way
to compress these large models without hurting SS performance has become an
important research topic. Recently, TasNet and Conv-TasNet have been proposed.
They achieved state-of-the-art results on several standardized SS tasks.
Moreover, their low latency natures make them definitely suitable for real-time
on-device applications. In this study, we propose two parameter-sharing schemes
to lower the memory consumption on TasNet and Conv-TasNet. Accordingly, we
derive a novel so-called MiTAS (Mini TasNet). Our experimental results first
confirmed the robustness of our MiTAS on two types of perturbations in mixed
audio. We also designed a series of ablation experiments to analyze the
relation between SS performance and the amount of parameters in the model. The
results show that MiTAS is able to reduce the model size by a factor of four
while maintaining comparable SS performance with improved stability as compared
to TasNet and Conv-TasNet. This suggests that MiTAS is more suitable for
real-time low latency applications.
</summary>
    <author>
      <name>Chao-I Tuan</name>
    </author>
    <author>
      <name>Yuan-Kuei Wu</name>
    </author>
    <author>
      <name>Hung-yi Lee</name>
    </author>
    <author>
      <name>Yu Tsao</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03884v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03884v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03879v1</id>
    <updated>2019-12-09T07:22:54Z</updated>
    <published>2019-12-09T07:22:54Z</published>
    <title>AI2D-RST: A multimodal corpus of 1000 primary school science diagrams</title>
    <summary>  This article introduces AI2D-RST, a multimodal corpus of 1000
English-language diagrams that represent topics in primary school natural
science, such as food webs, life cycles, moon phases and human physiology. The
corpus is based on the Allen Institute for Artificial Intelligence Diagrams
(AI2D) dataset, a collection of diagrams with crowd-sourced descriptions, which
was originally developed for computational tasks such as automatic diagram
understanding and visual question answering. Building on the segmentation of
diagram layouts in AI2D, the AI2D-RST corpus presents a new multi-layer
annotation schema that provides a rich description of their multimodal
structure. Annotated by trained experts, the layers describe (1) the grouping
of diagram elements into perceptual units, (2) the connections set up by
diagrammatic elements such as arrows and lines, and (3) the discourse relations
between diagram elements, which are described using Rhetorical Structure Theory
(RST). Each annotation layer in AI2D-RST is represented using a graph. The
corpus is freely available for research and teaching.
</summary>
    <author>
      <name>Tuomo Hiippala</name>
    </author>
    <author>
      <name>Malihe Alikhani</name>
    </author>
    <author>
      <name>Jonas Haverinen</name>
    </author>
    <author>
      <name>Timo Kalliokoski</name>
    </author>
    <author>
      <name>Evanfiya Logacheva</name>
    </author>
    <author>
      <name>Serafina Orekhova</name>
    </author>
    <author>
      <name>Aino Tuomainen</name>
    </author>
    <author>
      <name>Matthew Stone</name>
    </author>
    <author>
      <name>John A. Bateman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages; submitted to Language Resources &amp; Evaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03832v1</id>
    <updated>2019-12-09T03:38:16Z</updated>
    <published>2019-12-09T03:38:16Z</published>
    <title>Effective Attention Modeling for Neural Relation Extraction</title>
    <summary>  Relation extraction is the task of determining the relation between two
entities in a sentence. Distantly-supervised models are popular for this task.
However, sentences can be long and two entities can be located far from each
other in a sentence. The pieces of evidence supporting the presence of a
relation between two entities may not be very direct, since the entities may be
connected via some indirect links such as a third entity or via co-reference.
Relation extraction in such scenarios becomes more challenging as we need to
capture the long-distance interactions among the entities and other words in
the sentence. Also, the words in a sentence do not contribute equally in
identifying the relation between the two entities. To address this issue, we
propose a novel and effective attention model which incorporates syntactic
information of the sentence and a multi-factor attention mechanism. Experiments
on the New York Times corpus show that our proposed model outperforms prior
state-of-the-art models.
</summary>
    <author>
      <name>Tapas Nayak</name>
    </author>
    <author>
      <name>Hwee Tou Ng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at CoNLL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03804v1</id>
    <updated>2019-12-09T01:11:59Z</updated>
    <published>2019-12-09T01:11:59Z</published>
    <title>Women in ISIS Propaganda: A Natural Language Processing Analysis of
  Topics and Emotions in a Comparison with Mainstream Religious Group</title>
    <summary>  Online propaganda is central to the recruitment strategies of extremist
groups and in recent years these efforts have increasingly extended to women.
To investigate ISIS' approach to targeting women in their online propaganda and
uncover implications for counterterrorism, we rely on text mining and natural
language processing (NLP). Specifically, we extract articles published in Dabiq
and Rumiyah (ISIS's online English language publications) to identify prominent
topics. To identify similarities or differences between these texts and those
produced by non-violent religious groups, we extend the analysis to articles
from a Catholic forum dedicated to women. We also perform an emotional analysis
of both of these resources to better understand the emotional components of
propaganda. We rely on Depechemood (a lexical-base emotion analysis method) to
detect emotions most likely to be evoked in readers of these materials. The
findings indicate that the emotional appeal of ISIS and Catholic materials are
similar
</summary>
    <author>
      <name>Mojtaba Heidarysafa</name>
    </author>
    <author>
      <name>Kamran Kowsari</name>
    </author>
    <author>
      <name>Tolu Odukoya</name>
    </author>
    <author>
      <name>Philip Potter</name>
    </author>
    <author>
      <name>Laura E. Barnes</name>
    </author>
    <author>
      <name>Donald E. Brown</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03720v1</id>
    <updated>2019-12-08T17:22:07Z</updated>
    <published>2019-12-08T17:22:07Z</published>
    <title>Attentive Representation Learning with Adversarial Training for Short
  Text Clustering</title>
    <summary>  Short text clustering has far-reaching effects on semantic analysis, showing
its importance for multiple applications such as corpus summarization and
information retrieval. However, it inevitably encounters the severe sparsity of
short text representation, making the previous clustering approaches still far
from satisfactory. In this paper, we present a novel attentive representation
learning model for shot text clustering, wherein cluster-level attention is
proposed to capture the correlation between text representation and cluster
representation. Relying on this, the representation learning and clustering for
short text are seamlessly integrated into a unified framework. To further
facilitate the model training process, we apply adversarial training to the
unsupervised clustering setting, by adding perturbations to the cluster
representations. The model parameters and perturbations are optimized
alternately through a minimax game. Extensive experiments on three real-world
short text datasets demonstrate the superiority of the proposed model over
several strong competitors, verifying that adversarial training yields a
substantial performance gain.
</summary>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Chao Dong</name>
    </author>
    <author>
      <name>Jianhua Yin</name>
    </author>
    <author>
      <name>Jianyong Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03656v2</id>
    <updated>2020-03-02T14:44:34Z</updated>
    <published>2019-12-08T11:20:35Z</published>
    <title>Bidirectional Scene Text Recognition with a Single Decoder</title>
    <summary>  Scene Text Recognition (STR) is the problem of recognizing the correct word
or character sequence in a cropped word image. To obtain more robust output
sequences, the notion of bidirectional STR has been introduced. So far,
bidirectional STRs have been implemented by using two separate decoders; one
for left-to-right decoding and one for right-to-left. Having two separate
decoders for almost the same task with the same output space is undesirable
from a computational and optimization point of view. We introduce the
bidirectional Scene Text Transformer (Bi-STET), a novel bidirectional STR
method with a single decoder for bidirectional text decoding. With its single
decoder, Bi-STET outperforms methods that apply bidirectional decoding by using
two separate decoders while also being more efficient than those methods,
Furthermore, we achieve or beat state-of-the-art (SOTA) methods on all STR
benchmarks with Bi-STET. Finally, we provide analyses and insights into the
performance of Bi-STET.
</summary>
    <author>
      <name>Maurits Bleeker</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. In 24th European Conference on Artificial Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03656v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03656v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11334v1</id>
    <updated>2019-12-08T10:19:40Z</updated>
    <published>2019-12-08T10:19:40Z</published>
    <title>Open-domain Event Extraction and Embedding for Natural Gas Market
  Prediction</title>
    <summary>  We propose an approach to predict the natural gas price in several days using
historical price data and events extracted from news headlines. Most previous
methods treats price as an extrapolatable time series, those analyze the
relation between prices and news either trim their price data correspondingly
to a public news dataset, manually annotate headlines or use off-the-shelf
tools. In comparison to off-the-shelf tools, our event extraction method
detects not only the occurrence of phenomena but also the changes in
attribution and characteristics from public sources. Instead of using sentence
embedding as a feature, we use every word of the extracted events, encode and
organize them before feeding to the learning models. Empirical results show
favorable results, in terms of prediction performance, money saved and
scalability.
</summary>
    <author>
      <name>Minh Triet Chau</name>
    </author>
    <author>
      <name>Diego Esteves</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03627v1</id>
    <updated>2019-12-08T07:05:36Z</updated>
    <published>2019-12-08T07:05:36Z</published>
    <title>A Multi Purpose and Large Scale Speech Corpus in Persian and English for
  Speaker and Speech Recognition: the DeepMine Database</title>
    <summary>  DeepMine is a speech database in Persian and English designed to build and
evaluate text-dependent, text-prompted, and text-independent speaker
verification, as well as Persian speech recognition systems. It contains more
than 1850 speakers and 540 thousand recordings overall, more than 480 hours of
speech are transcribed. It is the first public large-scale speaker verification
database in Persian, the largest public text-dependent and text-prompted
speaker verification database in English, and the largest public evaluation
dataset for text-independent speaker verification. It has a good coverage of
age, gender, and accents. We provide several evaluation protocols for each part
of the database to allow for research on different aspects of speaker
verification. We also provide the results of several experiments that can be
considered as baselines: HMM-based i-vectors for text-dependent speaker
verification, and HMM-based as well as state-of-the-art deep neural network
based ASR. We demonstrate that the database can serve for training robust ASR
models.
</summary>
    <author>
      <name>Hossein Zeinali</name>
    </author>
    <author>
      <name>Lukáš Burget</name>
    </author>
    <author>
      <name>Jan "Honza'' Černocký</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03553v1</id>
    <updated>2019-12-07T20:12:43Z</updated>
    <published>2019-12-07T20:12:43Z</published>
    <title>Learning Norms from Stories: A Prior for Value Aligned Agents</title>
    <summary>  Value alignment is a property of an intelligent agent indicating that it can
only pursue goals and activities that are beneficial to humans. Traditional
approaches to value alignment use imitation learning or preference learning to
infer the values of humans by observing their behavior. We introduce a
complementary technique in which a value aligned prior is learned from
naturally occurring stories which encode societal norms. Training data is
sourced from the childrens educational comic strip, Goofus and Gallant. In this
work, we train multiple machine learning models to classify natural language
descriptions of situations found in the comic strip as normative or non
normative by identifying if they align with the main characters behavior. We
also report the models performance when transferring to two unrelated tasks
with little to no additional training on the new task.
</summary>
    <author>
      <name>Spencer Frazier</name>
    </author>
    <author>
      <name>Md Sultan Al Nahian</name>
    </author>
    <author>
      <name>Mark Riedl</name>
    </author>
    <author>
      <name>Brent Harrison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AIES 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03502v2</id>
    <updated>2019-12-12T14:20:19Z</updated>
    <published>2019-12-07T13:26:18Z</published>
    <title>Personalized Patent Claim Generation and Measurement</title>
    <summary>  This work-in-progress paper proposes a framework to generate and measure
personalized patent claims. The objective is to help inventors conceive better
inventions by learning from relevant inventors. Patent claim generation is a
way of "augmented inventing." for inventors. Such patent claim generation
leverages the recent transfer learning in the Deep Learning field, particularly
the state-of-the-art Transformer-based models. In terms of system
implementa-tion, it is planned to build an "auto-complete" function for patent
claim drafting. The auto-complete function is analyzed from four different
perspectives: extent of generation, generative direction, proximity of
generation, and constraint in generation. Technically, the framework is
composed of two Transformer models. One is for text generation and the other is
for quality measurement. Specifically, the patent claim generation is based on
GPT-2 model and the measurement of personalization is based on BERT model. The
training data is inventor-centric and comes from the Inventors Endpoint API
provided by the USPTO.
</summary>
    <author>
      <name>Jieh-Sheng Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 figures, 12 pages. Presented at the 32nd International Conference
  on Legal Knowledge and Information Systems (JURIX 2019) and to be published
  in the CEUR Workshop Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03502v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03502v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03457v1</id>
    <updated>2019-12-07T07:45:43Z</updated>
    <published>2019-12-07T07:45:43Z</published>
    <title>Unsung Challenges of Building and Deploying Language Technologies for
  Low Resource Language Communities</title>
    <summary>  In this paper, we examine and analyze the challenges associated with
developing and introducing language technologies to low-resource language
communities. While doing so, we bring to light the successes and failures of
past work in this area, challenges being faced in doing so, and what they have
achieved. Throughout this paper, we take a problem-facing approach and describe
essential factors which the success of such technologies hinges upon. We
present the various aspects in a manner which clarify and lay out the different
tasks involved, which can aid organizations looking to make an impact in this
area. We take the example of Gondi, an extremely-low resource Indian language,
to reinforce and complement our discussion.
</summary>
    <author>
      <name>Pratik Joshi</name>
    </author>
    <author>
      <name>Christain Barnes</name>
    </author>
    <author>
      <name>Sebastin Santy</name>
    </author>
    <author>
      <name>Simran Khanuja</name>
    </author>
    <author>
      <name>Sanket Shah</name>
    </author>
    <author>
      <name>Anirudh Srinivasan</name>
    </author>
    <author>
      <name>Satwik Bhattamishra</name>
    </author>
    <author>
      <name>Sunayana Sitaram</name>
    </author>
    <author>
      <name>Monojit Choudhury</name>
    </author>
    <author>
      <name>Kalika Bali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICON 2019; 9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03457v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03457v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03444v1</id>
    <updated>2019-12-07T05:30:09Z</updated>
    <published>2019-12-07T05:30:09Z</published>
    <title>PidginUNMT: Unsupervised Neural Machine Translation from West African
  Pidgin to English</title>
    <summary>  Over 800 languages are spoken across West Africa. Despite the obvious
diversity among people who speak these languages, one language significantly
unifies them all - West African Pidgin English. There are at least 80 million
speakers of West African Pidgin English. However, there is no known natural
language processing (NLP) work on this language. In this work, we perform the
first NLP work on the most popular variant of the language, providing three
major contributions. First, the provision of a Pidgin corpus of over 56000
sentences, which is the largest we know of. Secondly, the training of the first
ever cross-lingual embedding between Pidgin and English. This aligned embedding
will be helpful in the performance of various downstream tasks between English
and Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translation
model between Pidgin and English which achieves BLEU scores of 7.93 from Pidgin
to English, and 5.18 from English to Pidgin. In all, this work greatly reduces
the barrier of entry for future NLP works on West African Pidgin English.
</summary>
    <author>
      <name>Kelechi Ogueji</name>
    </author>
    <author>
      <name>Orevaoghene Ahia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at NeurIPS 2019 Workshop on Machine Learning for the
  Developing World</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03441v1</id>
    <updated>2019-12-07T05:12:03Z</updated>
    <published>2019-12-07T05:12:03Z</published>
    <title>Adversarial Analysis of Natural Language Inference Systems</title>
    <summary>  The release of large natural language inference (NLI) datasets like SNLI and
MNLI have led to rapid development and improvement of completely neural systems
for the task. Most recently, heavily pre-trained, Transformer-based models like
BERT and MT-DNN have reached near-human performance on these datasets. However,
these standard datasets have been shown to contain many annotation artifacts,
allowing models to shortcut understanding using simple fallible heuristics, and
still perform well on the test set. So it is no surprise that many adversarial
(challenge) datasets have been created that cause models trained on standard
datasets to fail dramatically. Although extra training on this data generally
improves model performance on just that type of data, transferring that
learning to unseen examples is still partial at best. This work evaluates the
failures of state-of-the-art models on existing adversarial datasets that test
different linguistic phenomena, and find that even though the models perform
similarly on MNLI, they differ greatly in their robustness to these attacks. In
particular, we find syntax-related attacks to be particularly effective across
all models, so we provide a fine-grained analysis and comparison of model
performance on those examples. We draw conclusions about the value of model
size and multi-task learning (beyond comparing their standard test set
performance), and provide suggestions for more effective training data.
</summary>
    <author>
      <name>Tiffany Chien</name>
    </author>
    <author>
      <name>Jugal Kalita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, accepted by IEEE ICSC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03393v1</id>
    <updated>2019-12-06T23:46:37Z</updated>
    <published>2019-12-06T23:46:37Z</published>
    <title>Re-Translation Strategies For Long Form, Simultaneous, Spoken Language
  Translation</title>
    <summary>  We investigate the problem of simultaneous machine translation of long-form
speech content. We target a continuous speech-to-text scenario, generating
translated captions for a live audio feed, such as a lecture or play-by-play
commentary. As this scenario allows for revisions to our incremental
translations, we adopt a re-translation approach to simultaneous translation,
where the source is repeatedly translated from scratch as it grows. This
approach naturally exhibits very low latency and high final quality, but at the
cost of incremental instability as the output is continuously refined. We
experiment with a pipeline of industry-grade speech recognition and translation
tools, augmented with simple inference heuristics to improve stability. We use
TED Talks as a source of multilingual test data, developing our techniques on
English-to-German spoken language translation. Our minimalist approach to
simultaneous translation allows us to easily scale our final evaluation to six
more target languages, dramatically improving incremental stability for all of
them.
</summary>
    <author>
      <name>Naveen Arivazhagan</name>
    </author>
    <author>
      <name>Colin Cherry</name>
    </author>
    <author>
      <name>Te I</name>
    </author>
    <author>
      <name>Wolfgang Macherey</name>
    </author>
    <author>
      <name>Pallavi Baljekar</name>
    </author>
    <author>
      <name>George Foster</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03366v2</id>
    <updated>2020-01-04T17:06:44Z</updated>
    <published>2019-12-06T22:11:37Z</published>
    <title>Med2Meta: Learning Representations of Medical Concepts with
  Meta-Embeddings</title>
    <summary>  Distributed representations of medical concepts have been used to support
downstream clinical tasks recently. Electronic Health Records (EHR) capture
different aspects of patients' hospital encounters and serve as a rich source
for augmenting clinical decision making by learning robust medical concept
embeddings. However, the same medical concept can be recorded in different
modalities (e.g., clinical notes, lab results)-with each capturing salient
information unique to that modality-and a holistic representation calls for
relevant feature ensemble from all information sources. We hypothesize that
representations learned from heterogeneous data types would lead to performance
enhancement on various clinical informatics and predictive modeling tasks. To
this end, our proposed approach makes use of meta-embeddings, embeddings
aggregated from learned embeddings. Firstly, modality-specific embeddings for
each medical concept is learned with graph autoencoders. The ensemble of all
the embeddings is then modeled as a meta-embedding learning problem to
incorporate their correlating and complementary information through a joint
reconstruction. Empirical results of our model on both quantitative and
qualitative clinical evaluations have shown improvements over state-of-the-art
embedding models, thus validating our hypothesis.
</summary>
    <author>
      <name>Shaika Chowdhury</name>
    </author>
    <author>
      <name>Chenwei Zhang</name>
    </author>
    <author>
      <name>Philip S. Yu</name>
    </author>
    <author>
      <name>Yuan Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">HEALTHINF 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.03366v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03366v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03363v2</id>
    <updated>2020-02-18T18:03:03Z</updated>
    <published>2019-12-06T22:09:07Z</published>
    <title>Audio-attention discriminative language model for ASR rescoring</title>
    <summary>  End-to-end approaches for automatic speech recognition (ASR) benefit from
directly modeling the probability of the word sequence given the input audio
stream in a single neural network. However, compared to conventional ASR
systems, these models typically require more data to achieve comparable
results. Well-known model adaptation techniques, to account for domain and
style adaptation, are not easily applicable to end-to-end systems. Conventional
HMM-based systems, on the other hand, have been optimized for various
production environments and use cases. In this work, we propose to combine the
benefits of end-to-end approaches with a conventional system using an
attention-based discriminative language model that learns to rescore the output
of a first-pass ASR system. We show that learning to rescore a list of
potential ASR outputs is much simpler than learning to generate the hypothesis.
The proposed model results in 8% improvement in word error rate even when the
amount of training data is a fraction of data used for training the first-pass
system.
</summary>
    <author>
      <name>Ankur Gandhe</name>
    </author>
    <author>
      <name>Ariya Rastrow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, Accepted at ICASSP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03363v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03363v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03334v1</id>
    <updated>2019-12-06T20:27:38Z</updated>
    <published>2019-12-06T20:27:38Z</published>
    <title>Explaining Sequence-Level Knowledge Distillation as Data-Augmentation
  for Neural Machine Translation</title>
    <summary>  Sequence-level knowledge distillation (SLKD) is a model compression technique
that leverages large, accurate teacher models to train smaller,
under-parameterized student models. Why does pre-processing MT data with SLKD
help us train smaller models? We test the common hypothesis that SLKD addresses
a capacity deficiency in students by "simplifying" noisy data points and find
it unlikely in our case. Models trained on concatenations of original and
"simplified" datasets generalize just as well as baseline SLKD. We then propose
an alternative hypothesis under the lens of data augmentation and
regularization. We try various augmentation strategies and observe that dropout
regularization can become unnecessary. Our methods achieve BLEU gains of
0.7-1.2 on TED Talks.
</summary>
    <author>
      <name>Mitchell A. Gordon</name>
    </author>
    <author>
      <name>Kevin Duh</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03234v1</id>
    <updated>2019-12-06T17:17:39Z</updated>
    <published>2019-12-06T17:17:39Z</published>
    <title>What Do You Mean I'm Funny? Personalizing the Joke Skill of a
  Voice-Controlled Virtual Assistant</title>
    <summary>  A considerable part of the success experienced by Voice-controlled virtual
assistants (VVA) is due to the emotional and personalized experience they
deliver, with humor being a key component in providing an engaging interaction.
In this paper we describe methods used to improve the joke skill of a VVA
through personalization. The first method, based on traditional NLP techniques,
is robust and scalable. The others combine self-attentional network and
multi-task learning to obtain better results, at the cost of added complexity.
A significant challenge facing these systems is the lack of explicit user
feedback needed to provide labels for the models. Instead, we explore the use
of two implicit feedback-based labelling strategies. All models were evaluated
on real production data. Online results show that models trained on any of the
considered labels outperform a heuristic method, presenting a positive
real-world impact on user satisfaction. Offline results suggest that the
deep-learning approaches can improve the joke experience with respect to the
other considered methods.
</summary>
    <author>
      <name>Alejandro Mottini</name>
    </author>
    <author>
      <name>Amber Roy Chowdhury</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the AAAI 2020 Workshop on Interactive and Conversational
  Recommendation Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03234v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03234v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03223v1</id>
    <updated>2019-12-06T16:45:52Z</updated>
    <published>2019-12-06T16:45:52Z</published>
    <title>A limited-size ensemble of homogeneous CNN/LSTMs for high-performance
  word classification</title>
    <summary>  In recent years, long short-term memory neural networks (LSTMs) have been
applied quite successfully to problems in handwritten text recognition.
However, their strength is more located in handling sequences of variable
length than in handling geometric variability of the image patterns.
Furthermore, the best results for LSTMs are often based on large-scale training
of an ensemble of network instances. In this paper, an end-to-end convolutional
LSTM Neural Network is used to handle both geometric variation and sequence
variability. We show that high performances can be reached on a common
benchmark set by using proper data augmentation for just five such networks
using a proper coding scheme and a proper voting scheme. The networks have
similar architectures (Convolutional Neural Network (CNN): five layers,
bidirectional LSTM (BiLSTM): three layers followed by a connectionist temporal
classification (CTC) processing step). The approach assumes differently-scaled
input images and different feature map sizes. Two datasets are used for
evaluation of the performance of our algorithm: A standard benchmark RIMES
dataset (French), and a historical handwritten dataset KdK (Dutch). Final
performance obtained for the word-recognition test of RIMES was 96.6%, a clear
improvement over other state-of-the-art approaches. On the KdK dataset, our
approach also shows good results. The proposed approach is deployed in the Monk
search engine for historical-handwriting collections.
</summary>
    <author>
      <name>Mahya Ameryan</name>
    </author>
    <author>
      <name>Lambert Schomaker</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03184v3</id>
    <updated>2020-03-03T13:32:42Z</updated>
    <published>2019-12-06T15:30:58Z</published>
    <title>GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception</title>
    <summary>  Most research on emotion analysis from text focuses on the task of emotion
classification or emotion intensity regression. Fewer works address emotions as
a phenomenon to be tackled with structured learning, which can be explained by
the lack of relevant datasets. We fill this gap by releasing a dataset of 5000
English news headlines annotated via crowdsourcing with their associated
emotions, the corresponding emotion experiencers and textual cues, related
emotion causes and targets, as well as the reader's perception of the emotion
of the headline. This annotation task is comparably challenging, given the
large number of classes and roles to be identified. We therefore propose a
multiphase annotation procedure in which we first find relevant instances with
emotional content and then annotate the more fine-grained aspects. Finally, we
develop a baseline for the task of automatic prediction of semantic role
structures and discuss the results. The corpus we release enables further
research on emotion classification, emotion intensity prediction, emotion cause
detection, and supports further qualitative studies.
</summary>
    <author>
      <name>Laura Bostan</name>
    </author>
    <author>
      <name>Evgeny Kim</name>
    </author>
    <author>
      <name>Roman Klinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03184v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03184v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03063v1</id>
    <updated>2019-12-06T11:04:08Z</updated>
    <published>2019-12-06T11:04:08Z</published>
    <title>Weak Supervision helps Emergence of Word-Object Alignment and improves
  Vision-Language Tasks</title>
    <summary>  The large adoption of the self-attention (i.e. transformer model) and
BERT-like training principles has recently resulted in a number of high
performing models on a large panoply of vision-and-language problems (such as
Visual Question Answering (VQA), image retrieval, etc.). In this paper we claim
that these State-Of-The-Art (SOTA) approaches perform reasonably well in
structuring information inside a single modality but, despite their impressive
performances , they tend to struggle to identify fine-grained inter-modality
relationships. Indeed, such relations are frequently assumed to be implicitly
learned during training from application-specific losses, mostly cross-entropy
for classification. While most recent works provide inductive bias for
inter-modality relationships via cross attention modules, in this work, we
demonstrate (1) that the latter assumption does not hold, i.e. modality
alignment does not necessarily emerge automatically, and (2) that adding weak
supervision for alignment between visual objects and words improves the quality
of the learned models on tasks requiring reasoning. In particular , we
integrate an object-word alignment loss into SOTA vision-language reasoning
models and evaluate it on two tasks VQA and Language-driven Comparison of
Images. We show that the proposed fine-grained inter-modality supervision
significantly improves performance on both tasks. In particular, this new
learning signal allows obtaining SOTA-level performances on GQA dataset (VQA
task) with pre-trained models without finetuning on the task, and a new SOTA on
NLVR2 dataset (Language-driven Comparison of Images). Finally, we also
illustrate the impact of the contribution on the models reasoning by
visualizing attention distributions.
</summary>
    <author>
      <name>Corentin Kervadec</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRIS</arxiv:affiliation>
    </author>
    <author>
      <name>Grigory Antipov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRIS</arxiv:affiliation>
    </author>
    <author>
      <name>Moez Baccouche</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRIS</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Wolf</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRIS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1912.03063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03048v1</id>
    <updated>2019-12-06T10:09:20Z</updated>
    <published>2019-12-06T10:09:20Z</published>
    <title>Document Network Embedding: Coping for Missing Content and Missing Links</title>
    <summary>  Searching through networks of documents is an important task. A promising
path to improve the performance of information retrieval systems in this
context is to leverage dense node and content representations learned with
embedding techniques. However, these techniques cannot learn representations
for documents that are either isolated or whose content is missing. To tackle
this issue, assuming that the topology of the network and the content of the
documents correlate, we propose to estimate the missing node representations
from the available content representations, and conversely. Inspired by recent
advances in machine translation, we detail in this paper how to learn a linear
transformation from a set of aligned content and node representations. The
projection matrix is efficiently calculated in terms of the singular value
decomposition. The usefulness of the proposed method is highlighted by the
improved ability to predict the neighborhood of nodes whose links are
unobserved based on the projected content representations, and to retrieve
similar documents when content is missing, based on the projected node
representations.
</summary>
    <author>
      <name>Jean Dupuy</name>
    </author>
    <author>
      <name>Adrien Guille</name>
    </author>
    <author>
      <name>Julien Jacques</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10163v1</id>
    <updated>2019-12-06T09:57:22Z</updated>
    <published>2019-12-06T09:57:22Z</published>
    <title>Can AI Generate Love Advice?: Toward Neural Answer Generation for
  Non-Factoid Questions</title>
    <summary>  Deep learning methods that extract answers for non-factoid questions from QA
sites are seen as critical since they can assist users in reaching their next
decisions through conversations with AI systems. The current methods, however,
have the following two problems: (1) They can not understand the ambiguous use
of words in the questions as word usage can strongly depend on the context. As
a result, the accuracies of their answer selections are not good enough. (2)
The current methods can only select from among the answers held by QA sites and
can not generate new ones. Thus, they can not answer the questions that are
somewhat different with those stored in QA sites. Our solution, Neural Answer
Construction Model, tackles these problems as it: (1) Incorporates the biases
of semantics behind questions into word embeddings while also computing them
regardless of the semantics. As a result, it can extract answers that suit the
contexts of words used in the question as well as following the common usage of
words across semantics. This improves the accuracy of answer selection. (2)
Uses biLSTM to compute the embeddings of questions as well as those of the
sentences often used to form answers. It then simultaneously learns the optimum
combination of those sentences as well as the closeness between the question
and those sentences. As a result, our model can construct an answer that
corresponds to the situation that underlies the question; it fills the gap
between answer selection and generation and is the first model to move beyond
the current simple answer selection model for non-factoid QAs. Evaluations
using datasets created for love advice stored in the Japanese QA site, Oshiete
goo, indicate that our model achieves 20% higher accuracy in answer creation
than the strong baselines. Our model is practical and has already been applied
to the love advice service in Oshiete goo.
</summary>
    <author>
      <name>Makoto Nakatsuji</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03041v1</id>
    <updated>2019-12-06T09:38:23Z</updated>
    <published>2019-12-06T09:38:23Z</published>
    <title>Integrating Deep Learning with Logic Fusion for Information Extraction</title>
    <summary>  Information extraction (IE) aims to produce structured information from an
input text, e.g., Named Entity Recognition and Relation Extraction. Various
attempts have been proposed for IE via feature engineering or deep learning.
However, most of them fail to associate the complex relationships inherent in
the task itself, which has proven to be especially crucial. For example, the
relation between 2 entities is highly dependent on their entity types. These
dependencies can be regarded as complex constraints that can be efficiently
expressed as logical rules. To combine such logic reasoning capabilities with
learning capabilities of deep neural networks, we propose to integrate logical
knowledge in the form of first-order logic into a deep learning system, which
can be trained jointly in an end-to-end manner. The integrated framework is
able to enhance neural outputs with knowledge regularization via logic rules,
and at the same time update the weights of logic rules to comply with the
characteristics of the training data. We demonstrate the effectiveness and
generalization of the proposed model on multiple IE tasks.
</summary>
    <author>
      <name>Wenya Wang</name>
    </author>
    <author>
      <name>Sinno Jialin Pan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10164v1</id>
    <updated>2019-12-06T09:36:15Z</updated>
    <published>2019-12-06T09:36:15Z</published>
    <title>Decomposing predictability: Semantic feature overlap between words and
  the dynamics of reading for meaning</title>
    <summary>  The present study uses a computational approach to examine the role of
semantic constraints in normal reading. This methodology avoids confounds
inherent in conventional measures of predictability, allowing for theoretically
deeper accounts of semantic processing. We start from a definition of
associations between words based on the significant log likelihood that two
words co-occur frequently together in the sentences of a large text corpus.
Direct associations between stimulus words were controlled, and semantic
feature overlap between prime and target words was manipulated by their common
associates. The stimuli consisted of sentences of the form pronoun, verb,
article, adjective and noun, followed by a series of closed class words, e. g.
"She rides the grey elephant on one of her many exploratory voyages". The
results showed that verb-noun overlap reduces single and first fixation
durations of the target noun and adjective-noun overlap reduces go-past
durations. A dynamic spreading of activation account suggests that associates
of the prime words take some time to become activated: The verb can act on the
target noun's early eye-movement measures presented three words later, while
the adjective is presented immediately prior to the target, which induces
sentence re-examination after a difficult adjective-noun semantic integration.
</summary>
    <author>
      <name>Markus J. Hofmann</name>
    </author>
    <author>
      <name>Mareike A. Kleemann</name>
    </author>
    <author>
      <name>Andre Roelke</name>
    </author>
    <author>
      <name>Christian Vorstius</name>
    </author>
    <author>
      <name>Ralph Radach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03010v1</id>
    <updated>2019-12-06T07:55:04Z</updated>
    <published>2019-12-06T07:55:04Z</published>
    <title>Semantic Mask for Transformer based End-to-End Speech Recognition</title>
    <summary>  Attention-based encoder-decoder model has achieved impressive results for
both automatic speech recognition (ASR) and text-to-speech (TTS) tasks. This
approach takes advantage of the memorization capacity of neural networks to
learn the mapping from the input sequence to the output sequence from scratch,
without the assumption of prior knowledge such as the alignments. However, this
model is prone to overfitting, especially when the amount of training data is
limited. Inspired by SpecAugment and BERT, in this paper, we propose a semantic
mask based regularization for training such kind of end-to-end (E2E) model. The
idea is to mask the input features corresponding to a particular output token,
e.g., a word or a word-piece, in order to encourage the model to fill the token
based on the contextual information. While this approach is applicable to the
encoder-decoder framework with any type of neural network architecture, we
study the transformer-based model for ASR in this work. We perform experiments
on Librispeech 960h and TedLium2 data sets, and achieve the state-of-the-art
performance on the test set in the scope of E2E models.
</summary>
    <author>
      <name>Chengyi Wang</name>
    </author>
    <author>
      <name>Yu Wu</name>
    </author>
    <author>
      <name>Yujiao Du</name>
    </author>
    <author>
      <name>Jinyu Li</name>
    </author>
    <author>
      <name>Shujie Liu</name>
    </author>
    <author>
      <name>Liang Lu</name>
    </author>
    <author>
      <name>Shuo Ren</name>
    </author>
    <author>
      <name>Guoli Ye</name>
    </author>
    <author>
      <name>Sheng Zhao</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
