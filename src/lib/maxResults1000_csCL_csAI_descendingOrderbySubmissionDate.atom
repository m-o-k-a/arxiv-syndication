<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dcat%3Acs.CL%20AND%20cat%3Acs.AI%26id_list%3D%26start%3D0%26max_results%3D1000" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=cat:cs.CL AND cat:cs.AI&amp;id_list=&amp;start=0&amp;max_results=1000</title>
  <id>http://arxiv.org/api/c+e7OPtQnB77pCF6SfWvMsyMMi8</id>
  <updated>2020-03-11T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">2660</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1000</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2003.04567v1</id>
    <updated>2020-03-10T08:24:41Z</updated>
    <published>2020-03-10T08:24:41Z</published>
    <title>Ecological Semantics: Programming Environments for Situated Language
  Understanding</title>
    <summary>  Large-scale natural language understanding (NLU) systems have made impressive
progress: they can be applied flexibly across a variety of tasks, and employ
minimal structural assumptions. However, extensive empirical research has shown
this to be a double-edged sword, coming at the cost of shallow understanding:
inferior generalization, grounding and explainability. Grounded language
learning approaches offer the promise of deeper understanding by situating
learning in richer, more structured training environments, but are limited in
scale to relatively narrow, predefined domains. How might we enjoy the best of
both worlds: grounded, general NLU? Following extensive contemporary cognitive
science, we propose treating environments as ``first-class citizens'' in
semantic representations, worthy of research and development in their own
right. Importantly, models should also be partners in the creation and
configuration of environments, rather than just actors within them, as in
existing approaches. To do so, we argue that models must begin to understand
and program in the language of affordances (which define possible actions in a
given situation) both for online, situated discourse comprehension, as well as
large-scale, offline common-sense knowledge mining. To this end we propose an
environment-oriented ecological semantics, outlining theoretical and practical
approaches towards implementation. We further provide actual demonstrations
building upon interactive fiction programming languages.
</summary>
    <author>
      <name>Ronen Tamari</name>
    </author>
    <author>
      <name>Gabriel Stanovsky</name>
    </author>
    <author>
      <name>Dafna Shahaf</name>
    </author>
    <author>
      <name>Reut Tsarfaty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Bridging AI and Cognitive Science (BAICS) workshop at
  ICLR2020. For interactive demos, see https://eco-sem.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04195v1</id>
    <updated>2020-03-09T15:20:21Z</updated>
    <published>2020-03-09T15:20:21Z</published>
    <title>An Empirical Investigation of Pre-Trained Transformer Language Models
  for Open-Domain Dialogue Generation</title>
    <summary>  We present an empirical investigation of pre-trained Transformer-based
auto-regressive language models for the task of open-domain dialogue
generation. Training paradigm of pre-training and fine-tuning is employed to
conduct the parameter learning. Corpora of News and Wikipedia in Chinese and
English are collected for the pre-training stage respectively. Dialogue context
and response are concatenated into a single sequence utilized as the input of
the models during the fine-tuning stage. A weighted joint prediction paradigm
for both context and response is designed to evaluate the performance of models
with or without the loss term for context prediction. Various of decoding
strategies such as greedy search, beam search, top-k sampling, etc. are
employed to conduct the response text generation. Extensive experiments are
conducted on the typical single-turn and multi-turn dialogue corpora such as
Weibo, Douban, Reddit, DailyDialog, and Persona-Chat. Detailed numbers of
automatic evaluation metrics on relevance and diversity of the generated
results for the languages models as well as the baseline approaches are
reported.
</summary>
    <author>
      <name>Piji Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04195v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04195v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04707v1</id>
    <updated>2020-03-09T15:04:07Z</updated>
    <published>2020-03-09T15:04:07Z</published>
    <title>Neuro-symbolic Architectures for Context Understanding</title>
    <summary>  Computational context understanding refers to an agent's ability to fuse
disparate sources of information for decision-making and is, therefore,
generally regarded as a prerequisite for sophisticated machine reasoning
capabilities, such as in artificial intelligence (AI). Data-driven and
knowledge-driven methods are two classical techniques in the pursuit of such
machine sense-making capability. However, while data-driven methods seek to
model the statistical regularities of events by making observations in the
real-world, they remain difficult to interpret and they lack mechanisms for
naturally incorporating external knowledge. Conversely, knowledge-driven
methods, combine structured knowledge bases, perform symbolic reasoning based
on axiomatic principles, and are more interpretable in their inferential
processing; however, they often lack the ability to estimate the statistical
salience of an inference. To combat these issues, we propose the use of hybrid
AI methodology as a general framework for combining the strengths of both
approaches. Specifically, we inherit the concept of neuro-symbolism as a way of
using knowledge-bases to guide the learning progress of deep neural networks.
We further ground our discussion in two applications of neuro-symbolism and, in
both cases, show that our systems maintain interpretability while achieving
comparable performance, relative to the state-of-the-art.
</summary>
    <author>
      <name>Alessandro Oltramari</name>
    </author>
    <author>
      <name>Jonathan Francis</name>
    </author>
    <author>
      <name>Cory Henson</name>
    </author>
    <author>
      <name>Kaixin Ma</name>
    </author>
    <author>
      <name>Ruwan Wickramarachchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge
  Graphs for eXplainable AI -- Foundations, Applications and Challenges.
  Studies on the Semantic Web, IOS Press, Amsterdam, 2020. arXiv admin note:
  text overlap with arXiv:1910.14087</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03875v1</id>
    <updated>2020-03-09T00:32:13Z</updated>
    <published>2020-03-09T00:32:13Z</published>
    <title>Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,
  Relation, Event and QA</title>
    <summary>  Knowledge graph models world knowledge as concepts, entities, and the
relationships between them, which has been widely used in many real-world
tasks. CCKS 2019 held an evaluation track with 6 tasks and attracted more than
1,600 teams. In this paper, we give an overview of the knowledge graph
evaluation tract at CCKS 2019. By reviewing the task definition, successful
methods, useful resources, good strategies and research challenges associated
with each task in CCKS 2019, this paper can provide a helpful reference for
developing knowledge graph applications and conducting future knowledge graph
researches.
</summary>
    <author>
      <name>Xianpei Han</name>
    </author>
    <author>
      <name>Zhichun Wang</name>
    </author>
    <author>
      <name>Jiangtao Zhang</name>
    </author>
    <author>
      <name>Qinghua Wen</name>
    </author>
    <author>
      <name>Wenqi Li</name>
    </author>
    <author>
      <name>Buzhou Tang</name>
    </author>
    <author>
      <name>Qi Wang</name>
    </author>
    <author>
      <name>Zhifan Feng</name>
    </author>
    <author>
      <name>Yang Zhang</name>
    </author>
    <author>
      <name>Yajuan Lu</name>
    </author>
    <author>
      <name>Haitao Wang</name>
    </author>
    <author>
      <name>Wenliang Chen</name>
    </author>
    <author>
      <name>Hao Shao</name>
    </author>
    <author>
      <name>Yubo Chen</name>
    </author>
    <author>
      <name>Kang Liu</name>
    </author>
    <author>
      <name>Jun Zhao</name>
    </author>
    <author>
      <name>Taifeng Wang</name>
    </author>
    <author>
      <name>Kezun Zhang</name>
    </author>
    <author>
      <name>Meng Wang</name>
    </author>
    <author>
      <name>Yinlin Jiang</name>
    </author>
    <author>
      <name>Guilin Qi</name>
    </author>
    <author>
      <name>Lei Zou</name>
    </author>
    <author>
      <name>Sen Hu</name>
    </author>
    <author>
      <name>Minhao Zhang</name>
    </author>
    <author>
      <name>Yinnian Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, in Chinese, 9 figures and 17 tables, CCKS 2019 held an
  evaluation track about knowledge graph with 6 tasks and attracted more than
  1,600 teams</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03645v1</id>
    <updated>2020-03-07T19:31:08Z</updated>
    <published>2020-03-07T19:31:08Z</published>
    <title>Generating Emotionally Aligned Responses in Dialogues using Affect
  Control Theory</title>
    <summary>  State-of-the-art neural dialogue systems excel at syntactic and semantic
modelling of language, but often have a hard time establishing emotional
alignment with the human interactant during a conversation. In this work, we
bring Affect Control Theory (ACT), a socio-mathematical model of emotions for
human-human interactions, to the neural dialogue generation setting. ACT makes
predictions about how humans respond to emotional stimuli in social situations.
Due to this property, ACT and its derivative probabilistic models have been
successfully deployed in several applications of Human-Computer Interaction,
including empathetic tutoring systems, assistive healthcare devices and
two-person social dilemma games. We investigate how ACT can be used to develop
affect-aware conversational agents, which produce emotionally aligned responses
to prompts and take into consideration the affective identities of the
interactants.
</summary>
    <author>
      <name>Nabiha Asghar</name>
    </author>
    <author>
      <name>Ivan Kobyzev</name>
    </author>
    <author>
      <name>Jesse Hoey</name>
    </author>
    <author>
      <name>Pascal Poupart</name>
    </author>
    <author>
      <name>Muhammad Bilal Sheikh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03446v1</id>
    <updated>2020-03-06T21:28:44Z</updated>
    <published>2020-03-06T21:28:44Z</published>
    <title>Natural Language QA Approaches using Reasoning with External Knowledge</title>
    <summary>  Question answering (QA) in natural language (NL) has been an important aspect
of AI from its early days. Winograd's ``councilmen'' example in his 1972 paper
and McCarthy's Mr. Hug example of 1976 highlights the role of external
knowledge in NL understanding. While Machine Learning has been the go-to
approach in NL processing as well as NL question answering (NLQA) for the last
30 years, recently there has been an increasingly emphasized thread on NLQA
where external knowledge plays an important role. The challenges inspired by
Winograd's councilmen example, and recent developments such as the Rebooting AI
book, various NLQA datasets, research on knowledge acquisition in the NLQA
context, and their use in various NLQA models have brought the issue of NLQA
using ``reasoning'' with external knowledge to the forefront. In this paper, we
present a survey of the recent work on them. We believe our survey will help
establish a bridge between multiple fields of AI, especially between (a) the
traditional fields of knowledge representation and reasoning and (b) the field
of NL understanding and NLQA.
</summary>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Pratyay Banerjee</name>
    </author>
    <author>
      <name>Kuntal Kumar Pal</name>
    </author>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, Work in Progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03350v1</id>
    <updated>2020-03-06T18:27:39Z</updated>
    <published>2020-03-06T18:27:39Z</published>
    <title>Distributional semantic modeling: a revised technique to train term/word
  vector space models applying the ontology-related approach</title>
    <summary>  We design a new technique for the distributional semantic modeling with a
neural network-based approach to learn distributed term representations (or
term embeddings) - term vector space models as a result, inspired by the recent
ontology-related approach (using different types of contextual knowledge such
as syntactic knowledge, terminological knowledge, semantic knowledge, etc.) to
the identification of terms (term extraction) and relations between them
(relation extraction) called semantic pre-processing technology - SPT. Our
method relies on automatic term extraction from the natural language texts and
subsequent formation of the problem-oriented or application-oriented (also
deeply annotated) text corpora where the fundamental entity is the term
(includes non-compositional and compositional terms). This gives us an
opportunity to changeover from distributed word representations (or word
embeddings) to distributed term representations (or term embeddings). This
transition will allow to generate more accurate semantic maps of different
subject domains (also, of relations between input terms - it is useful to
explore clusters and oppositions, or to test your hypotheses about them). The
semantic map can be represented as a graph using Vec2graph - a Python library
for visualizing word embeddings (term embeddings in our case) as dynamic and
interactive graphs. The Vec2graph library coupled with term embeddings will not
only improve accuracy in solving standard NLP tasks, but also update the
conventional concept of automated ontology development. The main practical
result of our work is the development kit (set of toolkits represented as web
service APIs and web application), which provides all necessary routines for
the basic linguistic pre-processing and the semantic pre-processing of the
natural language texts in Ukrainian for future training of term vector space
models.
</summary>
    <author>
      <name>Oleksandr Palagin</name>
    </author>
    <author>
      <name>Vitalii Velychko</name>
    </author>
    <author>
      <name>Kyrylo Malakhov</name>
    </author>
    <author>
      <name>Oleksandr Shchurov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In English, 9 pages, 2 figures. Not published yet. Prepared for
  special issue (UkrPROG 2020 conference) of the scientific journal "Problems
  in programming" (Founder: National Academy of Sciences of Ukraine, Institute
  of Software Systems of NAS Ukraine)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03239v1</id>
    <updated>2020-03-06T14:35:20Z</updated>
    <published>2020-03-06T14:35:20Z</published>
    <title>On the Role of Conceptualization in Commonsense Knowledge Graph
  Construction</title>
    <summary>  Commonsense knowledge graphs (CKG) like Atomic and ASER are substantially
different from conventional KG as they consist of much larger number of nodes
formed by loosely-structured texts, which, though, enable them to handle highly
diverse queries in natural language regarding commonsense, lead to unique
challenges to automatic KG construction methods. Besides identifying relations
absent from the KG between nodes, the methods are also expected to explore
absent nodes represented by texts, in which different real-world things or
entities may appear. To deal with innumerable entities involved with
commonsense in real world, we introduce to CKG construction methods
conceptualization, i.e., to view entities mentioned in texts as instances of
specific concepts or vice versa. We build synthetic triples by
conceptualization, and further formulate the task as triple classification,
handled by a discriminatory model with knowledge transferred from pretrained
language models and fine-tuned by negative sampling. Experiments demonstrate
that our methods could effectively identify plausible triples and expand the KG
by triples of both new nodes and edges in high diversity and novelty.
</summary>
    <author>
      <name>Mutian He</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <author>
      <name>Kun Xu</name>
    </author>
    <author>
      <name>Yu Dong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03069v1</id>
    <updated>2020-03-06T08:18:13Z</updated>
    <published>2020-03-06T08:18:13Z</published>
    <title>Parsing Thai Social Data: A New Challenge for Thai NLP</title>
    <summary>  Dependency parsing (DP) is a task that analyzes text for syntactic structure
and relationship between words. DP is widely used to improve natural language
processing (NLP) applications in many languages such as English. Previous works
on DP are generally applicable to formally written languages. However, they do
not apply to informal languages such as the ones used in social networks.
Therefore, DP has to be researched and explored with such social network data.
In this paper, we explore and identify a DP model that is suitable for Thai
social network data. After that, we will identify the appropriate linguistic
unit as an input. The result showed that, the transition based model called,
improve Elkared dependency parser outperform the others at UAS of 81.42%.
</summary>
    <author>
      <name>Sattaya Singkul</name>
    </author>
    <author>
      <name>Borirat Khampingyot</name>
    </author>
    <author>
      <name>Nattasit Maharattamalai</name>
    </author>
    <author>
      <name>Supawat Taerungruang</name>
    </author>
    <author>
      <name>Tawunrat Chalothorn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 8 figures, to be published in The 14th International Joint
  Symposium on Artificial Intelligence and Natural Language Processing
  (iSAI-NLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02756v1</id>
    <updated>2020-03-05T16:46:35Z</updated>
    <published>2020-03-05T16:46:35Z</published>
    <title>HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in
  Natural Language Inference</title>
    <summary>  Many recent studies have shown that for models trained on datasets for
natural language inference (NLI), it is possible to make correct predictions by
merely looking at the hypothesis while completely ignoring the premise. In this
work, we manage to derive adversarial examples in terms of the hypothesis-only
bias and explore eligible ways to mitigate such bias. Specifically, we extract
various phrases from the hypotheses (artificial patterns) in the training sets,
and show that they have been strong indicators to the specific labels. We then
figure out `hard' and `easy' instances from the original test sets whose labels
are opposite to or consistent with those indications. We also set up baselines
including both pretrained models (BERT, RoBERTa, XLNet) and competitive
non-pretrained models (InferSent, DAM, ESIM). Apart from the benchmark and
baselines, we also investigate two debiasing approaches which exploit the
artificial pattern modeling to mitigate such hypothesis-only bias:
down-sampling and adversarial training. We believe those methods can be treated
as competitive baselines in NLI debiasing tasks.
</summary>
    <author>
      <name>Tianyu Liu</name>
    </author>
    <author>
      <name>Xin Zheng</name>
    </author>
    <author>
      <name>Baobao Chang</name>
    </author>
    <author>
      <name>Zhifang Sui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02599v2</id>
    <updated>2020-03-06T10:33:23Z</updated>
    <published>2020-03-05T13:22:23Z</published>
    <title>An Incremental Explanation of Inference in Hybrid Bayesian Networks for
  Increasing Model Trustworthiness and Supporting Clinical Decision Making</title>
    <summary>  Various AI models are increasingly being considered as part of clinical
decision-support tools. However, the trustworthiness of such models is rarely
considered. Clinicians are more likely to use a model if they can understand
and trust its predictions. Key to this is if its underlying reasoning can be
explained. A Bayesian network (BN) model has the advantage that it is not a
black-box and its reasoning can be explained. In this paper, we propose an
incremental explanation of inference that can be applied to hybrid BNs, i.e.
those that contain both discrete and continuous nodes. The key questions that
we answer are: (1) which important evidence supports or contradicts the
prediction, and (2) through which intermediate variables does the information
flow. The explanation is illustrated using a real clinical case study. A small
evaluation study is also conducted.
</summary>
    <author>
      <name>Evangelia Kyrimi</name>
    </author>
    <author>
      <name>Somayyeh Mossadegh</name>
    </author>
    <author>
      <name>Nigel Tai</name>
    </author>
    <author>
      <name>William Marsh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02599v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02599v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01848v1</id>
    <updated>2020-03-04T01:14:27Z</updated>
    <published>2020-03-04T01:14:27Z</published>
    <title>On Emergent Communication in Competitive Multi-Agent Teams</title>
    <summary>  Several recent works have found the emergence of grounded compositional
language in the communication protocols developed by mostly cooperative
multi-agent systems when learned end-to-end to maximize performance on a
downstream task. However, human populations learn to solve complex tasks
involving communicative behaviors not only in fully cooperative settings but
also in scenarios where competition acts as an additional external pressure for
improvement. In this work, we investigate whether competition for performance
from an external, similar agent team could act as a social influence that
encourages multi-agent populations to develop better communication protocols
for improved performance, compositionality, and convergence speed. We start
from Task &amp; Talk, a previously proposed referential game between two
cooperative agents as our testbed and extend it into Task, Talk &amp; Compete, a
game involving two competitive teams each consisting of two aforementioned
cooperative agents. Using this new setting, we provide an empirical study
demonstrating the impact of competitive influence on multi-agent teams. Our
results show that an external competitive influence leads to improved accuracy
and generalization, as well as faster emergence of communicative languages that
are more informative and compositional.
</summary>
    <author>
      <name>Paul Pu Liang</name>
    </author>
    <author>
      <name>Jeffrey Chen</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Louis-Philippe Morency</name>
    </author>
    <author>
      <name>Satwik Kottur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAMAS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04360v1</id>
    <updated>2020-03-03T20:35:36Z</updated>
    <published>2020-03-03T20:35:36Z</published>
    <title>GenNet : Reading Comprehension with Multiple Choice Questions using
  Generation and Selection model</title>
    <summary>  Multiple-choice machine reading comprehension is difficult task as its
required machines to select the correct option from a set of candidate or
possible options using the given passage and question.Reading Comprehension
with Multiple Choice Questions task,required a human (or machine) to read a
given passage, question pair and select the best one option from n given
options. There are two different ways to select the correct answer from the
given passage. Either by selecting the best match answer to by eliminating the
worst match answer. Here we proposed GenNet model, a neural network-based
model. In this model first we will generate the answer of the question from the
passage and then will matched the generated answer with given answer, the best
matched option will be our answer. For answer generation we used S-net (Tan et
al., 2017) model trained on SQuAD and to evaluate our model we used Large-scale
RACE (ReAding Comprehension Dataset From Examinations) (Lai et al.,2017).
</summary>
    <author>
      <name>Vaishali Ingale</name>
    </author>
    <author>
      <name>Pushpender Singh</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01338v1</id>
    <updated>2020-03-03T05:10:13Z</updated>
    <published>2020-03-03T05:10:13Z</published>
    <title>Hierarchical Context Enhanced Multi-Domain Dialogue System for
  Multi-domain Task Completion</title>
    <summary>  Task 1 of the DSTC8-track1 challenge aims to develop an end-to-end
multi-domain dialogue system to accomplish complex users' goals under tourist
information desk settings. This paper describes our submitted solution,
Hierarchical Context Enhanced Dialogue System (HCEDS), for this task. The main
motivation of our system is to comprehensively explore the potential of
hierarchical context for sufficiently understanding complex dialogues. More
specifically, we apply BERT to capture token-level information and employ the
attention mechanism to capture sentence-level information. The results listed
in the leaderboard show that our system achieves first place in automatic
evaluation and the second place in human evaluation.
</summary>
    <author>
      <name>Jingyuan Yang</name>
    </author>
    <author>
      <name>Guang Liu</name>
    </author>
    <author>
      <name>Yuzhao Mao</name>
    </author>
    <author>
      <name>Zhiwei Zhao</name>
    </author>
    <author>
      <name>Weiguo Gao</name>
    </author>
    <author>
      <name>Xuan Li</name>
    </author>
    <author>
      <name>Haiqin Yang</name>
    </author>
    <author>
      <name>Jianping Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at DSTC workshop, AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01200v2</id>
    <updated>2020-03-04T19:15:30Z</updated>
    <published>2020-03-02T21:32:05Z</published>
    <title>Natural Language Processing Advancements By Deep Learning: A Survey</title>
    <summary>  Natural Language Processing (NLP) helps empower intelligent machines by
enhancing a better understanding of the human language for linguistic-based
human-computer communication. Recent developments in computational power and
the advent of large amounts of linguistic data have heightened the need and
demand for automating semantic analysis using data-driven approaches. The
utilization of data-driven strategies is pervasive now due to the significant
improvements demonstrated through the usage of deep learning methods in areas
such as Computer Vision, Automatic Speech Recognition, and in particular, NLP.
This survey categorizes and addresses the different aspects and applications of
NLP that have benefited from deep learning. It covers core NLP tasks and
applications and describes how deep learning methods and models advance these
areas. We further analyze and compare different approaches and state-of-the-art
models.
</summary>
    <author>
      <name>Amirsina Torfi</name>
    </author>
    <author>
      <name>Rouzbeh A. Shirvani</name>
    </author>
    <author>
      <name>Yaser Keneshloo</name>
    </author>
    <author>
      <name>Nader Tavvaf</name>
    </author>
    <author>
      <name>Edward A. Fox</name>
    </author>
    <link href="http://arxiv.org/abs/2003.01200v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01200v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.01006v3</id>
    <updated>2020-03-06T08:58:48Z</updated>
    <published>2020-03-02T16:35:17Z</published>
    <title>The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources</title>
    <summary>  We introduce the STEM (Science, Technology, Engineering, and Medicine)
Dataset for Scientific Entity Extraction, Classification, and Resolution,
version 1.0 (STEM-ECR v1.0). The STEM-ECR v1.0 dataset has been developed to
provide a benchmark for the evaluation of scientific entity extraction,
classification, and resolution tasks in a domain-independent fashion. It
comprises abstracts in 10 STEM disciplines that were found to be the most
prolific ones on a major publishing platform. We describe the creation of such
a multidisciplinary corpus and highlight the obtained findings in terms of the
following features: 1) a generic conceptual formalism for scientific entities
in a multidisciplinary scientific context; 2) the feasibility of the
domain-independent human annotation of scientific entities under such a generic
formalism; 3) a performance benchmark obtainable for automatic extraction of
multidisciplinary scientific entities using BERT-based neural models; 4) a
delineated 3-step entity resolution procedure for human annotation of the
scientific entities via encyclopedic entity linking and lexicographic word
sense disambiguation; and 5) human evaluations of Babelfy returned encyclopedic
links and lexicographic senses for our entities. Our findings cumulatively
indicate that human annotation and automatic learning of multidisciplinary
scientific concepts as well as their semantic disambiguation in a wide-ranging
setting as STEM is reasonable.
</summary>
    <author>
      <name>Jennifer D'Souza</name>
    </author>
    <author>
      <name>Anett Hoppe</name>
    </author>
    <author>
      <name>Arthur Brack</name>
    </author>
    <author>
      <name>Mohamad Yaser Jaradeh</name>
    </author>
    <author>
      <name>Sören Auer</name>
    </author>
    <author>
      <name>Ralph Ewerth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in LREC 2020 proceedings. 10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01006v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01006v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00744v1</id>
    <updated>2020-03-02T10:21:17Z</updated>
    <published>2020-03-02T10:21:17Z</published>
    <title>PhoBERT: Pre-trained language models for Vietnamese</title>
    <summary>  We present PhoBERT with two versions of "base" and "large"--the first public
large-scale monolingual language models pre-trained for Vietnamese. We show
that PhoBERT improves the state-of-the-art in multiple Vietnamese-specific NLP
tasks including Part-of-speech tagging, Named-entity recognition and Natural
language inference. We release PhoBERT to facilitate future research and
downstream applications for Vietnamese NLP. Our PhoBERT is released at:
https://github.com/VinAIResearch/PhoBERT
</summary>
    <author>
      <name>Dat Quoc Nguyen</name>
    </author>
    <author>
      <name>Anh Tuan Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00443v2</id>
    <updated>2020-03-09T22:06:54Z</updated>
    <published>2020-03-01T09:06:31Z</published>
    <title>Environment-agnostic Multitask Learning for Natural Language Grounded
  Navigation</title>
    <summary>  Recent research efforts enable study for natural language grounded navigation
in photo-realistic environments, e.g., following natural language instructions
or dialog. However, existing methods tend to overfit training data in seen
environments and fail to generalize well in previously unseen environments. In
order to close the gap between seen and unseen environments, we aim at learning
a generalized navigation model from two novel perspectives: (1) we introduce a
multitask navigation model that can be seamlessly trained on both
Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH)
tasks, which benefits from richer natural language guidance and effectively
transfers knowledge across tasks; (2) we propose to learn environment-agnostic
representations for the navigation policy that are invariant among the
environments seen during training, thus generalizing better on unseen
environments. Extensive experiments show that training with
environment-agnostic multitask learning objective significantly reduces the
performance gap between seen and unseen environments and the navigation agent
so trained outperforms the baselines on unseen environments by 16% (relative
measure on success rate) on VLN and 120% (goal progress) on NDH. Our submission
to the CVDN leaderboard establishes a new state-of-the-art for the NDH task
outperforming the existing best model by more than 66% (goal progress) on the
holdout test set. The code for training the navigation model using
environment-agnostic multitask learning is available at
https://github.com/google-research/valan.
</summary>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Vihan Jain</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <author>
      <name>Sujith Ravi</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00443v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00443v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00330v3</id>
    <updated>2020-03-06T12:14:42Z</updated>
    <published>2020-02-29T18:55:13Z</published>
    <title>Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and
  Perspective</title>
    <summary>  Neural-symbolic computing has now become the subject of interest of both
academic and industry research laboratories. Graph Neural Networks (GNN) have
been widely used in relational and symbolic domains, with widespread
application of GNNs in combinatorial optimization, constraint satisfaction,
relational reasoning and other scientific domains. The need for improved
explainability, interpretability and trust of AI systems in general demands
principled methodologies, as suggested by neural-symbolic computing. In this
paper, we review the state-of-the-art on the use of GNNs as a model of
neural-symbolic computing. This includes the application of GNNs in several
domains as well as its relationship to current developments in neural-symbolic
computing.
</summary>
    <author>
      <name>Luis Lamb</name>
    </author>
    <author>
      <name>Artur Garcez</name>
    </author>
    <author>
      <name>Marco Gori</name>
    </author>
    <author>
      <name>Marcelo Prates</name>
    </author>
    <author>
      <name>Pedro Avelar</name>
    </author>
    <author>
      <name>Moshe Vardi</name>
    </author>
    <link href="http://arxiv.org/abs/2003.00330v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00330v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.00201v1</id>
    <updated>2020-02-29T07:39:35Z</updated>
    <published>2020-02-29T07:39:35Z</published>
    <title>What Emotions Make One or Five Stars? Understanding Ratings of Online
  Product Reviews by Sentiment Analysis and XAI</title>
    <summary>  When people buy products online, they primarily base their decisions on the
recommendations of others given in online reviews. The current work analyzed
these online reviews by sentiment analysis and used the extracted sentiments as
features to predict the product ratings by several machine learning algorithms.
These predictions were disentangled by various meth-ods of explainable AI (XAI)
to understand whether the model showed any bias during prediction. Study 1
benchmarked these algorithms (knn, support vector machines, random forests,
gradient boosting machines, XGBoost) and identified random forests and XGBoost
as best algorithms for predicting the product ratings. In Study 2, the analysis
of global feature importance identified the sentiment joy and the emotional
valence negative as most predictive features. Two XAI visualization methods,
local feature attributions and partial dependency plots, revealed several
incorrect prediction mechanisms on the instance-level. Performing the
benchmarking as classification, Study 3 identified a high no-information rate
of 64.4% that indicated high class imbalance as underlying reason for the
identified problems. In conclusion, good performance by machine learning
algorithms must be taken with caution because the dataset, as encountered in
this work, could be biased towards certain predictions. This work demonstrates
how XAI methods reveal such prediction bias.
</summary>
    <author>
      <name>Chaehan So</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in: Lecture Notes in Artificial Intelligence, 1st
  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as
  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.00201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.00201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12196v2</id>
    <updated>2020-02-28T10:11:09Z</updated>
    <published>2020-02-27T15:42:39Z</published>
    <title>Annotation of Emotion Carriers in Personal Narratives</title>
    <summary>  We are interested in the problem of understanding personal narratives (PN) -
spoken or written - recollections of facts, events, and thoughts. In PN,
emotion carriers are the speech or text segments that best explain the
emotional state of the user. Such segments may include entities, verb or noun
phrases. Advanced automatic understanding of PNs requires not only the
prediction of the user emotional state but also to identify which events (e.g.
"the loss of relative" or "the visit of grandpa") or people ( e.g. "the old
group of high school mates") carry the emotion manifested during the personal
recollection. This work proposes and evaluates an annotation model for
identifying emotion carriers in spoken personal narratives. Compared to other
text genres such as news and microblogs, spoken PNs are particularly
challenging because a narrative is usually unstructured, involving multiple
sub-events and characters as well as thoughts and associated emotions perceived
by the narrator. In this work, we experiment with annotating emotion carriers
from speech transcriptions in the Ulm State-of-Mind in Speech (USoMS) corpus, a
dataset of German PNs. We believe this resource could be used for experiments
in the automatic extraction of emotion carriers from PN, a task that could
provide further advancements in narrative understanding.
</summary>
    <author>
      <name>Aniruddha Tammewar</name>
    </author>
    <author>
      <name>Alessandra Cervone</name>
    </author>
    <author>
      <name>Eva-Maria Messner</name>
    </author>
    <author>
      <name>Giuseppe Riccardi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12196v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12196v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.11004v1</id>
    <updated>2020-02-25T16:24:42Z</updated>
    <published>2020-02-25T16:24:42Z</published>
    <title>Language-Independent Tokenisation Rivals Language-Specific Tokenisation
  for Word Similarity Prediction</title>
    <summary>  Language-independent tokenisation (LIT) methods that do not require labelled
language resources or lexicons have recently gained popularity because of their
applicability in resource-poor languages. Moreover, they compactly represent a
language using a fixed size vocabulary and can efficiently handle unseen or
rare words. On the other hand, language-specific tokenisation (LST) methods
have a long and established history, and are developed using carefully created
lexicons and training resources. Unlike subtokens produced by LIT methods, LST
methods produce valid morphological subwords. Despite the contrasting
trade-offs between LIT vs. LST methods, their performance on downstream NLP
tasks remain unclear. In this paper, we empirically compare the two approaches
using semantic similarity measurement as an evaluation task across a diverse
set of languages. Our experimental results covering eight languages show that
LST consistently outperforms LIT when the vocabulary size is large, but LIT can
produce comparable or better results than LST in many languages with
comparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging
the use of LIT when language-specific resources are unavailable, incomplete or
a smaller model is required. Moreover, we find that smoothed inverse frequency
(SIF) to be an accurate method to create word embeddings from subword
embeddings for multilingual semantic similarity prediction tasks. Further
analysis of the nearest neighbours of tokens show that semantically and
syntactically related tokens are closely embedded in subword embedding spaces
</summary>
    <author>
      <name>Danushka Bollegala</name>
    </author>
    <author>
      <name>Ryuichi Kiryo</name>
    </author>
    <author>
      <name>Kosuke Tsujino</name>
    </author>
    <author>
      <name>Haruki Yukawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the 12th Language Resources and Evaluation (LREC 2020)
  Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10665v1</id>
    <updated>2020-02-25T04:56:47Z</updated>
    <published>2020-02-25T04:56:47Z</published>
    <title>Declarative Memory-based Structure for the Representation of Text Data</title>
    <summary>  In the era of intelligent computing, computational progress in text
processing is an essential consideration. Many systems have been developed to
process text over different languages. Though, there is considerable
development, they still lack in understanding of the text, i.e., instead of
keeping text as knowledge, many treat text as a data. In this work we introduce
a text representation scheme which is influenced by human memory
infrastructure. Since texts are declarative in nature, a structural
organization would foster efficient computation over text. We exploit long term
episodic memory to keep text information observed over time. This not only keep
fragments of text in an organized fashion but also reduces redundancy and
stores the temporal relation among them. Wordnet has been used to imitate
semantic memory, which works at word level to facilitate the understanding
about individual words within text. Experimental results of various operation
performed over episodic memory and growth of knowledge infrastructure over time
is reported.
</summary>
    <author>
      <name>Sumant Pushp</name>
    </author>
    <author>
      <name>Pragya Kashmira</name>
    </author>
    <author>
      <name>Shyamanta M Hazarika</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10329v1</id>
    <updated>2020-02-24T15:57:41Z</updated>
    <published>2020-02-24T15:57:41Z</published>
    <title>KBSET -- Knowledge-Based Support for Scholarly Editing and Text
  Processing with Declarative LaTeX Markup and a Core Written in SWI-Prolog</title>
    <summary>  KBSET is an environment that provides support for scholarly editing in two
flavors: First, as a practical tool KBSET/Letters that accompanies the
development of editions of correspondences (in particular from the 18th and
19th century), completely from source documents to PDF and HTML presentations.
Second, as a prototypical tool KBSET/NER for experimentally investigating novel
forms of working on editions that are centered around automated named entity
recognition. KBSET can process declarative application-specific markup that is
expressed in LaTeX notation and incorporate large external fact bases that are
typically provided in RDF. KBSET includes specially developed LaTeX styles and
a core system that is written in SWI-Prolog, which is used there in many roles,
utilizing that it realizes the potential of Prolog as a unifying language.
</summary>
    <author>
      <name>Jana Kittelmann</name>
    </author>
    <author>
      <name>Christoph Wernhard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in DECLARE 2019 Revised Selected Papers</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10107v1</id>
    <updated>2020-02-24T07:56:02Z</updated>
    <published>2020-02-24T07:56:02Z</published>
    <title>Predicting Subjective Features from Questions on QA Websites using BERT</title>
    <summary>  Modern Question-Answering websites, such as StackOverflow and Quora, have
specific user rules to maintain their content quality. These systems rely on
user reports for accessing new contents, which has serious problems including
the slow handling of violations, the loss of normal and experienced users'
time, the low quality of some reports, and discouraging feedback to new users.
Therefore, with the overall goal of providing solutions for automating
moderation actions in Q&amp;A websites, we aim to provide a model to predict 20
quality or subjective aspects of questions in QA websites. To this end, we used
data gathered by the CrowdSource team at Google Research in 2019 and fine-tuned
pre-trained BERT model on our problem. Model achieves 95.4% accuracy after 2
epochs of training and did not improve substantially in the next ones. Results
confirm that by simple fine-tuning, we can achieve accurate models, in little
time, and on less amount of data.
</summary>
    <author>
      <name>Issa Annamoradnejad</name>
    </author>
    <author>
      <name>Mohammadamin Fazli</name>
    </author>
    <author>
      <name>Jafar Habibi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7; I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10016v1</id>
    <updated>2020-02-23T23:58:04Z</updated>
    <published>2020-02-23T23:58:04Z</published>
    <title>Deep Multimodal Image-Text Embeddings for Automatic Cross-Media
  Retrieval</title>
    <summary>  This paper considers the task of matching images and sentences by learning a
visual-textual embedding space for cross-modal retrieval. Finding such a space
is a challenging task since the features and representations of text and image
are not comparable. In this work, we introduce an end-to-end deep multimodal
convolutional-recurrent network for learning both vision and language
representations simultaneously to infer image-text similarity. The model learns
which pairs are a match (positive) and which ones are a mismatch (negative)
using a hinge-based triplet ranking. To learn about the joint representations,
we leverage our newly extracted collection of tweets from Twitter. The main
characteristic of our dataset is that the images and tweets are not
standardized the same as the benchmarks. Furthermore, there can be a higher
semantic correlation between the pictures and tweets contrary to benchmarks in
which the descriptions are well-organized. Experimental results on MS-COCO
benchmark dataset show that our model outperforms certain methods presented
previously and has competitive performance compared to the state-of-the-art.
The code and dataset have been made available publicly.
</summary>
    <author>
      <name>Hadi Abdi Khojasteh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Ebrahim Ansari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics, Charles University, Czechia</arxiv:affiliation>
    </author>
    <author>
      <name>Parvin Razzaghi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Advanced Studies in Basic Sciences</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Research in Fundamental Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Akbar Karimi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMP Lab, Department of Engineering and Architecture, University of Parma, Parma, Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages and 2 figures, Learn more about this project at
  https://iasbs.ac.ir/~ansari/deeptwitter</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.0; H.3.3; I.2.0; I.2.6; I.2.7; I.2.10; I.5.0; I.4.0; I.4.10; I.7.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09919v1</id>
    <updated>2020-02-23T15:16:43Z</updated>
    <published>2020-02-23T15:16:43Z</published>
    <title>Do Multi-Hop Question Answering Systems Know How to Answer the
  Single-Hop Sub-Questions?</title>
    <summary>  Multi-hop question answering (QA) requires a model to retrieve and integrate
information from different parts of a long text to answer a question. Humans
answer this kind of complex questions via a divide-and-conquer approach. In
this paper, we investigate whether top-performing models for multi-hop
questions understand the underlying sub-questions like humans. We adopt a
neural decomposition model to generate sub-questions for a multi-hop complex
question, followed by extracting the corresponding sub-answers. We show that
multiple state-of-the-art multi-hop QA models fail to correctly answer a large
portion of sub-questions, although their corresponding multi-hop questions are
correctly answered. This indicates that these models manage to answer the
multi-hop questions using some partial clues, instead of truly understanding
the reasoning paths. We also propose a new model which significantly improves
the performance on answering the sub-questions. Our work takes a step forward
towards building a more explainable multi-hop QA system.
</summary>
    <author>
      <name>Yixuan Tang</name>
    </author>
    <author>
      <name>Hwee Tou Ng</name>
    </author>
    <author>
      <name>Anthony K. H. Tung</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.10943v1</id>
    <updated>2020-02-23T07:39:55Z</updated>
    <published>2020-02-23T07:39:55Z</published>
    <title>Data Augmentation for Personal Knowledge Graph Population</title>
    <summary>  A personal knowledge graph comprising people as nodes, their personal data as
node attributes, and their relationships as edges has a number of applications
in de-identification, master data management, and fraud prevention. While
artificial neural networks have led to significant improvements in different
tasks in cold start knowledge graph population, the overall F1 of the system
remains quite low. This problem is more acute in personal knowledge graph
population which presents additional challenges with regard to data protection,
fairness and privacy. In this work, we present a system that uses rule based
annotators to augment training data for neural models, and for slot filling to
increase the diversity of the populated knowledge graph. We also propose a
representative set sampling method to use the populated knowledge graph data
for downstream applications. We introduce new resources and discuss our
results.
</summary>
    <author>
      <name>Lingraj S Vannur</name>
    </author>
    <author>
      <name>Lokesh Nagalapatti</name>
    </author>
    <author>
      <name>Balaji Ganesan</name>
    </author>
    <author>
      <name>Hima Patel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures, under review. arXiv admin note: substantial text
  overlap with arXiv:2001.08013</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.10943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09758v1</id>
    <updated>2020-02-22T19:40:35Z</updated>
    <published>2020-02-22T19:40:35Z</published>
    <title>Unsupervised Question Decomposition for Question Answering</title>
    <summary>  We aim to improve question answering (QA) by decomposing hard questions into
easier sub-questions that existing QA systems can answer. Since collecting
labeled decompositions is cumbersome, we propose an unsupervised approach to
produce sub-questions. Specifically, by leveraging &gt;10M questions from Common
Crawl, we learn to map from the distribution of multi-hop questions to the
distribution of single-hop sub-questions. We answer sub-questions with an
off-the-shelf QA model and incorporate the resulting answers in a downstream,
multi-hop QA system. On a popular multi-hop QA dataset, HotpotQA, we show large
improvements over a strong baseline, especially on adversarial and
out-of-domain questions. Our method is generally applicable and automatically
learns to decompose questions of different classes, while matching the
performance of decomposition methods that rely heavily on hand-engineering and
annotation.
</summary>
    <author>
      <name>Ethan Perez</name>
    </author>
    <author>
      <name>Patrick Lewis</name>
    </author>
    <author>
      <name>Wen-tau Yih</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09604v1</id>
    <updated>2020-02-22T02:34:51Z</updated>
    <published>2020-02-22T02:34:51Z</published>
    <title>Emergent Communication with World Models</title>
    <summary>  We introduce Language World Models, a class of language-conditional
generative model which interpret natural language messages by predicting latent
codes of future observations. This provides a visual grounding of the message,
similar to an enhanced observation of the world, which may include objects
outside of the listening agent's field-of-view. We incorporate this
"observation" into a persistent memory state, and allow the listening agent's
policy to condition on it, akin to the relationship between memory and
controller in a World Model. We show this improves effective communication and
task success in 2D gridworld speaker-listener navigation tasks. In addition, we
develop two losses framed specifically for our model-based formulation to
promote positive signalling and positive listening. Finally, because messages
are interpreted in a generative model, we can visualize the model beliefs to
gain insight into how the communication channel is utilized.
</summary>
    <author>
      <name>Alexander I. Cowen-Rivers</name>
    </author>
    <author>
      <name>Jason Naradowsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS Workshop on Emergent Communication</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09599v1</id>
    <updated>2020-02-22T01:49:27Z</updated>
    <published>2020-02-22T01:49:27Z</published>
    <title>Training Question Answering Models From Synthetic Data</title>
    <summary>  Question and answer generation is a data augmentation method that aims to
improve question answering (QA) models given the limited amount of human
labeled data. However, a considerable gap remains between synthetic and
human-generated question-answer pairs. This work aims to narrow this gap by
taking advantage of large language models and explores several factors such as
model size, quality of pretrained models, scale of data synthesized, and
algorithmic choices. On the SQuAD1.1 question answering task, we achieve higher
accuracy using solely synthetic questions and answers than when using the
SQuAD1.1 training set questions alone. Removing access to real Wikipedia data,
we synthesize questions and answers from a synthetic corpus generated by an 8.3
billion parameter GPT-2 model. With no access to human supervision and only
access to other models, we are able to train state of the art question
answering networks on entirely model-generated data that achieve 88.4 Exact
Match (EM) and 93.9 F1 score on the SQuAD1.1 dev set. We further apply our
methodology to SQuAD2.0 and show a 2.8 absolute gain on EM score compared to
prior work using synthetic data.
</summary>
    <author>
      <name>Raul Puri</name>
    </author>
    <author>
      <name>Ryan Spring</name>
    </author>
    <author>
      <name>Mostofa Patwary</name>
    </author>
    <author>
      <name>Mohammad Shoeybi</name>
    </author>
    <author>
      <name>Bryan Catanzaro</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09253v1</id>
    <updated>2020-02-21T12:59:57Z</updated>
    <published>2020-02-21T12:59:57Z</published>
    <title>Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration</title>
    <summary>  Autonomous reinforcement learning agents must be intrinsically motivated to
explore their environment, discover potential goals, represent them and learn
how to achieve them. As children do the same, they benefit from exposure to
language, using it to formulate goals and imagine new ones as they learn their
meaning. In our proposed learning architecture (IMAGINE), the agent freely
explores its environment and turns natural language descriptions of interesting
interactions from a social partner into potential goals. IMAGINE learns to
represent goals by jointly learning a language model and a goal-conditioned
reward function. Just like humans, our agent uses language compositionality to
generate new goals by composing known ones. Leveraging modular model
architectures based on Deep Sets and gated-attention mechanisms, IMAGINE
autonomously builds a repertoire of behaviors and shows good zero-shot
generalization properties for various types of generalization. When imagining
its own goals, the agent leverages zero-shot generalization of the reward
function to further train on imagined goals and refine its behavior. We present
experiments in a simulated domain where the agent interacts with procedurally
generated scenes containing objects of various types and colors, discovers
goals, imagines others and learns to achieve them.
</summary>
    <author>
      <name>Cédric Colas</name>
    </author>
    <author>
      <name>Tristan Karch</name>
    </author>
    <author>
      <name>Nicolas Lair</name>
    </author>
    <author>
      <name>Jean-Michel Dussoux</name>
    </author>
    <author>
      <name>Clément Moulin-Frier</name>
    </author>
    <author>
      <name>Peter Ford Dominey</name>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contains main article and supplementaries</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09253v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09253v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.09247v1</id>
    <updated>2020-02-21T12:37:12Z</updated>
    <published>2020-02-21T12:37:12Z</published>
    <title>Is Aligning Embedding Spaces a Challenging Task? An Analysis of the
  Existing Methods</title>
    <summary>  Representation Learning of words and Knowledge Graphs (KG) into low
dimensional vector spaces along with its applications to many real-world
scenarios have recently gained momentum. In order to make use of multiple KG
embeddings for knowledge-driven applications such as question answering, named
entity disambiguation, knowledge graph completion, etc., alignment of different
KG embedding spaces is necessary. In addition to multilinguality and
domain-specific information, different KGs pose the problem of structural
differences making the alignment of the KG embeddings more challenging. This
paper provides a theoretical analysis and comparison of the state-of-the-art
alignment methods between two embedding spaces representing entity-entity and
entity-word. This paper also aims at assessing the capability and short-comings
of the existing alignment methods on the pretext of different applications.
</summary>
    <author>
      <name>Russa Biswas</name>
    </author>
    <author>
      <name>Mehwish Alam</name>
    </author>
    <author>
      <name>Harald Sack</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08911v1</id>
    <updated>2020-02-20T17:54:46Z</updated>
    <published>2020-02-20T17:54:46Z</published>
    <title>Measuring Social Biases in Grounded Vision and Language Embeddings</title>
    <summary>  We generalize the notion of social biases from language embeddings to
grounded vision and language embeddings. Biases are present in grounded
embeddings, and indeed seem to be equally or more significant than for
ungrounded embeddings. This is despite the fact that vision and language can
suffer from different biases, which one might hope could attenuate the biases
in both. Multiple ways exist to generalize metrics measuring bias in word
embeddings to this new setting. We introduce the space of generalizations
(Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations
answer different yet important questions about how biases, language, and vision
interact. These metrics are used on a new dataset, the first for grounded bias,
created by augmenting extending standard linguistic bias benchmarks with 10,228
images from COCO, Conceptual Captions, and Google Images. Dataset construction
is challenging because vision datasets are themselves very biased. The presence
of these biases in systems will begin to have real-world consequences as they
are deployed, making carefully measuring bias and then mitigating it critical
to building a fair society.
</summary>
    <author>
      <name>Candace Ross</name>
    </author>
    <author>
      <name>Boris Katz</name>
    </author>
    <author>
      <name>Andrei Barbu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08795v1</id>
    <updated>2020-02-19T17:18:20Z</updated>
    <published>2020-02-19T17:18:20Z</published>
    <title>How To Avoid Being Eaten By a Grue: Exploration Strategies for
  Text-Adventure Agents</title>
    <summary>  Text-based games -- in which an agent interacts with the world through
textual natural language -- present us with the problem of
combinatorially-sized action-spaces. Most current reinforcement learning
algorithms are not capable of effectively handling such a large number of
possible actions per turn. Poor sample efficiency, consequently, results in
agents that are unable to pass bottleneck states, where they are unable to
proceed because they do not see the right action sequence to pass the
bottleneck enough times to be sufficiently reinforced. Building on prior work
using knowledge graphs in reinforcement learning, we introduce two new game
state exploration strategies. We compare our exploration strategies against
strong baselines on the classic text-adventure game, Zork1, where prior agent
have been unable to get past a bottleneck where the agent is eaten by a Grue.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Ethan Tien</name>
    </author>
    <author>
      <name>Zhaochen Luo</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08024v1</id>
    <updated>2020-02-19T06:39:26Z</updated>
    <published>2020-02-19T06:39:26Z</published>
    <title>Non-Autoregressive Dialog State Tracking</title>
    <summary>  Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues
have progressed toward open-vocabulary or generation-based approaches where the
models can generate slot value candidates from the dialogue history itself.
These approaches have shown good performance gain, especially in complicated
dialogue domains with dynamic slot values. However, they fall short in two
aspects: (1) they do not allow models to explicitly learn signals across
domains and slots to detect potential dependencies among (domain, slot) pairs;
and (2) existing models follow auto-regressive approaches which incur high time
cost when the dialogue evolves over multiple domains and multiple turns. In
this paper, we propose a novel framework of Non-Autoregressive Dialog State
Tracking (NADST) which can factor in potential dependencies among domains and
slots to optimize the models towards better prediction of dialogue states as a
complete set rather than separate slots. In particular, the non-autoregressive
nature of our method not only enables decoding in parallel to significantly
reduce the latency of DST for real-time dialogue response generation, but also
detect dependencies among slots at token level in addition to slot and domain
level. Our empirical results show that our model achieves the state-of-the-art
joint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency
of our model is an order of magnitude lower than the previous state of the art
as the dialogue history extends over time.
</summary>
    <author>
      <name>Hung Le</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Steven C. H. Hoi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICLR 2020. International Conference on Learning
  Representations (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07775v1</id>
    <updated>2020-02-18T18:10:03Z</updated>
    <published>2020-02-18T18:10:03Z</published>
    <title>An enhanced Tree-LSTM architecture for sentence semantic modeling using
  typed dependencies</title>
    <summary>  Tree-based Long short term memory (LSTM) network has become state-of-the-art
for modeling the meaning of language texts as they can effectively exploit the
grammatical syntax and thereby non-linear dependencies among words of the
sentence. However, most of these models cannot recognize the difference in
meaning caused by a change in semantic roles of words or phrases because they
do not acknowledge the type of grammatical relations, also known as typed
dependencies, in sentence structure. This paper proposes an enhanced LSTM
architecture, called relation gated LSTM, which can model the relationship
between two inputs of a sequence using a control input. We also introduce a
Tree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence
dependency parse structure as well as the dependency type to embed sentence
meaning into a dense vector. The proposed model outperformed its type-unaware
counterpart in two typical NLP tasks - Semantic Relatedness Scoring and
Sentiment Analysis, in a lesser number of training epochs. The results were
comparable or competitive with other state-of-the-art models. Qualitative
analysis showed that changes in the voice of sentences had little effect on the
model's predicted scores, while changes in nominal (noun) words had a more
significant impact. The model recognized subtle semantic relationships in
sentence pairs. The magnitudes of learned typed dependencies embeddings were
also in agreement with human intuitions. The research findings imply the
significance of grammatical relations in sentence modeling. The proposed models
would serve as a base for future researches in this direction.
</summary>
    <author>
      <name>Jeena Kleenankandy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science and Engineering, National Institute of Technology Calicut, Kerala, India</arxiv:affiliation>
    </author>
    <author>
      <name>K. A. Abdul Nazeer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science and Engineering, National Institute of Technology Calicut, Kerala, India</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a preprint submitted to Journal of Information Processing and
  Management ( Elsevier ) on December 29, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.07775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.07338v1</id>
    <updated>2020-02-18T02:22:31Z</updated>
    <published>2020-02-18T02:22:31Z</published>
    <title>Conditional Self-Attention for Query-based Summarization</title>
    <summary>  Self-attention mechanisms have achieved great success on a variety of NLP
tasks due to its flexibility of capturing dependency between arbitrary
positions in a sequence. For problems such as query-based summarization (Qsumm)
and knowledge graph reasoning where each input sequence is associated with an
extra query, explicitly modeling such conditional contextual dependencies can
lead to a more accurate solution, which however cannot be captured by existing
self-attention mechanisms. In this paper, we propose \textit{conditional
self-attention} (CSA), a neural network module designed for conditional
dependency modeling. CSA works by adjusting the pairwise attention between
input tokens in a self-attention module with the matching score of the inputs
to the given query. Thereby, the contextual dependencies modeled by CSA will be
highly relevant to the query. We further studied variants of CSA defined by
different types of attention. Experiments on Debatepedia and HotpotQA benchmark
datasets show CSA consistently outperforms vanilla Transformer and previous
models for the Qsumm problem.
</summary>
    <author>
      <name>Yujia Xie</name>
    </author>
    <author>
      <name>Tianyi Zhou</name>
    </author>
    <author>
      <name>Yi Mao</name>
    </author>
    <author>
      <name>Weizhu Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2002.07338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.07338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06397v2</id>
    <updated>2020-02-19T14:42:41Z</updated>
    <published>2020-02-15T15:25:44Z</published>
    <title>Open Knowledge Enrichment for Long-tail Entities</title>
    <summary>  Knowledge bases (KBs) have gradually become a valuable asset for many AI
applications. While many current KBs are quite large, they are widely
acknowledged as incomplete, especially lacking facts of long-tail entities,
e.g., less famous persons. Existing approaches enrich KBs mainly on completing
missing links or filling missing values. However, they only tackle a part of
the enrichment problem and lack specific considerations regarding long-tail
entities. In this paper, we propose a full-fledged approach to knowledge
enrichment, which predicts missing properties and infers true facts of
long-tail entities from the open Web. Prior knowledge from popular entities is
leveraged to improve every enrichment step. Our experiments on the synthetic
and real-world datasets and comparison with related work demonstrate the
feasibility and superiority of the approach.
</summary>
    <author>
      <name>Ermei Cao</name>
    </author>
    <author>
      <name>Difeng Wang</name>
    </author>
    <author>
      <name>Jiacheng Huang</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 29th International World Wide Web Conference (WWW
  2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06397v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06397v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06235v1</id>
    <updated>2020-02-14T20:02:11Z</updated>
    <published>2020-02-14T20:02:11Z</published>
    <title>Semantic Relatedness and Taxonomic Word Embeddings</title>
    <summary>  This paper connects a series of papers dealing with taxonomic word
embeddings. It begins by noting that there are different types of semantic
relatedness and that different lexical representations encode different forms
of relatedness. A particularly important distinction within semantic
relatedness is that of thematic versus taxonomic relatedness. Next, we present
a number of experiments that analyse taxonomic embeddings that have been
trained on a synthetic corpus that has been generated via a random walk over a
taxonomy. These experiments demonstrate how the properties of the synthetic
corpus, such as the percentage of rare words, are affected by the shape of the
knowledge graph the corpus is generated from. Finally, we explore the
interactions between the relative sizes of natural and synthetic corpora on the
performance of embeddings when taxonomic and thematic embeddings are combined.
</summary>
    <author>
      <name>Magdalena Kacmajor</name>
    </author>
    <author>
      <name>John D. Kelleher</name>
    </author>
    <author>
      <name>Filip Klubicka</name>
    </author>
    <author>
      <name>Alfredo Maldonado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06071v1</id>
    <updated>2020-02-14T15:23:38Z</updated>
    <published>2020-02-14T15:23:38Z</published>
    <title>FQuAD: French Question Answering Dataset</title>
    <summary>  Recent advances in the field of language modeling have improved
state-of-the-art results on many Natural Language Processing tasks. Among them,
the Machine Reading Comprehension task has made significant progress. However,
most of the results are reported in English since labeled resources available
in other languages, such as French, remain scarce. In the present work, we
introduce the French Question Answering Dataset (FQuAD). FQuAD is French Native
Reading Comprehension dataset that consists of 25,000+ questions on a set of
Wikipedia articles. A baseline model is trained which achieves an F1 score of
88.0% and an exact match ratio of 77.9% on the test set. The dataset is made
freely available at https://fquad.illuin.tech.
</summary>
    <author>
      <name>Martin d'Hoffschmidt</name>
    </author>
    <author>
      <name>Maxime Vidal</name>
    </author>
    <author>
      <name>Wacim Belblidia</name>
    </author>
    <author>
      <name>Tom Brendlé</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05867v1</id>
    <updated>2020-02-14T04:23:28Z</updated>
    <published>2020-02-14T04:23:28Z</published>
    <title>Transformers as Soft Reasoners over Language</title>
    <summary>  AI has long pursued the goal of having systems reason over *explicitly
provided* knowledge, but building suitable representations has proved
challenging. Here we explore whether transformers can similarly learn to reason
(or emulate reasoning), but using rules expressed in language, thus bypassing a
formal representation. We provide the first demonstration that this is
possible, and characterize the extent of this capability. To do this, we use a
collection of synthetic datasets that test increasing levels of reasoning
complexity (number of rules, presence of negation, and depth of chaining). We
find transformers appear to learn rule-based reasoning with high (99%) accuracy
on these datasets, and in a way that generalizes to test data requiring
substantially deeper chaining than in the training data (95%+ scores). We also
demonstrate that the models transfer well to two hand-authored rulebases, and
to rulebases paraphrased into more natural language. These findings are
significant as it suggests a new role for transformers, namely as a limited
"soft theorem prover" operating over explicit theories in language. This in
turn suggests new possibilities for explainability, correctability, and
counterfactual reasoning in question-answering. All datasets and a live demo
are available at http://rule-reasoning.apps.allenai.org/
</summary>
    <author>
      <name>Peter Clark</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Kyle Richardson</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04936v1</id>
    <updated>2020-02-12T12:06:32Z</updated>
    <published>2020-02-12T12:06:32Z</published>
    <title>Joint Embedding in Named Entity Linking on Sentence Level</title>
    <summary>  Named entity linking is to map an ambiguous mention in documents to an entity
in a knowledge base. The named entity linking is challenging, given the fact
that there are multiple candidate entities for a mention in a document. It is
difficult to link a mention when it appears multiple times in a document, since
there are conflicts by the contexts around the appearances of the mention. In
addition, it is difficult since the given training dataset is small due to the
reason that it is done manually to link a mention to its mapping entity. In the
literature, there are many reported studies among which the recent embedding
methods learn vectors of entities from the training dataset at document level.
To address these issues, we focus on how to link entity for mentions at a
sentence level, which reduces the noises introduced by different appearances of
the same mention in a document at the expense of insufficient information to be
used. We propose a new unified embedding method by maximizing the relationships
learned from knowledge graphs. We confirm the effectiveness of our method in
our experimental studies.
</summary>
    <author>
      <name>Wei Shi</name>
    </author>
    <author>
      <name>Siyuan Zhang</name>
    </author>
    <author>
      <name>Zhiwei Zhang</name>
    </author>
    <author>
      <name>Hong Cheng</name>
    </author>
    <author>
      <name>Jeffrey Xu Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04793v1</id>
    <updated>2020-02-12T04:31:40Z</updated>
    <published>2020-02-12T04:31:40Z</published>
    <title>ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and
  Diagnosing Dialogue Systems</title>
    <summary>  We present ConvLab-2, an open-source toolkit that enables researchers to
build task-oriented dialogue systems with state-of-the-art models, perform an
end-to-end evaluation, and diagnose the weakness of systems. As the successor
of ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but
integrates more powerful dialogue models and supports more datasets. Besides,
we have developed an analysis tool and an interactive tool to assist
researchers in diagnosing dialogue systems. The analysis tool presents rich
statistics and summarizes common mistakes from simulated dialogues, which
facilitates error analysis and system improvement. The interactive tool
provides a user interface that allows developers to diagnose an assembled
dialogue system by interacting with the system and modifying the output of each
system component.
</summary>
    <author>
      <name>Qi Zhu</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Yan Fang</name>
    </author>
    <author>
      <name>Xiang Li</name>
    </author>
    <author>
      <name>Ryuichi Takanobu</name>
    </author>
    <author>
      <name>Jinchao Li</name>
    </author>
    <author>
      <name>Baolin Peng</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04326v1</id>
    <updated>2020-02-11T11:54:29Z</updated>
    <published>2020-02-11T11:54:29Z</published>
    <title>ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning</title>
    <summary>  Recent powerful pre-trained language models have achieved remarkable
performance on most of the popular datasets for reading comprehension. It is
time to introduce more challenging datasets to push the development of this
field towards more comprehensive reasoning of text. In this paper, we introduce
a new Reading Comprehension dataset requiring logical reasoning (ReClor)
extracted from standardized graduate admission examinations. As earlier studies
suggest, human-annotated datasets usually contain biases, which are often
exploited by models to achieve high accuracy without truly understanding the
text. In order to comprehensively evaluate the logical reasoning ability of
models on ReClor, we propose to identify biased data points and separate them
into EASY set while the rest as HARD set. Empirical results show that
state-of-the-art models have an outstanding ability to capture biases contained
in the dataset with high accuracy on EASY set. However, they struggle on HARD
set with poor performance near that of random guess, indicating more research
is needed to essentially enhance the logical reasoning ability of current
models.
</summary>
    <author>
      <name>Weihao Yu</name>
    </author>
    <author>
      <name>Zihang Jiang</name>
    </author>
    <author>
      <name>Yanfei Dong</name>
    </author>
    <author>
      <name>Jiashi Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04306v1</id>
    <updated>2020-02-11T10:56:42Z</updated>
    <published>2020-02-11T10:56:42Z</published>
    <title>Learning Coupled Policies for Simultaneous Machine Translation</title>
    <summary>  In simultaneous machine translation, the system needs to incrementally
generate the output translation before the input sentence ends. This is a
coupled decision process consisting of a programmer and interpreter. The
programmer's policy decides about when to WRITE the next output or READ the
next input, and the interpreter's policy decides what word to write. We present
an imitation learning (IL) approach to efficiently learn effective coupled
programmer-interpreter policies. To enable IL, we present an algorithmic oracle
to produce oracle READ/WRITE actions for training bilingual sentence-pairs
using the notion of word alignments. We attribute the effectiveness of the
learned coupled policies to (i) scheduled sampling addressing the coupled
exposure bias, and (ii) quality of oracle actions capturing enough information
from the partial input before writing the output. Experiments show our method
outperforms strong baselines in terms of translation quality and delay, when
translating from German/Arabic/Czech/Bulgarian/Romanian to English.
</summary>
    <author>
      <name>Philip Arthur</name>
    </author>
    <author>
      <name>Trevor Cohn</name>
    </author>
    <author>
      <name>Gholamreza Haffari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.04306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.04108v2</id>
    <updated>2020-02-20T05:37:37Z</updated>
    <published>2020-02-10T21:59:21Z</published>
    <title>Adversarial Filters of Dataset Biases</title>
    <summary>  Large neural models have demonstrated human-level performance on language and
vision benchmarks such as ImageNet and Stanford Natural Language Inference
(SNLI). Yet, their performance degrades considerably when tested on adversarial
or out-of-distribution samples. This raises the question of whether these
models have learned to solve a dataset rather than the underlying task by
overfitting on spurious dataset biases. We investigate one recently proposed
approach, AFLite, which adversarially filters such dataset biases, as a means
to mitigate the prevalent overestimation of machine performance. We provide a
theoretical understanding for AFLite, by situating it in the generalized
framework for optimum bias reduction. Our experiments show that as a result of
the substantial reduction of these biases, models trained on the filtered
datasets yield better generalization to out-of-distribution tasks, especially
when the benchmarks used for training are over-populated with biased samples.
We show that AFLite is broadly applicable to a variety of both real and
synthetic datasets for reduction of measurable dataset biases and provide
extensive supporting analyses. Finally, filtering results in a large drop in
model performance (e.g., from 92% to 63% for SNLI), while human performance
still remains high. Our work thus shows that such filtered datasets can pose
new research challenges for robust generalization by serving as upgraded
benchmarks.
</summary>
    <author>
      <name>Ronan Le Bras</name>
    </author>
    <author>
      <name>Swabha Swayamdipta</name>
    </author>
    <author>
      <name>Chandra Bhagavatula</name>
    </author>
    <author>
      <name>Rowan Zellers</name>
    </author>
    <author>
      <name>Matthew E. Peters</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04108v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04108v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03531v1</id>
    <updated>2020-02-10T04:00:07Z</updated>
    <published>2020-02-10T04:00:07Z</published>
    <title>A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly
  Articles</title>
    <summary>  Thomas Kuhn proposed his paradigmatic view of scientific discovery five
decades ago. The concept of paradigm has not only explained the progress of
science, but has also become the central epistemic concept among STM
scientists. Here, we adopt the principles of Kuhnian philosophy to construct a
novel ontology aims at classifying and evaluating the impact of STM scholarly
articles. First, we explain how the Kuhnian cycle of science describes research
at different epistemic stages. Second, we show how the Kuhnian cycle could be
reconstructed into modular ontologies which classify scholarly articles
according to their contribution to paradigm-centred knowledge. The proposed
ontology and its scenarios are discussed. To the best of the authors knowledge,
this is the first attempt for creating an ontology for describing scholarly
articles based on the Kuhnian paradigmatic view of science.
</summary>
    <author>
      <name>Khalid M. Saqr</name>
    </author>
    <author>
      <name>Abdelrahman Elsharawy</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03056v1</id>
    <updated>2020-02-08T00:42:21Z</updated>
    <published>2020-02-08T00:42:21Z</published>
    <title>autoNLP: NLP Feature Recommendations for Text Analytics Applications</title>
    <summary>  While designing machine learning based text analytics applications, often,
NLP data scientists manually determine which NLP features to use based upon
their knowledge and experience with related problems. This results in increased
efforts during feature engineering process and renders automated reuse of
features across semantically related applications inherently difficult. In this
paper, we argue for standardization in feature specification by outlining
structure of a language for specifying NLP features and present an approach for
their reuse across applications to increase likelihood of identifying optimal
features.
</summary>
    <author>
      <name>Janardan Misra</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02878v2</id>
    <updated>2020-02-10T20:45:20Z</updated>
    <published>2020-02-07T16:22:36Z</published>
    <title>I love your chain mail! Making knights smile in a fantasy game world:
  Open-domain goal-oriented dialogue agents</title>
    <summary>  Dialogue research tends to distinguish between chit-chat and goal-oriented
tasks. While the former is arguably more naturalistic and has a wider use of
language, the latter has clearer metrics and a straightforward learning signal.
Humans effortlessly combine the two, for example engaging in chit-chat with the
goal of exchanging information or eliciting a specific response. Here, we
bridge the divide between these two domains in the setting of a rich
multi-player text-based fantasy environment where agents and humans engage in
both actions and dialogue. Specifically, we train a goal-oriented model with
reinforcement learning against an imitation-learned ``chit-chat'' model with
two approaches: the policy either learns to pick a topic or learns to pick an
utterance given the top-K utterances from the chit-chat model. We show that
both models outperform an inverse model baseline and can converse naturally
with their dialogue partner in order to achieve goals.
</summary>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <author>
      <name>Margaret Li</name>
    </author>
    <author>
      <name>Jack Urbanek</name>
    </author>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02878v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02878v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02631v1</id>
    <updated>2020-02-07T05:52:06Z</updated>
    <published>2020-02-07T05:52:06Z</published>
    <title>Translating Web Search Queries into Natural Language Questions</title>
    <summary>  Users often query a search engine with a specific question in mind and often
these queries are keywords or sub-sentential fragments. For example, if the
users want to know the answer for "What's the capital of USA", they will most
probably query "capital of USA" or "USA capital" or some keyword-based
variation of this. For example, for the user entered query "capital of USA",
the most probable question intent is "What's the capital of USA?". In this
paper, we are proposing a method to generate well-formed natural language
question from a given keyword-based query, which has the same question intent
as the query. Conversion of keyword-based web query into a well-formed question
has lots of applications, with some of them being in search engines, Community
Question Answering (CQA) website and bots communication. We found a synergy
between query-to-question problem with standard machine translation(MT) task.
We have used both Statistical MT (SMT) and Neural MT (NMT) models to generate
the questions from the query. We have observed that MT models perform well in
terms of both automatic and human evaluation.
</summary>
    <author>
      <name>Adarsh Kumar</name>
    </author>
    <author>
      <name>Sandipan Dandapat</name>
    </author>
    <author>
      <name>Sushil Chordia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Eleventh International Conference on Language Resources and
  Evaluation, LREC 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08898v1</id>
    <updated>2020-02-07T05:34:58Z</updated>
    <published>2020-02-07T05:34:58Z</published>
    <title>MA-DST: Multi-Attention Based Scalable Dialog State Tracking</title>
    <summary>  Task oriented dialog agents provide a natural language interface for users to
complete their goal. Dialog State Tracking (DST), which is often a core
component of these systems, tracks the system's understanding of the user's
goal throughout the conversation. To enable accurate multi-domain DST, the
model needs to encode dependencies between past utterances and slot semantics
and understand the dialog context, including long-range cross-domain
references. We introduce a novel architecture for this task to encode the
conversation history and slot semantics more robustly by using attention
mechanisms at multiple granularities. In particular, we use cross-attention to
model relationships between the context and slots at different semantic levels
and self-attention to resolve cross-domain coreferences. In addition, our
proposed architecture does not rely on knowing the domain ontologies beforehand
and can also be used in a zero-shot setting for new domains or unseen slot
values. Our model improves the joint goal accuracy by 5% (absolute) in the
full-data setting and by up to 2% (absolute) in the zero-shot setting over the
present state-of-the-art on the MultiWoZ 2.1 dataset.
</summary>
    <author>
      <name>Adarsh Kumar</name>
    </author>
    <author>
      <name>Peter Ku</name>
    </author>
    <author>
      <name>Anuj Kumar Goyal</name>
    </author>
    <author>
      <name>Angeliki Metallinou</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02511v1</id>
    <updated>2020-02-06T20:44:12Z</updated>
    <published>2020-02-06T20:44:12Z</published>
    <title>Introducing Aspects of Creativity in Automatic Poetry Generation</title>
    <summary>  Poetry Generation involves teaching systems to automatically generate text
that resembles poetic work. A deep learning system can learn to generate poetry
on its own by training on a corpus of poems and modeling the particular style
of language. In this paper, we propose taking an approach that fine-tunes
GPT-2, a pre-trained language model, to our downstream task of poetry
generation. We extend prior work on poetry generation by introducing creative
elements. Specifically, we generate poems that express emotion and elicit the
same in readers, and poems that use the language of dreams---called dream
poetry. We are able to produce poems that correctly elicit the emotions of
sadness and joy 87.5 and 85 percent, respectively, of the time. We produce
dreamlike poetry by training on a corpus of texts that describe dreams. Poems
from this model are shown to capture elements of dream poetry with scores of no
less than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for
all our poems. We also make use of the Coh-Metrix tool, outlining metrics we
use to gauge the quality of text generated.
</summary>
    <author>
      <name>Brendan Bena</name>
    </author>
    <author>
      <name>Jugal Kalita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures, 4 tables, ICON-2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02427v1</id>
    <updated>2020-02-06T18:23:27Z</updated>
    <published>2020-02-06T18:23:27Z</published>
    <title>Irony Detection in a Multilingual Context</title>
    <summary>  This paper proposes the first multilingual (French, English and Arabic) and
multicultural (Indo-European languages vs. less culturally close languages)
irony detection system. We employ both feature-based models and neural
architectures using monolingual word representation. We compare the performance
of these systems with state-of-the-art systems to identify their capabilities.
We show that these monolingual models trained separately on different languages
using multilingual word representation or text-based features can open the door
to irony detection in languages that lack of annotated data for irony.
</summary>
    <author>
      <name>Bilal Ghanem</name>
    </author>
    <author>
      <name>Jihen Karoui</name>
    </author>
    <author>
      <name>Farah Benamara</name>
    </author>
    <author>
      <name>Paolo Rosso</name>
    </author>
    <author>
      <name>Véronique Moriceau</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02406v1</id>
    <updated>2020-02-06T17:40:01Z</updated>
    <published>2020-02-06T17:40:01Z</published>
    <title>Message Passing for Query Answering over Knowledge Graphs</title>
    <summary>  Logic-based systems for query answering over knowledge graphs return only
answers that rely on information explicitly represented in the graph. To
improve recall, recent works have proposed the use of embeddings to predict
additional information like missing links, or labels. These embeddings enable
scoring entities in the graph as the answer a query, without being fully
dependent on the graph structure. In its simplest case, answering a query in
such a setting requires predicting a link between two entities. However, link
prediction is not sufficient to address complex queries that involve multiple
entities and variables. To solve this task, we propose to apply a message
passing mechanism to a graph representation of the query, where nodes
correspond to variables and entities. This results in an embedding of the
query, such that answering entities are close to it in the embedding space. The
general formulation of our method allows it to encode a more diverse set of
query types in comparison to previous work. We evaluate our method by answering
queries that rely on edges not seen during training, obtaining competitive
performance. In contrast with previous work, we show that our method can
generalize from training for the single-hop, link prediction task, to answering
queries with more complex structures. A qualitative analysis reveals that the
learned embeddings successfully capture the notion of different entity types.
</summary>
    <author>
      <name>Daniel Daza</name>
    </author>
    <author>
      <name>Michael Cochez</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02238v1</id>
    <updated>2020-02-06T13:11:46Z</updated>
    <published>2020-02-06T13:11:46Z</published>
    <title>Towards Semantic Noise Cleansing of Categorical Data based on Semantic
  Infusion</title>
    <summary>  Semantic Noise affects text analytics activities for the domain-specific
industries significantly. It impedes the text understanding which holds prime
importance in the critical decision making tasks. In this work, we formalize
semantic noise as a sequence of terms that do not contribute to the narrative
of the text. We look beyond the notion of standard statistically-based stop
words and consider the semantics of terms to exclude the semantic noise. We
present a novel Semantic Infusion technique to associate meta-data with the
categorical corpus text and demonstrate its near-lossless nature. Based on this
technique, we propose an unsupervised text-preprocessing framework to filter
the semantic noise using the context of the terms. Later we present the
evaluation results of the proposed framework using a web forum dataset from the
automobile-domain.
</summary>
    <author>
      <name>Rishabh Gupta</name>
    </author>
    <author>
      <name>Rajesh N Rao</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02153v1</id>
    <updated>2020-02-06T08:24:33Z</updated>
    <published>2020-02-06T08:24:33Z</published>
    <title>A Neural Topical Expansion Framework for Unstructured Persona-oriented
  Dialogue Generation</title>
    <summary>  Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated
effective in generating persona consistent responses by utilizing predefined
natural language user persona descriptions (e.g., "I am a vegan"). However, the
predefined user persona descriptions are usually short and limited to only a
few descriptive words, which makes it hard to correlate them with the
dialogues. As a result, existing methods either fail to use the persona
description or use them improperly when generating persona consistent
responses. To address this, we propose a neural topical expansion framework,
namely Persona Exploration and Exploitation (PEE), which is able to extend the
predefined user persona description with semantically correlated content before
utilizing them to generate dialogue responses. PEE consists of two main
modules: persona exploration and persona exploitation. The former learns to
extend the predefined user persona description by mining and correlating with
existing dialogue corpus using a variational auto-encoder (VAE) based topic
model. The latter learns to generate persona consistent responses by utilizing
the predefined and extended user persona description. In order to make persona
exploitation learn to utilize user persona description more properly, we also
introduce two persona-oriented loss functions: Persona-oriented Matching
(P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which
respectively supervise persona selection in encoder and decoder. Experimental
results show that our approach outperforms state-of-the-art baselines, in terms
of both automatic and human evaluations.
</summary>
    <author>
      <name>Minghong Xu</name>
    </author>
    <author>
      <name>Piji Li</name>
    </author>
    <author>
      <name>Haoran Yang</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Zhaochun Ren</name>
    </author>
    <author>
      <name>Zhumin Chen</name>
    </author>
    <author>
      <name>Jun Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ECAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.02153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02031v1</id>
    <updated>2020-02-05T22:56:11Z</updated>
    <published>2020-02-05T22:56:11Z</published>
    <title>Stimulating Creativity with FunLines: A Case Study of Humor Generation
  in Headlines</title>
    <summary>  Building datasets of creative text, such as humor, is quite challenging. We
introduce FunLines, a competitive game where players edit news headlines to
make them funny, and where they rate the funniness of headlines edited by
others. FunLines makes the humor generation process fun, interactive,
collaborative, rewarding and educational, keeping players engaged and providing
humor data at a very low cost compared to traditional crowdsourcing approaches.
FunLines offers useful performance feedback, assisting players in getting
better over time at generating and assessing humor, as our analysis shows. This
helps to further increase the quality of the generated dataset. We show the
effectiveness of this data by training humor classification models that
outperform a previous benchmark, and we release this dataset to the public.
</summary>
    <author>
      <name>Nabil Hossain</name>
    </author>
    <author>
      <name>John Krumm</name>
    </author>
    <author>
      <name>Tanvir Sajed</name>
    </author>
    <author>
      <name>Henry Kautz</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01862v1</id>
    <updated>2020-02-05T16:52:52Z</updated>
    <published>2020-02-05T16:52:52Z</published>
    <title>If I Hear You Correctly: Building and Evaluating Interview Chatbots with
  Active Listening Skills</title>
    <summary>  Interview chatbots engage users in a text-based conversation to draw out
their views and opinions. It is, however, challenging to build effective
interview chatbots that can handle user free-text responses to open-ended
questions and deliver engaging user experience. As the first step, we are
investigating the feasibility and effectiveness of using publicly available,
practical AI technologies to build effective interview chatbots. To demonstrate
feasibility, we built a prototype scoped to enable interview chatbots with a
subset of active listening skills - the abilities to comprehend a user's input
and respond properly. To evaluate the effectiveness of our prototype, we
compared the performance of interview chatbots with or without active listening
skills on four common interview topics in a live evaluation with 206 users. Our
work presents practical design implications for building effective interview
chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview
tasks.
</summary>
    <author>
      <name>Ziang Xiao</name>
    </author>
    <author>
      <name>Michelle X. Zhou</name>
    </author>
    <author>
      <name>Wenxi Chen</name>
    </author>
    <author>
      <name>Huahai Yang</name>
    </author>
    <author>
      <name>Changyan Chi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3313831.3376131</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3313831.3376131" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working draft. To appear in the ACM CHI Conference on Human Factors
  in Computing Systems (CHI 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01761v1</id>
    <updated>2020-02-05T12:44:01Z</updated>
    <published>2020-02-05T12:44:01Z</published>
    <title>Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and
  Manual Correction</title>
    <summary>  Princeton WordNet (PWN) is a lexicon-semantic network based on cognitive
linguistics, which promotes the development of natural language processing.
Based on PWN, five Chinese wordnets have been developed to solve the problems
of syntax and semantics. They include: Northeastern University Chinese WordNet
(NEW), Sinica Bilingual Ontological WordNet (BOW), Southeast University Chinese
WordNet (SEW), Taiwan University Chinese WordNet (CWN), Chinese Open WordNet
(COW). By using them, we found that these word networks have low accuracy and
coverage, and cannot completely portray the semantic network of PWN. So we
decided to make a new Chinese wordnet called Multi-Fusion Chinese Wordnet (MCW)
to make up those shortcomings. The key idea is to extend the SEW with the help
of Oxford bilingual dictionary and Xinhua bilingual dictionary, and then
correct it. More specifically, we used machine learning and manual adjustment
in our corrections. Two standards were formulated to help our work. We
conducted experiments on three tasks including relatedness calculation, word
similarity and word sense disambiguation for the comparison of lemma's
accuracy, at the same time, coverage also was compared. The results indicate
that MCW can benefit from coverage and accuracy via our method. However, it
still has room for improvement, especially with lemmas. In the future, we will
continue to enhance the accuracy of MCW and expand the concepts in it.
</summary>
    <author>
      <name>Mingchen Li</name>
    </author>
    <author>
      <name>Zili Zhou</name>
    </author>
    <author>
      <name>Yanna Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. CICLing 2019: International Conference on Computational
  Linguistics and Intelligent Text Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01464v1</id>
    <updated>2020-02-04T18:42:30Z</updated>
    <published>2020-02-04T18:42:30Z</published>
    <title>Visual Concept-Metaconcept Learning</title>
    <summary>  Humans reason with concepts and metaconcepts: we recognize red and green from
visual input; we also understand that they describe the same property of
objects (i.e., the color). In this paper, we propose the visual
concept-metaconcept learner (VCML) for joint learning of concepts and
metaconcepts from images and associated question-answer pairs. The key is to
exploit the bidirectional connection between visual concepts and metaconcepts.
Visual representations provide grounding cues for predicting relations between
unseen pairs of concepts. Knowing that red and green describe the same property
of objects, we generalize to the fact that cube and sphere also describe the
same property of objects, since they both categorize the shape of objects.
Meanwhile, knowledge about metaconcepts empowers visual concept learning from
limited, noisy, and even biased data. From just a few examples of purple cubes
we can understand a new color purple, which resembles the hue of the cubes
instead of the shape of them. Evaluation on both synthetic and real-world
datasets validates our claims.
</summary>
    <author>
      <name>Chi Han</name>
    </author>
    <author>
      <name>Jiayuan Mao</name>
    </author>
    <author>
      <name>Chuang Gan</name>
    </author>
    <author>
      <name>Joshua B. Tenenbaum</name>
    </author>
    <author>
      <name>Jiajun Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019. First two authors contributed equally. Project page:
  http://vcml.csail.mit.edu/</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01365v2</id>
    <updated>2020-02-17T11:22:04Z</updated>
    <published>2020-02-04T15:19:09Z</published>
    <title>Compositional Languages Emerge in a Neural Iterated Learning Model</title>
    <summary>  The principle of compositionality, which enables natural language to
represent complex concepts via a structured combination of simpler ones, allows
us to convey an open-ended set of messages using a limited vocabulary. If
compositionality is indeed a natural property of language, we may expect it to
appear in communication protocols that are created by neural agents in language
games. In this paper, we propose an effective neural iterated learning (NIL)
algorithm that, when applied to interacting neural agents, facilitates the
emergence of a more structured type of language. Indeed, these languages
provide learning speed advantages to neural agents during training, which can
be incrementally amplified via NIL. We provide a probabilistic model of NIL and
an explanation of why the advantage of compositional language exist. Our
experiments confirm our analysis, and also demonstrate that the emerged
languages largely improve the generalizing power of the neural agent
communication.
</summary>
    <author>
      <name>Yi Ren</name>
    </author>
    <author>
      <name>Shangmin Guo</name>
    </author>
    <author>
      <name>Matthieu Labeau</name>
    </author>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <author>
      <name>Simon Kirby</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by ICLR-2020</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR-2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.01365v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01365v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01335v1</id>
    <updated>2020-02-04T14:59:08Z</updated>
    <published>2020-02-04T14:59:08Z</published>
    <title>Exploring Structural Inductive Biases in Emergent Communication</title>
    <summary>  Human language and thought are characterized by the ability to systematically
generate a potentially infinite number of complex structures (e.g., sentences)
from a finite set of familiar components (e.g., words). Recent works in
emergent communication have discussed the propensity of artificial agents to
develop a systematically compositional language through playing co-operative
referential games. The degree of structure in the input data was found to
affect the compositionality of the emerged communication protocols. Thus, we
explore various structural priors in multi-agent communication and propose a
novel graph referential game. We compare the effect of structural inductive
bias (bag-of-words, sequences and graphs) on the emergence of compositional
understanding of the input concepts measured by topographic similarity and
generalization to unseen combinations of familiar properties. We empirically
show that graph neural networks induce a better compositional language prior
and a stronger generalization to out-of-domain data. We further perform
ablation studies that show the robustness of the emerged protocol in graph
referential games.
</summary>
    <author>
      <name>Agnieszka Słowik</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>William L. Hamilton</name>
    </author>
    <author>
      <name>Mateja Jamnik</name>
    </author>
    <author>
      <name>Sean B. Holden</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01093v1</id>
    <updated>2020-02-04T02:35:19Z</updated>
    <published>2020-02-04T02:35:19Z</published>
    <title>On the interaction between supervision and self-play in emergent
  communication</title>
    <summary>  A promising approach for teaching artificial agents to use natural language
involves using human-in-the-loop training. However, recent work suggests that
current machine learning methods are too data inefficient to be trained in this
way from scratch. In this paper, we investigate the relationship between two
categories of learning signals with the ultimate goal of improving sample
efficiency: imitating human language data via supervised learning, and
maximizing reward in a simulated multi-agent environment via self-play (as done
in emergent communication), and introduce the term supervised self-play (S2P)
for algorithms using both of these signals. We find that first training agents
via supervised learning on human data followed by self-play outperforms the
converse, suggesting that it is not beneficial to emerge languages from
scratch. We then empirically investigate various S2P schedules that begin with
supervised learning in two environments: a Lewis signaling game with symbolic
inputs, and an image-based referential game with natural language descriptions.
Lastly, we introduce population based approaches to S2P, which further improves
the performance over single-agent methods.
</summary>
    <author>
      <name>Ryan Lowe</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Joelle Pineau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally. Accepted at ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01065v1</id>
    <updated>2020-02-04T00:28:38Z</updated>
    <published>2020-02-04T00:28:38Z</published>
    <title>Fake News Detection by means of Uncertainty Weighted Causal Graphs</title>
    <summary>  Society is experimenting changes in information consumption, as new
information channels such as social networks let people share news that do not
necessarily be trust worthy. Sometimes, these sources of information produce
fake news deliberately with doubtful purposes and the consumers of that
information share it to other users thinking that the information is accurate.
This transmission of information represents an issue in our society, as can
influence negatively the opinion of people about certain figures, groups or
ideas. Hence, it is desirable to design a system that is able to detect and
classify information as fake and categorize a source of information as trust
worthy or not. Current systems experiment difficulties performing this task, as
it is complicated to design an automatic procedure that can classify this
information independent on the context. In this work, we propose a mechanism to
detect fake news through a classifier based on weighted causal graphs. These
graphs are specific hybrid models that are built through causal relations
retrieved from texts and consider the uncertainty of causal relations. We take
advantage of this representation to use the probability distributions of this
graph and built a fake news classifier based on the entropy and KL divergence
of learned and new information. We believe that the problem of fake news is
accurately tackled by this model due to its hybrid nature between a symbolic
and quantitative methodology. We describe the methodology of this classifier
and add empirical evidence of the usefulness of our proposed approach in the
form of synthetic experiments and a real experiment involving lung cancer.
</summary>
    <author>
      <name>Eduardo C. Garrido-Merchán</name>
    </author>
    <author>
      <name>Cristina Puente</name>
    </author>
    <author>
      <name>Rafael Palacios</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00652v1</id>
    <updated>2020-02-03T11:28:10Z</updated>
    <published>2020-02-03T11:28:10Z</published>
    <title>How Far are We from Effective Context Modeling ? An Exploratory Study on
  Semantic Parsing in Context</title>
    <summary>  Recently semantic parsing in context has received a considerable attention,
which is challenging since there are complex contextual phenomena. Previous
works verified their proposed methods in limited scenarios, which motivates us
to conduct an exploratory study on context modeling methods under real-world
semantic parsing in context. We present a grammar-based decoding semantic
parser and adapt typical context modeling methods on top of it. We evaluate 13
context modeling methods on two large complex cross-domain datasets, and our
best model achieves state-of-the-art performances on both datasets with
significant improvements. Furthermore, we summarize the most frequent
contextual phenomena, with a fine-grained analysis on representative models,
which may shed light on potential research directions.
</summary>
    <author>
      <name>Qian Liu</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Jiaqi Guo</name>
    </author>
    <author>
      <name>Jian-Guang Lou</name>
    </author>
    <author>
      <name>Bin Zhou</name>
    </author>
    <author>
      <name>Dongmei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00557v1</id>
    <updated>2020-02-03T04:52:47Z</updated>
    <published>2020-02-03T04:52:47Z</published>
    <title>Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker</title>
    <summary>  To access data stored in relational databases, users need to understand the
database schema and write a query using a query language such as SQL. To
simplify this task, text-to-SQL models attempt to translate a user's natural
language question to corresponding SQL query. Recently, several generative
text-to-SQL models have been developed. We propose a novel discriminative
re-ranker to improve the performance of generative text-to-SQL models by
extracting the best SQL query from the beam output predicted by the text-to-SQL
generator, resulting in improved performance in the cases where the best query
was in the candidate list, but not at the top of the list. We build the
re-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative
strengths of the text-to-SQL and re-ranker models across different query
hardness levels, and suggest how to combine the two models for optimal
performance. We demonstrate the effectiveness of the re-ranker by applying it
to two state-of-the-art text-to-SQL models, and achieve top 4 score on the
Spider leaderboard at the time of writing this article.
</summary>
    <author>
      <name>Amol Kelkar</name>
    </author>
    <author>
      <name>Rohan Relan</name>
    </author>
    <author>
      <name>Vaishali Bhardwaj</name>
    </author>
    <author>
      <name>Saurabh Vaichal</name>
    </author>
    <author>
      <name>Peter Relan</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00388v1</id>
    <updated>2020-02-02T13:17:31Z</updated>
    <published>2020-02-02T13:17:31Z</published>
    <title>A Survey on Knowledge Graphs: Representation, Acquisition and
  Applications</title>
    <summary>  Human knowledge provides a formal understanding of the world. Knowledge
graphs that represent structural relations between entities have become an
increasingly popular research direction towards cognition and human-level
intelligence. In this survey, we provide a comprehensive review on knowledge
graph covering overall research topics about 1) knowledge graph representation
learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph,
and 4) knowledge-aware applications, and summarize recent breakthroughs and
perspective directions to facilitate future research. We propose a full-view
categorization and new taxonomies on these topics. Knowledge graph embedding is
organized from four aspects of representation space, scoring function, encoding
models and auxiliary information. For knowledge acquisition, especially
knowledge graph completion, embedding methods, path inference and logical rule
reasoning are reviewed. We further explore several emerging topics including
meta relational learning, commonsense reasoning, and temporal knowledge graphs.
To facilitate future research on knowledge graphs, we also provide a curated
collection of datasets and open-source libraries on different tasks. In the
end, we have a thorough outlook on several promising research directions.
</summary>
    <author>
      <name>Shaoxiong Ji</name>
    </author>
    <author>
      <name>Shirui Pan</name>
    </author>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Pekka Marttinen</name>
    </author>
    <author>
      <name>Philip S. Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 10 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01071v1</id>
    <updated>2020-02-01T09:18:56Z</updated>
    <published>2020-02-01T09:18:56Z</published>
    <title>Concept Embedding for Information Retrieval</title>
    <summary>  Concepts are used to solve the term-mismatch problem. However, we need an
effective similarity measure between concepts. Word embedding presents a
promising solution. We present in this study three approaches to build concepts
vectors based on words vectors. We use a vector-based measure to estimate
inter-concepts similarity. Our experiments show promising results. Furthermore,
words and concepts become comparable. This could be used to improve conceptual
indexing process.
</summary>
    <author>
      <name>Karam Abdulahhad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-76941-7_45</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-76941-7_45" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68-XX, 68Pxx, 68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11985v1</id>
    <updated>2020-01-31T18:14:17Z</updated>
    <published>2020-01-31T18:14:17Z</published>
    <title>Pretrained Transformers for Simple Question Answering over Knowledge
  Graphs</title>
    <summary>  Answering simple questions over knowledge graphs is a well-studied problem in
question answering. Previous approaches for this task built on recurrent and
convolutional neural network based architectures that use pretrained word
embeddings. It was recently shown that finetuning pretrained transformer
networks (e.g. BERT) can outperform previous approaches on various natural
language processing tasks. In this work, we investigate how well BERT performs
on SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based
models in datasparse scenarios.
</summary>
    <author>
      <name>D. Lukovnikov</name>
    </author>
    <author>
      <name>A. Fischer</name>
    </author>
    <author>
      <name>J. Lehmann</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11673v1</id>
    <updated>2020-01-31T06:31:39Z</updated>
    <published>2020-01-31T06:31:39Z</published>
    <title>Augmenting Visual Question Answering with Semantic Frame Information in
  a Multitask Learning Approach</title>
    <summary>  Visual Question Answering (VQA) concerns providing answers to Natural
Language questions about images. Several deep neural network approaches have
been proposed to model the task in an end-to-end fashion. Whereas the task is
grounded in visual processing, if the question focuses on events described by
verbs, the language understanding component becomes crucial. Our hypothesis is
that models should be aware of verb semantics, as expressed via semantic role
labels, argument types, and/or frame elements. Unfortunately, no VQA dataset
exists that includes verb semantic information. Our first contribution is a new
VQA dataset (imSituVQA) that we built by taking advantage of the imSitu
annotations. The imSitu dataset consists of images manually labeled with
semantic frame elements, mostly taken from FrameNet. Second, we propose a
multitask CNN-LSTM VQA model that learns to classify the answers as well as the
semantic frame elements. Our experiments show that semantic frame element
classification helps the VQA system avoid inconsistent responses and improves
performance.
</summary>
    <author>
      <name>Mehrdad Alizadeh</name>
    </author>
    <author>
      <name>Barbara Di Eugenio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14th IEEE International Conference on SEMANTIC COMPUTING, 8 Pages,
  February 2020, San Diego CA USA</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00737v1</id>
    <updated>2020-01-30T11:06:49Z</updated>
    <published>2020-01-30T11:06:49Z</published>
    <title>Are Pre-trained Language Models Aware of Phrases? Simple but Strong
  Baselines for Grammar Induction</title>
    <summary>  With the recent success and popularity of pre-trained language models (LMs)
in natural language processing, there has been a rise in efforts to understand
their inner workings. In line with such interest, we propose a novel method
that assists us in investigating the extent to which pre-trained LMs capture
the syntactic notion of constituency. Our method provides an effective way of
extracting constituency trees from the pre-trained LMs without training. In
addition, we report intriguing findings in the induced trees, including the
fact that pre-trained LMs outperform other approaches in correctly demarcating
adverb phrases in sentences.
</summary>
    <author>
      <name>Taeuk Kim</name>
    </author>
    <author>
      <name>Jihun Choi</name>
    </author>
    <author>
      <name>Daniel Edmiston</name>
    </author>
    <author>
      <name>Sang-goo Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11224v1</id>
    <updated>2020-01-30T09:17:32Z</updated>
    <published>2020-01-30T09:17:32Z</published>
    <title>Introducing the diagrammatic mode</title>
    <summary>  In this article, we propose a multimodal perspective to diagrammatic
representations by sketching a description of what may be tentatively termed
the diagrammatic mode. We consider diagrammatic representations in the light of
contemporary multimodality theory and explicate what enables diagrammatic
representations to integrate natural language, various forms of graphics,
diagrammatic elements such as arrows, lines and other expressive resources into
coherent organisations. We illustrate the proposed approach using two recent
diagram corpora and show how a multimodal approach supports the empirical
analysis of diagrammatic representations, especially in identifying
diagrammatic constituents and describing their interrelations.
</summary>
    <author>
      <name>Tuomo Hiippala</name>
    </author>
    <author>
      <name>John A. Bateman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages; submitted to Diagrams 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.11224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10929v1</id>
    <updated>2020-01-29T16:19:44Z</updated>
    <published>2020-01-29T16:19:44Z</published>
    <title>AMR Similarity Metrics from Principles</title>
    <summary>  Different metrics have been proposed to compare Abstract Meaning
Representation (AMR) graphs. The canonical Smatch metric (Cai and Knight, 2013)
aligns variables from one graph to another and compares the matching triples.
The recently released SemBleu metric (Song and Gildea, 2019) is based on the
machine-translation metric Bleu (Papineni et al., 2002), increasing
computational efficiency by ablating a variable-alignment step and aiming at
capturing more global graph properties.
  Our aims are threefold: i) we establish criteria that allow us to perform a
principled comparison between metrics of symbolic meaning representations like
AMR; ii) we undertake a thorough analysis of Smatch and SemBleu where we show
that the latter exhibits some undesirable properties. E.g., it violates the
identity of indiscernibles rule and introduces biases that are hard to control;
iii) we propose a novel metric S2match that is more benevolent to only very
slight meaning deviations and targets the fulfilment of all established
criteria. We assess its suitability and show its advantages over Smatch and
SemBleu.
</summary>
    <author>
      <name>Juri Opitz</name>
    </author>
    <author>
      <name>Letitia Parcalabescu</name>
    </author>
    <author>
      <name>Anette Frank</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 10 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00744v1</id>
    <updated>2020-01-28T16:42:40Z</updated>
    <published>2020-01-28T16:42:40Z</published>
    <title>PEL-BERT: A Joint Model for Protocol Entity Linking</title>
    <summary>  Pre-trained models such as BERT are widely used in NLP tasks and are
fine-tuned to improve the performance of various NLP tasks consistently.
Nevertheless, the fine-tuned BERT model trained on our protocol corpus still
has a weak performance on the Entity Linking (EL) task. In this paper, we
propose a model that joints a fine-tuned language model with an RFC Domain
Model. Firstly, we design a Protocol Knowledge Base as the guideline for
protocol EL. Secondly, we propose a novel model, PEL-BERT, to link named
entities in protocols to categories in Protocol Knowledge Base. Finally, we
conduct a comprehensive study on the performance of pre-trained language models
on descriptive texts and abstract concepts. Experimental results demonstrate
that our model achieves state-of-the-art performance in EL on our annotated
dataset, outperforming all the baselines.
</summary>
    <author>
      <name>Shoubin Li</name>
    </author>
    <author>
      <name>Wenzao Cui</name>
    </author>
    <author>
      <name>Yujiang Liu</name>
    </author>
    <author>
      <name>Xuran Ming</name>
    </author>
    <author>
      <name>Jun Hu</name>
    </author>
    <author>
      <name> YuanzheHu</name>
    </author>
    <author>
      <name>Qing Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2002.00744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10161v1</id>
    <updated>2020-01-28T04:13:05Z</updated>
    <published>2020-01-28T04:13:05Z</published>
    <title>Bringing Stories Alive: Generating Interactive Fiction Worlds</title>
    <summary>  World building forms the foundation of any task that requires narrative
intelligence. In this work, we focus on procedurally generating interactive
fiction worlds---text-based worlds that players "see" and "talk to" using
natural language. Generating these worlds requires referencing everyday and
thematic commonsense priors in addition to being semantically consistent,
interesting, and coherent throughout. Using existing story plots as
inspiration, we present a method that first extracts a partial knowledge graph
encoding basic information regarding world structure such as locations and
objects. This knowledge graph is then automatically completed utilizing
thematic knowledge and used to guide a neural language generation model that
fleshes out the rest of the world. We perform human participant-based
evaluations, testing our neural model's ability to extract and fill-in a
knowledge graph and to generate language conditioned on it against rule-based
and human-made baselines. Our code is available at
https://github.com/rajammanabrolu/WorldGeneration.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Wesley Cheung</name>
    </author>
    <author>
      <name>Dan Tu</name>
    </author>
    <author>
      <name>William Broniec</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00747v1</id>
    <updated>2020-01-27T17:10:11Z</updated>
    <published>2020-01-27T17:10:11Z</published>
    <title>Conversations with Documents. An Exploration of Document-Centered
  Assistance</title>
    <summary>  The role of conversational assistants has become more prevalent in helping
people increase their productivity. Document-centered assistance, for example
to help an individual quickly review a document, has seen less significant
progress, even though it has the potential to tremendously increase a user's
productivity. This type of document-centered assistance is the focus of this
paper. Our contributions are three-fold: (1) We first present a survey to
understand the space of document-centered assistance and the capabilities
people expect in this scenario. (2) We investigate the types of queries that
users will pose while seeking assistance with documents, and show that
document-centered questions form the majority of these queries. (3) We present
a set of initial machine learned models that show that (a) we can accurately
detect document-centered questions, and (b) we can build reasonably accurate
models for answering such questions. These positive results are encouraging,
and suggest that even greater results may be attained with continued study of
this interesting and novel problem space. Our findings have implications for
the design of intelligent systems to support task completion via natural
interactions with documents.
</summary>
    <author>
      <name>Maartje ter Hoeve</name>
    </author>
    <author>
      <name>Robert Sim</name>
    </author>
    <author>
      <name>Elnaz Nouri</name>
    </author>
    <author>
      <name>Adam Fourney</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <author>
      <name>Ryen W. White</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3343413.3377971</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3343413.3377971" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as full paper at CHIIR 2020; 9 pages + Appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10617v1</id>
    <updated>2020-01-27T15:59:24Z</updated>
    <published>2020-01-27T15:59:24Z</published>
    <title>Systematic Review of Approaches to Improve Peer Assessment at Scale</title>
    <summary>  Peer Assessment is a task of analysis and commenting on student's writing by
peers, is core of all educational components both in campus and in MOOC's.
However, with the sheer scale of MOOC's &amp; its inherent personalised open ended
learning, automatic grading and tools assisting grading at scale is highly
important. Previously we presented survey on tasks of post classification,
knowledge tracing and ended with brief review on Peer Assessment (PA), with
some initial problems. In this review we shall continue review on PA from
perspective of improving the review process itself. As such rest of this review
focus on three facets of PA namely Auto grading and Peer Assessment Tools (we
shall look only on how peer reviews/auto-grading is carried), strategies to
handle Rogue Reviews, Peer Review Improvement using Natural Language
Processing. The consolidated set of papers and resources so used are released
in https://github.com/manikandan-ravikiran/cs6460-Survey-2.
</summary>
    <author>
      <name>Manikandan Ravikiran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a review assignment, work on progress. Expected to be updated
  regularly</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09830v1</id>
    <updated>2020-01-27T14:45:55Z</updated>
    <published>2020-01-27T14:45:55Z</published>
    <title>What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer
  Feedbacks? A Review</title>
    <summary>  Learning Management Systems (LMS) and Educational Data Mining (EDM) are two
important parts of online educational environment with the former being a
centralised web-based information systems where the learning content is managed
and learning activities are organised (Stone and Zheng,2014) and latter
focusing on using data mining techniques for the analysis of data so generated.
As part of this work, we present a literature review of three major tasks of
EDM (See section 2), by identifying shortcomings and existing open problems,
and a Blumenfield chart (See section 3). The consolidated set of papers and
resources so used are released in
https://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics
and review matrix of the survey are as shown in Figure 1 &amp; Table 1
respectively. Acronym expansions are added in the Appendix Section 4.1.
</summary>
    <author>
      <name>Manikandan Ravikiran</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09694v1</id>
    <updated>2020-01-27T11:14:34Z</updated>
    <published>2020-01-27T11:14:34Z</published>
    <title>Retrospective Reader for Machine Reading Comprehension</title>
    <summary>  Machine reading comprehension (MRC) is an AI challenge that requires machine
to determine the correct answers to questions based on a given passage. MRC
systems must not only answer question when necessary but also distinguish when
no answer is available according to the given passage and then tactfully
abstain from answering. When unanswerable questions are involved in the MRC
task, an essential verification module called verifier is especially required
in addition to the encoder, though the latest practice on MRC modeling still
most benefits from adopting well pre-trained language models as the encoder
block by only focusing on the "reading". This paper devotes itself to exploring
better verifier design for the MRC task with unanswerable questions. Inspired
by how humans solve reading comprehension questions, we proposed a
retrospective reader (Retro-Reader) that integrates two stages of reading and
verification strategies: 1) sketchy reading that briefly investigates the
overall interactions of passage and question, and yield an initial judgment; 2)
intensive reading that verifies the answer and gives the final prediction. The
proposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0
and NewsQA, achieving new state-of-the-art results. Significance tests show
that our model is significantly better than the strong ALBERT baseline. A
series of analysis is also conducted to interpret the effectiveness of the
proposed reader.
</summary>
    <author>
      <name>Zhuosheng Zhang</name>
    </author>
    <author>
      <name>Junjie Yang</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09522v1</id>
    <updated>2020-01-26T21:30:21Z</updated>
    <published>2020-01-26T21:30:21Z</published>
    <title>TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced
  Graph Neural Network</title>
    <summary>  Taxonomies consist of machine-interpretable semantics and provide valuable
knowledge for many web applications. For example, online retailers (e.g.,
Amazon and eBay) use taxonomies for product recommendation, and web search
engines (e.g., Google and Bing) leverage taxonomies to enhance query
understanding. Enormous efforts have been made on constructing taxonomies
either manually or semi-automatically. However, with the fast-growing volume of
web content, existing taxonomies will become outdated and fail to capture
emerging knowledge. Therefore, in many applications, dynamic expansions of an
existing taxonomy are in great demand. In this paper, we study how to expand an
existing taxonomy by adding a set of new concepts. We propose a novel
self-supervised framework, named TaxoExpan, which automatically generates a set
of &lt;query concept, anchor concept&gt; pairs from the existing taxonomy as training
data. Using such self-supervision data, TaxoExpan learns a model to predict
whether a query concept is the direct hyponym of an anchor concept. We develop
two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural
network that encodes the local structure of an anchor concept in the existing
taxonomy, and (2) a noise-robust training objective that enables the learned
model to be insensitive to the label noise in the self-supervision data.
Extensive experiments on three large-scale datasets from different domains
demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy
expansion.
</summary>
    <author>
      <name>Jiaming Shen</name>
    </author>
    <author>
      <name>Zhihong Shen</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Chi Wang</name>
    </author>
    <author>
      <name>Kuansan Wang</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3366423.3380132</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3366423.3380132" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WWW 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09386v3</id>
    <updated>2020-02-01T21:39:47Z</updated>
    <published>2020-01-26T02:08:22Z</published>
    <title>Generating Representative Headlines for News Stories</title>
    <summary>  Millions of news articles are published online every day, which can be
overwhelming for readers to follow. Grouping articles that are reporting the
same event into news stories is a common way of assisting readers in their news
consumption. However, it remains a challenging research problem to efficiently
and effectively generate a representative headline for each story. Automatic
summarization of a document set has been studied for decades, while few studies
have focused on generating representative headlines for a set of articles.
Unlike summaries, which aim to capture most information with least redundancy,
headlines aim to capture information jointly shared by the story articles in
short length, and exclude information that is too specific to each individual
article. In this work, we study the problem of generating representative
headlines for news stories. We develop a distant supervision approach to train
large-scale generation models without any human annotation. This approach
centers on two technical components. First, we propose a multi-level
pre-training framework that incorporates massive unlabeled corpus with
different quality-vs.-quantity balance at different levels. We show that models
trained within this framework outperform those trained with pure human curated
corpus. Second, we propose a novel self-voting-based article attention layer to
extract salient information shared by multiple articles. We show that models
that incorporate this layer are robust to potential noises in news stories and
outperform existing baselines with or without noises. We can further enhance
our model by incorporating human labels, and we show our distant supervision
approach significantly reduces the demand on labeled data.
</summary>
    <author>
      <name>Xiaotao Gu</name>
    </author>
    <author>
      <name>Yuning Mao</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <author>
      <name>Jialu Liu</name>
    </author>
    <author>
      <name>Hongkun Yu</name>
    </author>
    <author>
      <name>You Wu</name>
    </author>
    <author>
      <name>Cong Yu</name>
    </author>
    <author>
      <name>Daniel Finnie</name>
    </author>
    <author>
      <name>Jiaqi Zhai</name>
    </author>
    <author>
      <name>Nicholas Zukoski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WebConf 2020 (WWW 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09386v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09386v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00720v1</id>
    <updated>2020-01-25T15:52:29Z</updated>
    <published>2020-01-25T15:52:29Z</published>
    <title>Introduction of Quantification in Frame Semantics</title>
    <summary>  Feature Structures (FSs) are a widespread tool used for decompositional
frameworks of Attribute-Value associations. Even though they thrive in simple
systems, they lack a way of representing higher-order entities and relations.
This is however needed in Frame Semantics, where semantic dependencies should
be able to connect groups of individuals and their properties, especially to
model quantification. To answer this issue, this master report introduces
wrappings as a way to envelop a sub-FS and treat it as a node. Following the
work of [Kallmeyer, Osswald 2013], we extend its syntax, semantics and some
properties (translation to FOL, subsumption, unification). We can then expand
the proposed pipeline. Lexical minimal model sets are generated from formulas.
They unify by FS value equations obtained by LTAG parsing to an underspecified
sentence representation. The syntactic approach of quantifiers allows us to use
existing methods to produce any possible reading. Finally, we give a
transcription to type-logical formulas to interact with the context in the view
of dynamic semantics. Supported by ideas of Frame Types, this system provides a
workable and tractable tool for higher-order relations with FS.
</summary>
    <author>
      <name>Valentin D. Richard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master report</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03B65 (Primary) 03C30 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; F.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00733v1</id>
    <updated>2020-01-25T08:20:46Z</updated>
    <published>2020-01-25T08:20:46Z</published>
    <title>Generation-Distillation for Efficient Natural Language Understanding in
  Low-Data Settings</title>
    <summary>  Over the past year, the emergence of transfer learning with large-scale
language models (LM) has led to dramatic performance improvements across a
broad range of natural language understanding tasks. However, the size and
memory footprint of these large LMs makes them difficult to deploy in many
scenarios (e.g. on mobile phones). Recent research points to knowledge
distillation as a potential solution, showing that when training data for a
given task is abundant, it is possible to distill a large (teacher) LM into a
small task-specific (student) network with minimal loss of performance.
However, when such data is scarce, there remains a significant performance gap
between large pretrained LMs and smaller task-specific models, even when
training via distillation. In this paper, we bridge this gap with a novel
training approach, called generation-distillation, that leverages large
finetuned LMs in two ways: (1) to generate new (unlabeled) training examples,
and (2) to distill their knowledge into a small network using these examples.
Across three low-resource text classification datsets, we achieve comparable
performance to BERT while using 300x fewer parameters, and we outperform prior
approaches to distillation for text classification while using 3x fewer
parameters.
</summary>
    <author>
      <name>Luke Melas-Kyriazi</name>
    </author>
    <author>
      <name>George Han</name>
    </author>
    <author>
      <name>Celine Liang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 Workshop on Deep Learning for Low-resource NLP</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09063v2</id>
    <updated>2020-02-04T14:18:31Z</updated>
    <published>2020-01-24T15:55:59Z</published>
    <title>Towards Graph Representation Learning in Emergent Communication</title>
    <summary>  Recent findings in neuroscience suggest that the human brain represents
information in a geometric structure (for instance, through conceptual spaces).
In order to communicate, we flatten the complex representation of entities and
their attributes into a single word or a sentence. In this paper we use graph
convolutional networks to support the evolution of language and cooperation in
multi-agent systems. Motivated by an image-based referential game, we propose a
graph referential game with varying degrees of complexity, and we provide
strong baseline models that exhibit desirable properties in terms of language
emergence and cooperation. We show that the emerged communication protocol is
robust, that the agents uncover the true factors of variation in the game, and
that they learn to generalize beyond the samples encountered during training.
</summary>
    <author>
      <name>Agnieszka Słowik</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>William L. Hamilton</name>
    </author>
    <author>
      <name>Mateja Jamnik</name>
    </author>
    <author>
      <name>Sean B. Holden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally. Accepted at the
  Reinforcement Learning in Games workshop at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08868v1</id>
    <updated>2020-01-24T03:03:51Z</updated>
    <published>2020-01-24T03:03:51Z</published>
    <title>Exploration Based Language Learning for Text-Based Games</title>
    <summary>  This work presents an exploration and imitation-learning-based agent capable
of state-of-the-art performance in playing text-based computer games.
Text-based computer games describe their world to the player through natural
language and expect the player to interact with the game using text. These
games are of interest as they can be seen as a testbed for language
understanding, problem-solving, and language generation by artificial agents.
Moreover, they provide a learning environment in which these skills can be
acquired through interactions with an environment rather than using fixed
corpora. One aspect that makes these games particularly challenging for
learning agents is the combinatorially large action space. Existing methods for
solving text-based games are limited to games that are either very simple or
have an action space restricted to a predetermined set of admissible actions.
In this work, we propose to use the exploration approach of Go-Explore for
solving text-based games. More specifically, in an initial exploration phase,
we first extract trajectories with high rewards, after which we train a policy
to solve the game by imitating these trajectories. Our experiments show that
this approach outperforms existing solutions in solving text-based games, and
it is more sample efficient in terms of the number of interactions with the
environment. Moreover, we show that the learned policy can generalize better
than existing solutions to unseen games without using any restriction on the
action space.
</summary>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Joost Huizinga</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Adrien Ecoffet</name>
    </author>
    <author>
      <name>Huaixiu Zheng</name>
    </author>
    <author>
      <name>Alexandros Papangelis</name>
    </author>
    <author>
      <name>Dian Yu</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under Review</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08837v1</id>
    <updated>2020-01-23T22:33:18Z</updated>
    <published>2020-01-23T22:33:18Z</published>
    <title>Graph Constrained Reinforcement Learning for Natural Language Action
  Spaces</title>
    <summary>  Interactive Fiction games are text-based simulations in which an agent
interacts with the world purely through natural language. They are ideal
environments for studying how to extend reinforcement learning agents to meet
the challenges of natural language understanding, partial observability, and
action generation in combinatorially-large text-based action spaces. We present
KG-A2C, an agent that builds a dynamic knowledge graph while exploring and
generates actions using a template-based action space. We contend that the dual
uses of the knowledge graph to reason about game state and to constrain natural
language generation are the keys to scalable exploration of combinatorially
large natural language actions. Results across a wide variety of IF games show
that KG-A2C outperforms current IF agents despite the exponential increase in
action space size.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Matthew Hausknecht</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08779v1</id>
    <updated>2020-01-23T19:37:20Z</updated>
    <published>2020-01-23T19:37:20Z</published>
    <title>Deep Bayesian Network for Visual Question Generation</title>
    <summary>  Generating natural questions from an image is a semantic task that requires
using vision and language modalities to learn multimodal representations.
Images can have multiple visual and language cues such as places, captions, and
tags. In this paper, we propose a principled deep Bayesian learning framework
that combines these cues to produce natural questions. We observe that with the
addition of more cues and by minimizing uncertainty in the among cues, the
Bayesian network becomes more confident. We propose a Minimizing Uncertainty of
Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues
experts for generating probabilistic questions. This is a Bayesian framework
and the results show a remarkable similarity to natural questions as validated
by a human study. We observe that with the addition of more cues and by
minimizing uncertainty among the cues, the Bayesian framework becomes more
confident. Ablation studies of our model indicate that a subset of cues is
inferior at this task and hence the principled fusion of cues is preferred.
Further, we observe that the proposed approach substantially improves over
state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,
and CIDEr). Here we provide project link for Deep Bayesian VQG
\url{https://delta-lab-iitk.github.io/BVQG/}
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Vinod K. Kurmi</name>
    </author>
    <author>
      <name>Sandeep Kumar</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WACV-2020 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08779v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08779v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08730v1</id>
    <updated>2020-01-23T18:43:34Z</updated>
    <published>2020-01-23T18:43:34Z</published>
    <title>Robust Explanations for Visual Question Answering</title>
    <summary>  In this paper, we propose a method to obtain robust explanations for visual
question answering(VQA) that correlate well with the answers. Our model
explains the answers obtained through a VQA model by providing visual and
textual explanations. The main challenges that we address are i) Answers and
textual explanations obtained by current methods are not well correlated and
ii) Current methods for visual explanation do not focus on the right location
for explaining the answer. We address both these challenges by using a
collaborative correlated module which ensures that even if we do not train for
noise based attacks, the enhanced correlation ensures that the right
explanation and answer can be generated. We further show that this also aids in
improving the generated visual and textual explanations. The use of the
correlated module can be thought of as a robust method to verify if the answer
and explanations are coherent. We evaluate this model using VQA-X dataset. We
observe that the proposed method yields better textual and visual justification
that supports the decision. We showcase the robustness of the model against a
noise-based perturbation attack using corresponding visual and textual
explanations. A detailed empirical analysis is shown. Here we provide source
code link for our model \url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Shivansh Pate</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WACV-2020 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08279v2</id>
    <updated>2020-01-28T22:09:19Z</updated>
    <published>2020-01-22T20:58:22Z</published>
    <title>Transition-Based Dependency Parsing using Perceptron Learner</title>
    <summary>  Syntactic parsing using dependency structures has become a standard technique
in natural language processing with many different parsing models, in
particular data-driven models that can be trained on syntactically annotated
corpora. In this paper, we tackle transition-based dependency parsing using a
Perceptron Learner. Our proposed model, which adds more relevant features to
the Perceptron Learner, outperforms a baseline arc-standard parser. We beat the
UAS of the MALT and LSTM parsers. We also give possible ways to address parsing
of non-projective trees.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Miguel Ballesteros</name>
    </author>
    <author>
      <name>Chris Dyer</name>
    </author>
    <author>
      <name>Robert Frederking</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This was part of an assignment at my graduate course at LTI. This
  does not offer any major novelties</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08279v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08279v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08034v1</id>
    <updated>2020-01-22T14:39:28Z</updated>
    <published>2020-01-22T14:39:28Z</published>
    <title>ManyModalQA: Modality Disambiguation and QA over Diverse Inputs</title>
    <summary>  We present a new multimodal question answering challenge, ManyModalQA, in
which an agent must answer a question by considering three distinct modalities:
text, images, and tables. We collect our data by scraping Wikipedia and then
utilize crowdsourcing to collect question-answer pairs. Our questions are
ambiguous, in that the modality that contains the answer is not easily
determined based solely upon the question. To demonstrate this ambiguity, we
construct a modality selector (or disambiguator) network, and this model gets
substantially lower accuracy on our challenge set, compared to existing
datasets, indicating that our questions are more ambiguous. By analyzing this
model, we investigate which words in the question are indicative of the
modality. Next, we construct a simple baseline ManyModalQA model, which, based
on the prediction from the modality selector, fires a corresponding pre-trained
state-of-the-art unimodal QA model. We focus on providing the community with a
new manymodal evaluation set and only provide a fine-tuning set, with the
expectation that existing datasets and approaches will be transferred for most
of the training, to encourage low-resource generalization without large,
monolithic training sets for each new task. There is a significant gap between
our baseline models and human performance; therefore, we hope that this
challenge encourages research in end-to-end modality disambiguation and
multimodal QA models, as well as transfer learning. Code and data available at:
https://github.com/hannandarryl/ManyModalQA
</summary>
    <author>
      <name>Darryl Hannan</name>
    </author>
    <author>
      <name>Akshay Jain</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (10 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08013v1</id>
    <updated>2020-01-22T13:49:14Z</updated>
    <published>2020-01-22T13:49:14Z</published>
    <title>A Neural Architecture for Person Ontology population</title>
    <summary>  A person ontology comprising concepts, attributes and relationships of people
has a number of applications in data protection, didentification, population of
knowledge graphs for business intelligence and fraud prevention. While
artificial neural networks have led to improvements in Entity Recognition,
Entity Classification, and Relation Extraction, creating an ontology largely
remains a manual process, because it requires a fixed set of semantic relations
between concepts. In this work, we present a system for automatically
populating a person ontology graph from unstructured data using neural models
for Entity Classification and Relation Extraction. We introduce a new dataset
for these tasks and discuss our results.
</summary>
    <author>
      <name>Balaji Ganesan</name>
    </author>
    <author>
      <name>Riddhiman Dasgupta</name>
    </author>
    <author>
      <name>Akshay Parekh</name>
    </author>
    <author>
      <name>Hima Patel</name>
    </author>
    <author>
      <name>Berthold Reinwald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:1811.09368</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07752v1</id>
    <updated>2020-01-21T19:37:33Z</updated>
    <published>2020-01-21T19:37:33Z</published>
    <title>Emergence of Pragmatics from Referential Game between Theory of Mind
  Agents</title>
    <summary>  Pragmatics studies how context can contribute to language meanings [1]. In
human communication, language is never interpreted out of context, and
sentences can usually convey more information than their literal meanings [2].
However, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],
restricting the communication efficiency and the capability of human-agent
interaction. In this paper, we propose an algorithm, using which agents can
spontaneously learn the ability to "read between lines" without any explicit
hand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a
cooperative multi-agent pedagogical situation and propose an adaptive
reinforcement learning (RL) algorithm to develop a communication protocol. ToM
is a profound cognitive science concept, claiming that people regularly reason
about other's mental states, including beliefs, goals, and intentions, to
obtain performance advantage in competition, cooperation or coalition. With
this ability, agents consider language as not only messages but also rational
acts reflecting others' hidden states. Our experiments demonstrate the
advantage of pragmatic protocols over non-pragmatic protocols. We also show the
teaching complexity following the pragmatic protocol empirically approximates
to recursive teaching dimension (RTD).
</summary>
    <author>
      <name>Luyao Yuan</name>
    </author>
    <author>
      <name>Zipeng Fu</name>
    </author>
    <author>
      <name>Jingyue Shen</name>
    </author>
    <author>
      <name>Lu Xu</name>
    </author>
    <author>
      <name>Junhong Shen</name>
    </author>
    <author>
      <name>Song-Chun Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07615v1</id>
    <updated>2020-01-21T15:39:12Z</updated>
    <published>2020-01-21T15:39:12Z</published>
    <title>Improving Interaction Quality Estimation with BiLSTMs and the Impact on
  Dialogue Policy Learning</title>
    <summary>  Learning suitable and well-performing dialogue behaviour in statistical
spoken dialogue systems has been in the focus of research for many years. While
most work which is based on reinforcement learning employs an objective measure
like task success for modelling the reward signal, we use a reward based on
user satisfaction estimation. We propose a novel estimator and show that it
outperforms all previous estimators while learning temporal dependencies
implicitly. Furthermore, we apply this novel user satisfaction estimation model
live in simulated experiments where the satisfaction estimation model is
trained on one domain and applied in many other domains which cover a similar
task. We show that applying this model results in higher estimated
satisfaction, similar task success rates and a higher robustness to noise.
</summary>
    <author>
      <name>Stefan Ultes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at SIGDIAL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07526v1</id>
    <updated>2020-01-21T13:41:09Z</updated>
    <published>2020-01-21T13:41:09Z</published>
    <title>Domain-Aware Dialogue State Tracker for Multi-Domain Dialogue Systems</title>
    <summary>  In task-oriented dialogue systems the dialogue state tracker (DST) component
is responsible for predicting the state of the dialogue based on the dialogue
history. Current DST approaches rely on a predefined domain ontology, a fact
that limits their effective usage for large scale conversational agents, where
the DST constantly needs to be interfaced with ever-increasing services and
APIs. Focused towards overcoming this drawback, we propose a domain-aware
dialogue state tracker, that is completely data-driven and it is modeled to
predict for dynamic service schemas. The proposed model utilizes domain and
slot information to extract both domain and slot specific representations for a
given dialogue, and then uses such representations to predict the values of the
corresponding slot. Integrating this mechanism with a pretrained language model
(i.e. BERT), our approach can effectively learn semantic relations.
</summary>
    <author>
      <name>Vevake Balaraman</name>
    </author>
    <author>
      <name>Bernardo Magnini</name>
    </author>
    <link href="http://arxiv.org/abs/2001.07526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08546v1</id>
    <updated>2020-01-21T06:47:11Z</updated>
    <published>2020-01-21T06:47:11Z</published>
    <title>CheckThat! at CLEF 2020: Enabling the Automatic Identification and
  Verification of Claims in Social Media</title>
    <summary>  We describe the third edition of the CheckThat! Lab, which is part of the
2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four
complementary tasks and a related task from previous lab editions, offered in
English, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter
stream are worth fact-checking. Task 2 asks to determine whether a claim posted
in a tweet can be verified using a set of previously fact-checked claims. Task
3 asks to retrieve text snippets from a given set of Web pages that would be
useful for verifying a target tweet's claim. Task 4 asks to predict the
veracity of a target tweet's claim using a set of Web pages and potentially
useful snippets in them. Finally, the lab offers a fifth task that asks to
predict the check-worthiness of the claims made in English political debates
and speeches. CheckThat! features a full evaluation framework. The evaluation
is carried out using mean average precision or precision at rank k for ranking
tasks, and F1 for classification tasks.
</summary>
    <author>
      <name>Alberto Barron-Cedeno</name>
    </author>
    <author>
      <name>Tamer Elsayed</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Giovanni Da San Martino</name>
    </author>
    <author>
      <name>Maram Hasanain</name>
    </author>
    <author>
      <name>Reem Suwaileh</name>
    </author>
    <author>
      <name>Fatima Haouari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computational journalism, Check-worthiness, Fact-checking, Veracity,
  CLEF-2020 CheckThat! Lab</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CLEF-2018 ECIR-2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.08546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11384v1</id>
    <updated>2020-01-20T06:12:12Z</updated>
    <published>2020-01-20T06:12:12Z</published>
    <title>Unsupervised Sentiment Analysis for Code-mixed Data</title>
    <summary>  Code-mixing is the practice of alternating between two or more languages.
Mostly observed in multilingual societies, its occurrence is increasing and
therefore its importance. A major part of sentiment analysis research has been
monolingual, and most of them perform poorly on code-mixed text. In this work,
we introduce methods that use different kinds of multilingual and cross-lingual
embeddings to efficiently transfer knowledge from monolingual text to
code-mixed text for sentiment analysis of code-mixed text. Our methods can
handle code-mixed text through a zero-shot learning. Our methods beat
state-of-the-art on English-Spanish code-mixed sentiment analysis by absolute
3\% F1-score. We are able to achieve 0.58 F1-score (without parallel corpus)
and 0.62 F1-score (with parallel corpus) on the same benchmark in a zero-shot
way as compared to 0.68 F1-score in supervised settings. Our code is publicly
available.
</summary>
    <author>
      <name>Siddharth Yadav</name>
    </author>
    <author>
      <name>Tanmoy Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06927v1</id>
    <updated>2020-01-20T01:02:36Z</updated>
    <published>2020-01-20T01:02:36Z</published>
    <title>SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions</title>
    <summary>  Existing VQA datasets contain questions with varying levels of complexity.
While the majority of questions in these datasets require perception for
recognizing existence, properties, and spatial relationships of entities, a
significant portion of questions pose challenges that correspond to reasoning
tasks -- tasks that can only be answered through a synthesis of perception and
knowledge about the world, logic and / or reasoning. This distinction allows us
to notice when existing VQA models have consistency issues -- they answer the
reasoning question correctly but fail on associated low-level perception
questions. For example, models answer the complex reasoning question "Is the
banana ripe enough to eat?" correctly, but fail on the associated perception
question "Are the bananas mostly green or yellow?" indicating that the model
likely answered the reasoning question correctly but for the wrong reason. We
quantify the extent to which this phenomenon occurs by creating a new Reasoning
split of the VQA dataset and collecting Sub-VQA, a new dataset consisting of
200K new perception questions which serve as sub questions corresponding to the
set of perceptual tasks needed to effectively answer the complex reasoning
questions in the Reasoning split. Additionally, we propose an approach called
Sub-Question Importance-aware Network Tuning (SQuINT), which encourages the
model to attend do the same parts of the image when answering the reasoning
question and the perception sub questions. We show that SQuINT improves model
consistency by 7.8%, also marginally improving its performance on the Reasoning
questions in VQA, while also displaying qualitatively better attention maps.
</summary>
    <author>
      <name>Ramprasaath R. Selvaraju</name>
    </author>
    <author>
      <name>Purva Tendulkar</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Eric Horvitz</name>
    </author>
    <author>
      <name>Marco Ribeiro</name>
    </author>
    <author>
      <name>Besmira Nushi</name>
    </author>
    <author>
      <name>Ece Kamar</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06693v1</id>
    <updated>2020-01-18T15:38:04Z</updated>
    <published>2020-01-18T15:38:04Z</published>
    <title>Fair Transfer of Multiple Style Attributes in Text</title>
    <summary>  To preserve anonymity and obfuscate their identity on online platforms users
may morph their text and portray themselves as a different gender or
demographic. Similarly, a chatbot may need to customize its communication style
to improve engagement with its audience. This manner of changing the style of
written text has gained significant attention in recent years. Yet these past
research works largely cater to the transfer of single style attributes. The
disadvantage of focusing on a single style alone is that this often results in
target text where other existing style attributes behave unpredictably or are
unfairly dominated by the new style. To counteract this behavior, it would be
nice to have a style transfer mechanism that can transfer or control multiple
styles simultaneously and fairly. Through such an approach, one could obtain
obfuscated or written text incorporated with a desired degree of multiple soft
styles such as female-quality, politeness, or formalness.
  In this work, we demonstrate that the transfer of multiple styles cannot be
achieved by sequentially performing multiple single-style transfers. This is
because each single style-transfer step often reverses or dominates over the
style incorporated by a previous transfer step. We then propose a neural
network architecture for fairly transferring multiple style attributes in a
given text. We test our architecture on the Yelp data set to demonstrate our
superior performance as compared to existing one-style transfer steps performed
in a sequence.
</summary>
    <author>
      <name>Karan Dabas</name>
    </author>
    <author>
      <name>Nishtha Madan</name>
    </author>
    <author>
      <name>Vijay Arya</name>
    </author>
    <author>
      <name>Sameep Mehta</name>
    </author>
    <author>
      <name>Gautam Singh</name>
    </author>
    <author>
      <name>Tanmoy Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06463v1</id>
    <updated>2020-01-17T18:27:29Z</updated>
    <published>2020-01-17T18:27:29Z</published>
    <title>Plato Dialogue System: A Flexible Conversational AI Research Platform</title>
    <summary>  As the field of Spoken Dialogue Systems and Conversational AI grows, so does
the need for tools and environments that abstract away implementation details
in order to expedite the development process, lower the barrier of entry to the
field, and offer a common test-bed for new ideas. In this paper, we present
Plato, a flexible Conversational AI platform written in Python that supports
any kind of conversational agent architecture, from standard architectures to
architectures with jointly-trained components, single- or multi-party
interactions, and offline or online training of any conversational agent
component. Plato has been designed to be easy to understand and debug and is
agnostic to the underlying learning frameworks that train each component.
</summary>
    <author>
      <name>Alexandros Papangelis</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Yi-Chia Wang</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06354v1</id>
    <updated>2020-01-17T14:57:12Z</updated>
    <published>2020-01-17T14:57:12Z</published>
    <title>Modality-Balanced Models for Visual Dialogue</title>
    <summary>  The Visual Dialog task requires a model to exploit both image and
conversational context information to generate the next response to the
dialogue. However, via manual analysis, we find that a large number of
conversational questions can be answered by only looking at the image without
any access to the context history, while others still need the conversation
context to predict the correct answers. We demonstrate that due to this reason,
previous joint-modality (history and image) models over-rely on and are more
prone to memorizing the dialogue history (e.g., by extracting certain keywords
or patterns in the context information), whereas image-only models are more
generalizable (because they cannot memorize or extract keywords from history)
and perform substantially better at the primary normalized discounted
cumulative gain (NDCG) task metric which allows multiple correct answers.
Hence, this observation encourages us to explicitly maintain two models, i.e.,
an image-only model and an image-history joint model, and combine their
complementary abilities for a more balanced multimodal model. We present
multiple methods for this integration of the two models, via ensemble and
consensus dropout fusion with shared parameters. Empirically, our models
achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and
high balance across metrics), and substantially outperform the winner of the
Visual Dialog challenge 2018 on most metrics.
</summary>
    <author>
      <name>Hyounghun Kim</name>
    </author>
    <author>
      <name>Hao Tan</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (11 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06007v1</id>
    <updated>2020-01-16T18:06:43Z</updated>
    <published>2020-01-16T18:06:43Z</published>
    <title>User-in-the-loop Adaptive Intent Detection for Instructable Digital
  Assistant</title>
    <summary>  People are becoming increasingly comfortable using Digital Assistants (DAs)
to interact with services or connected objects. However, for non-programming
users, the available possibilities for customizing their DA are limited and do
not include the possibility of teaching the assistant new tasks. To make the
most of the potential of DAs, users should be able to customize assistants by
instructing them through Natural Language (NL). To provide such
functionalities, NL interpretation in traditional assistants should be
improved: (1) The intent identification system should be able to recognize new
forms of known intents, and to acquire new intents as they are expressed by the
user. (2) In order to be adaptive to novel intents, the Natural Language
Understanding module should be sample efficient, and should not rely on a
pretrained model. Rather, the system should continuously collect the training
data as it learns new intents from the user. In this work, we propose AidMe
(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop
adaptive intent detection framework that allows the assistant to adapt to its
user by learning his intents as their interaction progresses. AidMe builds its
repertoire of intents and collects data to train a model of semantic similarity
evaluation that can discriminate between the learned intents and autonomously
discover new forms of known intents. AidMe addresses two major issues - intent
learning and user adaptation - for instructable digital assistants. We
demonstrate the capabilities of AidMe as a standalone system by comparing it
with a one-shot learning system and a pretrained NLU module through simulations
of interactions with a user. We also show how AidMe can smoothly integrate to
an existing instructable digital assistant.
</summary>
    <author>
      <name>Nicolas Lair</name>
    </author>
    <author>
      <name>Clément Delgrange</name>
    </author>
    <author>
      <name>David Mugisha</name>
    </author>
    <author>
      <name>Jean-Michel Dussoux</name>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <author>
      <name>Peter Ford Dominey</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3377325.3377490</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3377325.3377490" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published as a conference paper in the proceedings of IUI'20</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">25th International Conference on Intelligent User Interfaces (IUI
  '20), March 17--20, 2020, Cagliari, Italy</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.06007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05970v1</id>
    <updated>2020-01-16T18:05:46Z</updated>
    <published>2020-01-16T18:05:46Z</published>
    <title>#MeToo on Campus: Studying College Sexual Assault at Scale Using Data
  Reported on Social Media</title>
    <summary>  Recently, the emergence of the #MeToo trend on social media has empowered
thousands of people to share their own sexual harassment experiences. This
viral trend, in conjunction with the massive personal information and content
available on Twitter, presents a promising opportunity to extract data driven
insights to complement the ongoing survey based studies about sexual harassment
in college. In this paper, we analyze the influence of the #MeToo trend on a
pool of college followers. The results show that the majority of topics
embedded in those #MeToo tweets detail sexual harassment stories, and there
exists a significant correlation between the prevalence of this trend and
official reports on several major geographical regions. Furthermore, we
discover the outstanding sentiments of the #MeToo tweets using deep semantic
meaning representations and their implications on the affected users
experiencing different types of sexual harassment. We hope this study can raise
further awareness regarding sexual misconduct in academia.
</summary>
    <author>
      <name>Viet Duong</name>
    </author>
    <author>
      <name>Phu Pham</name>
    </author>
    <author>
      <name>Ritwik Bose</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05970v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05970v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05495v1</id>
    <updated>2020-01-15T18:17:36Z</updated>
    <published>2020-01-15T18:17:36Z</published>
    <title>Stereotypical Bias Removal for Hate Speech Detection Task using
  Knowledge-based Generalizations</title>
    <summary>  With the ever-increasing cases of hate spread on social media platforms, it
is critical to design abuse detection mechanisms to proactively avoid and
control such incidents. While there exist methods for hate speech detection,
they stereotype words and hence suffer from inherently biased training. Bias
removal has been traditionally studied for structured datasets, but we aim at
bias mitigation from unstructured text data. In this paper, we make two
important contributions. First, we systematically design methods to quantify
the bias for any model and propose algorithms for identifying the set of words
which the model stereotypes. Second, we propose novel methods leveraging
knowledge-based generalizations for bias-free learning. Knowledge-based
generalization provides an effective way to encode knowledge because the
abstraction they provide not only generalizes content but also facilitates
retraction of information from the hate speech detection classifier, thereby
reducing the imbalance. We experiment with multiple knowledge generalization
policies and analyze their effect on general performance and in mitigating
bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages
dataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that
the use of knowledge-based generalizations results in better performance by
forcing the classifier to learn from generalized content. Our methods utilize
existing knowledge-bases and can easily be extended to other tasks
</summary>
    <author>
      <name>Pinkesh Badjatiya</name>
    </author>
    <author>
      <name>Manish Gupta</name>
    </author>
    <author>
      <name>Vasudeva Varma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313504</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313504" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In The World Wide Web Conference (WWW '19). Association for
  Computing Machinery, New York, NY, USA, 49-59. 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.05495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.05871v1</id>
    <updated>2020-01-14T19:00:00Z</updated>
    <published>2020-01-14T19:00:00Z</published>
    <title>"Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials
  for Humans</title>
    <summary>  To support human decision making with machine learning models, we often need
to elucidate patterns embedded in the models that are unsalient, unknown, or
counterintuitive to humans. While existing approaches focus on explaining
machine predictions with real-time assistance, we explore model-driven
tutorials to help humans understand these patterns in a training phase. We
consider both tutorials with guidelines from scientific papers, analogous to
current practices of science communication, and automatically selected examples
from training data with explanations. We use deceptive review detection as a
testbed and conduct large-scale, randomized human-subject experiments to
examine the effectiveness of such tutorials. We find that tutorials indeed
improve human performance, with and without real-time assistance. In
particular, although deep learning provides superior predictive performance
than simple models, tutorials and explanations from simple models are more
useful to humans. Our work suggests future directions for human-centered
tutorials and explanations towards a synergy between humans and AI.
</summary>
    <author>
      <name>Vivian Lai</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <author>
      <name>Chenhao Tan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/10.1145/3313831.3376873</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/10.1145/3313831.3376873" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 48 figures, CHI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04701v6</id>
    <updated>2020-02-15T17:06:34Z</updated>
    <published>2020-01-14T10:26:51Z</published>
    <title>A (Simplified) Supreme Being Necessarily Exists -- Says the Computer!</title>
    <summary>  A simplified variant of Kurt G\"odel's modal ontological argument is
presented. Some of G\"odel's, resp. Scott's, premises are modified, others are
dropped, and modal collapse is avoided. The emended argument is shown valid
already in quantified modal logic K.
  The presented simplifications have been computationally explored utilising
latest knowledge representation and reasoning technology based on higher-order
logic. The paper thus illustrates how modern symbolic AI technology can
contribute new knowledge to formal philosophy and theology.
</summary>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04701v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04701v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04425v3</id>
    <updated>2020-01-20T14:45:01Z</updated>
    <published>2020-01-13T17:49:37Z</published>
    <title>Negative Statements Considered Useful</title>
    <summary>  Knowledge bases (KBs), pragmatic collections of knowledge about notable
entities, are an important asset in applications such as search, question
answering and dialogue. Rooted in a long tradition in knowledge representation,
all popular KBs only store positive information, while they abstain from taking
any stance towards statements not contained in them.
  In this paper, we make the case for explicitly stating interesting statements
which are not true. Negative statements would be important to overcome current
limitations of question answering, yet due to their potential abundance, any
effort towards compiling them needs a tight coupling with ranking. We introduce
two approaches towards compiling negative statements. (i) In peer-based
statistical inferences, we compare entities with highly related entities in
order to derive potential negative statements, which we then rank using
supervised and unsupervised features. (ii) In query-log-based text extraction,
we use a pattern-based approach for harvesting search engine query logs.
Experimental results show that both approaches hold promising and complementary
potential. Along with this paper, we publish the first datasets on interesting
negative information, containing over 1.1M statements for 100K popular Wikidata
entities.
</summary>
    <author>
      <name>Hiba Arnaout</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04425v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04425v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04219v1</id>
    <updated>2020-01-13T13:16:13Z</updated>
    <published>2020-01-13T13:16:13Z</published>
    <title>Structural Decompositions of Epistemic Logic Programs</title>
    <summary>  Epistemic logic programs (ELPs) are a popular generalization of standard
Answer Set Programming (ASP) providing means for reasoning over answer sets
within the language. This richer formalism comes at the price of higher
computational complexity reaching up to the fourth level of the polynomial
hierarchy. However, in contrast to standard ASP, dedicated investigations
towards tractability have not been undertaken yet. In this paper, we give first
results in this direction and show that central ELP problems can be solved in
linear time for ELPs exhibiting structural properties in terms of bounded
treewidth. We also provide a full dynamic programming algorithm that adheres to
these bounds. Finally, we show that applying treewidth to a novel dependency
structure---given in terms of epistemic literals---allows to bound the number
of ASP solver calls in typical ELP solving procedures.
</summary>
    <author>
      <name>Markus Hecher</name>
    </author>
    <author>
      <name>Michael Morak</name>
    </author>
    <author>
      <name>Stefan Woltran</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T27" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8; G.2.2; G.2.3; F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04192v1</id>
    <updated>2020-01-13T12:47:49Z</updated>
    <published>2020-01-13T12:47:49Z</published>
    <title>A logic-based relational learning approach to relation extraction: The
  OntoILPER system</title>
    <summary>  Relation Extraction (RE), the task of detecting and characterizing semantic
relations between entities in text, has gained much importance in the last two
decades, mainly in the biomedical domain. Many papers have been published on
Relation Extraction using supervised machine learning techniques. Most of these
techniques rely on statistical methods, such as feature-based and
tree-kernels-based methods. Such statistical learning techniques are usually
based on a propositional hypothesis space for representing examples, i.e., they
employ an attribute-value representation of features. This kind of
representation has some drawbacks, particularly in the extraction of complex
relations which demand more contextual information about the involving
instances, i.e., it is not able to effectively capture structural information
from parse trees without loss of information. In this work, we present
OntoILPER, a logic-based relational learning approach to Relation Extraction
that uses Inductive Logic Programming for generating extraction models in the
form of symbolic extraction rules. OntoILPER takes profit of a rich relational
representation of examples, which can alleviate the aforementioned drawbacks.
The proposed relational approach seems to be more suitable for Relation
Extraction than statistical ones for several reasons that we argue. Moreover,
OntoILPER uses a domain ontology that guides the background knowledge
generation process and is used for storing the extracted relation instances.
The induced extraction rules were evaluated on three protein-protein
interaction datasets from the biomedical domain. The performance of OntoILPER
extraction models was compared with other state-of-the-art RE systems. The
encouraging results seem to demonstrate the effectiveness of the proposed
solution.
</summary>
    <author>
      <name>Rinaldo Lima</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, R2I</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Espinasse</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, R2I</arxiv:affiliation>
    </author>
    <author>
      <name>Fred Freitas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.engappai.2018.11.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.engappai.2018.11.001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Engineering Applications of Artificial Intelligence, Elsevier,
  2019, 78, pp.142-157</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04170v1</id>
    <updated>2020-01-13T11:34:25Z</updated>
    <published>2020-01-13T11:34:25Z</published>
    <title>Joint Reasoning for Multi-Faceted Commonsense Knowledge</title>
    <summary>  Commonsense knowledge (CSK) supports a variety of AI applications, from
visual understanding to chatbots. Prior works on acquiring CSK, such as
ConceptNet, have compiled statements that associate concepts, like everyday
objects or activities, with properties that hold for most or some instances of
the concept. Each concept is treated in isolation from other concepts, and the
only quantitative measure (or ranking) of properties is a confidence score that
the statement is valid. This paper aims to overcome these limitations by
introducing a multi-faceted model of CSK statements and methods for joint
reasoning over sets of inter-related statements. Our model captures four
different dimensions of CSK statements: plausibility, typicality, remarkability
and salience, with scoring and ranking along each dimension. For example,
hyenas drinking water is typical but not salient, whereas hyenas eating
carcasses is salient. For reasoning and ranking, we develop a method with soft
constraints, to couple the inference over concepts that are related in in a
taxonomic hierarchy. The reasoning is cast into an integer linear programming
(ILP), and we leverage the theory of reduction costs of a relaxed LP to compute
informative rankings. This methodology is applied to several large CSK
collections. Our evaluation shows that we can consolidate these inputs into
much cleaner and more expressive knowledge. Results are available at
https://dice.mpi-inf.mpg.de.
</summary>
    <author>
      <name>Yohan Chalier</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04809v2</id>
    <updated>2020-01-27T23:16:48Z</updated>
    <published>2020-01-13T10:47:13Z</published>
    <title>Detecting depression in dyadic conversations with multimodal narratives
  and visualizations</title>
    <summary>  Conversations contain a wide spectrum of multimodal information that gives us
hints about the emotions and moods of the speaker. In this paper, we developed
a system that supports humans to analyze conversations. Our main contribution
is the identification of appropriate multimodal features and the integration of
such features into verbatim conversation transcripts. We demonstrate the
ability of our system to take in a wide range of multimodal information and
automatically generated a prediction score for the depression state of the
individual. Our experiments showed that this approach yielded better
performance than the baseline model. Furthermore, the multimodal narrative
approach makes it easy to integrate learnings from other disciplines, such as
conversational analysis and psychology. Lastly, this interdisciplinary and
automated approach is a step towards emulating how practitioners record the
course of treatment as well as emulating how conversational analysts have been
analyzing conversations by hand.
</summary>
    <author>
      <name>Joshua Y. Kim</name>
    </author>
    <author>
      <name>Greyson Y. Kim</name>
    </author>
    <author>
      <name>Kalina Yacef</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-35288-2_25</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-35288-2_25" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AI 2019: Advances in Artificial Intelligence. AI 2019 vol 11919</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03671v1</id>
    <updated>2020-01-10T21:35:28Z</updated>
    <published>2020-01-10T21:35:28Z</published>
    <title>Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for
  Language Grounding Tasks in Street View</title>
    <summary>  The Touchdown dataset (Chen et al., 2019) provides instructions by human
annotators for navigation through New York City streets and for resolving
spatial descriptions at a given location. To enable the wider research
community to work effectively with the Touchdown tasks, we are publicly
releasing the 29k raw Street View panoramas needed for Touchdown. We follow the
process used for the StreetLearn data release (Mirowski et al., 2019) to check
panoramas for personally identifiable information and blur them as necessary.
These have been added to the StreetLearn dataset and can be obtained via the
same process as used previously for StreetLearn. We also provide a reference
implementation for both of the Touchdown tasks: vision and language navigation
(VLN) and spatial description resolution (SDR). We compare our model results to
those given in Chen et al. (2019) and show that the panoramas we have added to
StreetLearn fully support both Touchdown tasks and can be used effectively for
further research and comparison.
</summary>
    <author>
      <name>Harsh Mehta</name>
    </author>
    <author>
      <name>Yoav Artzi</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>Piotr Mirowski</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03521v1</id>
    <updated>2020-01-10T15:45:59Z</updated>
    <published>2020-01-10T15:45:59Z</published>
    <title>Towards Minimal Supervision BERT-based Grammar Error Correction</title>
    <summary>  Current grammatical error correction (GEC) models typically consider the task
as sequence generation, which requires large amounts of annotated data and
limit the applications in data-limited settings. We try to incorporate
contextual information from pre-trained language model to leverage annotation
and benefit multilingual scenarios. Results show strong potential of
Bidirectional Encoder Representations from Transformers (BERT) in grammatical
error correction task.
</summary>
    <author>
      <name>Yiyuan Li</name>
    </author>
    <author>
      <name>Antonios Anastasopoulos</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03436v1</id>
    <updated>2020-01-09T15:19:45Z</updated>
    <published>2020-01-09T15:19:45Z</published>
    <title>Debate Dynamics for Human-comprehensible Fact-checking on Knowledge
  Graphs</title>
    <summary>  We propose a novel method for fact-checking on knowledge graphs based on
debate dynamics. The underlying idea is to frame the task of triple
classification as a debate game between two reinforcement learning agents which
extract arguments -- paths in the knowledge graph -- with the goal to justify
the fact being true (thesis) or the fact being false (antithesis),
respectively. Based on these arguments, a binary classifier, referred to as the
judge, decides whether the fact is true or false. The two agents can be
considered as sparse feature extractors that present interpretable evidence for
either the thesis or the antithesis. In contrast to black-box methods, the
arguments enable the user to gain an understanding for the decision of the
judge. Moreover, our method allows for interactive reasoning on knowledge
graphs where the users can raise additional arguments or evaluate the debate
taking common sense reasoning and external information into account. Such
interactive systems can increase the acceptance of various AI applications
based on knowledge graphs and can further lead to higher efficiency,
robustness, and fairness.
</summary>
    <author>
      <name>Marcel Hildebrandt</name>
    </author>
    <author>
      <name>Jorge Andres Quintero Serna</name>
    </author>
    <author>
      <name>Yunpu Ma</name>
    </author>
    <author>
      <name>Martin Ringsquandl</name>
    </author>
    <author>
      <name>Mitchell Joblin</name>
    </author>
    <author>
      <name>Volker Tresp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text
  overlap with arXiv:2001.00461</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03041v1</id>
    <updated>2020-01-09T15:07:32Z</updated>
    <published>2020-01-09T15:07:32Z</published>
    <title>Open Challenge for Correcting Errors of Speech Recognition Systems</title>
    <summary>  The paper announces the new long-term challenge for improving the performance
of automatic speech recognition systems. The goal of the challenge is to
investigate methods of correcting the recognition results on the basis of
previously made errors by the speech processing system. The dataset prepared
for the task is described and evaluation criteria are presented.
</summary>
    <author>
      <name>Marek Kubis</name>
    </author>
    <author>
      <name>Zygmunt Vetulani</name>
    </author>
    <author>
      <name>Mikołaj Wypych</name>
    </author>
    <author>
      <name>Tomasz Ziętkiewicz</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vetulani, Zygmunt, Paroubek, Patrick (eds.): Proceedings of the
  9th Language and Technology Conference, pp. 219-223, Wydawnictwo Nauka i
  Innowacje, Pozna\'n, Poland, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.03041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02462v1</id>
    <updated>2020-01-08T11:44:47Z</updated>
    <published>2020-01-08T11:44:47Z</published>
    <title>From Natural Language Instructions to Complex Processes: Issues in
  Chaining Trigger Action Rules</title>
    <summary>  Automation services for complex business processes usually require a high
level of information technology literacy. There is a strong demand for a
smartly assisted process automation (IPA: intelligent process automation)
service that enables even general users to easily use advanced automation. A
natural language interface for such automation is expected as an elemental
technology for the IPA realization. The workflow targeted by IPA is generally
composed of a combination of multiple tasks. However, semantic parsing, one of
the natural language processing methods, for such complex workflows has not yet
been fully studied. The reasons are that (1) the formal expression and grammar
of the workflow required for semantic analysis have not been sufficiently
examined and (2) the dataset of the workflow formal expression with its
corresponding natural language description required for learning workflow
semantics did not exist. This paper defines a new grammar for complex workflows
with chaining machine-executable meaning representations for semantic parsing.
The representations are at a high abstraction level. Additionally, an approach
to creating datasets is proposed based on this grammar.
</summary>
    <author>
      <name>Nobuhiro Ito</name>
    </author>
    <author>
      <name>Yuya Suzuki</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02284v1</id>
    <updated>2020-01-07T21:47:37Z</updated>
    <published>2020-01-07T21:47:37Z</published>
    <title>Multipurpose Intelligent Process Automation via Conversational Assistant</title>
    <summary>  Intelligent Process Automation (IPA) is an emerging technology with a primary
goal to assist the knowledge worker by taking care of repetitive, routine and
low-cognitive tasks. Conversational agents that can interact with users in a
natural language are potential application for IPA systems. Such intelligent
agents can assist the user by answering specific questions and executing
routine tasks that are ordinarily performed in a natural language (i.e.,
customer support). In this work, we tackle a challenge of implementing an IPA
conversational assistant in a real-world industrial setting with a lack of
structured training data. Our proposed system brings two significant benefits:
First, it reduces repetitive and time-consuming activities and, therefore,
allows workers to focus on more intelligent processes. Second, by interacting
with users, it augments the resources with structured and to some extent
labeled training data. We showcase the usage of the latter by re-implementing
several components of our system with Transfer Learning (TL) methods.
</summary>
    <author>
      <name>Alena Moiseeva</name>
    </author>
    <author>
      <name>Dietrich Trautmann</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the AAAI-20 Workshop on Intelligent Process Automation</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01126v1</id>
    <updated>2020-01-04T20:56:21Z</updated>
    <published>2020-01-04T20:56:21Z</published>
    <title>Can x2vec Save Lives? Integrating Graph and Language Embeddings for
  Automatic Mental Health Classification</title>
    <summary>  Graph and language embedding models are becoming commonplace in large scale
analyses given their ability to represent complex sparse data densely in
low-dimensional space. Integrating these models' complementary relational and
communicative data may be especially helpful if predicting rare events or
classifying members of hidden populations - tasks requiring huge and sparse
datasets for generalizable analyses. For example, due to social stigma and
comorbidities, mental health support groups often form in amorphous online
groups. Predicting suicidality among individuals in these settings using
standard network analyses is prohibitive due to resource limits (e.g., memory),
and adding auxiliary data like text to such models exacerbates complexity- and
sparsity-related issues. Here, I show how merging graph and language embedding
models (metapath2vec and doc2vec) avoids these limits and extracts unsupervised
clustering data without domain expertise or feature engineering. Graph and
language distances to a suicide support group have little correlation (\r{ho} &lt;
0.23), implying the two models are not embedding redundant information. When
used separately to predict suicidality among individuals, graph and language
data generate relatively accurate results (69% and 76%, respectively); however,
when integrated, both data produce highly accurate predictions (90%, with 10%
false-positives and 12% false-negatives). Visualizing graph embeddings
annotated with predictions of potentially suicidal individuals shows the
integrated model could classify such individuals even if they are positioned
far from the support group. These results extend research on the importance of
simultaneously analyzing behavior and language in massive networks and efforts
to integrate embedding models for different kinds of data when predicting and
classifying, particularly when they involve rare events.
</summary>
    <author>
      <name>Alexander Ruch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages (23 body, 2 supplemental material), 12 figures (10 body, 2
  supplemental material), 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.2.8; H.3.3; H.3.4; H.3.5; H.4.3; I.2.1; I.2.6; I.2.7; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01115v2</id>
    <updated>2020-01-07T16:54:33Z</updated>
    <published>2020-01-04T19:38:00Z</published>
    <title>A Comprehensive Survey of Multilingual Neural Machine Translation</title>
    <summary>  We present a survey on multilingual neural machine translation (MNMT), which
has gained a lot of traction in the recent years. MNMT has been useful in
improving translation quality as a result of translation knowledge transfer
(transfer learning). MNMT is more promising and interesting than its
statistical machine translation counterpart because end-to-end modeling and
distributed representations open new avenues for research on machine
translation. Many approaches have been proposed in order to exploit
multilingual parallel corpora for improving translation quality. However, the
lack of a comprehensive survey makes it difficult to determine which approaches
are promising and hence deserve further exploration. In this paper, we present
an in-depth survey of existing literature on MNMT. We first categorize various
approaches based on their central use-case and then further categorize them
based on resource scenarios, underlying modeling principles, core-issues and
challenges. Wherever possible we address the strengths and weaknesses of
several techniques by comparing them with each other. We also discuss the
future directions that MNMT research might take. This paper is aimed towards
both, beginners and experts in NMT. We hope this paper will serve as a starting
point as well as a source of new ideas for researchers and engineers interested
in MNMT.
</summary>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Chenhui Chu</name>
    </author>
    <author>
      <name>Anoop Kunchukuttan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an extended version of our survey paper on multilingual NMT.
  The previous version [arXiv:1905.05395] is rather condensed and is useful for
  speed-reading whereas this version is more beginner friendly. Under review at
  the computing surveys journal. We have intentionally decided to maintain both
  short and long versions of our survey paper for different reader groups</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01115v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01115v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01588v1</id>
    <updated>2020-01-03T17:16:28Z</updated>
    <published>2020-01-03T17:16:28Z</published>
    <title>Information Extraction based on Named Entity for Tourism Corpus</title>
    <summary>  Tourism information is scattered around nowadays. To search for the
information, it is usually time consuming to browse through the results from
search engine, select and view the details of each accommodation. In this
paper, we present a methodology to extract particular information from full
text returned from the search engine to facilitate the users. Then, the users
can specifically look to the desired relevant information. The approach can be
used for the same task in other domains. The main steps are 1) building
training data and 2) building recognition model. First, the tourism data is
gathered and the vocabularies are built. The raw corpus is used to train for
creating vocabulary embedding. Also, it is used for creating annotated data.
The process of creating named entity annotation is presented. Then, the
recognition model of a given entity type can be built. From the experiments,
given hotel description, the model can extract the desired entity,i.e, name,
location, facility. The extracted data can further be stored as a structured
information, e.g., in the ontology format, for future querying and inference.
The model for automatic named entity identification, based on machine learning,
yields the error ranging 8%-25%.
</summary>
    <author>
      <name>Chantana Chantrapornchai</name>
    </author>
    <author>
      <name>Aphisit Tunsakul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JCSSE.2019.8864166</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JCSSE.2019.8864166" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">16th International Joint Conference on Computer Science and
  Software Engineering (JCSSE), 2019, pp. 187-192</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2, I.7" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00733v1</id>
    <updated>2020-01-03T05:56:13Z</updated>
    <published>2020-01-03T05:56:13Z</published>
    <title>"Love is as Complex as Math": Metaphor Generation System for Social
  Chatbot</title>
    <summary>  As the wide adoption of intelligent chatbot in human daily life, user demands
for such systems evolve from basic task-solving conversations to more casual
and friend-like communication. To meet the user needs and build emotional bond
with users, it is essential for social chatbots to incorporate more human-like
and advanced linguistic features. In this paper, we investigate the usage of a
commonly used rhetorical device by human -- metaphor for social chatbot. Our
work first designs a metaphor generation framework, which generates topic-aware
and novel figurative sentences. By embedding the framework into a chatbot
system, we then enables the chatbot to communicate with users using figurative
language. Human annotators validate the novelty and properness of the generated
metaphors. More importantly, we evaluate the effects of employing metaphors in
human-chatbot conversations. Experiments indicate that our system effectively
arouses user interests in communicating with our chatbot, resulting in
significantly longer human-chatbot conversations.
</summary>
    <author>
      <name>Danning Zheng</name>
    </author>
    <author>
      <name>Ruihua Song</name>
    </author>
    <author>
      <name>Tianran Hu</name>
    </author>
    <author>
      <name>Hao Fu</name>
    </author>
    <author>
      <name>Jin Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00572v2</id>
    <updated>2020-01-16T14:27:21Z</updated>
    <published>2020-01-03T03:43:35Z</published>
    <title>Read Beyond the Lines: Understanding the Implied Textual Meaning via a
  Skim and Intensive Reading Model</title>
    <summary>  The nonliteral interpretation of a text is hard to be understood by machine
models due to its high context-sensitivity and heavy usage of figurative
language. In this study, inspired by human reading comprehension, we propose a
novel, simple, and effective deep neural framework, called Skim and Intensive
Reading Model (SIRM), for figuring out implied textual meaning. The proposed
SIRM consists of two main components, namely the skim reading component and
intensive reading component. N-gram features are quickly extracted from the
skim reading component, which is a combination of several convolutional neural
networks, as skim (entire) information. An intensive reading component enables
a hierarchical investigation for both local (sentence) and global (paragraph)
representation, which encapsulates the current embedding and the contextual
information with a dense connection. More specifically, the contextual
information includes the near-neighbor information and the skim information
mentioned above. Finally, besides the normal training loss function, we employ
an adversarial loss function as a penalty over the skim reading component to
eliminate noisy information arisen from special figurative words in the
training data. To verify the effectiveness, robustness, and efficiency of the
proposed architecture, we conduct extensive comparative experiments on several
sarcasm benchmarks and an industrial spam dataset with metaphors. Experimental
results indicate that (1) the proposed model, which benefits from context
modeling and consideration of figurative language, outperforms existing
state-of-the-art solutions, with comparable parameter scale and training speed;
(2) the SIRM yields superior robustness in terms of parameter size sensitivity;
(3) compared with ablation and addition variants of the SIRM, the final
framework is efficient enough.
</summary>
    <author>
      <name>Guoxiu He</name>
    </author>
    <author>
      <name>Zhe Gao</name>
    </author>
    <author>
      <name>Zhuoren Jiang</name>
    </author>
    <author>
      <name>Yangyang Kang</name>
    </author>
    <author>
      <name>Changlong Sun</name>
    </author>
    <author>
      <name>Xiaozhong Liu</name>
    </author>
    <author>
      <name>Wei Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00572v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00572v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00571v1</id>
    <updated>2020-01-03T00:16:46Z</updated>
    <published>2020-01-03T00:16:46Z</published>
    <title>Question Type Classification Methods Comparison</title>
    <summary>  The paper presents a comparative study of state-of-the-art approaches for
question classification task: Logistic Regression, Convolutional Neural
Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent
Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and
trained on human-labeled data. The best accuracy is achieved using CNN model
with five convolutional layers and various kernel sizes stacked in parallel,
followed by one fully connected layer. The model reached 90.7% accuracy on TREC
10 test set. All the model architectures in this paper were developed from
scratch on PyTorch, in few cases based on reliable open-source implementation.
</summary>
    <author>
      <name>Tamirlan Seidakhmetov</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00569v1</id>
    <updated>2019-12-31T18:33:03Z</updated>
    <published>2019-12-31T18:33:03Z</published>
    <title>Emergent Behaviors from Folksonomy Driven Interactions</title>
    <summary>  To reflect the evolving knowledge on the Web this paper considers ontologies
based on folksonomies according to a new concept structure called
"Folksodriven" to represent folksonomies. This paper describes a research
program for studying Folksodriven tags interactions leading to Folksodriven
cluster behavior. The goal of the research is to understand the type of simple
local interactions which produce complex and purposive group behaviors on
Folksodriven tags. We describe a synthetic, bottom-up approach to studying
group behavior, consisting of designing and testing a variety of social
interactions and cultural scenarios with Folksodriven tags. We propose a set of
basic interactions which can be used to structure and simplify the process of
both designing and analyzing emergent group behaviors. The presented behavior
repertories was developed and tested on a folksonomy environment.
</summary>
    <author>
      <name>Massimiliano Dal Mas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures; for details see: http://www.maxdalmas.com arXiv
  admin note: text overlap with arXiv:1612.09574</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; G.1.10; G.2.2; H.1.1; H.1.2; H.3.1; H.3.3; H.3.5; H.5.2;&#10;  H.5.3; H.5.4; I.2.1; I.2.4; I.2.7; I.3.6; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13283v1</id>
    <updated>2019-12-31T12:11:35Z</updated>
    <published>2019-12-31T12:11:35Z</published>
    <title>oLMpics -- On what Language Model Pre-training Captures</title>
    <summary>  Recent success of pre-trained language models (LMs) has spurred widespread
interest in the language capabilities that they possess. However, efforts to
understand whether LM representations are useful for symbolic reasoning tasks
have been limited and scattered. In this work, we propose eight reasoning
tasks, which conceptually require operations such as comparison, conjunction,
and composition. A fundamental challenge is to understand whether the
performance of a LM on a task should be attributed to the pre-trained
representations or to the process of fine-tuning on the task data. To address
this, we propose an evaluation protocol that includes both zero-shot evaluation
(no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to
the learning curve of multiple controls, which paints a rich picture of the LM
capabilities. Our main findings are that: (a) different LMs exhibit
qualitatively different reasoning abilities, e.g., RoBERTa succeeds in
reasoning tasks where BERT fails completely; (b) LMs do not reason in an
abstract manner and are context-dependent, e.g., while RoBERTa can compare
ages, it can do so only when the ages are in the typical range of human ages;
(c) On half of our reasoning tasks all models fail completely. Our findings and
infrastructure can help future work on designing new datasets, models and
objective functions for pre-training.
</summary>
    <author>
      <name>Alon Talmor</name>
    </author>
    <author>
      <name>Yanai Elazar</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <author>
      <name>Jonathan Berant</name>
    </author>
    <link href="http://arxiv.org/abs/1912.13283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13082v2</id>
    <updated>2020-01-01T16:06:48Z</updated>
    <published>2019-12-30T21:03:59Z</published>
    <title>The Shmoop Corpus: A Dataset of Stories with Loosely Aligned Summaries</title>
    <summary>  Understanding stories is a challenging reading comprehension problem for
machines as it requires reading a large volume of text and following long-range
dependencies. In this paper, we introduce the Shmoop Corpus: a dataset of 231
stories that are paired with detailed multi-paragraph summaries for each
individual chapter (7,234 chapters), where the summary is chronologically
aligned with respect to the story chapter. From the corpus, we construct a set
of common NLP tasks, including Cloze-form question answering and a simplified
form of abstractive summarization, as benchmarks for reading comprehension on
stories. We then show that the chronological alignment provides a strong
supervisory signal that learning-based methods can exploit leading to
significant improvements on these tasks. We believe that the unique structure
of this corpus provides an important foothold towards making machine story
comprehension more approachable.
</summary>
    <author>
      <name>Atef Chaudhury</name>
    </author>
    <author>
      <name>Makarand Tapaswi</name>
    </author>
    <author>
      <name>Seung Wook Kim</name>
    </author>
    <author>
      <name>Sanja Fidler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: http://www.cs.toronto.edu/~makarand/shmoop/ Dataset at:
  https://github.com/achaudhury/shmoop-corpus/</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13082v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13082v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12800v1</id>
    <updated>2019-12-30T03:31:17Z</updated>
    <published>2019-12-30T03:31:17Z</published>
    <title>Likelihood Ratios and Generative Classifiers for Unsupervised
  Out-of-Domain Detection In Task Oriented Dialog</title>
    <summary>  The task of identifying out-of-domain (OOD) input examples directly at
test-time has seen renewed interest recently due to increased real world
deployment of models. In this work, we focus on OOD detection for natural
language sentence inputs to task-based dialog systems. Our findings are
three-fold: First, we curate and release ROSTD (Real Out-of-Domain Sentences
From Task-oriented Dialog) - a dataset of 4K OOD examples for the publicly
available dataset from (Schuster et al. 2019). In contrast to existing settings
which synthesize OOD examples by holding out a subset of classes, our examples
were authored by annotators with apriori instructions to be out-of-domain with
respect to the sentences in an existing dataset. Second, we explore likelihood
ratio based approaches as an alternative to currently prevalent paradigms.
Specifically, we reformulate and apply these approaches to natural language
inputs. We find that they match or outperform the latter on all datasets, with
larger improvements on non-artificial OOD benchmarks such as our dataset. Our
ablations validate that specifically using likelihood ratios rather than plain
likelihood is necessary to discriminate well between OOD and in-domain data.
Third, we propose learning a generative classifier and computing a marginal
likelihood (ratio) for OOD detection. This allows us to use a principled
likelihood while at the same time exploiting training-time labels. We find that
this approach outperforms both simple likelihood (ratio) based and other prior
approaches. We are hitherto the first to investigate the use of generative
classifiers for OOD detection at test-time.
</summary>
    <author>
      <name>Varun Gangal</name>
    </author>
    <author>
      <name>Abhinav Arora</name>
    </author>
    <author>
      <name>Arash Einolghozati</name>
    </author>
    <author>
      <name>Sonal Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for AAAI-2020 Main Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11739v2</id>
    <updated>2020-01-14T03:16:24Z</updated>
    <published>2019-12-26T01:12:31Z</published>
    <title>Coursera Corpus Mining and Multistage Fine-Tuning for Improving Lectures
  Translation</title>
    <summary>  Lectures translation is a case of spoken language translation and there is a
lack of publicly available parallel corpora for this purpose. To address this,
we examine a language independent framework for parallel corpus mining which is
a quick and effective way to mine a parallel corpus from publicly available
lectures at Coursera. Our approach determines sentence alignments, relying on
machine translation and cosine similarity over continuous-space sentence
representations. We also show how to use the resulting corpora in a multistage
fine-tuning based domain adaptation for high-quality lectures translation. For
Japanese--English lectures translation, we extracted parallel data of
approximately 40,000 lines and created development and test sets through manual
filtering for benchmarking translation performance. We demonstrate that the
mined corpus greatly enhances the quality of translation when used in
conjunction with out-of-domain parallel corpora via multistage training. This
paper also suggests some guidelines to gather and clean corpora, mine parallel
sentences, address noise in the mined data, and create high-quality evaluation
splits. For the sake of reproducibility, we will release our code for parallel
data creation.
</summary>
    <author>
      <name>Haiyue Song</name>
    </author>
    <author>
      <name>Raj Dabre</name>
    </author>
    <author>
      <name>Atsushi Fujita</name>
    </author>
    <author>
      <name>Sadao Kurohashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, 9 tables, under review by LREC2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11739v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11739v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11668v1</id>
    <updated>2019-12-25T13:43:44Z</updated>
    <published>2019-12-25T13:43:44Z</published>
    <title>Learning to Answer Ambiguous Questions with Knowledge Graph</title>
    <summary>  In the task of factoid question answering over knowledge base, many questions
have more than one plausible interpretation. Previous works on SimpleQuestions
assume only one interpretation as the ground truth for each question, so they
lack the ability to answer ambiguous questions correctly. In this paper, we
present a new way to utilize the dataset that takes into account the existence
of ambiguous questions. Then we introduce a simple and effective model which
combines local knowledge subgraph with attention mechanism. Our experimental
results show that our approach achieves outstanding performance in this task.
</summary>
    <author>
      <name>Yikai Zhu</name>
    </author>
    <author>
      <name>Jianhao Shen</name>
    </author>
    <author>
      <name>Ming Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10514v1</id>
    <updated>2019-12-22T19:20:10Z</updated>
    <published>2019-12-22T19:20:10Z</published>
    <title>Tag-less Back-Translation</title>
    <summary>  An effective method to generate a large number of parallel sentences for
training improved neural machine translation (NMT) systems is the use of
back-translations of the target-side monolingual data. Tagging, or using gates,
has been used to enable translation models to distinguish between synthetic and
natural data. This improves standard back-translation and also enables the use
of iterative back-translation on language pairs that underperformed using
standard back-translation. This work presents a simplified approach of
differentiating between the two data using pretraining and finetuning. The
approach - tag-less back-translation - trains the model on the synthetic data
and finetunes it on the natural data. Preliminary experiments have shown the
approach to continuously outperform the tagging approach on low resource
English-Vietnamese neural machine translation. While the need for tagging
(noising) the dataset has been removed, the approach outperformed the tagged
back-translation approach by an average of 0.4 BLEU.
</summary>
    <author>
      <name>Idris Abdulmumin</name>
    </author>
    <author>
      <name>Bashir Shehu Galadanci</name>
    </author>
    <author>
      <name>Aliyu Garba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to 2020 International Conference on Computer and
  Information Sciences, 5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10514v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10514v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00471v1</id>
    <updated>2019-12-20T18:58:25Z</updated>
    <published>2019-12-20T18:58:25Z</published>
    <title>A Voice Interactive Multilingual Student Support System using IBM Watson</title>
    <summary>  Systems powered by artificial intelligence are being developed to be more
user-friendly by communicating with users in a progressively human-like
conversational way. Chatbots, also known as dialogue systems, interactive
conversational agents, or virtual agents are an example of such systems used in
a wide variety of applications ranging from customer support in the business
domain to companionship in the healthcare sector. It is becoming increasingly
important to develop chatbots that can best respond to the personalized needs
of their users so that they can be as helpful to the user as possible in a real
human way. This paper investigates and compares three popular existing chatbots
API offerings and then propose and develop a voice interactive and multilingual
chatbot that can effectively respond to users mood, tone, and language using
IBM Watson Assistant, Tone Analyzer, and Language Translator. The chatbot was
evaluated using a use case that was targeted at responding to users needs
regarding exam stress based on university students survey data generated using
Google Forms. The results of measuring the chatbot effectiveness at analyzing
responses regarding exam stress indicate that the chatbot responding
appropriately to the user queries regarding how they are feeling about exams
76.5%. The chatbot could also be adapted for use in other application areas
such as student info-centers, government kiosks, and mental health support
systems.
</summary>
    <author>
      <name>Kennedy Ralston</name>
    </author>
    <author>
      <name>Yuhao Chen</name>
    </author>
    <author>
      <name>Haruna Isah</name>
    </author>
    <author>
      <name>Farhana Zulkernine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10000v2</id>
    <updated>2020-02-13T10:38:54Z</updated>
    <published>2019-12-20T18:31:33Z</published>
    <title>Probability Calibration for Knowledge Graph Embedding Models</title>
    <summary>  Knowledge graph embedding research has overlooked the problem of probability
calibration. We show popular embedding models are indeed uncalibrated. That
means probability estimates associated to predicted triples are unreliable. We
present a novel method to calibrate a model when ground truth negatives are not
available, which is the usual case in knowledge graphs. We propose to use Platt
scaling and isotonic regression alongside our method. Experiments on three
datasets with ground truth negatives show our contribution leads to
well-calibrated models when compared to the gold standard of using negatives.
We get significantly better results than the uncalibrated models from all
calibration methods. We show isotonic regression offers the best the
performance overall, not without trade-offs. We also show that calibrated
models reach state-of-the-art accuracy without the need to define
relation-specific decision thresholds.
</summary>
    <author>
      <name>Pedro Tabacof</name>
    </author>
    <author>
      <name>Luca Costabello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10000v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10000v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09551v1</id>
    <updated>2019-12-19T21:29:22Z</updated>
    <published>2019-12-19T21:29:22Z</published>
    <title>Deep Exemplar Networks for VQA and VQG</title>
    <summary>  In this paper, we consider the problem of solving semantic tasks such as
`Visual Question Answering' (VQA), where one aims to answers related to an
image and `Visual Question Generation' (VQG), where one aims to generate a
natural question pertaining to an image. Solutions for VQA and VQG tasks have
been proposed using variants of encoder-decoder deep learning based frameworks
that have shown impressive performance. Humans however often show
generalization by relying on exemplar based approaches. For instance, the work
by Tversky and Kahneman suggests that humans use exemplars when making
categorizations and decisions. In this work, we propose the incorporation of
exemplar based approaches towards solving these problems. Specifically, we
incorporate exemplar based approaches and show that an exemplar based module
can be incorporated in almost any of the deep learning architectures proposed
in the literature and the addition of such a block results in improved
performance for solving these tasks. Thus, just as the incorporation of
attention is now considered de facto useful for solving these tasks, similarly,
incorporating exemplars also can be considered to improve any proposed
architecture for solving this task. We provide extensive empirical analysis for
the same through various architectures, ablations, and state of the art
comparisons.
</summary>
    <author>
      <name>Badri N. Patro</name>
    </author>
    <author>
      <name>Vinay P. Namboodiri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work is an extension of CVPR-2018 accepted paper
  arXiv:1804.00298 and EMNLP-2018 accepted paper arXiv:1808.03986</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08633v1</id>
    <updated>2019-12-18T14:33:05Z</updated>
    <published>2019-12-18T14:33:05Z</published>
    <title>Semantic integration of disease-specific knowledge</title>
    <summary>  Biomedical researchers working on a specific disease need up-to-date and
unified access to knowledge relevant to the disease of their interest.
Knowledge is continuously accumulated in scientific literature and other
resources such as biomedical ontologies. Identifying the specific information
needed is a challenging task and computational tools can be valuable. In this
study, we propose a pipeline to automatically retrieve and integrate relevant
knowledge based on a semantic graph representation, the iASiS Open Data Graph.
  Results: The disease-specific semantic graph can provide easy access to
resources relevant to specific concepts and individual aspects of these
concepts, in the form of concept relations and attributes. The proposed
approach is applied to three different case studies: Two prevalent diseases,
Lung Cancer and Dementia, for which a lot of knowledge is available, and one
rare disease, Duchenne Muscular Dystrophy, for which knowledge is less abundant
and difficult to locate. Results from exemplary queries are presented,
investigating the potential of this approach in integrating and accessing
knowledge as an automatically generated semantic graph.
</summary>
    <author>
      <name>Anastasios Nentidis</name>
    </author>
    <author>
      <name>Konstantinos Bougiatiotis</name>
    </author>
    <author>
      <name>Anastasia Krithara</name>
    </author>
    <author>
      <name>Georgios Paliouras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08442v1</id>
    <updated>2019-12-18T08:14:10Z</updated>
    <published>2019-12-18T08:14:10Z</published>
    <title>MALA: Cross-Domain Dialogue Generation with Action Learning</title>
    <summary>  Response generation for task-oriented dialogues involves two basic
components: dialogue planning and surface realization. These two components,
however, have a discrepancy in their objectives, i.e., task completion and
language quality. To deal with such discrepancy, conditioned response
generation has been introduced where the generation process is factorized into
action decision and language generation via explicit action representations. To
obtain action representations, recent studies learn latent actions in an
unsupervised manner based on the utterance lexical similarity. Such an action
learning approach is prone to diversities of language surfaces, which may
impinge task completion and language quality. To address this issue, we propose
multi-stage adaptive latent action learning (MALA) that learns semantic latent
actions by distinguishing the effects of utterances on dialogue progress. We
model the utterance effect using the transition of dialogue states caused by
the utterance and develop a semantic similarity measurement that estimates
whether utterances have similar effects. For learning semantic actions on
domains without dialogue states, MsALA extends the semantic similarity
measurement across domains progressively, i.e., from aligning shared actions to
learning domain-specific actions. Experiments using multi-domain datasets, SMD
and MultiWOZ, show that our proposed model achieves consistent improvements
over the baselines models in terms of both task completion and language
quality.
</summary>
    <author>
      <name>Xinting Huang</name>
    </author>
    <author>
      <name>Jianzhong Qi</name>
    </author>
    <author>
      <name>Yu Sun</name>
    </author>
    <author>
      <name>Rui Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08441v2</id>
    <updated>2019-12-19T02:12:09Z</updated>
    <published>2019-12-18T08:13:43Z</published>
    <title>Multi-channel Reverse Dictionary Model</title>
    <summary>  A reverse dictionary takes the description of a target word as input and
outputs the target word together with other words that match the description.
Existing reverse dictionary methods cannot deal with highly variable input
queries and low-frequency target words successfully. Inspired by the
description-to-word inference process of humans, we propose the multi-channel
reverse dictionary model, which can mitigate the two problems simultaneously.
Our model comprises a sentence encoder and multiple predictors. The predictors
are expected to identify different characteristics of the target word from the
input query. We evaluate our model on English and Chinese datasets including
both dictionary definitions and human-written descriptions. Experimental
results show that our model achieves the state-of-the-art performance, and even
outperforms the most popular commercial reverse dictionary system on the
human-written description dataset. We also conduct quantitative analyses and a
case study to demonstrate the effectiveness and robustness of our model. All
the code and data of this work can be obtained on
https://github.com/thunlp/MultiRD.
</summary>
    <author>
      <name>Lei Zhang</name>
    </author>
    <author>
      <name>Fanchao Qi</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <author>
      <name>Yasheng Wang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI Conference on Artificial Intelligence 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08441v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08441v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08404v1</id>
    <updated>2019-12-18T06:25:12Z</updated>
    <published>2019-12-18T06:25:12Z</published>
    <title>Collective Embedding-based Entity Alignment via Adaptive Features</title>
    <summary>  Entity alignment (EA) identifies entities that refer to the same real-world
object but locate in different knowledge graphs (KGs), and has been harnessed
for KG construction and integration. When generating EA results, current
embedding-based solutions treat entities independently and fail to take into
account the interdependence between entities. In addition, most of
embedding-based EA methods either fuse different features on
representation-level and generate unified entity embedding for alignment, which
potentially causes information loss, or aggregate features on outcome-level
with hand-tuned weights, which is not practical with increasing numbers of
features. To tackle these deficiencies, we propose a collective embedding-based
EA framework with adaptive feature fusion mechanism. We first employ three
representative features, i.e., structural, semantic and string signals, for
capturing different aspects of the similarity between entities in heterogeneous
KGs. These features are then integrated at outcome-level, with dynamically
assigned weights generated by our carefully devised adaptive feature fusion
strategy. Eventually, in order to make collective EA decisions, we formulate EA
as the classical stable matching problem between entities to be aligned, with
preference lists constructed using fused feature matrix. It is further
effectively solved by deferred acceptance algorithm. Our proposal is evaluated
on both cross-lingual and mono-lingual EA benchmarks against state-of-the-art
solutions, and the empirical results verify its effectiveness and superiority.
We also perform ablation study to gain insights into framework modules.
</summary>
    <author>
      <name>Wexin Zeng</name>
    </author>
    <author>
      <name>Xiang Zhao</name>
    </author>
    <author>
      <name>Jiuyang Tang</name>
    </author>
    <author>
      <name>Xuemin Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08374v3</id>
    <updated>2020-01-24T03:49:50Z</updated>
    <published>2019-12-18T04:32:18Z</published>
    <title>Uncovering Relations for Marketing Knowledge Representation</title>
    <summary>  Online behaviors of consumers and marketers generate massive marketing data,
which ever more sophisticated models attempt to turn into insights and aid
decisions by marketers. Yet, in making decisions human managers bring to bear
marketing knowledge which reside outside of data and models. Thus, it behooves
creation of an automated marketing knowledge base that can interact with data
and models. Currently, marketing knowledge is dispersed in large corpora, but
no definitive knowledge base for marketing exists. Out of the two broad aspects
of marketing knowledge - representation and reasoning - this treatise focuses
on the former. Specifically, we focus on creation of marketing knowledge graph
from corpora, which requires identification of entities and relations. The
relation identification task is particularly challenging in marketing, because
of the non-factoid nature of much marketing knowledge, and the difficulty of
forming rules that govern relations. Specifically, we define a set of relations
to capture marketing knowledge, propose a pipeline for creating the knowledge
graph from text and propose a rule-guided semi-supervised relation prediction
algorithm to extract relations between marketing entities from sentences.
</summary>
    <author>
      <name>Somak Aditya</name>
    </author>
    <author>
      <name>Atanu Sinha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, 8 tables (2 page Appendix)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08374v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08374v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07915v1</id>
    <updated>2019-12-17T10:33:17Z</updated>
    <published>2019-12-17T10:33:17Z</published>
    <title>Knowledge-Enhanced Attentive Learning for Answer Selection in Community
  Question Answering Systems</title>
    <summary>  In the community question answering (CQA) system, the answer selection task
aims to identify the best answer for a specific question, and thus is playing a
key role in enhancing the service quality through recommending appropriate
answers for new questions. Recent advances in CQA answer selection focus on
enhancing the performance by incorporating the community information,
particularly the expertise (previous answers) and authority (position in the
social network) of an answerer. However, existing approaches for incorporating
such information are limited in (a) only considering either the expertise or
the authority, but not both; (b) ignoring the domain knowledge to differentiate
topics of previous answers; and (c) simply using the authority information to
adjust the similarity score, instead of fully utilizing it in the process of
measuring the similarity between segments of the question and the answer. We
propose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which
enhances the performance through (a) considering both the expertise and the
authority of the answerer; (b) utilizing the human-labeled tags, the taxonomy
of the tags, and the votes as the domain knowledge to infer the expertise of
the answer; (c) using matrix decomposition of the social network (formed by
following-relationship) to infer the authority of the answerer and
incorporating such information in the process of evaluating the similarity
between segments. Besides, for vertical community, we incorporate an external
knowledge graph to capture more professional information for vertical CQA
systems. Then we adopt the attention mechanism to integrate the analysis of the
text of questions and answers and the aforementioned community information.
Experiments with both vertical and general CQA sites demonstrate the superior
performance of the proposed KAAS model.
</summary>
    <author>
      <name>Fengshi Jing</name>
    </author>
    <author>
      <name>Qingpeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07840v2</id>
    <updated>2020-02-15T18:48:42Z</updated>
    <published>2019-12-17T06:53:05Z</published>
    <title>Cross-Lingual Ability of Multilingual BERT: An Empirical Study</title>
    <summary>  Recent work has exhibited the surprising cross-lingual abilities of
multilingual BERT (M-BERT) -- surprising since it is trained without any
cross-lingual objective and with no aligned data. In this work, we provide a
comprehensive study of the contribution of different components in M-BERT to
its cross-lingual ability. We study the impact of linguistic properties of the
languages, the architecture of the model, and the learning objectives. The
experimental study is done in the context of three typologically different
languages -- Spanish, Hindi, and Russian -- and using two conceptually
different NLP tasks, textual entailment and named entity recognition. Among our
key conclusions is the fact that the lexical overlap between languages plays a
negligible role in the cross-lingual success, while the depth of the network is
an integral part of it. All our models and implementations can be found on our
project page: http://cogcomp.org/page/publication_view/900 .
</summary>
    <author>
      <name>Karthikeyan K</name>
    </author>
    <author>
      <name>Zihan Wang</name>
    </author>
    <author>
      <name>Stephen Mayhew</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07421v1</id>
    <updated>2019-12-16T14:45:56Z</updated>
    <published>2019-12-16T14:45:56Z</published>
    <title>Semantic Similarity To Improve Question Understanding in a Virtual
  Patient</title>
    <summary>  In medicine, a communicating virtual patient or doctor allows students to
train in medical diagnosis and develop skills to conduct a medical
consultation. In this paper, we describe a conversational virtual standardized
patient system to allow medical students to simulate a diagnosis strategy of an
abdominal surgical emergency. We exploited the semantic properties captured by
distributed word representations to search for similar questions in the virtual
patient dialogue system. We created two dialogue systems that were evaluated on
datasets collected during tests with students. The first system based on
hand-crafted rules obtains $92.29\%$ as $F1$-score on the studied clinical case
while the second system that combines rules and semantic similarity achieves
$94.88\%$. It represents an error reduction of $9.70\%$ as compared to the
rules-only-based system.
</summary>
    <author>
      <name>Fréjus A. A. Laleye</name>
    </author>
    <author>
      <name>Antonia Blanié</name>
    </author>
    <author>
      <name>Antoine Brouquet</name>
    </author>
    <author>
      <name>Dan Behnamou</name>
    </author>
    <author>
      <name>Gaël de Chalendar</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10818v1</id>
    <updated>2019-12-15T19:48:48Z</updated>
    <published>2019-12-15T19:48:48Z</published>
    <title>Artificial mental phenomena: Psychophysics as a framework to detect
  perception biases in AI models</title>
    <summary>  Detecting biases in artificial intelligence has become difficult because of
the impenetrable nature of deep learning. The central difficulty is in relating
unobservable phenomena deep inside models with observable, outside quantities
that we can measure from inputs and outputs. For example, can we detect
gendered perceptions of occupations (e.g., female librarian, male electrician)
using questions to and answers from a word embedding-based system? Current
techniques for detecting biases are often customized for a task, dataset, or
method, affecting their generalization. In this work, we draw from
Psychophysics in Experimental Psychology---meant to relate quantities from the
real world (i.e., "Physics") into subjective measures in the mind (i.e.,
"Psyche")---to propose an intellectually coherent and generalizable framework
to detect biases in AI. Specifically, we adapt the two-alternative forced
choice task (2AFC) to estimate potential biases and the strength of those
biases in black-box models. We successfully reproduce previously-known biased
perceptions in word embeddings and sentiment analysis predictions. We discuss
how concepts in experimental psychology can be naturally applied to
understanding artificial mental phenomena, and how psychophysics can form a
useful methodological foundation to study fairness in AI.
</summary>
    <author>
      <name>Lizhen Liang</name>
    </author>
    <author>
      <name>Daniel E. Acuna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3351095.3375623</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3351095.3375623" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">FAT Conference 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.10818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06825v1</id>
    <updated>2019-12-14T11:02:17Z</updated>
    <published>2019-12-14T11:02:17Z</published>
    <title>Knowledge forest: a novel model to organize knowledge fragments</title>
    <summary>  With the rapid growth of knowledge, it shows a steady trend of knowledge
fragmentization. Knowledge fragmentization manifests as that the knowledge
related to a specific topic in a course is scattered in isolated and autonomous
knowledge sources. We term the knowledge of a facet in a specific topic as a
knowledge fragment. The problem of knowledge fragmentization brings two
challenges: First, knowledge is scattered in various knowledge sources, which
exerts users' considerable efforts to search for the knowledge of their
interested topics, thereby leading to information overload. Second, learning
dependencies which refer to the precedence relationships between topics in the
learning process are concealed by the isolation and autonomy of knowledge
sources, thus causing learning disorientation. To solve the knowledge
fragmentization problem, we propose a novel knowledge organization model,
knowledge forest, which consists of facet trees and learning dependencies.
Facet trees can organize knowledge fragments with facet hyponymy to alleviate
information overload. Learning dependencies can organize disordered topics to
cope with learning disorientation. We conduct extensive experiments on three
manually constructed datasets from the Data Structure, Data Mining, and
Computer Network courses, and the experimental results show that knowledge
forest can effectively organize knowledge fragments, and alleviate information
overload and learning disorientation.
</summary>
    <author>
      <name>Qinghua Zheng</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <author>
      <name>Hongwei Zeng</name>
    </author>
    <author>
      <name>Zhaotong Guo</name>
    </author>
    <author>
      <name>Bei Wu</name>
    </author>
    <author>
      <name>Bifan Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figures, Accepted for publication in Science China
  Information Science</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.06745v1</id>
    <updated>2019-12-13T23:32:38Z</updated>
    <published>2019-12-13T23:32:38Z</published>
    <title>An Unsupervised Domain-Independent Framework for Automated Detection of
  Persuasion Tactics in Text</title>
    <summary>  With the increasing growth of social media, people have started relying
heavily on the information shared therein to form opinions and make decisions.
While such a reliance is motivation for a variety of parties to promote
information, it also makes people vulnerable to exploitation by slander,
misinformation, terroristic and predatorial advances. In this work, we aim to
understand and detect such attempts at persuasion. Existing works on detecting
persuasion in text make use of lexical features for detecting persuasive
tactics, without taking advantage of the possible structures inherent in the
tactics used. We formulate the task as a multi-class classification problem and
propose an unsupervised, domain-independent machine learning framework for
detecting the type of persuasion used in text, which exploits the inherent
sentence structure present in the different persuasion tactics. Our work shows
promising results as compared to existing work.
</summary>
    <author>
      <name>Rahul Radhakrishnan Iyer</name>
    </author>
    <author>
      <name>Katia Sycara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 8 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.06745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.06745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05877v1</id>
    <updated>2019-12-12T11:02:30Z</updated>
    <published>2019-12-12T11:02:30Z</published>
    <title>Extending Machine Language Models toward Human-Level Language
  Understanding</title>
    <summary>  Language is central to human intelligence. We review recent breakthroughs in
machine language processing and consider what remains to be achieved. Recent
approaches rely on domain general principles of learning and representation
captured in artificial neural networks. Most current models, however, focus too
closely on language itself. In humans, language is part of a larger system for
acquiring, representing, and communicating about objects and situations in the
physical and social world, and future machine language models should emulate
such a system. We describe existing machine models linking language to concrete
situations, and point toward extensions to address more abstract cases. Human
language processing exploits complementary learning systems, including a deep
neural network-like learning system that learns gradually as machine systems
do, as well as a fast-learning system that supports learning new information
quickly. Adding such a system to machine language models will be an important
further step toward truly human-like language understanding.
</summary>
    <author>
      <name>James L. McClelland</name>
    </author>
    <author>
      <name>Felix Hill</name>
    </author>
    <author>
      <name>Maja Rudolph</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05728v1</id>
    <updated>2019-12-12T02:04:44Z</updated>
    <published>2019-12-12T02:04:44Z</published>
    <title>AliMe KBQA: Question Answering over Structured Knowledge for E-commerce
  Customer Service</title>
    <summary>  With the rise of knowledge graph (KG), question answering over knowledge base
(KBQA) has attracted increasing attention in recent years. Despite much
research has been conducted on this topic, it is still challenging to apply
KBQA technology in industry because business knowledge and real-world questions
can be rather complicated. In this paper, we present AliMe-KBQA, a bold attempt
to apply KBQA in the E-commerce customer service field. To handle real
knowledge and questions, we extend the classic "subject-predicate-object (SPO)"
structure with property hierarchy, key-value structure and compound value type
(CVT), and enhance traditional KBQA with constraints recognition and reasoning
ability. We launch AliMe-KBQA in the Marketing Promotion scenario for merchants
during the "Double 11" period in 2018 and other such promotional events
afterwards. Online results suggest that AliMe-KBQA is not only able to gain
better resolution and improve customer satisfaction, but also becomes the
preferred knowledge management method by business knowledge staffs since it
offers a more convenient and efficient management experience.
</summary>
    <author>
      <name>Feng-Lin Li</name>
    </author>
    <author>
      <name>Weijia Chen</name>
    </author>
    <author>
      <name>Qi Huang</name>
    </author>
    <author>
      <name>Yikun Guo</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05525v1</id>
    <updated>2019-12-11T18:48:05Z</updated>
    <published>2019-12-11T18:48:05Z</published>
    <title>Learning to Request Guidance in Emergent Communication</title>
    <summary>  Previous research into agent communication has shown that a pre-trained guide
can speed up the learning process of an imitation learning agent. The guide
achieves this by providing the agent with discrete messages in an emerged
language about how to solve the task. We extend this one-directional
communication by a one-bit communication channel from the learner back to the
guide: It is able to ask the guide for help, and we limit the guidance by
penalizing the learner for these requests. During training, the agent learns to
control this gate based on its current observation. We find that the amount of
requested guidance decreases over time and guidance is requested in situations
of high uncertainty. We investigate the agent's performance in cases of open
and closed gates and discuss potential motives for the observed gating
behavior.
</summary>
    <author>
      <name>Benjamin Kolb</name>
    </author>
    <author>
      <name>Leon Lang</name>
    </author>
    <author>
      <name>Henning Bartsch</name>
    </author>
    <author>
      <name>Arwin Gansekoele</name>
    </author>
    <author>
      <name>Raymond Koopmanschap</name>
    </author>
    <author>
      <name>Leonardo Romor</name>
    </author>
    <author>
      <name>David Speck</name>
    </author>
    <author>
      <name>Mathijs Mul</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05238v1</id>
    <updated>2019-12-11T11:27:06Z</updated>
    <published>2019-12-11T11:27:06Z</published>
    <title>BERT has a Moral Compass: Improvements of ethical and moral values of
  machines</title>
    <summary>  Allowing machines to choose whether to kill humans would be devastating for
world peace and security. But how do we equip machines with the ability to
learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying
machine learning to human texts can extract deontological ethical reasoning
about "right" and "wrong" conduct by calculating a moral bias score on a
sentence level using sentence embeddings. The machine learned that it is
objectionable to kill living beings, but it is fine to kill time; It is
essential to eat, yet one might not eat dirt; it is important to spread
information, yet one should not spread misinformation. However, the evaluated
moral bias was restricted to simple actions -- one verb -- and a ranking of
actions with surrounding context. Recently BERT ---and variants such as RoBERTa
and SBERT--- has set a new state-of-the-art performance for a wide range of NLP
tasks. But has BERT also a better moral compass? In this paper, we discuss and
show that this is indeed the case. Thus, recent improvements of language
representations also improve the representation of the underlying ethical and
moral values of the machine. We argue that through an advanced semantic
representation of text, BERT allows one to get better insights of moral and
ethical values implicitly represented in text. This enables the Moral Choice
Machine (MCM) to extract more accurate imprints of moral choices and ethical
values.
</summary>
    <author>
      <name>Patrick Schramowski</name>
    </author>
    <author>
      <name>Cigdem Turan</name>
    </author>
    <author>
      <name>Sophie Jentzsch</name>
    </author>
    <author>
      <name>Constantin Rothkopf</name>
    </author>
    <author>
      <name>Kristian Kersting</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03553v1</id>
    <updated>2019-12-07T20:12:43Z</updated>
    <published>2019-12-07T20:12:43Z</published>
    <title>Learning Norms from Stories: A Prior for Value Aligned Agents</title>
    <summary>  Value alignment is a property of an intelligent agent indicating that it can
only pursue goals and activities that are beneficial to humans. Traditional
approaches to value alignment use imitation learning or preference learning to
infer the values of humans by observing their behavior. We introduce a
complementary technique in which a value aligned prior is learned from
naturally occurring stories which encode societal norms. Training data is
sourced from the childrens educational comic strip, Goofus and Gallant. In this
work, we train multiple machine learning models to classify natural language
descriptions of situations found in the comic strip as normative or non
normative by identifying if they align with the main characters behavior. We
also report the models performance when transferring to two unrelated tasks
with little to no additional training on the new task.
</summary>
    <author>
      <name>Spencer Frazier</name>
    </author>
    <author>
      <name>Md Sultan Al Nahian</name>
    </author>
    <author>
      <name>Mark Riedl</name>
    </author>
    <author>
      <name>Brent Harrison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AIES 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03393v1</id>
    <updated>2019-12-06T23:46:37Z</updated>
    <published>2019-12-06T23:46:37Z</published>
    <title>Re-Translation Strategies For Long Form, Simultaneous, Spoken Language
  Translation</title>
    <summary>  We investigate the problem of simultaneous machine translation of long-form
speech content. We target a continuous speech-to-text scenario, generating
translated captions for a live audio feed, such as a lecture or play-by-play
commentary. As this scenario allows for revisions to our incremental
translations, we adopt a re-translation approach to simultaneous translation,
where the source is repeatedly translated from scratch as it grows. This
approach naturally exhibits very low latency and high final quality, but at the
cost of incremental instability as the output is continuously refined. We
experiment with a pipeline of industry-grade speech recognition and translation
tools, augmented with simple inference heuristics to improve stability. We use
TED Talks as a source of multilingual test data, developing our techniques on
English-to-German spoken language translation. Our minimalist approach to
simultaneous translation allows us to easily scale our final evaluation to six
more target languages, dramatically improving incremental stability for all of
them.
</summary>
    <author>
      <name>Naveen Arivazhagan</name>
    </author>
    <author>
      <name>Colin Cherry</name>
    </author>
    <author>
      <name>Te I</name>
    </author>
    <author>
      <name>Wolfgang Macherey</name>
    </author>
    <author>
      <name>Pallavi Baljekar</name>
    </author>
    <author>
      <name>George Foster</name>
    </author>
    <link href="http://arxiv.org/abs/1912.03393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.03184v3</id>
    <updated>2020-03-03T13:32:42Z</updated>
    <published>2019-12-06T15:30:58Z</published>
    <title>GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception</title>
    <summary>  Most research on emotion analysis from text focuses on the task of emotion
classification or emotion intensity regression. Fewer works address emotions as
a phenomenon to be tackled with structured learning, which can be explained by
the lack of relevant datasets. We fill this gap by releasing a dataset of 5000
English news headlines annotated via crowdsourcing with their associated
emotions, the corresponding emotion experiencers and textual cues, related
emotion causes and targets, as well as the reader's perception of the emotion
of the headline. This annotation task is comparably challenging, given the
large number of classes and roles to be identified. We therefore propose a
multiphase annotation procedure in which we first find relevant instances with
emotional content and then annotate the more fine-grained aspects. Finally, we
develop a baseline for the task of automatic prediction of semantic role
structures and discuss the results. The corpus we release enables further
research on emotion classification, emotion intensity prediction, emotion cause
detection, and supports further qualitative studies.
</summary>
    <author>
      <name>Laura Bostan</name>
    </author>
    <author>
      <name>Evgeny Kim</name>
    </author>
    <author>
      <name>Roman Klinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.03184v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.03184v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.02164v4</id>
    <updated>2020-03-03T05:33:49Z</updated>
    <published>2019-12-04T18:32:15Z</published>
    <title>Plug and Play Language Models: A Simple Approach to Controlled Text
  Generation</title>
    <summary>  Large transformer-based language models (LMs) trained on huge text corpora
have shown unparalleled generation capabilities. However, controlling
attributes of the generated language (e.g. switching topic or sentiment) is
difficult without modifying the model architecture or fine-tuning on
attribute-specific data and entailing the significant cost of retraining. We
propose a simple alternative: the Plug and Play Language Model (PPLM) for
controllable language generation, which combines a pretrained LM with one or
more simple attribute classifiers that guide text generation without any
further training of the LM. In the canonical scenario we present, the attribute
models are simple classifiers consisting of a user-specified bag of words or a
single learned layer with 100,000 times fewer parameters than the LM. Sampling
entails a forward and backward pass in which gradients from the attribute model
push the LM's hidden activations and thus guide the generation. Model samples
demonstrate control over a range of topics and sentiment styles, and extensive
automated and human annotated evaluations show attribute alignment and fluency.
PPLMs are flexible in that any combination of differentiable attribute models
may be used to steer text generation, which will allow for diverse and creative
applications beyond the examples given in this paper.
</summary>
    <author>
      <name>Sumanth Dathathri</name>
    </author>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Janice Lan</name>
    </author>
    <author>
      <name>Jane Hung</name>
    </author>
    <author>
      <name>Eric Frank</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Jason Yosinski</name>
    </author>
    <author>
      <name>Rosanne Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020 camera ready</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.02164v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.02164v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10160v1</id>
    <updated>2019-12-04T17:35:03Z</updated>
    <published>2019-12-04T17:35:03Z</published>
    <title>AMUSED: A Multi-Stream Vector Representation Method for Use in Natural
  Dialogue</title>
    <summary>  The problem of building a coherent and non-monotonous conversational agent
with proper discourse and coverage is still an area of open research. Current
architectures only take care of semantic and contextual information for a given
query and fail to completely account for syntactic and external knowledge which
are crucial for generating responses in a chit-chat system. To overcome this
problem, we propose an end to end multi-stream deep learning architecture which
learns unified embeddings for query-response pairs by leveraging contextual
information from memory networks and syntactic information by incorporating
Graph Convolution Networks (GCN) over their dependency parse. A stream of this
network also utilizes transfer learning by pre-training a bidirectional
transformer to extract semantic representation for each input sentence and
incorporates external knowledge through the the neighborhood of the entities
from a Knowledge Base (KB). We benchmark these embeddings on next sentence
prediction task and significantly improve upon the existing techniques.
Furthermore, we use AMUSED to represent query and responses along with its
context to develop a retrieval based conversational agent which has been
validated by expert linguists to have comprehensive engagement with humans.
</summary>
    <author>
      <name>Gaurav Kumar</name>
    </author>
    <author>
      <name>Rishabh Joshi</name>
    </author>
    <author>
      <name>Jaspreet Singh</name>
    </author>
    <author>
      <name>Promod Yenigalla</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01795v1</id>
    <updated>2019-12-04T04:39:32Z</updated>
    <published>2019-12-04T04:39:32Z</published>
    <title>Towards Building a Multilingual Sememe Knowledge Base: Predicting
  Sememes for BabelNet Synsets</title>
    <summary>  A sememe is defined as the minimum semantic unit of human languages. Sememe
knowledge bases (KBs), which contain words annotated with sememes, have been
successfully applied to many NLP tasks. However, existing sememe KBs are built
on only a few languages, which hinders their widespread utilization. To address
the issue, we propose to build a unified sememe KB for multiple languages based
on BabelNet, a multilingual encyclopedic dictionary. We first build a dataset
serving as the seed of the multilingual sememe KB. It manually annotates
sememes for over $15$ thousand synsets (the entries of BabelNet). Then, we
present a novel task of automatic sememe prediction for synsets, aiming to
expand the seed dataset into a usable KB. We also propose two simple and
effective models, which exploit different information of synsets. Finally, we
conduct quantitative and qualitative analyses to explore important factors and
difficulties in the task. All the source code and data of this work can be
obtained on https://github.com/thunlp/BabelNet-Sememe-Prediction.
</summary>
    <author>
      <name>Fanchao Qi</name>
    </author>
    <author>
      <name>Liang Chang</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <author>
      <name>Sicong Ouyang</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI Conference on Artificial Intelligence 2020 for oral
  presentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.01795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01734v1</id>
    <updated>2019-12-03T23:18:59Z</updated>
    <published>2019-12-03T23:18:59Z</published>
    <title>ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday
  Tasks</title>
    <summary>  We present ALFRED (Action Learning From Realistic Environments and
Directives), a benchmark for learning a mapping from natural language
instructions and egocentric vision to sequences of actions for household tasks.
Long composition rollouts with non-reversible state changes are among the
phenomena we include to shrink the gap between research benchmarks and
real-world applications. ALFRED consists of expert demonstrations in
interactive visual environments for 25k natural language directives. These
directives contain both high-level goals like "Rinse off a mug and place it in
the coffee maker." and low-level language instructions like "Walk to the coffee
maker on the right." ALFRED tasks are more complex in terms of sequence length,
action space, and language than existing vision-and-language task datasets. We
show that a baseline model designed for recent embodied vision-and-language
tasks performs poorly on ALFRED, suggesting that there is significant room for
developing innovative grounded visual language understanding models with this
benchmark.
</summary>
    <author>
      <name>Mohit Shridhar</name>
    </author>
    <author>
      <name>Jesse Thomason</name>
    </author>
    <author>
      <name>Daniel Gordon</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Winson Han</name>
    </author>
    <author>
      <name>Roozbeh Mottaghi</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <author>
      <name>Dieter Fox</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://askforalfred.com/</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.01734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01220v1</id>
    <updated>2019-12-03T07:02:38Z</updated>
    <published>2019-12-03T07:02:38Z</published>
    <title>Modelling Semantic Categories using Conceptual Neighborhood</title>
    <summary>  While many methods for learning vector space embeddings have been proposed in
the field of Natural Language Processing, these methods typically do not
distinguish between categories and individuals. Intuitively, if individuals are
represented as vectors, we can think of categories as (soft) regions in the
embedding space. Unfortunately, meaningful regions can be difficult to
estimate, especially since we often have few examples of individuals that
belong to a given category. To address this issue, we rely on the fact that
different categories are often highly interdependent. In particular, categories
often have conceptual neighbors, which are disjoint from but closely related to
the given category (e.g.\ fruit and vegetable). Our hypothesis is that more
accurate category representations can be learned by relying on the assumption
that the regions representing such conceptual neighbors should be adjacent in
the embedding space. We propose a simple method for identifying conceptual
neighbors and then show that incorporating these conceptual neighbors indeed
leads to more accurate region based representations.
</summary>
    <author>
      <name>Zied Bouraoui</name>
    </author>
    <author>
      <name>Jose Camacho-Collados</name>
    </author>
    <author>
      <name>Luis Espinosa-Anke</name>
    </author>
    <author>
      <name>Steven Schockaert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.01220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00879v3</id>
    <updated>2020-02-03T03:13:40Z</updated>
    <published>2019-12-02T15:57:40Z</published>
    <title>Improving Question Generation with Sentence-level Semantic Matching and
  Answer Position Inferring</title>
    <summary>  Taking an answer and its context as input, sequence-to-sequence models have
made considerable progress on question generation. However, we observe that
these approaches often generate wrong question words or keywords and copy
answer-irrelevant words from the input. We believe that lacking global question
semantics and exploiting answer position-awareness not well are the key root
causes. In this paper, we propose a neural question generation model with two
concrete modules: sentence-level semantic matching and answer position
inferring. Further, we enhance the initial state of the decoder by leveraging
the answer-aware gated fusion mechanism. Experimental results demonstrate that
our model outperforms the state-of-the-art (SOTA) models on SQuAD and MARCO
datasets. Owing to its generality, our work also improves the existing models
significantly.
</summary>
    <author>
      <name>Xiyao Ma</name>
    </author>
    <author>
      <name>Qile Zhu</name>
    </author>
    <author>
      <name>Yanlin Zhou</name>
    </author>
    <author>
      <name>Xiaolin Li</name>
    </author>
    <author>
      <name>Dapeng Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version of paper accepted to Thirty-fourth AAAI Conference on
  Artificial Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00879v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00879v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00819v2</id>
    <updated>2019-12-05T15:31:54Z</updated>
    <published>2019-12-02T14:29:22Z</published>
    <title>Enriching Existing Conversational Emotion Datasets with Dialogue Acts
  using Neural Annotators</title>
    <summary>  The recognition of emotion and dialogue acts enrich conversational analysis
and help to build natural dialogue systems. Emotion makes us understand
feelings and dialogue acts reflect the intentions and performative functions in
the utterances. However, most of the textual and multi-modal conversational
emotion datasets contain only emotion labels but not dialogue acts. To address
this problem, we propose to use a pool of various recurrent neural models
trained on a dialogue act corpus, with or without context. These neural models
annotate the emotion corpus with dialogue act labels and an ensemble annotator
extracts the final dialogue act label. We annotated two popular multi-modal
emotion datasets: IEMOCAP and MELD. We analysed the co-occurrence of emotion
and dialogue act labels and discovered specific relations. For example,
Accept/Agree dialogue acts often occur with the Joy emotion, Apology with
Sadness, and Thanking with Joy. We make the Emotional Dialogue Act (EDA) corpus
publicly available to the research community for further study and analysis.
</summary>
    <author>
      <name>Chandrakant Bothe</name>
    </author>
    <author>
      <name>Cornelius Weber</name>
    </author>
    <author>
      <name>Sven Magg</name>
    </author>
    <author>
      <name>Stefan Wermter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00819v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00819v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00730v1</id>
    <updated>2019-12-02T12:57:52Z</updated>
    <published>2019-12-02T12:57:52Z</published>
    <title>SemEval-2017 Task 3: Community Question Answering</title>
    <summary>  We describe SemEval-2017 Task 3 on Community Question Answering. This year,
we reran the four subtasks from SemEval-2016:(A) Question-Comment
Similarity,(B) Question-Question Similarity,(C) Question-External Comment
Similarity, and (D) Rerank the correct answers for a new question in Arabic,
providing all the data from 2015 and 2016 for training, and fresh data for
testing. Additionally, we added a new subtask E in order to enable
experimentation with Multi-domain Question Duplicate Detection in a
larger-scale scenario, using StackExchange subforums. A total of 23 teams
participated in the task, and submitted a total of 85 runs (36 primary and 49
contrastive) for subtasks A-D. Unfortunately, no teams participated in subtask
E. A variety of approaches and features were used by the participating systems
to address the different subtasks. The best systems achieved an official score
(MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D,
respectively. These scores are better than the baselines, especially for
subtasks A-C.
</summary>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Doris Hoogeveen</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Alessandro Moschitti</name>
    </author>
    <author>
      <name>Hamdy Mubarak</name>
    </author>
    <author>
      <name>Timothy Baldwin</name>
    </author>
    <author>
      <name>Karin Verspoor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">community question answering, question-question similarity,
  question-comment similarity, answer reranking, Multi-domain Question
  Duplicate Detection, StackExchange, English, Arabic</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.00730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00690v1</id>
    <updated>2019-12-02T11:32:53Z</updated>
    <published>2019-12-02T11:32:53Z</published>
    <title>EduBERT: Pretrained Deep Language Models for Learning Analytics</title>
    <summary>  The use of large pretrained neural networks to create contextualized word
embeddings has drastically improved performance on several natural language
processing (NLP) tasks. These computationally expensive models have begun to be
applied to domain-specific NLP tasks such as re-hospitalization prediction from
clinical notes. This paper demonstrates that using large pretrained models
produces excellent results on common learning analytics tasks. Pre-training
deep language models using student forum data from a wide array of online
courses improves performance beyond the state of the art on three text
classification tasks. We also show that a smaller, distilled version of our
model produces the best results on two of the three tasks while limiting
computational cost. We make both models available to the research community at
large.
</summary>
    <author>
      <name>Benjamin Clavié</name>
    </author>
    <author>
      <name>Kobi Gal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for poster presentation at the 10th International Learning
  Analytics and Knowledge (LAK20) Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00667v1</id>
    <updated>2019-12-02T10:18:27Z</updated>
    <published>2019-12-02T10:18:27Z</published>
    <title>A Human-AI Loop Approach for Joint Keyword Discovery and Expectation
  Estimation in Micropost Event Detection</title>
    <summary>  Microblogging platforms such as Twitter are increasingly being used in event
detection. Existing approaches mainly use machine learning models and rely on
event-related keywords to collect the data for model training. These approaches
make strong assumptions on the distribution of the relevant micro-posts
containing the keyword -- referred to as the expectation of the distribution --
and use it as a posterior regularization parameter during model training. Such
approaches are, however, limited as they fail to reliably estimate the
informativeness of a keyword and its expectation for model training. This paper
introduces a Human-AI loop approach to jointly discover informative keywords
for model training while estimating their expectation. Our approach iteratively
leverages the crowd to estimate both keyword specific expectation and the
disagreement between the crowd and the model in order to discover new keywords
that are most beneficial for model training. These keywords and their
expectation not only improve the resulting performance but also make the model
training process more transparent. We empirically demonstrate the merits of our
approach, both in terms of accuracy and interpretability, on multiple
real-world datasets and show that our approach improves the state of the art by
24.3%.
</summary>
    <author>
      <name>Akansha Bhardwaj</name>
    </author>
    <author>
      <name>Jie Yang</name>
    </author>
    <author>
      <name>Philippe Cudré-Mauroux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at AAAI, 2020</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI, 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.00667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00569v1</id>
    <updated>2019-12-02T03:14:23Z</updated>
    <published>2019-12-02T03:14:23Z</published>
    <title>Abstract Reasoning with Distracting Features</title>
    <summary>  Abstraction reasoning is a long-standing challenge in artificial
intelligence. Recent studies suggest that many of the deep architectures that
have triumphed over other domains failed to work well in abstract reasoning. In
this paper, we first illustrate that one of the main challenges in such a
reasoning task is the presence of distracting features, which requires the
learning algorithm to leverage counterevidence and to reject any of the false
hypotheses in order to learn the true patterns. We later show that carefully
designed learning trajectory over different categories of training data can
effectively boost learning performance by mitigating the impacts of distracting
features. Inspired by this fact, we propose feature robust abstract reasoning
(FRAR) model, which consists of a reinforcement learning based teacher network
to determine the sequence of training and a student network for predictions.
Experimental results demonstrated strong improvements over baseline algorithms
and we are able to beat the state-of-the-art models by 18.7% in the RAVEN
dataset and 13.3% in the PGM dataset.
</summary>
    <author>
      <name>Kecheng Zheng</name>
    </author>
    <author>
      <name>Zheng-jun Zha</name>
    </author>
    <author>
      <name>Wei Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00512v2</id>
    <updated>2020-02-29T05:26:23Z</updated>
    <published>2019-12-01T22:36:14Z</published>
    <title>Knowledge Infused Learning (K-IL): Towards Deep Incorporation of
  Knowledge in Deep Learning</title>
    <summary>  Learning the underlying patterns in data goes beyond instance-based
generalization to external knowledge represented in structured graphs or
networks. Deep learning that primarily constitutes neural computing stream in
AI has shown significant advances in probabilistically learning latent patterns
using a multi-layered network of computational nodes (i.e., neurons/hidden
units). Structured knowledge that underlies symbolic computing approaches and
often supports reasoning, has also seen significant growth in recent years, in
the form of broad-based (e.g., DBPedia, Yago) and domain, industry or
application specific knowledge graphs. A common substrate with careful
integration of the two will raise opportunities to develop neuro-symbolic
learning approaches for AI, where conceptual and probabilistic representations
are combined. As the incorporation of external knowledge will aid in
supervising the learning of features for the model, deep infusion of
representational knowledge from knowledge graphs within hidden layers will
further enhance the learning process. Although much work remains, we believe
that knowledge graphs will play an increasing role in developing hybrid
neuro-symbolic intelligent systems (bottom-up deep learning with top-down
symbolic computing) as well as in building explainable AI systems for which
knowledge graphs will provide scaffolding for punctuating neural computing. In
this position paper, we describe our motivation for such a neuro-symbolic
approach and framework that combines knowledge graph and neural networks.
</summary>
    <author>
      <name>Ugur Kursuncu</name>
    </author>
    <author>
      <name>Manas Gaur</name>
    </author>
    <author>
      <name>Amit Sheth</name>
    </author>
    <link href="http://arxiv.org/abs/1912.00512v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00512v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00398v1</id>
    <updated>2019-12-01T13:03:03Z</updated>
    <published>2019-12-01T13:03:03Z</published>
    <title>AntNet: Deep Answer Understanding Network for Natural Reverse QA</title>
    <summary>  This study refers to a reverse question answering(reverse QA) procedure, in
which machines proactively raise questions and humans supply answers. This
procedure exists in many real human-machine interaction applications. A crucial
problem in human-machine interaction is answer understanding. Existing
solutions rely on mandatory option term selection to avoid automatic answer
understanding. However, these solutions lead to unnatural human-computer
interaction and harm user experience. To this end, this study proposed a novel
deep answer understanding network, called AntNet, for reverse QA. The network
consists of three new modules, namely, skeleton extraction for questions,
relevance-aware representation of answers, and multi-hop based fusion. As
answer understanding for reverse QA has not been explored, a new data corpus is
compiled in this study. Experimental results indicate that our proposed network
is significantly better than existing methods and those modified from classical
natural language processing (NLP) deep models. The effectiveness of the three
new modules is also verified.
</summary>
    <author>
      <name>Lei Yang</name>
    </author>
    <author>
      <name>Qing Yin</name>
    </author>
    <author>
      <name>Linlin Hou</name>
    </author>
    <author>
      <name>Jie Gui</name>
    </author>
    <author>
      <name>Ou Wu</name>
    </author>
    <author>
      <name>James Kwok</name>
    </author>
    <link href="http://arxiv.org/abs/1912.00398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00147v2</id>
    <updated>2019-12-03T06:36:36Z</updated>
    <published>2019-11-30T07:13:25Z</published>
    <title>Integrating Graph Contextualized Knowledge into Pre-trained Language
  Models</title>
    <summary>  Complex node interactions are common in knowledge graphs, and these
interactions also contain rich knowledge information. However, traditional
methods usually treat a triple as a training unit during the knowledge
representation learning (KRL) procedure, neglecting contextualized information
of the nodes in knowledge graphs (KGs). We generalize the modeling object to a
very general form, which theoretically supports any subgraph extracted from the
knowledge graph, and these subgraphs are fed into a novel transformer-based
model to learn the knowledge embeddings. To broaden usage scenarios of
knowledge, pre-trained language models are utilized to build a model that
incorporates the learned knowledge representations. Experimental results
demonstrate that our model achieves the state-of-the-art performance on several
medical NLP tasks, and improvement above TransE indicates that our KRL method
captures the graph contextualized information effectively.
</summary>
    <author>
      <name>Bin He</name>
    </author>
    <author>
      <name>Di Zhou</name>
    </author>
    <author>
      <name>Jinghui Xiao</name>
    </author>
    <author>
      <name>Xin jiang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <author>
      <name>Nicholas Jing Yuan</name>
    </author>
    <author>
      <name>Tong Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00147v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00147v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.13182v1</id>
    <updated>2019-11-29T16:34:00Z</updated>
    <published>2019-11-29T16:34:00Z</published>
    <title>An Iterative Polishing Framework based on Quality Aware Masked Language
  Model for Chinese Poetry Generation</title>
    <summary>  Owing to its unique literal and aesthetical characteristics, automatic
generation of Chinese poetry is still challenging in Artificial Intelligence,
which can hardly be straightforwardly realized by end-to-end methods. In this
paper, we propose a novel iterative polishing framework for highly qualified
Chinese poetry generation. In the first stage, an encoder-decoder structure is
utilized to generate a poem draft. Afterwards, our proposed Quality-Aware
Masked Language Model (QAMLM) is employed to polish the draft towards higher
quality in terms of linguistics and literalness. Based on a multi-task learning
scheme, QA-MLM is able to determine whether polishing is needed based on the
poem draft. Furthermore, QAMLM is able to localize improper characters of the
poem draft and substitute with newly predicted ones accordingly. Benefited from
the masked language model structure, QAMLM incorporates global context
information into the polishing process, which can obtain more appropriate
polishing results than the unidirectional sequential decoding. Moreover, the
iterative polishing process will be terminated automatically when QA-MLM
regards the processed poem as a qualified one. Both human and automatic
evaluation have been conducted, and the results demonstrate that our approach
is effective to improve the performance of encoder-decoder structure.
</summary>
    <author>
      <name>Liming Deng</name>
    </author>
    <author>
      <name>Jie Wang</name>
    </author>
    <author>
      <name>Hangming Liang</name>
    </author>
    <author>
      <name>Hui Chen</name>
    </author>
    <author>
      <name>Zhiqiang Xie</name>
    </author>
    <author>
      <name>Bojin Zhuang</name>
    </author>
    <author>
      <name>Shaojun Wang</name>
    </author>
    <author>
      <name>Jing Xiao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by AAAI-2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.13182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.13182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.12753v1</id>
    <updated>2019-11-28T15:38:53Z</updated>
    <published>2019-11-28T15:38:53Z</published>
    <title>Inducing Relational Knowledge from BERT</title>
    <summary>  One of the most remarkable properties of word embeddings is the fact that
they capture certain types of semantic and syntactic relationships. Recently,
pre-trained language models such as BERT have achieved groundbreaking results
across a wide range of Natural Language Processing tasks. However, it is
unclear to what extent such models capture relational knowledge beyond what is
already captured by standard word embeddings. To explore this question, we
propose a methodology for distilling relational knowledge from a pre-trained
language model. Starting from a few seed instances of a given relation, we
first use a large text corpus to find sentences that are likely to express this
relation. We then use a subset of these extracted sentences as templates.
Finally, we fine-tune a language model to predict whether a given word pair is
likely to be an instance of some relation, when given an instantiated template
for that relation as input.
</summary>
    <author>
      <name>Zied Bouraoui</name>
    </author>
    <author>
      <name>Jose Camacho-Collados</name>
    </author>
    <author>
      <name>Steven Schockaert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.12753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.12547v1</id>
    <updated>2019-11-28T06:05:12Z</updated>
    <published>2019-11-28T06:05:12Z</published>
    <title>DiscoTK: Using Discourse Structure for Machine Translation Evaluation</title>
    <summary>  We present novel automatic metrics for machine translation evaluation that
use discourse structure and convolution kernels to compare the discourse tree
of an automatic translation with that of the human reference. We experiment
with five transformations and augmentations of a base discourse tree
representation based on the rhetorical structure theory, and we combine the
kernel scores for each of them into a single score. Finally, we add other
metrics from the ASIYA MT evaluation toolkit, and we tune the weights of the
combination on actual human judgments. Experiments on the WMT12 and WMT13
metrics shared task datasets show correlation with human judgments that
outperforms what the best systems that participated in these years achieved,
both at the segment and at the system level.
</summary>
    <author>
      <name>Shafiq Joty</name>
    </author>
    <author>
      <name>Francisco Guzman</name>
    </author>
    <author>
      <name>Lluis Marquez</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">machine translation evaluation, machine translation, tree kernels,
  discourse, convolutional kernels, discourse tree, RST, rhetorical structure
  theory, ASIYA</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WMT-2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.12547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.12091v1</id>
    <updated>2019-11-27T11:45:15Z</updated>
    <published>2019-11-27T11:45:15Z</published>
    <title>Findings of the 2016 WMT Shared Task on Cross-lingual Pronoun Prediction</title>
    <summary>  We describe the design, the evaluation setup, and the results of the 2016 WMT
shared task on cross-lingual pronoun prediction. This is a classification task
in which participants are asked to provide predictions on what pronoun class
label should replace a placeholder value in the target-language text, provided
in lemmatised and PoS-tagged form. We provided four subtasks, for the
English-French and English-German language pairs, in both directions. Eleven
teams participated in the shared task; nine for the English-French subtask,
five for French-English, nine for English-German, and six for German-English.
Most of the submissions outperformed two strong language-model based baseline
systems, with systems using deep recurrent neural networks outperforming those
using other architectures for most language pairs.
</summary>
    <author>
      <name>Liane Guillou</name>
    </author>
    <author>
      <name>Christian Hardmeier</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Sara Stymne</name>
    </author>
    <author>
      <name>Jörg Tiedemann</name>
    </author>
    <author>
      <name>Yannick Versley</name>
    </author>
    <author>
      <name>Mauro Cettolo</name>
    </author>
    <author>
      <name>Bonnie Webber</name>
    </author>
    <author>
      <name>Andrei Popescu-Belis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">cross-lingual pronoun prediction, WMT, shared task, English, German,
  French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WMT-2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.12091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.12085v1</id>
    <updated>2019-11-27T11:25:43Z</updated>
    <published>2019-11-27T11:25:43Z</published>
    <title>Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web
  as a Corpus</title>
    <summary>  Responding to the need for semantic lexical resources in natural language
processing applications, we examine methods to acquire noun compounds (NCs),
e.g., "orange juice", together with suitable fine-grained semantic
interpretations, e.g., "squeezed from", which are directly usable as
paraphrases. We employ bootstrapping and web statistics, and utilize the
relationship between NCs and paraphrasing patterns to jointly extract NCs and
such patterns in multiple alternating iterations. In evaluation, we found that
having one compound noun fixed yields both a higher number of semantically
interpreted NCs and improved accuracy due to stronger semantic restrictions.
</summary>
    <author>
      <name>Su Nam Kim</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">noun compounds, paraphrasing verbs, paraphrases, semantic
  interpretation, bootstrapping, semi-supervised learning</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.12085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11931v1</id>
    <updated>2019-11-27T03:22:40Z</updated>
    <published>2019-11-27T03:22:40Z</published>
    <title>Evaluating Commonsense in Pre-trained Language Models</title>
    <summary>  Contextualized representations trained over large raw text data have given
remarkable improvements for NLP tasks including question answering and reading
comprehension. There have been works showing that syntactic, semantic and word
sense knowledge are contained in such representations, which explains why they
benefit such tasks. However, relatively little work has been done investigating
commonsense knowledge contained in contextualized representations, which is
crucial for human question answering and reading comprehension. We study the
commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven
challenging benchmarks, finding that language modeling and its variants are
effective objectives for promoting models' commonsense ability while
bi-directional context and larger training set are bonuses. We additionally
find that current models do poorly on tasks require more necessary inference
steps. Finally, we test the robustness of models by making dual test cases,
which are correlated so that the correct prediction of one sample should lead
to correct prediction of the other. Interestingly, the models show confusion on
these test cases, which suggests that they learn commonsense at the surface
rather than the deep level. We release a test set, named CATs publicly, for
future research.
</summary>
    <author>
      <name>Xuhui Zhou</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Leyang Cui</name>
    </author>
    <author>
      <name>Dandan Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11668v2</id>
    <updated>2019-12-27T19:36:13Z</updated>
    <published>2019-11-26T16:07:44Z</published>
    <title>Biology and Compositionality: Empirical Considerations for
  Emergent-Communication Protocols</title>
    <summary>  Significant advances have been made in artificial systems by using biological
systems as a guide. However, there is often little interaction between
computational models for emergent communication and biological models of the
emergence of language. Many researchers in language origins and emergent
communication take compositionality as their primary target for explaining how
simple communication systems can become more like natural language. However,
there is reason to think that compositionality is the wrong target on the
biological side, and so too the wrong target on the machine-learning side. As
such, the purpose of this paper is to explore this claim. This has theoretical
implications for language origins research more generally, but the focus here
will be the implications for research on emergent communication in computer
science and machine learning---specifically regarding the types of programmes
that might be expected to work and those which will not. I further suggest an
alternative approach for future research which focuses on reflexivity, rather
than compositionality, as a target for explaining how simple communication
systems may become more like natural language. I end by providing some
reference to the language origins literature that may be of some use to
researchers in machine learning.
</summary>
    <author>
      <name>Travis LaCroix</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for NeurIPS 2019 workshop Emergent Communication: Towards
  Natural Language</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11668v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11668v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11641v1</id>
    <updated>2019-11-26T15:31:46Z</updated>
    <published>2019-11-26T15:31:46Z</published>
    <title>PIQA: Reasoning about Physical Commonsense in Natural Language</title>
    <summary>  To apply eyeshadow without a brush, should I use a cotton swab or a
toothpick? Questions requiring this kind of physical commonsense pose a
challenge to today's natural language understanding systems. While recent
pretrained models (such as BERT) have made progress on question answering over
more abstract domains - such as news articles and encyclopedia entries, where
text is plentiful - in more physical domains, text is inherently limited due to
reporting bias. Can AI systems learn to reliably answer physical common-sense
questions without experiencing the physical world? In this paper, we introduce
the task of physical commonsense reasoning and a corresponding benchmark
dataset Physical Interaction: Question Answering or PIQA. Though humans find
the dataset easy (95% accuracy), large pretrained models struggle (77%). We
provide analysis about the dimensions of knowledge that existing models lack,
which offers significant opportunities for future research.
</summary>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Rowan Zellers</name>
    </author>
    <author>
      <name>Ronan Le Bras</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11503v1</id>
    <updated>2019-11-26T13:05:33Z</updated>
    <published>2019-11-26T13:05:33Z</published>
    <title>Feature-Rich Part-of-speech Tagging for Morphologically Complex
  Languages: Application to Bulgarian</title>
    <summary>  We present experiments with part-of-speech tagging for Bulgarian, a Slavic
language with rich inflectional and derivational morphology. Unlike most
previous work, which has used a small number of grammatical categories, we work
with 680 morpho-syntactic tags. We combine a large morphological lexicon with
prior linguistic knowledge and guided learning from a POS-annotated corpus,
achieving accuracy of 97.98%, which is a significant improvement over the
state-of-the-art for Bulgarian.
</summary>
    <author>
      <name>Georgi Georgiev</name>
    </author>
    <author>
      <name>Valentin Zhikov</name>
    </author>
    <author>
      <name>Petya Osenova</name>
    </author>
    <author>
      <name>Kiril Simov</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">part-of-speech tagging, POS tagging, morpho-syntactic tags, guided
  learning, Bulgarian, Slavic</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EACL-2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.11503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11423v2</id>
    <updated>2019-11-27T12:00:15Z</updated>
    <published>2019-11-26T09:45:33Z</published>
    <title>Single Headed Attention RNN: Stop Thinking With Your Head</title>
    <summary>  The leading approaches in language modeling are all obsessed with TV shows of
my youth - namely Transformers and Sesame Street. Transformers this,
Transformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer
scale silicon. We opt for the lazy path of old and proven techniques with a
fancy crypto inspired acronym: the Single Headed Attention RNN (SHA-RNN). The
author's lone goal is to show that the entire field might have evolved a
different direction if we had instead been obsessed with a slightly different
acronym and slightly different result. We take a previously strong language
model based only on boring LSTMs and get it to within a stone's throw of a
stone's throw of state-of-the-art byte level language model results on enwik8.
This work has undergone no intensive hyperparameter optimization and lived
entirely on a commodity desktop machine that made the author's small studio
apartment far too warm in the midst of a San Franciscan summer. The final
results are achievable in plus or minus 24 hours on a single GPU as the author
is impatient. The attention mechanism is also readily extended to large
contexts with minimal computation. Take that Sesame Street.
</summary>
    <author>
      <name>Stephen Merity</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Addition of citations and contextual results (no attention head,
  single attention head, attention per layer), removal of wordpiece
  WikiText-103 numbers due to normalization issues, fix of SHA attention figure
  Q arrow, other minor fixes</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11423v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11423v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11403v1</id>
    <updated>2019-11-26T08:40:49Z</updated>
    <published>2019-11-26T08:40:49Z</published>
    <title>SemEval-2015 Task 3: Answer Selection in Community Question Answering</title>
    <summary>  Community Question Answering (cQA) provides new interesting research
directions to the traditional Question Answering (QA) field, e.g., the
exploitation of the interaction between users and the structure of related
posts. In this context, we organized SemEval-2015 Task 3 on "Answer Selection
in cQA", which included two subtasks: (a) classifying answers as "good", "bad",
or "potentially relevant" with respect to the question, and (b) answering a
YES/NO question with "yes", "no", or "unsure", based on the list of all
answers. We set subtask A for Arabic and English on two relatively different
cQA domains, i.e., the Qatar Living website for English, and a Quran-related
website for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a
large English training dataset, which we released to the research community.
Thirteen teams participated in the challenge with a total of 61 submissions: 24
primary and 37 contrastive. The best systems achieved an official score
(macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and
78.55 for the Arabic subtask A.
</summary>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Walid Magdy</name>
    </author>
    <author>
      <name>Alessandro Moschitti</name>
    </author>
    <author>
      <name>James Glass</name>
    </author>
    <author>
      <name>Bilal Randeree</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">community question answering, answer selection, English, Arabic</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.11403v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11403v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11298v1</id>
    <updated>2019-11-26T01:01:37Z</updated>
    <published>2019-11-26T01:01:37Z</published>
    <title>Few-Shot Knowledge Graph Completion</title>
    <summary>  Knowledge graphs (KGs) serve as useful resources for various natural language
processing applications. Previous KG completion approaches require a large
number of training instances (i.e., head-tail entity pairs) for every relation.
The real case is that for most of the relations, very few entity pairs are
available. Existing work of one-shot learning limits method generalizability
for few-shot scenarios and does not fully use the supervisory information;
however, few-shot KG completion has not been well studied yet. In this work, we
propose a novel few-shot relation learning model (FSRL) that aims at
discovering facts of new relations with few-shot references. FSRL can
effectively capture knowledge from heterogeneous graph structure, aggregate
representations of few-shot references, and match similar entity pairs of
reference set for every relation. Extensive experiments on two public datasets
demonstrate that FSRL outperforms the state-of-the-art.
</summary>
    <author>
      <name>Chuxu Zhang</name>
    </author>
    <author>
      <name>Huaxiu Yao</name>
    </author>
    <author>
      <name>Chao Huang</name>
    </author>
    <author>
      <name>Meng Jiang</name>
    </author>
    <author>
      <name>Zhenhui Li</name>
    </author>
    <author>
      <name>Nitesh V. Chawla</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10776v1</id>
    <updated>2019-11-25T09:21:17Z</updated>
    <published>2019-11-25T09:21:17Z</published>
    <title>Filling Conversation Ellipsis for Better Social Dialog Understanding</title>
    <summary>  The phenomenon of ellipsis is prevalent in social conversations. Ellipsis
increases the difficulty of a series of downstream language understanding
tasks, such as dialog act prediction and semantic role labeling. We propose to
resolve ellipsis through automatic sentence completion to improve language
understanding. However, automatic ellipsis completion can result in output
which does not accurately reflect user intent. To address this issue, we
propose a method which considers both the original utterance that has ellipsis
and the automatically completed utterance in dialog act and semantic role
labeling tasks. Specifically, we first complete user utterances to resolve
ellipsis using an end-to-end pointer network model. We then train a prediction
model using both utterances containing ellipsis and our automatically completed
utterances. Finally, we combine the prediction results from these two
utterances using a selection model that is guided by expert knowledge. Our
approach improves dialog act prediction and semantic role labeling by 1.3% and
2.5% in F1 score respectively in social conversations. We also present an
open-domain human-machine conversation dataset with manually completed user
utterances and annotated semantic role labeling after manual completion.
</summary>
    <author>
      <name>Xiyuan Zhang</name>
    </author>
    <author>
      <name>Chengxi Li</name>
    </author>
    <author>
      <name>Dian Yu</name>
    </author>
    <author>
      <name>Samuel Davidson</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.10776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10763v1</id>
    <updated>2019-11-25T08:29:37Z</updated>
    <published>2019-11-25T08:29:37Z</published>
    <title>Corpus Wide Argument Mining -- a Working Solution</title>
    <summary>  One of the main tasks in argument mining is the retrieval of argumentative
content pertaining to a given topic. Most previous work addressed this task by
retrieving a relatively small number of relevant documents as the initial
source for such content. This line of research yielded moderate success, which
is of limited use in a real-world system. Furthermore, for such a system to
yield a comprehensive set of relevant arguments, over a wide range of topics,
it requires leveraging a large and diverse corpus in an appropriate manner.
Here we present a first end-to-end high-precision, corpus-wide argument mining
system. This is made possible by combining sentence-level queries over an
appropriate indexing of a very large corpus of newspaper articles, with an
iterative annotation scheme. This scheme addresses the inherent label bias in
the data and pinpoints the regions of the sample space whose manual labeling is
required to obtain high-precision among top-ranked candidates.
</summary>
    <author>
      <name>Liat Ein-Dor</name>
    </author>
    <author>
      <name>Eyal Shnarch</name>
    </author>
    <author>
      <name>Lena Dankin</name>
    </author>
    <author>
      <name>Alon Halfon</name>
    </author>
    <author>
      <name>Benjamin Sznajder</name>
    </author>
    <author>
      <name>Ariel Gera</name>
    </author>
    <author>
      <name>Carlos Alzate</name>
    </author>
    <author>
      <name>Martin Gleize</name>
    </author>
    <author>
      <name>Leshem Choshen</name>
    </author>
    <author>
      <name>Yufang Hou</name>
    </author>
    <author>
      <name>Yonatan Bilu</name>
    </author>
    <author>
      <name>Ranit Aharonov</name>
    </author>
    <author>
      <name>Noam Slonim</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.10763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10742v1</id>
    <updated>2019-11-25T07:34:37Z</updated>
    <published>2019-11-25T07:34:37Z</published>
    <title>End-to-End Trainable Non-Collaborative Dialog System</title>
    <summary>  End-to-end task-oriented dialog models have achieved promising performance on
collaborative tasks where users willingly coordinate with the system to
complete a given task. While in non-collaborative settings, for example,
negotiation and persuasion, users and systems do not share a common goal. As a
result, compared to collaborate tasks, people use social content to build
rapport and trust in these non-collaborative settings in order to advance their
goals. To handle social content, we introduce a hierarchical intent annotation
scheme, which can be generalized to different non-collaborative dialog tasks.
Building upon TransferTransfo (Wolf et al. 2019), we propose an end-to-end
neural network model to generate diverse coherent responses. Our model utilizes
intent and semantic slots as the intermediate sentence representation to guide
the generation process. In addition, we design a filter to select appropriate
responses based on whether these intermediate representations fit the designed
task and conversation constraints. Our non-collaborative dialog model guides
users to complete the task while simultaneously keeps them engaged. We test our
approach on our newly proposed ANTISCAM dataset and an existing
PERSUASIONFORGOOD dataset. Both automatic and human evaluations suggest that
our model outperforms multiple baselines in these two non-collaborative tasks.
</summary>
    <author>
      <name>Yu Li</name>
    </author>
    <author>
      <name>Kun Qian</name>
    </author>
    <author>
      <name>Weiyan Shi</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.10742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00864v1</id>
    <updated>2019-11-25T07:06:25Z</updated>
    <published>2019-11-25T07:06:25Z</published>
    <title>Conclusion-Supplement Answer Generation for Non-Factoid Questions</title>
    <summary>  This paper tackles the goal of conclusion-supplement answer generation for
non-factoid questions, which is a critical issue in the field of Natural
Language Processing (NLP) and Artificial Intelligence (AI), as users often
require supplementary information before accepting a conclusion. The current
encoder-decoder framework, however, has difficulty generating such answers,
since it may become confused when it tries to learn several different long
answers to the same non-factoid question. Our solution, called an ensemble
network, goes beyond single short sentences and fuses logically connected
conclusion statements and supplementary statements. It extracts the context
from the conclusion decoder's output sequence and uses it to create
supplementary decoder states on the basis of an attention mechanism. It also
assesses the closeness of the question encoder's output sequence and the
separate outputs of the conclusion and supplement decoders as well as their
combination. As a result, it generates answers that match the questions and
have natural-sounding supplementary sequences in line with the context
expressed by the conclusion sequence. Evaluations conducted on datasets
including "Love Advice" and "Arts &amp; Humanities" categories indicate that our
model outputs much more accurate results than the tested baseline models do.
</summary>
    <author>
      <name>Makoto Nakatsuji</name>
    </author>
    <author>
      <name>Sohei Okui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI-2020 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10708v1</id>
    <updated>2019-11-25T05:46:56Z</updated>
    <published>2019-11-25T05:46:56Z</published>
    <title>hauWE: Hausa Words Embedding for Natural Language Processing</title>
    <summary>  Words embedding (distributed word vector representations) have become an
essential component of many natural language processing (NLP) tasks such as
machine translation, sentiment analysis, word analogy, named entity recognition
and word similarity. Despite this, the only work that provides word vectors for
Hausa language is that of Bojanowski et al. [1] trained using fastText,
consisting of only a few words vectors. This work presents words embedding
models using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)
models. The models, hauWE (Hausa Words Embedding), are bigger and better than
the only previous model, making them more useful in NLP tasks. To compare the
models, they were used to predict the 10 most similar words to 30 randomly
selected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction
accuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.
</summary>
    <author>
      <name>Idris Abdulmumin</name>
    </author>
    <author>
      <name>Bashir Shehu Galadanci</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/NigeriaComputConf45974.2019.8949674</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/NigeriaComputConf45974.2019.8949674" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 2019 2nd International Conference of the IEEE
  Nigeria Computer Chapter</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.10708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10484v2</id>
    <updated>2019-12-02T17:37:11Z</updated>
    <published>2019-11-24T09:32:55Z</published>
    <title>Task-Oriented Dialog Systems that Consider Multiple Appropriate
  Responses under the Same Context</title>
    <summary>  Conversations have an intrinsic one-to-many property, which means that
multiple responses can be appropriate for the same dialog context. In
task-oriented dialogs, this property leads to different valid dialog policies
towards task completion. However, none of the existing task-oriented dialog
generation approaches takes this property into account. We propose a
Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many
property to generate diverse appropriate dialog responses. Specifically, we
first use dialog states to summarize the dialog history, and then discover all
possible mappings from every dialog state to its different valid system
actions. During dialog system training, we enable the current dialog state to
map to all valid system actions discovered in the previous process to create
additional state-action pairs. By incorporating these additional pairs, the
dialog policy learns a balanced action distribution, which further guides the
dialog model to generate diverse responses. Experimental results show that the
proposed framework consistently improves dialog policy diversity, and results
in improved response diversity and appropriateness. Our model obtains
state-of-the-art results on MultiWOZ.
</summary>
    <author>
      <name>Yichi Zhang</name>
    </author>
    <author>
      <name>Zhijian Ou</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.10484v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10484v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10422v1</id>
    <updated>2019-11-23T21:49:10Z</updated>
    <published>2019-11-23T21:49:10Z</published>
    <title>SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations
  Between Pairs of Nominals</title>
    <summary>  In response to the continuing research interest in computational semantic
analysis, we have proposed a new task for SemEval-2010: multi-way
classification of mutually exclusive semantic relations between pairs of
nominals. The task is designed to compare different approaches to the problem
and to provide a standard testbed for future research. In this paper, we define
the task, describe the creation of the datasets, and discuss the results of the
participating 28 systems submitted by 10 teams.
</summary>
    <author>
      <name>Iris Hendrickx</name>
    </author>
    <author>
      <name>Su Nam Kim</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Diarmuid Ó Séaghdha</name>
    </author>
    <author>
      <name>Sebastian Padó</name>
    </author>
    <author>
      <name>Marco Pennacchiotti</name>
    </author>
    <author>
      <name>Lorenza Romano</name>
    </author>
    <author>
      <name>Stan Szpakowicz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">semantic relations, nominals</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.10422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10421v1</id>
    <updated>2019-11-23T21:42:23Z</updated>
    <published>2019-11-23T21:42:23Z</published>
    <title>SemEval-2013 Task 4: Free Paraphrases of Noun Compounds</title>
    <summary>  In this paper, we describe SemEval-2013 Task 4: the definition, the data, the
evaluation and the results. The task is to capture some of the meaning of
English noun compounds via paraphrasing. Given a two-word noun compound, the
participating system is asked to produce an explicitly ranked list of its
free-form paraphrases. The list is automatically compared and evaluated against
a similarly ranked list of paraphrases proposed by human annotators, recruited
and managed through Amazon's Mechanical Turk. The comparison of raw paraphrases
is sensitive to syntactic and morphological variation. The "gold" ranking is
based on the relative popularity of paraphrases among annotators. To make the
ranking more reliable, highly similar paraphrases are grouped, so as to
downplay superficial differences in syntax and morphology. Three systems
participated in the task. They all beat a simple baseline on one of the two
evaluation measures, but not on both measures. This shows that the task is
difficult.
</summary>
    <author>
      <name>Iris Hendrickx</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Stan Szpakowicz</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <author>
      <name>Diarmuid Ó Séaghdha</name>
    </author>
    <author>
      <name>Tony Veale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">noun compounds, paraphrasing verbs, semantic interpretation,
  multi-word expressions, MWEs</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.10421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10183v2</id>
    <updated>2019-11-29T14:16:44Z</updated>
    <published>2019-11-22T18:31:53Z</published>
    <title>Interactive Text Ranking with Bayesian Optimisation: A Case Study on
  Community QA and Summarisation</title>
    <summary>  For many NLP applications, such as question answering and summarisation, the
goal is to select the best solution from a large space of candidates to meet a
particular user's needs. To address the lack of user-specific training data, we
propose an interactive text ranking approach that actively selects pairs of
candidates, from which the user selects the best. Unlike previous strategies,
which attempt to learn a ranking across the whole candidate space, our method
employs Bayesian optimisation to focus the user's labelling effort on high
quality candidates and integrates prior knowledge in a Bayesian manner to cope
better with small data scenarios. We apply our method to community question
answering (cQA) and extractive summarisation, finding that it significantly
outperforms existing interactive approaches. We also show that the ranking
function learned by our method is an effective reward function for
reinforcement learning, which improves the state of the art for interactive
summarisation.
</summary>
    <author>
      <name>Edwin Simpson</name>
    </author>
    <author>
      <name>Yang Gao</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <link href="http://arxiv.org/abs/1911.10183v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10183v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10154v1</id>
    <updated>2019-11-22T17:25:32Z</updated>
    <published>2019-11-22T17:25:32Z</published>
    <title>Moral Dilemmas for Artificial Intelligence: a position paper on an
  application of Compositional Quantum Cognition</title>
    <summary>  Traditionally, the way one evaluates the performance of an Artificial
Intelligence (AI) system is via a comparison to human performance in specific
tasks, treating humans as a reference for high-level cognition. However, these
comparisons leave out important features of human intelligence: the capability
to transfer knowledge and make complex decisions based on emotional and
rational reasoning. These decisions are influenced by current inferences as
well as prior experiences, making the decision process strongly subjective and
apparently biased. In this context, a definition of compositional intelligence
is necessary to incorporate these features in future AI tests. Here, a concrete
implementation of this will be suggested, using recent developments in quantum
cognition, natural language and compositional meaning of sentences, thanks to
categorical compositional models of meaning.
</summary>
    <author>
      <name>Camilo M. Signorelli</name>
    </author>
    <author>
      <name>Xerxes D. Arsiwalla</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-35895-2_9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-35895-2_9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures, Conference paper at Quantum Interaction 2018,
  Nice, France. Published in Lecture Notes in Computer Science, vol 11690,
  Springer, Cham. Online ISBN 978-3-030-35895-2</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quantum Interaction. QI 2018. Lecture Notes in Computer Science,
  vol 11690</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.10154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01111v1</id>
    <updated>2019-11-22T16:07:02Z</updated>
    <published>2019-11-22T16:07:02Z</published>
    <title>Use of Artificial Intelligence to Analyse Risk in Legal Documents for a
  Better Decision Support</title>
    <summary>  Assessing risk for voluminous legal documents such as request for proposal;
contracts is tedious and error prone. We have developed "risk-o-meter", a
framework, based on machine learning and natural language processing to review
and assess risks of any legal document. Our framework uses Paragraph Vector, an
unsupervised model to generate vector representation of text. This enables the
framework to learn contextual relations of legal terms and generate sensible
context aware embedding. The framework then feeds the vector space into a
supervised classification algorithm to predict whether a paragraph belongs to a
per-defined risk category or not. The framework thus extracts risk prone
paragraphs. This technique efficiently overcomes the limitations of
keyword-based search. We have achieved an accuracy of 91% for the risk category
having the largest training dataset. This framework will help organizations
optimize effort to identify risk from large document base with minimal human
intervention and thus will help to have risk mitigated sustainable growth. Its
machine learning capability makes it scalable to uncover relevant information
from any type of document apart from legal documents, provided the library is
per-populated and rich.
</summary>
    <author>
      <name>Dipankar Chakrabarti</name>
    </author>
    <author>
      <name>Neelam Patodia</name>
    </author>
    <author>
      <name>Udayan Bhattacharya</name>
    </author>
    <author>
      <name>Indranil Mitra</name>
    </author>
    <author>
      <name>Satyaki Roy</name>
    </author>
    <author>
      <name>Jayanta Mandi</name>
    </author>
    <author>
      <name>Nandini Roy</name>
    </author>
    <author>
      <name>Prasun Nandy</name>
    </author>
    <link href="http://arxiv.org/abs/1912.01111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09994v1</id>
    <updated>2019-11-22T12:20:44Z</updated>
    <published>2019-11-22T12:20:44Z</published>
    <title>Anaphora Resolution in Dialogue Systems for South Asian Languages</title>
    <summary>  Anaphora resolution is a challenging task which has been the interest of NLP
researchers for a long time. Traditional resolution techniques like eliminative
constraints and weighted preferences were successful in many languages.
However, they are ineffective in free word order languages like most SouthAsian
languages.Heuristic and rule-based techniques were typical in these languages,
which are constrained to context and domain.In this paper, we venture a new
strategy us-ing neural networks for resolving anaphora in human-human
dialogues. The architecture chiefly consists of three components, a shallow
parser for extracting features, a feature vector generator which produces the
word embed-dings, and a neural network model which will predict the antecedent
mention of an anaphora.The system has been trained and tested on Telugu
conversation corpus we generated. Given the advantage of the semantic
information in word embeddings and appending actor, gender, number, person and
part of plural features the model has reached an F1-score of 86.
</summary>
    <author>
      <name>Vinay Annam</name>
    </author>
    <author>
      <name>Nikhil Koditala</name>
    </author>
    <author>
      <name>Radhika Mamidi</name>
    </author>
    <link href="http://arxiv.org/abs/1911.09994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09969v2</id>
    <updated>2019-11-25T08:38:17Z</updated>
    <published>2019-11-22T10:55:50Z</published>
    <title>The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service</title>
    <summary>  Human conversations in real scenarios are complicated and building a
human-like dialogue agent is an extremely challenging task. With the rapid
development of deep learning techniques, data-driven models become more and
more prevalent which need a huge amount of real conversation data. In this
paper, we construct a large-scale real scenario Chinese E-commerce conversation
corpus, JDDC, with more than 1 million multi-turn dialogues, 20 million
utterances, and 150 million words. The dataset reflects several characteristics
of human-human conversations, e.g., goal-driven, and long-term dependency among
the context. It also covers various dialogue types including task-oriented,
chitchat and question-answering. Extra intent information and three
well-annotated challenge sets are also provided. Then, we evaluate several
retrieval-based and generative models to provide basic benchmark performance on
JDDC corpus. And we hope JDDC can serve as an effective testbed and benefit the
development of fundamental research in dialogue task.
</summary>
    <author>
      <name>Meng Chen</name>
    </author>
    <author>
      <name>Ruixue Liu</name>
    </author>
    <author>
      <name>Lei Shen</name>
    </author>
    <author>
      <name>Shaozu Yuan</name>
    </author>
    <author>
      <name>Jingyan Zhou</name>
    </author>
    <author>
      <name>Youzheng Wu</name>
    </author>
    <author>
      <name>Xiaodong He</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1911.09969v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09969v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09709v3</id>
    <updated>2019-12-12T16:04:17Z</updated>
    <published>2019-11-21T19:15:03Z</published>
    <title>Automatically Neutralizing Subjective Bias in Text</title>
    <summary>  Texts like news, encyclopedias, and some social media strive for objectivity.
Yet bias in the form of inappropriate subjectivity - introducing attitudes via
framing, presupposing truth, and casting doubt - remains ubiquitous. This kind
of bias erodes our collective trust and fuels social conflict. To address this
issue, we introduce a novel testbed for natural language generation:
automatically bringing inappropriately subjective text into a neutral point of
view ("neutralizing" biased text). We also offer the first parallel corpus of
biased language. The corpus contains 180,000 sentence pairs and originates from
Wikipedia edits that removed various framings, presuppositions, and attitudes
from biased sentences. Last, we propose two strong encoder-decoder baselines
for the task. A straightforward yet opaque CONCURRENT system uses a BERT
encoder to identify subjective words as part of the generation process. An
interpretable and controllable MODULAR algorithm separates these steps, using
(1) a BERT-based classifier to identify problematic words and (2) a novel join
embedding through which the classifier can edit the hidden states of the
encoder. Large-scale human evaluation across four domains (encyclopedias, news
headlines, books, and political speeches) suggests that these algorithms are a
first step towards the automatic identification and reduction of bias.
</summary>
    <author>
      <name>Reid Pryzant</name>
    </author>
    <author>
      <name>Richard Diehl Martinez</name>
    </author>
    <author>
      <name>Nathan Dass</name>
    </author>
    <author>
      <name>Sadao Kurohashi</name>
    </author>
    <author>
      <name>Dan Jurafsky</name>
    </author>
    <author>
      <name>Diyi Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09709v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09709v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09478v1</id>
    <updated>2019-11-21T14:09:33Z</updated>
    <published>2019-11-21T14:09:33Z</published>
    <title>What Do You Mean `Why?': Resolving Sluices in Conversations</title>
    <summary>  In conversation, we often ask one-word questions such as `Why?' or `Who?'.
Such questions are typically easy for humans to answer, but can be hard for
computers, because their resolution requires retrieving both the right semantic
frames and the right arguments from context. This paper introduces the novel
ellipsis resolution task of resolving such one-word questions, referred to as
sluices in linguistics. We present a crowd-sourced dataset containing
annotations of sluices from over 4,000 dialogues collected from conversational
QA datasets, as well as a series of strong baseline architectures.
</summary>
    <author>
      <name>Victor Petrén Bach Hansen</name>
    </author>
    <author>
      <name>Anders Søgaard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 34TH AAAI Conference on Artificial Intelligence
  (AAAI-2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09304v1</id>
    <updated>2019-11-21T06:14:05Z</updated>
    <published>2019-11-21T06:14:05Z</published>
    <title>Automatic Text-based Personality Recognition on Monologues and
  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings</title>
    <summary>  Previous works related to automatic personality recognition focus on using
traditional classification models with linguistic features. However, attentive
neural networks with contextual embeddings, which have achieved huge success in
text classification, are rarely explored for this task. In this project, we
have two major contributions. First, we create the first dialogue-based
personality dataset, FriendsPersona, by annotating 5 personality traits of
speakers from Friends TV Show through crowdsourcing. Second, we present a novel
approach to automatic personality recognition using pre-trained contextual
embeddings (BERT and RoBERTa) and attentive neural networks. Our models largely
improve the state-of-art results on the monologue Essays dataset by 2.49%, and
establish a solid benchmark on our FriendsPersona. By comparing results in two
datasets, we demonstrate the challenges of modeling personality in multi-party
dialogue.
</summary>
    <author>
      <name>Hang Jiang</name>
    </author>
    <author>
      <name>Xianzhe Zhang</name>
    </author>
    <author>
      <name>Jinho D. Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper Accepted to AAAI-20 Student Abstract and Poster Program</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09242v2</id>
    <updated>2019-11-22T19:06:20Z</updated>
    <published>2019-11-21T02:08:14Z</published>
    <title>How Do You #relax When You're #stressed? A Content Analysis and
  Infodemiology Study of Stress-Related Tweets</title>
    <summary>  Background: Stress is a contributing factor to many major health problems in
the United States, such as heart disease, depression, and autoimmune diseases.
Relaxation is often recommended in mental health treatment as a frontline
strategy to reduce stress, thereby improving health conditions.
  Objective: The objective of our study was to understand how people express
their feelings of stress and relaxation through Twitter messages.
  Methods: We first performed a qualitative content analysis of 1326 and 781
tweets containing the keywords "stress" and "relax", respectively. We then
investigated the use of machine learning algorithms to automatically classify
tweets as stress versus non stress and relaxation versus non relaxation.
Finally, we applied these classifiers to sample datasets drawn from 4 cities
with the goal of evaluating the extent of any correlation between our automatic
classification of tweets and results from public stress surveys.
  Results: Content analysis showed that the most frequent topic of stress
tweets was education, followed by work and social relationships. The most
frequent topic of relaxation tweets was rest and vacation, followed by nature
and water. When we applied the classifiers to the cities dataset, the
proportion of stress tweets in New York and San Diego was substantially higher
than that in Los Angeles and San Francisco.
  Conclusions: This content analysis and infodemiology study revealed that
Twitter, when used in conjunction with natural language processing techniques,
is a useful data source for understanding stress and stress management
strategies, and can potentially supplement infrequently collected survey-based
stress data.
</summary>
    <author>
      <name>Son Doan</name>
    </author>
    <author>
      <name>Amanda Ritchart</name>
    </author>
    <author>
      <name>Nicholas Perry</name>
    </author>
    <author>
      <name>Juan D Chaparro</name>
    </author>
    <author>
      <name>Mike Conway</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2196/publichealth.5939</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2196/publichealth.5939" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages,12 figures, 6 tables, 5 Appendix (full version) -- shorter
  version published in JMIR Public Health Surveill 2017;3(2):e35</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JMIR Public Health Surveill 2017;3(2):e35</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.09242v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09242v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09194v2</id>
    <updated>2019-12-04T19:46:21Z</updated>
    <published>2019-11-20T22:20:52Z</published>
    <title>Generating Interactive Worlds with Text</title>
    <summary>  Procedurally generating cohesive and interesting game environments is
challenging and time-consuming. In order for the relationships between the game
elements to be natural, common-sense has to be encoded into arrangement of the
elements. In this work, we investigate a machine learning approach for world
creation using content from the multi-player text adventure game environment
LIGHT. We introduce neural network based models to compositionally arrange
locations, characters, and objects into a coherent whole. In addition to
creating worlds based on existing elements, our models can generate new game
content. Humans can also leverage our models to interactively aid in
worldbuilding. We show that the game environments created with our approach are
cohesive, diverse, and preferred by human evaluators compared to other machine
learning based world construction algorithms.
</summary>
    <author>
      <name>Angela Fan</name>
    </author>
    <author>
      <name>Jack Urbanek</name>
    </author>
    <author>
      <name>Pratik Ringshia</name>
    </author>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Emma Qian</name>
    </author>
    <author>
      <name>Siddharth Karamcheti</name>
    </author>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Tim Rocktaschel</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1911.09194v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09194v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08976v1</id>
    <updated>2019-11-20T15:41:47Z</updated>
    <published>2019-11-20T15:41:47Z</published>
    <title>Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted
  Explanation Generation</title>
    <summary>  The TextGraphs-13 Shared Task on Explanation Regeneration asked participants
to develop methods to reconstruct gold explanations for elementary science
questions. Red Dragon AI's entries used the language of the questions and
explanation text directly, rather than a constructing a separate graph-like
representation. Our leaderboard submission placed us 3rd in the competition,
but we present here three methods of increasing sophistication, each of which
scored successively higher on the test set after the competition close.
</summary>
    <author>
      <name>Yew Ken Chia</name>
    </author>
    <author>
      <name>Sam Witteveen</name>
    </author>
    <author>
      <name>Martin Andrews</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/D19-5311</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/D19-5311" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper for TextGraphs-13 workshop at EMNLP-IJCNLP 2019. (5
  pages including references)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08936v1</id>
    <updated>2019-11-20T14:40:23Z</updated>
    <published>2019-11-20T14:40:23Z</published>
    <title>Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood
  Aggregation</title>
    <summary>  Graph neural networks (GNNs) have emerged as a powerful paradigm for
embedding-based entity alignment due to their capability of identifying
isomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart
entities usually have non-isomorphic neighborhood structures, which easily
causes GNNs to yield different representations for them. To tackle this
problem, we propose a new KG alignment network, namely AliNet, aiming at
mitigating the non-isomorphism of neighborhood structures in an end-to-end
manner. As the direct neighbors of counterpart entities are usually dissimilar
due to the schema heterogeneity, AliNet introduces distant neighbors to expand
the overlap between their neighborhood structures. It employs an attention
mechanism to highlight helpful distant neighbors and reduce noises. Then, it
controls the aggregation of both direct and distant neighborhood information
using a gating mechanism. We further propose a relation loss to refine entity
representations. We perform thorough experiments with detailed ablation studies
and analyses on five entity alignment datasets, demonstrating the effectiveness
of AliNet.
</summary>
    <author>
      <name>Zequn Sun</name>
    </author>
    <author>
      <name>Chengming Wang</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <author>
      <name>Muhao Chen</name>
    </author>
    <author>
      <name>Jian Dai</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI
  2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08935v2</id>
    <updated>2019-12-28T15:33:17Z</updated>
    <published>2019-11-20T14:38:58Z</published>
    <title>Rule-Guided Compositional Representation Learning on Knowledge Graphs</title>
    <summary>  Representation learning on a knowledge graph (KG) is to embed entities and
relations of a KG into low-dimensional continuous vector spaces. Early KG
embedding methods only pay attention to structured information encoded in
triples, which would cause limited performance due to the structure sparseness
of KGs. Some recent attempts consider paths information to expand the structure
of KGs but lack explainability in the process of obtaining the path
representations. In this paper, we propose a novel Rule and Path-based Joint
Embedding (RPJE) scheme, which takes full advantage of the explainability and
accuracy of logic rules, the generalization of KG embedding as well as the
supplementary semantic structure of paths. Specifically, logic rules of
different lengths (the number of relations in rule body) in the form of Horn
clauses are first mined from the KG and elaborately encoded for representation
learning. Then, the rules of length 2 are applied to compose paths accurately
while the rules of length 1 are explicitly employed to create semantic
associations among relations and constrain relation embeddings. Besides, the
confidence level of each rule is also considered in optimization to guarantee
the availability of applying the rule to representation learning. Extensive
experimental results illustrate that RPJE outperforms other state-of-the-art
baselines on KG completion task, which also demonstrate the superiority of
utilizing logic rules as well as paths for improving the accuracy and
explainability of representation learning.
</summary>
    <author>
      <name>Guanglin Niu</name>
    </author>
    <author>
      <name>Yongfei Zhang</name>
    </author>
    <author>
      <name>Bo Li</name>
    </author>
    <author>
      <name>Peng Cui</name>
    </author>
    <author>
      <name>Si Liu</name>
    </author>
    <author>
      <name>Jingyang Li</name>
    </author>
    <author>
      <name>Xiaowei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The full version of a paper accepted to AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08935v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08935v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08776v2</id>
    <updated>2019-12-23T14:52:03Z</updated>
    <published>2019-11-20T09:05:11Z</published>
    <title>Joint Embedding Learning of Educational Knowledge Graphs</title>
    <summary>  As an efficient model for knowledge organization, the knowledge graph has
been widely adopted in several fields, e.g., biomedicine, sociology, and
education. And there is a steady trend of learning embedding representations of
knowledge graphs to facilitate knowledge graph construction and downstream
tasks. In general, knowledge graph embedding techniques aim to learn vectorized
representations which preserve the structural information of the graph. And
conventional embedding learning models rely on structural relationships among
entities and relations. However, in educational knowledge graphs, structural
relationships are not the focus. Instead, rich literals of the graphs are more
valuable. In this paper, we focus on this problem and propose a novel model for
embedding learning of educational knowledge graphs. Our model considers both
structural and literal information and jointly learns embedding
representations. Three experimental graphs were constructed based on an
educational knowledge graph which has been applied in real-world teaching. We
conducted two experiments on the three graphs and other common benchmark
graphs. The experimental results proved the effectiveness of our model and its
superiority over other baselines when processing educational knowledge graphs.
</summary>
    <author>
      <name>Siyu Yao</name>
    </author>
    <author>
      <name>Ruijie Wang</name>
    </author>
    <author>
      <name>Shen Sun</name>
    </author>
    <author>
      <name>Derui Bu</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.08776v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08776v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08762v1</id>
    <updated>2019-11-20T08:29:10Z</updated>
    <published>2019-11-20T08:29:10Z</published>
    <title>Paraphrasing Verbs for Noun Compound Interpretation</title>
    <summary>  An important challenge for the automatic analysis of English written text is
the abundance of noun compounds: sequences of nouns acting as a single noun. In
our view, their semantics is best characterized by the set of all possible
paraphrasing verbs, with associated weights, e.g., malaria mosquito is carry
(23), spread (16), cause (12), transmit (9), etc. Using Amazon's Mechanical
Turk, we collect paraphrasing verbs for 250 noun-noun compounds previously
proposed in the linguistic literature, thus creating a valuable resource for
noun compound interpretation. Using these verbs, we further construct a dataset
of pairs of sentences representing a special kind of textual entailment task,
where a binary decision is to be made about whether an expression involving a
verb and two nouns can be transformed into a noun compound, while preserving
the sentence meaning.
</summary>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">noun compounds, paraphrasing verbs, semantic interpretation,
  multi-word expressions, MWEs</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">MWE-2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08755v1</id>
    <updated>2019-11-20T08:09:36Z</updated>
    <published>2019-11-20T08:09:36Z</published>
    <title>Global Thread-Level Inference for Comment Classification in Community
  Question Answering</title>
    <summary>  Community question answering, a recent evolution of question answering in the
Web context, allows a user to quickly consult the opinion of a number of people
on a particular topic, thus taking advantage of the wisdom of the crowd. Here
we try to help the user by deciding automatically which answers are good and
which are bad for a given question. In particular, we focus on exploiting the
output structure at the thread level in order to make more consistent global
decisions. More specifically, we exploit the relations between pairs of
comments at any distance in the thread, which we incorporate in a graph-cut and
in an ILP frameworks. We evaluated our approach on the benchmark dataset of
SemEval-2015 Task 3. Results improved over the state of the art, confirming the
importance of using thread level information.
</summary>
    <author>
      <name>Shafiq Joty</name>
    </author>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Giovanni Da San Martino</name>
    </author>
    <author>
      <name>Simone Filice</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Alessandro Moschitti</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">community question answering, thread-level inference, graph-cut,
  inductive logic programming</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08743v1</id>
    <updated>2019-11-20T07:16:16Z</updated>
    <published>2019-11-20T07:16:16Z</published>
    <title>SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community
  Question Answering Using Semantic Similarity Based on Fine-tuned Word
  Embeddings</title>
    <summary>  We describe our system for finding good answers in a community forum, as
defined in SemEval-2016, Task 3 on Community Question Answering. Our approach
relies on several semantic similarity features based on fine-tuned word
embeddings and topics similarities. In the main Subtask C, our primary
submission was ranked third, with a MAP of 51.68 and accuracy of 69.94. In
Subtask A, our primary submission was also third, with MAP of 77.58 and
accuracy of 73.39.
</summary>
    <author>
      <name>Todor Mihaylov</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">community question answering, semantic similarity</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval-2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08522v1</id>
    <updated>2019-11-19T19:34:15Z</updated>
    <published>2019-11-19T19:34:15Z</published>
    <title>Aging Memories Generate More Fluent Dialogue Responses with Memory
  Networks</title>
    <summary>  The integration of a Knowledge Base (KB) into a neural dialogue agent is one
of the key challenges in Conversational AI. Memory networks has proven to be
effective to encode KB information into an external memory to thus generate
more fluent and informed responses. Unfortunately, such memory becomes full of
latent representations during training, so the most common strategy is to
overwrite old memory entries randomly.
  In this paper, we question this approach and provide experimental evidence
showing that conventional memory networks generate many redundant latent
vectors resulting in overfitting and the need for larger memories.
  We introduce memory dropout as an automatic technique that encourages
diversity in the latent space by 1) Aging redundant memories to increase their
probability of being overwritten during training 2) Sampling new memories that
summarize the knowledge acquired by redundant memories. This technique allows
us to incorporate Knowledge Bases to achieve state-of-the-art dialogue
generation in the Stanford Multi-Turn Dialogue dataset. Considering the same
architecture, its use provides an improvement of +2.2 BLEU points for the
automatic generation of responses and an increase of +8.1% in the recognition
of named entities.
</summary>
    <author>
      <name>Omar U. Florez</name>
    </author>
    <author>
      <name>Erik Mueller</name>
    </author>
    <link href="http://arxiv.org/abs/1911.08522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08437v1</id>
    <updated>2019-11-19T18:02:06Z</updated>
    <published>2019-11-19T18:02:06Z</published>
    <title>Towards unstructured mortality prediction with free-text clinical notes</title>
    <summary>  Healthcare data continues to flourish yet a relatively small portion, mostly
structured, is being utilized effectively for predicting clinical outcomes. The
rich subjective information available in unstructured clinical notes can
possibly facilitate higher discrimination but tends to be under-utilized in
mortality prediction. This work attempts to assess the gain in performance when
multiple notes that have been minimally preprocessed are used as an input for
prediction. A hierarchical architecture consisting of both convolutional and
recurrent layers is used to concurrently model the different notes compiled in
an individual hospital stay. This approach is evaluated on predicting
in-hospital mortality on the MIMIC-III dataset. On comparison to approaches
utilizing structured data, it achieved higher metrics despite requiring less
cleaning and preprocessing. This demonstrates the potential of unstructured
data in enhancing mortality prediction and signifies the need to incorporate
more raw unstructured data into current clinical prediction methods.
</summary>
    <author>
      <name>Mohammad Hashir</name>
    </author>
    <author>
      <name>Rapinder Sawhney</name>
    </author>
    <link href="http://arxiv.org/abs/1911.08437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08340v1</id>
    <updated>2019-11-19T15:18:39Z</updated>
    <published>2019-11-19T15:18:39Z</published>
    <title>Unsupervised Natural Question Answering with a Small Model</title>
    <summary>  The recent (2019-02) demonstration of the power of huge language models such
as GPT-2 to memorise the answers to factoid questions raises questions about
the extent to which knowledge is being embedded directly within these large
models. This short paper describes an architecture through which much smaller
models can also answer such questions - by making use of 'raw' external
knowledge. The contribution of this work is that the methods presented here
rely on unsupervised learning techniques, complementing the unsupervised
training of the Language Model. The goal of this line of research is to be able
to add knowledge explicitly, without extensive training.
</summary>
    <author>
      <name>Martin Andrews</name>
    </author>
    <author>
      <name>Sam Witteveen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/D19-6606</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/D19-6606" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper for FEVER workshop at EMNLP-IJCNLP 2019. (4 pages +
  references)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08151v2</id>
    <updated>2020-02-19T11:04:28Z</updated>
    <published>2019-11-19T08:20:45Z</published>
    <title>Retrospective and Prospective Mixture-of-Generators for Task-oriented
  Dialogue Response Generation</title>
    <summary>  Dialogue response generation (DRG) is a critical component of task-oriented
dialogue systems (TDSs). Its purpose is to generate proper natural language
responses given some context, e.g., historical utterances, system states, etc.
State-of-the-art work focuses on how to better tackle DRG in an end-to-end way.
Typically, such studies assume that each token is drawn from a single
distribution over the output vocabulary, which may not always be optimal.
Responses vary greatly with different intents, e.g., domains, system actions.
  We propose a novel mixture-of-generators network (MoGNet) for DRG, where we
assume that each token of a response is drawn from a mixture of distributions.
MoGNet consists of a chair generator and several expert generators. Each expert
is specialized for DRG w.r.t. a particular intent. The chair coordinates
multiple experts and combines the output they have generated to produce more
appropriate responses. We propose two strategies to help the chair make better
decisions, namely, a retrospective mixture-of-generators (RMoG) and prospective
mixture-of-generators (PMoG). The former only considers the historical
expert-generated responses until the current time step while the latter also
considers possible expert-generated responses in the future by encouraging
exploration. In order to differentiate experts, we also devise a
global-and-local (GL) learning scheme that forces each expert to be specialized
towards a particular intent using a local loss and trains the chair and all
experts to coordinate using a global loss.
  We carry out extensive experiments on the MultiWOZ benchmark dataset. MoGNet
significantly outperforms state-of-the-art methods in terms of both automatic
and human evaluations, demonstrating its effectiveness for DRG.
</summary>
    <author>
      <name>Jiahuan Pei</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper is accepted by 24th European Conference on Artificial
  Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08151v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08151v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08125v1</id>
    <updated>2019-11-19T07:06:22Z</updated>
    <published>2019-11-19T07:06:22Z</published>
    <title>In Search of Credible News</title>
    <summary>  We study the problem of finding fake online news. This is an important
problem as news of questionable credibility have recently been proliferating in
social media at an alarming scale. As this is an understudied problem,
especially for languages other than English, we first collect and release to
the research community three new balanced credible vs. fake news datasets
derived from four online sources. We then propose a language-independent
approach for automatically distinguishing credible from fake news, based on a
rich feature set. In particular, we use linguistic (n-gram),
credibility-related (capitalization, punctuation, pronoun use, sentiment
polarity), and semantic (embeddings and DBPedia data) features. Our experiments
on three different testsets show that our model can distinguish credible from
fake news with very high accuracy.
</summary>
    <author>
      <name>Momchil Hardalov</name>
    </author>
    <author>
      <name>Ivan Koychev</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Credibility, veracity, fact checking, humor detection</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AIMSA-2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08112v1</id>
    <updated>2019-11-19T06:38:14Z</updated>
    <published>2019-11-19T06:38:14Z</published>
    <title>Extended Answer and Uncertainty Aware Neural Question Generation</title>
    <summary>  In this paper, we study automatic question generation, the task of creating
questions from corresponding text passages where some certain spans of the text
can serve as the answers. We propose an Extended Answer-aware Network (EAN)
which is trained with Word-based Coverage Mechanism (WCM) and decodes with
Uncertainty-aware Beam Search (UBS). The EAN represents the target answer by
its surrounding sentence with an encoder, and incorporates the information of
the extended answer into paragraph representation with gated
paragraph-to-answer attention to tackle the problem of the inadequate
representation of the target answer. To reduce undesirable repetition, the WCM
penalizes repeatedly attending to the same words at different time-steps in the
training stage. The UBS aims to seek a better balance between the model
confidence in copying words from an input text paragraph and the confidence in
generating words from a vocabulary. We conduct experiments on the SQuAD
dataset, and the results show our approach achieves significant performance
improvement.
</summary>
    <author>
      <name>Hongwei Zeng</name>
    </author>
    <author>
      <name>Zhuo Zhi</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <author>
      <name>Bifan Wei</name>
    </author>
    <link href="http://arxiv.org/abs/1911.08112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07588v1</id>
    <updated>2019-11-18T12:41:25Z</updated>
    <published>2019-11-18T12:41:25Z</published>
    <title>An Annotated Corpus of Reference Resolution for Interpreting Common
  Grounding</title>
    <summary>  Common grounding is the process of creating, repairing and updating mutual
understandings, which is a fundamental aspect of natural language conversation.
However, interpreting the process of common grounding is a challenging task,
especially under continuous and partially-observable context where complex
ambiguity, uncertainty, partial understandings and misunderstandings are
introduced. Interpretation becomes even more challenging when we deal with
dialogue systems which still have limited capability of natural language
understanding and generation. To address this problem, we consider reference
resolution as the central subtask of common grounding and propose a new
resource to study its intermediate process. Based on a simple and general
annotation schema, we collected a total of 40,172 referring expressions in
5,191 dialogues curated from an existing corpus, along with multiple judgements
of referent interpretations. We show that our annotation is highly reliable,
captures the complexity of common grounding through a natural degree of
reasonable disagreements, and allows for more detailed and quantitative
analyses of common grounding strategies. Finally, we demonstrate the advantages
of our annotation for interpreting, analyzing and improving common grounding in
baseline dialogue systems.
</summary>
    <author>
      <name>Takuma Udagawa</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, 6 tables, Accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07470v2</id>
    <updated>2019-11-30T12:49:24Z</updated>
    <published>2019-11-18T07:45:19Z</published>
    <title>Graph Transformer for Graph-to-Sequence Learning</title>
    <summary>  The dominant graph-to-sequence transduction models employ graph neural
networks for graph representation learning, where the structural information is
reflected by the receptive field of neurons. Unlike graph neural networks that
restrict the information exchange between immediate neighborhood, we propose a
new model, known as Graph Transformer, that uses explicit relation encoding and
allows direct communication between two distant nodes. It provides a more
efficient way for global graph structure modeling. Experiments on the
applications of text generation from Abstract Meaning Representation (AMR) and
syntax-based neural machine translation show the superiority of our proposed
model. Specifically, our model achieves 27.4 BLEU on LDC2015E86 and 29.7 BLEU
on LDC2017T10 for AMR-to-text generation, outperforming the state-of-the-art
results by up to 2.2 points. On the syntax-based translation tasks, our model
establishes new single-model state-of-the-art BLEU scores, 21.3 for
English-to-German and 14.1 for English-to-Czech, improving over the existing
best results, including ensembles, by over 1 BLEU.
</summary>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Wai Lam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by AAAI2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07470v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07470v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07405v1</id>
    <updated>2019-11-18T03:11:36Z</updated>
    <published>2019-11-18T03:11:36Z</published>
    <title>Multi-task Sentence Encoding Model for Semantic Retrieval in Question
  Answering Systems</title>
    <summary>  Question Answering (QA) systems are used to provide proper responses to
users' questions automatically. Sentence matching is an essential task in the
QA systems and is usually reformulated as a Paraphrase Identification (PI)
problem. Given a question, the aim of the task is to find the most similar
question from a QA knowledge base. In this paper, we propose a Multi-task
Sentence Encoding Model (MSEM) for the PI problem, wherein a connected graph is
employed to depict the relation between sentences, and a multi-task learning
model is applied to address both the sentence matching and sentence intent
classification problem. In addition, we implement a general semantic retrieval
framework that combines our proposed model and the Approximate Nearest Neighbor
(ANN) technology, which enables us to find the most similar question from all
available candidates very quickly during online serving. The experiments show
the superiority of our proposed method as compared with the existing sentence
matching models.
</summary>
    <author>
      <name>Qiang Huang</name>
    </author>
    <author>
      <name>Jianhui Bu</name>
    </author>
    <author>
      <name>Weijian Xie</name>
    </author>
    <author>
      <name>Shengwen Yang</name>
    </author>
    <author>
      <name>Weijia Wu</name>
    </author>
    <author>
      <name>Liping Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCNN 2019 - International Joint Conference on Neural Networks,
  Budapest Hungary, 14-19 July 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07141v2</id>
    <updated>2020-02-20T02:09:20Z</updated>
    <published>2019-11-17T03:14:02Z</published>
    <title>Working Memory Graphs</title>
    <summary>  Transformers have increasingly outperformed gated RNNs in obtaining new
state-of-the-art results on supervised tasks involving text sequences. Inspired
by this trend, we study the question of how Transformer-based models can
improve the performance of sequential decision-making agents. We present the
Working Memory Graph (WMG), an agent that employs multi-head self-attention to
reason over a dynamic set of vectors representing observed and recurrent state.
We evaluate WMG in three environments featuring factored observation spaces: a
Pathfinding environment that requires complex reasoning over past observations,
BabyAI gridworld levels that involve text instructions, and Sokoban which
emphasizes future planning. We find that the combination of WMG's
Transformer-based architecture with factored observation spaces leads to
significant gains in learning efficiency compared to other architectures across
all tasks. Our results imply that for environments where it is possible to
factorize environment observations, WMG's Transformer-based architecture can
dramatically boost sample efficiency.
</summary>
    <author>
      <name>Ricky Loynd</name>
    </author>
    <author>
      <name>Roland Fernandez</name>
    </author>
    <author>
      <name>Asli Celikyilmaz</name>
    </author>
    <author>
      <name>Adith Swaminathan</name>
    </author>
    <author>
      <name>Matthew Hausknecht</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures, 8 page appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07141v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07141v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.08554v1</id>
    <updated>2019-11-16T01:58:27Z</updated>
    <published>2019-11-16T01:58:27Z</published>
    <title>Classification as Decoder: Trading Flexibility for Control in Medical
  Dialogue</title>
    <summary>  Generative seq2seq dialogue systems are trained to predict the next word in
dialogues that have already occurred. They can learn from large unlabeled
conversation datasets, build a deeper understanding of conversational context,
and generate a wide variety of responses. This flexibility comes at the cost of
control, a concerning tradeoff in doctor/patient interactions. Inaccuracies,
typos, or undesirable content in the training data will be reproduced by the
model at inference time. We trade a small amount of labeling effort and some
loss of response variety in exchange for quality control. More specifically, a
pretrained language model encodes the conversational context, and we finetune a
classification head to map an encoded conversational context to a response
class, where each class is a noisily labeled group of interchangeable
responses. Experts can update these exemplar responses over time as best
practices change without retraining the classifier or invalidating old training
data. Expert evaluation of 775 unseen doctor/patient conversations shows that
only 12% of the discriminative model's responses are worse than the what the
doctor ended up writing, compared to 18% for the generative model.
</summary>
    <author>
      <name>Sam Shleifer</name>
    </author>
    <author>
      <name>Manish Chablani</name>
    </author>
    <author>
      <name>Anitha Kannan</name>
    </author>
    <author>
      <name>Namit Katariya</name>
    </author>
    <author>
      <name>Xavier Amatriain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended
  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.03476</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.08554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.06747v1</id>
    <updated>2019-11-15T16:56:17Z</updated>
    <published>2019-11-15T16:56:17Z</published>
    <title>Towards Personalized Dialog Policies for Conversational Skill Discovery</title>
    <summary>  Many businesses and consumers are extending the capabilities of voice-based
services such as Amazon Alexa, Google Home, Microsoft Cortana, and Apple Siri
to create custom voice experiences (also known as skills). As the number of
these experiences increases, a key problem is the discovery of skills that can
be used to address a user's request. In this paper, we focus on conversational
skill discovery and present a conversational agent which engages in a dialog
with users to help them find the skills that fulfill their needs. To this end,
we start with a rule-based agent and improve it by using reinforcement
learning. In this way, we enable the agent to adapt to different user
attributes and conversational styles as it interacts with users. We evaluate
our approach in a real production setting by deploying the agent to interact
with real users, and show the effectiveness of the conversational agent in
helping users find the skills that serve their request.
</summary>
    <author>
      <name>Maryam Fazel-Zarandi</name>
    </author>
    <author>
      <name>Sampat Biswas</name>
    </author>
    <author>
      <name>Ryan Summers</name>
    </author>
    <author>
      <name>Ahmed Elmalt</name>
    </author>
    <author>
      <name>Andy McCraw</name>
    </author>
    <author>
      <name>Michael McPhilips</name>
    </author>
    <author>
      <name>John Peach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 3rd Conversational AI workshop - today's practice and tomorrow's
  potential</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.06747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07629v1</id>
    <updated>2019-11-15T09:20:32Z</updated>
    <published>2019-11-15T09:20:32Z</published>
    <title>Selection-based Question Answering of an MOOC</title>
    <summary>  e-Yantra Robotics Competition (eYRC) is a unique Robotics Competition hosted
by IIT Bombay that is actually an Embedded Systems and Robotics MOOC.
Registrations have been growing exponentially in each year from 4500 in 2012 to
over 34000 in 2019. In this 5-month long competition students learn complex
skills under severe time pressure and have access to a discussion forum to post
doubts about the learning material. Responding to questions in real-time is a
challenge for project staff. Here, we illustrate the advantage of Deep Learning
for real-time question answering in the eYRC discussion forum. We illustrate
the advantage of Transformer based contextual embedding mechanisms such as
Bidirectional Encoder Representation From Transformer (BERT) over word
embedding mechanisms such as Word2Vec. We propose a weighted similarity metric
as a measure of matching and find it more reliable than Content-Content or
Title-Title similarities alone. The automation of replying to questions has
brought the turn around response time(TART) down from a minimum of 21 mins to a
minimum of 0.3 secs.
</summary>
    <author>
      <name>Atul Sahay</name>
    </author>
    <author>
      <name>Smita Gholkar</name>
    </author>
    <author>
      <name>Kavi Arya</name>
    </author>
    <link href="http://arxiv.org/abs/1911.07629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.06602v1</id>
    <updated>2019-11-14T18:20:36Z</updated>
    <published>2019-11-14T18:20:36Z</published>
    <title>Radically Compositional Cognitive Concepts</title>
    <summary>  Despite ample evidence that our concepts, our cognitive architecture, and
mathematics itself are all deeply compositional, few models take advantage of
this structure. We therefore propose a radically compositional approach to
computational neuroscience, drawing on the methods of applied category theory.
We describe how these tools grant us a means to overcome complexity and improve
interpretability, and supply a rigorous common language for scientific
modelling, analogous to the type theories of computer science. As a case study,
we sketch how to translate from compositional narrative concepts to neural
circuits and back again.
</summary>
    <author>
      <name>Toby B. St Clere Smithe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures; NeurIPS 2019 Context and Compositionality
  workshop. Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.06602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.05889v3</id>
    <updated>2019-12-02T01:47:14Z</updated>
    <published>2019-11-14T01:47:53Z</published>
    <title>Generating Persona Consistent Dialogues by Exploiting Natural Language
  Inference</title>
    <summary>  Consistency is one of the major challenges faced by dialogue agents. A
human-like dialogue agent should not only respond naturally, but also maintain
a consistent persona. In this paper, we exploit the advantages of natural
language inference (NLI) technique to address the issue of generating persona
consistent dialogues. Different from existing work that re-ranks the retrieved
responses through an NLI model, we cast the task as a reinforcement learning
problem and propose to exploit the NLI signals from response-persona pairs as
rewards for the process of dialogue generation. Specifically, our generator
employs an attention-based encoder-decoder to generate persona-based responses.
Our evaluator consists of two components: an adversarially trained naturalness
module and an NLI based consistency module. Moreover, we use another
well-performed NLI model in the evaluation of persona-consistency. Experimental
results on both human and automatic metrics, including the model-based
consistency evaluation, demonstrate that the proposed approach outperforms
strong generative baselines, especially in the persona-consistency of generated
responses.
</summary>
    <author>
      <name>Haoyu Song</name>
    </author>
    <author>
      <name>Wei-Nan Zhang</name>
    </author>
    <author>
      <name>Jingwen Hu</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.05889v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05889v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.05241v1</id>
    <updated>2019-11-13T01:52:27Z</updated>
    <published>2019-11-13T01:52:27Z</published>
    <title>Robustness to Capitalization Errors in Named Entity Recognition</title>
    <summary>  Robustness to capitalization errors is a highly desirable characteristic of
named entity recognizers, yet we find standard models for the task are
surprisingly brittle to such noise. Existing methods to improve robustness to
the noise completely discard given orthographic information, mwhich
significantly degrades their performance on well-formed text. We propose a
simple alternative approach based on data augmentation, which allows the model
to \emph{learn} to utilize or ignore orthographic information depending on its
usefulness in the context. It achieves competitive robustness to capitalization
errors while making negligible compromise to its performance on well-formed
text and significantly improving generalization power on noisy user-generated
text. Our experiments clearly and consistently validate our claim across
different types of machine learning models, languages, and dataset sizes.
</summary>
    <author>
      <name>Sravan Bodapati</name>
    </author>
    <author>
      <name>Hyokun Yun</name>
    </author>
    <author>
      <name>Yaser Al-Onaizan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019 Workshop : W-NUT 2019 5th Workshop on Noisy
  User Generated Text</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">http://noisy-text.github.io/2019/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.05241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.05202v1</id>
    <updated>2019-11-12T23:31:12Z</updated>
    <published>2019-11-12T23:31:12Z</published>
    <title>Creating Auxiliary Representations from Charge Definitions for Criminal
  Charge Prediction</title>
    <summary>  Charge prediction, determining charges for criminal cases by analyzing the
textual fact descriptions, is a promising technology in legal assistant
systems. In practice, the fact descriptions could exhibit a significant
intra-class variation due to factors like non-normative use of language, which
makes the prediction task very challenging, especially for charge classes with
too few samples to cover the expression variation. In this work, we explore to
use the charge definitions from criminal law to alleviate this issue. The key
idea is that the expressions in a fact description should have corresponding
formal terms in charge definitions, and those terms are shared across classes
and could account for the diversity in the fact descriptions. Thus, we propose
to create auxiliary fact representations from charge definitions to augment
fact descriptions representation. The generated auxiliary representations are
created through the interaction of fact description with the relevant charge
definitions and terms in those definitions by integrated sentence- and
word-level attention scheme. Experimental results on two datasets show that our
model achieves significant improvement than baselines, especially for classes
with few samples.
</summary>
    <author>
      <name>Liangyi Kang</name>
    </author>
    <author>
      <name>Jie Liu</name>
    </author>
    <author>
      <name>Lingqiao Liu</name>
    </author>
    <author>
      <name>Qinfeng Shi</name>
    </author>
    <author>
      <name>Dan Ye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.05202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.05153v1</id>
    <updated>2019-11-12T21:34:15Z</updated>
    <published>2019-11-12T21:34:15Z</published>
    <title>Improving Robustness of Task Oriented Dialog Systems</title>
    <summary>  Task oriented language understanding in dialog systems is often modeled using
intents (task of a query) and slots (parameters for that task). Intent
detection and slot tagging are, in turn, modeled using sentence classification
and word tagging techniques respectively. Similar to adversarial attack
problems with computer vision models discussed in existing literature, these
intent-slot tagging models are often over-sensitive to small variations in
input -- predicting different and often incorrect labels when small changes are
made to a query, thus reducing their accuracy and reliability. However,
evaluating a model's robustness to these changes is harder for language since
words are discrete and an automated change (e.g. adding `noise') to a query
sometimes changes the meaning and thus labels of a query. In this paper, we
first describe how to create an adversarial test set to measure the robustness
of these models. Furthermore, we introduce and adapt adversarial training
methods as well as data augmentation using back-translation to mitigate these
issues. Our experiments show that both techniques improve the robustness of the
system substantially and can be combined to yield the best results.
</summary>
    <author>
      <name>Arash Einolghozati</name>
    </author>
    <author>
      <name>Sonal Gupta</name>
    </author>
    <author>
      <name>Mrinal Mohit</name>
    </author>
    <author>
      <name>Rushin Shah</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3rd Conversational AI Workshop at 33rd Conference on Neural
  Information Processing Systems (NeurIPS 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.05153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.05013v1</id>
    <updated>2019-11-12T17:11:55Z</updated>
    <published>2019-11-12T17:11:55Z</published>
    <title>EDUQA: Educational Domain Question Answering System using Conceptual
  Network Mapping</title>
    <summary>  Most of the existing question answering models can be largely compiled into
two categories: i) open domain question answering models that answer generic
questions and use large-scale knowledge base along with the targeted web-corpus
retrieval and ii) closed domain question answering models that address focused
questioning area and use complex deep learning models. Both the above models
derive answers through textual comprehension methods. Due to their inability to
capture the pedagogical meaning of textual content, these models are not
appropriately suited to the educational field for pedagogy. In this paper, we
propose an on-the-fly conceptual network model that incorporates educational
semantics. The proposed model preserves correlations between conceptual
entities by applying intelligent indexing algorithms on the concept network so
as to improve answer generation. This model can be utilized for building
interactive conversational agents for aiding classroom learning.
</summary>
    <author>
      <name>Abhishek Agarwal</name>
    </author>
    <author>
      <name>Nikhil Sachdeva</name>
    </author>
    <author>
      <name>Raj Kamal Yadav</name>
    </author>
    <author>
      <name>Vishaal Udandarao</name>
    </author>
    <author>
      <name>Vrinda Mittal</name>
    </author>
    <author>
      <name>Anubha Gupta</name>
    </author>
    <author>
      <name>Abhinav Mathur</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICASSP.2019.8683538</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICASSP.2019.8683538" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the 44th International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP) 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE ICASSP (2019) 8137-8141</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.05013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04759v1</id>
    <updated>2019-11-12T09:41:44Z</updated>
    <published>2019-11-12T09:41:44Z</published>
    <title>Prediction of Missing Semantic Relations in Lexical-Semantic Network
  using Random Forest Classifier</title>
    <summary>  This study focuses on the prediction of missing six semantic relations (such
as is_a and has_part) between two given nodes in RezoJDM a French
lexical-semantic network. The output of this prediction is a set of pairs in
which the first entries are semantic relations and the second entries are the
probabilities of existence of such relations. Due to the statement of the
problem we choose the random forest (RF) predictor classifier approach to
tackle this problem. We take for granted the existing semantic relations, for
training/test dataset, gathered and validated by crowdsourcing. We describe how
all of the mentioned ideas can be followed after using the node2vec approach in
the feature extraction phase. We show how this approach can lead to acceptable
results.
</summary>
    <author>
      <name>Kévin Cousot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TEXTE</arxiv:affiliation>
    </author>
    <author>
      <name>Mehdi Mirzapour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TEXTE</arxiv:affiliation>
    </author>
    <author>
      <name>Waleed Ragheb</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ADVANSE</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CJC PRAXILING 2019, Nov 2019, Montpellier, France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.04759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04700v1</id>
    <updated>2019-11-12T07:13:42Z</updated>
    <published>2019-11-12T07:13:42Z</published>
    <title>A Pre-training Based Personalized Dialogue Generation Model with
  Persona-sparse Data</title>
    <summary>  Endowing dialogue systems with personas is essential to deliver more
human-like conversations. However, this problem is still far from well explored
due to the difficulties of both embodying personalities in natural languages
and the persona sparsity issue observed in most dialogue corpora. This paper
proposes a pre-training based personalized dialogue model that can generate
coherent responses using persona-sparse dialogue data. In this method, a
pre-trained language model is used to initialize an encoder and decoder, and
personal attribute embeddings are devised to model richer dialogue contexts by
encoding speakers' personas together with dialogue histories. Further, to
incorporate the target persona in the decoding process and to balance its
contribution, an attention routing structure is devised in the decoder to merge
features extracted from the target persona and dialogue contexts using
dynamically predicted weights. Our model can utilize persona-sparse dialogues
in a unified manner during the training process, and can also control the
amount of persona-related features to exhibit during the inference process.
Both automatic and manual evaluation demonstrates that the proposed model
outperforms state-of-the-art methods for generating more coherent and persona
consistent responses with persona-sparse data.
</summary>
    <author>
      <name>Yinhe Zheng</name>
    </author>
    <author>
      <name>Rongsheng Zhang</name>
    </author>
    <author>
      <name>Xiaoxi Mao</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long paper accepted at AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.04700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04192v1</id>
    <updated>2019-11-11T11:35:21Z</updated>
    <published>2019-11-11T11:35:21Z</published>
    <title>Keep it Consistent: Topic-Aware Storytelling from an Image Stream via
  Iterative Multi-agent Communication</title>
    <summary>  Visual storytelling aims to generate a narrative paragraph from a sequence of
images automatically. Existing approaches construct text description
independently for each image and roughly concatenate them as a story, which
leads to the problem of generating semantically incoherent content. In this
paper, we proposed a new way for visual storytelling by introducing a topic
description task to detect the global semantic context of an image stream. A
story is then constructed with the guidance of the topic description. In order
to combine the two generation tasks, we propose a multi-agent communication
framework that regards the topic description generator and the story generator
as two agents and learn them simultaneously via iterative updating mechanism.
We validate our approach on VIST, where quantitative results, ablations, and
human evaluation demonstrate our method's good ability in generating stories
with higher quality compared to state-of-the-art methods.
</summary>
    <author>
      <name>Ruize Wang</name>
    </author>
    <author>
      <name>Zhongyu Wei</name>
    </author>
    <author>
      <name>Piji Li</name>
    </author>
    <author>
      <name>Haijun Shan</name>
    </author>
    <author>
      <name>Ji Zhang</name>
    </author>
    <author>
      <name>Qi Zhang</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, 5 tables submitted for consideration of
  publication to the IEEE Transactions on Audio, Speech, and Language
  Processing, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.04192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04156v1</id>
    <updated>2019-11-11T10:07:57Z</updated>
    <published>2019-11-11T10:07:57Z</published>
    <title>Meta Answering for Machine Reading</title>
    <summary>  We investigate a framework for machine reading, inspired by real world
information-seeking problems, where a meta question answering system interacts
with a black box environment. The environment encapsulates a competitive
machine reader based on BERT, providing candidate answers to questions, and
possibly some context. To validate the realism of our formulation, we ask
humans to play the role of a meta-answerer. With just a small snippet of text
around an answer, humans can outperform the machine reader, improving recall.
Similarly, a simple machine meta-answerer outperforms the environment,
improving both precision and recall on the Natural Questions dataset. The
system relies on joint training of answer scoring and the selection of
conditioning information.
</summary>
    <author>
      <name>Benjamin Borschinger</name>
    </author>
    <author>
      <name>Jordan Boyd-Graber</name>
    </author>
    <author>
      <name>Christian Buck</name>
    </author>
    <author>
      <name>Jannis Bulian</name>
    </author>
    <author>
      <name>Massimiliano Ciaramita</name>
    </author>
    <author>
      <name>Michelle Chen Huebscher</name>
    </author>
    <author>
      <name>Wojciech Gajewski</name>
    </author>
    <author>
      <name>Yannic Kilcher</name>
    </author>
    <author>
      <name>Rodrigo Nogueira</name>
    </author>
    <author>
      <name>Lierni Sestorain Saralegu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.04156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04065v2</id>
    <updated>2019-11-12T03:03:25Z</updated>
    <published>2019-11-11T04:06:46Z</published>
    <title>Learning to Order Sub-questions for Complex Question Answering</title>
    <summary>  Answering complex questions involving multiple entities and relations is a
challenging task. Logically, the answer to a complex question should be derived
by decomposing the complex question into multiple simple sub-questions and then
answering those sub-questions. Existing work has followed this strategy but has
not attempted to optimize the order of how those sub-questions are answered. As
a result, the sub-questions are answered in an arbitrary order, leading to
larger search space and a higher risk of missing an answer. In this paper, we
propose a novel reinforcement learning(RL) approach to answering complex
questions that can learn a policy to dynamically decide which sub-question
should be answered at each stage of reasoning. We lever-age the expected
value-variance criterion to enable the learned policy to balance between the
risk and utility of answering a sub-question. Experiment results show that the
RL approach can substantially improve the optimality of ordering the
sub-questions, leading to improved accuracy of question answering. The proposed
method for learning to order sub-questions is general and can thus be
potentially combined with many existing ideas for answering complex questions
to enhance their performance.
</summary>
    <author>
      <name>Yunan Zhang</name>
    </author>
    <author>
      <name>Xiang Cheng</name>
    </author>
    <author>
      <name>Yufeng Zhang</name>
    </author>
    <author>
      <name>Zihan Wang</name>
    </author>
    <author>
      <name>Zhengqi Fang</name>
    </author>
    <author>
      <name>Xiaoyan Wang</name>
    </author>
    <author>
      <name>Zhenya Huang</name>
    </author>
    <author>
      <name>Chengxiang Zhai</name>
    </author>
    <link href="http://arxiv.org/abs/1911.04065v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04065v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03977v1</id>
    <updated>2019-11-10T18:58:20Z</updated>
    <published>2019-11-10T18:58:20Z</published>
    <title>Multimodal Intelligence: Representation Learning, Information Fusion,
  and Applications</title>
    <summary>  Deep learning has revolutionized speech recognition, image recognition, and
natural language processing since 2010, each involving a single modality in the
input signal. However, many applications in artificial intelligence involve
more than one modality. It is therefore of broad interest to study the more
difficult and complex problem of modeling and learning across multiple
modalities. In this paper, a technical review of the models and learning
methods for multimodal intelligence is provided. The main focus is the
combination of vision and natural language, which has become an important area
in both computer vision and natural language processing research communities.
This review provides a comprehensive analysis of recent work on multimodal deep
learning from three new angles - learning multimodal representations, the
fusion of multimodal signals at various levels, and multimodal applications. On
multimodal representation learning, we review the key concept of embedding,
which unifies the multimodal signals into the same vector space and thus
enables cross-modality signal processing. We also review the properties of the
many types of embedding constructed and learned for general downstream tasks.
On multimodal fusion, this review focuses on special architectures for the
integration of the representation of unimodal signals for a particular task. On
applications, selected areas of a broad interest in current literature are
covered, including caption generation, text-to-image generation, and visual
question answering. We believe this review can facilitate future studies in the
emerging field of multimodal intelligence for the community.
</summary>
    <author>
      <name>Chao Zhang</name>
    </author>
    <author>
      <name>Zichao Yang</name>
    </author>
    <author>
      <name>Xiaodong He</name>
    </author>
    <author>
      <name>Li Deng</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04942v1</id>
    <updated>2019-11-10T09:09:13Z</updated>
    <published>2019-11-10T09:09:13Z</published>
    <title>RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL
  Parsers</title>
    <summary>  When translating natural language questions into SQL queries to answer
questions from a database, contemporary semantic parsing models struggle to
generalize to unseen database schemas. The generalization challenge lies in (a)
encoding the database relations in an accessible way for the semantic parser,
and (b) modeling alignment between database columns and their mentions in a
given query. We present a unified framework, based on the relation-aware
self-attention mechanism, to address schema encoding, schema linking, and
feature representation within a text-to-SQL encoder. On the challenging Spider
dataset this framework boosts the exact match accuracy to 53.7%, compared to
47.4% for the state-of-the-art model unaugmented with BERT embeddings. In
addition, we observe qualitative improvements in the model's understanding of
schema linking and alignment.
</summary>
    <author>
      <name>Bailin Wang</name>
    </author>
    <author>
      <name>Richard Shin</name>
    </author>
    <author>
      <name>Xiaodong Liu</name>
    </author>
    <author>
      <name>Oleksandr Polozov</name>
    </author>
    <author>
      <name>Matthew Richardson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1906.11790</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.04942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03868v1</id>
    <updated>2019-11-10T06:58:44Z</updated>
    <published>2019-11-10T06:58:44Z</published>
    <title>Knowledge Guided Text Retrieval and Reading for Open Domain Question
  Answering</title>
    <summary>  This paper presents a general approach for open-domain question answering
(QA) that models interactions between paragraphs using structural information
from a knowledge base. We first describe how to construct a graph of passages
from a large corpus, where the relations are either from the knowledge base or
the internal structure of Wikipedia. We then introduce a reading comprehension
model which takes this graph as an input, to better model relationships across
pairs of paragraphs. This approach consistently outperforms competitive
baselines in three open-domain QA datasets, WebQuestions, Natural Questions and
TriviaQA, improving the pipeline-based state-of-the-art by 3--13%.
</summary>
    <author>
      <name>Sewon Min</name>
    </author>
    <author>
      <name>Danqi Chen</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03850v1</id>
    <updated>2019-11-10T04:41:31Z</updated>
    <published>2019-11-10T04:41:31Z</published>
    <title>Not All Claims are Created Equal: Choosing the Right Approach to Assess
  Your Hypotheses</title>
    <summary>  Empirical research in Natural Language Processing (NLP) has adopted a narrow
set of principles for assessing hypotheses, relying mainly on p-value
computation, which suffers from several known issues. While alternative
proposals have been well-debated and adopted in other fields, they remain
rarely discussed or used within the NLP community. We address this gap by
contrasting various hypothesis assessment techniques, especially those not
commonly used in the field (such as evaluations based on Bayesian inference).
Since these statistical techniques differ in the hypotheses they can support,
we argue that practitioners should first decide their target hypothesis before
choosing an assessment method. This is crucial because common fallacies,
misconceptions, and misinterpretation surrounding hypothesis assessment methods
often stem from a discrepancy between what one would like to claim versus what
the method used actually assesses. Our survey reveals that these issues are
omnipresent in the NLP research community. As a step forward, we provide best
practices and guidelines tailored to NLP research, as well as an easy-to-use
package called 'HyBayes' for Bayesian assessment of hypotheses, complementing
existing tools.
</summary>
    <author>
      <name>Erfan Sadeqi Azer</name>
    </author>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11078v1</id>
    <updated>2019-11-09T23:53:19Z</updated>
    <published>2019-11-09T23:53:19Z</published>
    <title>Predictive Biases in Natural Language Processing Models: A Conceptual
  Framework and Overview</title>
    <summary>  An increasing number of works in natural language processing have addressed
the effect of bias on the predicted outcomes, introducing mitigation techniques
that act on different parts of the standard NLP pipeline (data and models).
However, these works have been conducted in isolation, without a unifying
framework to organize efforts within the field. This leads to repetitive
approaches, and puts an undue focus on the effects of bias, rather than on
their origins. Research focused on bias symptoms rather than the underlying
origins could limit the development of effective countermeasures. In this
paper, we propose a unifying conceptualization: the predictive bias framework
for NLP. We summarize the NLP literature and propose a general mathematical
definition of predictive bias in NLP along with a conceptual framework,
differentiating four main origins of biases: label bias, selection bias, model
overamplification, and semantic bias. We discuss how past work has countered
each bias origin. Our framework serves to guide an introductory overview of
predictive bias in NLP, integrating existing work into a single structure and
opening avenues for future research.
</summary>
    <author>
      <name>Deven Shah</name>
    </author>
    <author>
      <name>H. Andrew Schwartz</name>
    </author>
    <author>
      <name>Dirk Hovy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages excluding references, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03768v1</id>
    <updated>2019-11-09T20:05:06Z</updated>
    <published>2019-11-09T20:05:06Z</published>
    <title>The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded
  Conversational Agents</title>
    <summary>  We introduce dodecaDialogue: a set of 12 tasks that measures if a
conversational agent can communicate engagingly with personality and empathy,
ask questions, answer questions by utilizing knowledge resources, discuss
topics and situations, and perceive and converse about images. By multi-tasking
on such a broad large-scale set of data, we hope to both move towards and
measure progress in producing a single unified agent that can perceive, reason
and converse with humans in an open-domain setting. We show that such
multi-tasking improves over a BERT pre-trained baseline, largely due to
multi-tasking with very large dialogue datasets in a similar domain, and that
the multi-tasking in general provides gains to both text and image-based tasks
using several metrics in both the fine-tune and task transfer settings. We
obtain state-of-the-art results on many of the tasks, providing a strong
baseline for this challenge.
</summary>
    <author>
      <name>Kurt Shuster</name>
    </author>
    <author>
      <name>Da Ju</name>
    </author>
    <author>
      <name>Stephen Roller</name>
    </author>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Y-Lan Boureau</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03743v1</id>
    <updated>2019-11-09T17:56:47Z</updated>
    <published>2019-11-09T17:56:47Z</published>
    <title>A perspective on multi-agent communication for information fusion</title>
    <summary>  Collaborative decision making in multi-agent systems typically requires a
predefined communication protocol among agents. Usually, agent-level
observations are locally processed and information is exchanged using the
predefined protocol, enabling the team to perform more efficiently than each
agent operating in isolation. In this work, we consider the situation where
agents, with complementary sensing modalities must co-operate to achieve a
common goal/task by learning an efficient communication protocol. We frame the
problem within an actor-critic scheme, where the agents learn optimal policies
in a centralized fashion, while taking action in a distributed manner. We
provide an interpretation of the emergent communication between the agents. We
observe that the information exchanged is not just an encoding of the raw
sensor data but is, rather, a specific set of directive actions that depend on
the overall task. Simulation results demonstrate the interpretability of the
learnt communication in a variety of tasks.
</summary>
    <author>
      <name>Homagni Saha</name>
    </author>
    <author>
      <name>Vijay Venkataraman</name>
    </author>
    <author>
      <name>Alberto Speranzon</name>
    </author>
    <author>
      <name>Soumik Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,
  Vancouver, CA</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03705v1</id>
    <updated>2019-11-09T14:53:59Z</updated>
    <published>2019-11-09T14:53:59Z</published>
    <title>CommonGen: A Constrained Text Generation Dataset Towards Generative
  Commonsense Reasoning</title>
    <summary>  Rational humans can generate sentences that cover a certain set of concepts
while describing natural and common scenes. For example, given {apple(noun),
tree(noun), pick(verb)}, humans can easily come up with scenes like "a boy is
picking an apple from a tree" via their generative commonsense reasoning
ability. However, we find this capacity has not been well learned by machines.
Most prior works in machine commonsense focus on discriminative reasoning tasks
with a multi-choice question answering setting. Herein, we present CommonGen: a
challenging dataset for testing generative commonsense reasoning with a
constrained text generation task. We collect 37k concept-sets as inputs and 90k
human-written sentences as associated outputs. Additionally, we also provide
high-quality rationales behind the reasoning process for the development and
test sets from the human annotators. We demonstrate the difficulty of the task
by examining a wide range of sequence generation methods with both automatic
metrics and human evaluation. The state-of-the-art pre-trained generation
model, UniLM, is still far from human performance in this task. Our data and
code is publicly available at http://inklab.usc.edu/CommonGen/ .
</summary>
    <author>
      <name>Bill Yuchen Lin</name>
    </author>
    <author>
      <name>Ming Shen</name>
    </author>
    <author>
      <name>Yu Xing</name>
    </author>
    <author>
      <name>Pei Zhou</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in process; 10 pages, Table 4 is on the last page ; The data and
  code can be found at http://inklab.usc.edu/CommonGen/</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03663v1</id>
    <updated>2019-11-09T10:55:34Z</updated>
    <published>2019-11-09T10:55:34Z</published>
    <title>xSLUE: A Benchmark and Analysis Platform for Cross-Style Language
  Understanding and Evaluation</title>
    <summary>  Every natural text is written in some style. The style is formed by a complex
combination of different stylistic factors, including formality markers,
emotions, metaphors, etc. Some factors implicitly reflect the author's
personality, while others are explicitly controlled by the author's choices in
order to achieve some personal or social goal. One cannot form a complete
understanding of a text and its author without considering these factors. The
factors combine and co-vary in complex ways to form styles. Studying the nature
of the covarying combinations sheds light on stylistic language in general,
sometimes called cross-style language understanding. This paper provides a
benchmark corpus (xSLUE) with an online platform (http://xslue.com) for
cross-style language understanding and evaluation. The benchmark contains text
in 15 different styles and 23 classification tasks. For each task, we provide
the fine-tuned classifier for further analysis. Our analysis shows that some
styles are highly dependent on each other (e.g., impoliteness and offense), and
some domains (e.g., tweets, political debates) are stylistically more diverse
than others (e.g., academic manuscripts). We discuss the technical challenges
of cross-style understanding and potential directions for future research:
cross-style modeling which shares the internal representation for low-resource
or low-performance styles and other applications such as cross-style
generation.
</summary>
    <author>
      <name>Dongyeop Kang</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04910v1</id>
    <updated>2019-11-09T07:02:33Z</updated>
    <published>2019-11-09T07:02:33Z</published>
    <title>Orthogonal Relation Transforms with Graph Context Modeling for Knowledge
  Graph Embedding</title>
    <summary>  Translational distance-based knowledge graph embedding has shown progressive
improvements on the link prediction task, from TransE to the latest
state-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain
challenging. In this work, we propose a novel translational distance-based
approach for knowledge graph link prediction. The proposed method includes
two-folds, first we extend the RotatE from 2D complex domain to high dimension
space with orthogonal transforms to model relations for better modeling
capacity. Second, the graph context is explicitly modeled via two directed
context representations. These context representations are used as part of the
distance scoring function to measure the plausibility of the triples during
training and inference. The proposed approach effectively improves prediction
accuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link
prediction task. The experimental results show that it achieves better
performance on two benchmark data sets compared to the baseline RotatE,
especially on data set (FB15k-237) with many high in-degree connection nodes.
</summary>
    <author>
      <name>Yun Tang</name>
    </author>
    <author>
      <name>Jing Huang</name>
    </author>
    <author>
      <name>Guangtao Wang</name>
    </author>
    <author>
      <name>Xiaodong He</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1911.04910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03429v1</id>
    <updated>2019-11-08T18:29:03Z</updated>
    <published>2019-11-08T18:29:03Z</published>
    <title>ERASER: A Benchmark to Evaluate Rationalized NLP Models</title>
    <summary>  State-of-the-art models in NLP are now predominantly based on deep neural
networks that are generally opaque in terms of how they come to specific
predictions. This limitation has led to increased interest in designing more
interpretable deep models for NLP that can reveal the `reasoning' underlying
model outputs. But work in this direction has been conducted on different
datasets and tasks with correspondingly unique aims and metrics; this makes it
difficult to track progress.
  We propose the Evaluating Rationales And Simple English Reasoning (ERASER)
benchmark to advance research on interpretable models in NLP. This benchmark
comprises multiple datasets and tasks for which human annotations of
"rationales" (supporting evidence) have been collected. We propose several
metrics that aim to capture how well the rationales provided by models align
with human rationales, and also how faithful these rationales are (i.e., the
degree to which provided rationales influenced the corresponding predictions).
Our hope is that releasing this benchmark facilitates progress on designing
more interpretable NLP systems. The benchmark, code, and documentation are
available at: www.eraserbenchmark.com .
</summary>
    <author>
      <name>Jay DeYoung</name>
    </author>
    <author>
      <name>Sarthak Jain</name>
    </author>
    <author>
      <name>Nazneen Fatema Rajani</name>
    </author>
    <author>
      <name>Eric Lehman</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Byron C. Wallace</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://github.com/jayded/eraserbenchmark
  http://www.eraserbenchmark.com/</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03429v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03429v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03378v1</id>
    <updated>2019-11-08T16:59:17Z</updated>
    <published>2019-11-08T16:59:17Z</published>
    <title>Investigation of Error Simulation Techniques for Learning Dialog
  Policies for Conversational Error Recovery</title>
    <summary>  Training dialog policies for speech-based virtual assistants requires a
plethora of conversational data. The data collection phase is often expensive
and time consuming due to human involvement. To address this issue, a common
solution is to build user simulators for data generation. For the successful
deployment of the trained policies into real world domains, it is vital that
the user simulator mimics realistic conditions. In particular, speech-based
assistants are heavily affected by automatic speech recognition and language
understanding errors, hence the user simulator should be able to simulate
similar errors. In this paper, we review the existing error simulation methods
that induce errors at audio, phoneme, text, or semantic level; and conduct
detailed comparisons between the audio-level and text-level methods. In the
process, we improve the existing text-level method by introducing confidence
score prediction and out-of-vocabulary word mapping. We also explore the impact
of audio-level and text-level methods on learning a simple clarification dialog
policy to recover from errors to provide insight on future improvement for both
approaches.
</summary>
    <author>
      <name>Maryam Fazel-Zarandi</name>
    </author>
    <author>
      <name>Longshaokan Wang</name>
    </author>
    <author>
      <name>Aditya Tiwari</name>
    </author>
    <author>
      <name>Spyros Matsoukas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 3rd Conversational AI workshop - today's practice and tomorrow's
  potential</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.03350v1</id>
    <updated>2019-11-08T16:17:40Z</updated>
    <published>2019-11-08T16:17:40Z</published>
    <title>Ask to Learn: A Study on Curiosity-driven Question Generation</title>
    <summary>  We propose a novel text generation task, namely Curiosity-driven Question
Generation. We start from the observation that the Question Generation task has
traditionally been considered as the dual problem of Question Answering, hence
tackling the problem of generating a question given the text that contains its
answer. Such questions can be used to evaluate machine reading comprehension.
However, in real life, and especially in conversational settings, humans tend
to ask questions with the goal of enriching their knowledge and/or clarifying
aspects of previously gathered information. We refer to these inquisitive
questions as Curiosity-driven: these questions are generated with the goal of
obtaining new information (the answer) which is not present in the input text.
In this work, we experiment on this new task using a conversational Question
Answering (QA) dataset; further, since the majority of QA dataset are not built
in a conversational manner, we describe a methodology to derive data for this
novel task from non-conversational QA data. We investigate several automated
metrics to measure the different properties of Curious Questions, and
experiment different approaches on the Curiosity-driven Question Generation
task, including model pre-training and reinforcement learning. Finally, we
report a qualitative evaluation of the generated outputs.
</summary>
    <author>
      <name>Thomas Scialom</name>
    </author>
    <author>
      <name>Jacopo Staiano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04873v1</id>
    <updated>2019-11-07T11:22:44Z</updated>
    <published>2019-11-07T11:22:44Z</published>
    <title>Can Neural Networks Learn Symbolic Rewriting?</title>
    <summary>  This work investigates if the current neural architectures are adequate for
learning symbolic rewriting. Two kinds of data sets are proposed for this
research -- one based on automated proofs and the other being a synthetic set
of polynomial terms. The experiments with use of the current neural machine
translation models are performed and its results are discussed. Ideas for
extending this line of research are proposed and its relevance is motivated.
</summary>
    <author>
      <name>Bartosz Piotrowski</name>
    </author>
    <author>
      <name>Josef Urban</name>
    </author>
    <author>
      <name>Chad E. Brown</name>
    </author>
    <author>
      <name>Cezary Kaliszyk</name>
    </author>
    <link href="http://arxiv.org/abs/1911.04873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.06192v1</id>
    <updated>2019-11-07T10:00:16Z</updated>
    <published>2019-11-07T10:00:16Z</published>
    <title>Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced
  Question Answering</title>
    <summary>  Multi-domain dialogue state tracking (DST) is a critical component for
conversational AI systems. The domain ontology (i.e., specification of domains,
slots, and values) of a conversational AI system is generally incomplete,
making the capability for DST models to generalize to new slots, values, and
domains during inference imperative. In this paper, we propose to model
multi-domain DST as a question answering problem, referred to as Dialogue State
Tracking via Question Answering (DSTQA). Within DSTQA, each turn generates a
question asking for the value of a (domain, slot) pair, thus making it
naturally extensible to unseen domains, slots, and values. Additionally, we use
a dynamically-evolving knowledge graph to explicitly learn relationships
between (domain, slot) pairs. Our model has a 5.80% and 12.21% relative
improvement over the current state-of-the-art model on MultiWOZ 2.0 and
MultiWOZ 2.1 datasets, respectively. Additionally, our model consistently
outperforms the state-of-the-art model in domain adaptation settings.
</summary>
    <author>
      <name>Li Zhou</name>
    </author>
    <author>
      <name>Kevin Small</name>
    </author>
    <link href="http://arxiv.org/abs/1911.06192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02707v1</id>
    <updated>2019-11-07T01:40:39Z</updated>
    <published>2019-11-07T01:40:39Z</published>
    <title>Conversation Generation with Concept Flow</title>
    <summary>  Human conversations naturally evolve around related entities and connected
concepts, while may also shift from topic to topic. This paper presents
ConceptFlow, which leverages commonsense knowledge graphs to explicitly model
such conversation flows for better conversation response generation.
ConceptFlow grounds the conversation inputs to the latent concept space and
represents the potential conversation flow as a concept flow along the
commonsense relations. The concept is guided by a graph attention mechanism
that models the possibility of the conversation evolving towards different
concepts. The conversation response is then decoded using the encodings of both
utterance texts and concept flows, integrating the learned conversation
structure in the concept space. Our experiments on Reddit conversations
demonstrate the advantage of ConceptFlow over previous commonsense aware dialog
models and fine-tuned GPT-2 models, while using much fewer parameters but with
explicit modeling of conversation structures.
</summary>
    <author>
      <name>Houyu Zhang</name>
    </author>
    <author>
      <name>Zhenghao Liu</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02690v2</id>
    <updated>2020-01-30T19:07:39Z</updated>
    <published>2019-11-07T00:52:38Z</published>
    <title>SIMMC: Situated Interactive Multi-Modal Conversational Data Collection
  And Evaluation Platform</title>
    <summary>  As digital virtual assistants become ubiquitous, it becomes increasingly
important to understand the situated behaviour of users as they interact with
these assistants. To this end, we introduce SIMMC, an extension to ParlAI for
multi-modal conversational data collection and system evaluation. SIMMC
simulates an immersive setup, where crowd workers are able to interact with
environments constructed in AI Habitat or Unity while engaging in a
conversation. The assistant in SIMMC can be a crowd worker or Artificial
Intelligent (AI) agent. This enables both (i) a multi-player / Wizard of Oz
setting for data collection, or (ii) a single player mode for model / system
evaluation. We plan to open-source a situated conversational data-set collected
on this platform for the Conversational AI research community.
</summary>
    <author>
      <name>Paul A. Crook</name>
    </author>
    <author>
      <name>Shivani Poddar</name>
    </author>
    <author>
      <name>Ankita De</name>
    </author>
    <author>
      <name>Semir Shafi</name>
    </author>
    <author>
      <name>David Whitney</name>
    </author>
    <author>
      <name>Alborz Geramifard</name>
    </author>
    <author>
      <name>Rajen Subba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ASRU 2019 (demonstration)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.02690v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02690v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02524v1</id>
    <updated>2019-11-06T18:05:13Z</updated>
    <published>2019-11-06T18:05:13Z</published>
    <title>A Spoken Dialogue System for Spatial Question Answering in a Physical
  Blocks World</title>
    <summary>  The blocks world is a classic toy domain that has long been used to build and
test spatial reasoning systems. Despite its relative simplicity, tackling this
domain in its full complexity requires the agent to exhibit a rich set of
functional capabilities, ranging from vision to natural language understanding.
There is currently a resurgence of interest in solving problems in such limited
domains using modern techniques. In this work we tackle spatial question
answering in a holistic way, using a vision system, speech input and output
mediated by an animated avatar, a dialogue system that robustly interprets
spatial queries, and a constraint solver that derives answers based on 3-D
spatial modeling. The contributions of this work include a semantic parser that
maps spatial questions into logical forms consistent with a general approach to
meaning representation, a dialog manager based on a schema representation, and
a constraint solver for spatial questions that provides answers in agreement
with human perception. These and other components are integrated into a
multi-modal human-computer interaction pipeline.
</summary>
    <author>
      <name>Georgiy Platonov</name>
    </author>
    <author>
      <name>Benjamin Kane</name>
    </author>
    <author>
      <name>Aaron Gindi</name>
    </author>
    <author>
      <name>Lenhart K. Schubert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages (with references), 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.02524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02365v1</id>
    <updated>2019-11-06T13:23:41Z</updated>
    <published>2019-11-06T13:23:41Z</published>
    <title>Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and
  BERT Worlds</title>
    <summary>  Automatic question generation aims at the generation of questions from a
context, with the corresponding answers being sub-spans of the given passage.
Whereas, most of the methods mostly rely on heuristic rules to generate
questions, more recently also neural network approaches have been proposed. In
this work, we propose a variant of the self-attention Transformer network
architectures model to generate meaningful and diverse questions. To this end,
we propose an easy to use model consisting of the conjunction of the
Transformer decoder GPT-2 model with Transformer encoder BERT for the
downstream task for question answering. The model is trained in an end-to-end
fashion, where the language model is trained to produce a question-answer-aware
input representation that facilitates to generate an answer focused question.
Our result of neural question generation from text on the SQuAD 1.1 dataset
suggests that our method can produce semantically correct and diverse
questions. Additionally, we assessed the performance of our proposed method for
the downstream task of question answering. The analysis shows that our proposed
generation &amp; answering collaboration framework relatively improves both tasks
and is particularly powerful in the semi-supervised setup. The results further
suggest a robust and comparably lean pipeline facilitating question generation
in the small-data regime.
</summary>
    <author>
      <name>Tassilo Klein</name>
    </author>
    <author>
      <name>Moin Nabi</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02168v1</id>
    <updated>2019-11-06T02:27:39Z</updated>
    <published>2019-11-06T02:27:39Z</published>
    <title>CoKE: Contextualized Knowledge Graph Embedding</title>
    <summary>  Knowledge graph embedding, which projects symbolic entities and relations
into continuous vector spaces, is gaining increasing attention. Previous
methods allow a single static embedding for each entity or relation, ignoring
their intrinsic contextual nature, i.e., entities and relations may appear in
different graph contexts, and accordingly, exhibit different properties. This
work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm
that takes into account such contextual nature, and learns dynamic, flexible,
and fully contextualized entity and relation embeddings. Two types of graph
contexts are studied: edges and paths, both formulated as sequences of entities
and relations. CoKE takes a sequence as input and uses a Transformer encoder to
obtain contextualized representations. These representations are hence
naturally adaptive to the input, capturing contextual meanings of entities and
relations therein. Evaluation on a wide variety of public benchmarks verifies
the superiority of CoKE in link prediction and path query answering. It
performs consistently better than, or at least equally well as current
state-of-the-art in almost every case, in particular offering an absolute
improvement of 19.7% in H@10 on path query answering. Our code is available at
\url{https://github.com/paddlepaddle/models/tree/develop/PaddleKG/CoKE}.
</summary>
    <author>
      <name>Quan Wang</name>
    </author>
    <author>
      <name>Pingping Huang</name>
    </author>
    <author>
      <name>Haifeng Wang</name>
    </author>
    <author>
      <name>Songtai Dai</name>
    </author>
    <author>
      <name>Wenbin Jiang</name>
    </author>
    <author>
      <name>Jing Liu</name>
    </author>
    <author>
      <name>Yajuan Lyu</name>
    </author>
    <author>
      <name>Yong Zhu</name>
    </author>
    <author>
      <name>Hua Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02085v2</id>
    <updated>2020-02-04T04:17:44Z</updated>
    <published>2019-11-05T21:06:04Z</published>
    <title>Path-Based Contextualization of Knowledge Graphs for Textual Entailment</title>
    <summary>  In this paper, we introduce the problem of knowledge graph contextualization
-- that is, given a specific NLP task, the problem of extracting meaningful and
relevant sub-graphs from a given knowledge graph. The task in the case of this
paper is the textual entailment problem, and the context is a relevant
sub-graph for an instance of the textual entailment problem -- where given two
sentences p and h, the entailment relationship between them has to be predicted
automatically. We base our methodology on finding paths in a cost-customized
external knowledge graph, and building the most relevant sub-graph that
connects p and h. We show that our path selection mechanism to generate
sub-graphs not only reduces noise, but also retrieves meaningful information
from large knowledge graphs. Our evaluation shows that using information on
entities as well as the relationships between them improves on the performance
of purely text-based systems.
</summary>
    <author>
      <name>Kshitij Fadnis</name>
    </author>
    <author>
      <name>Kartik Talamadupula</name>
    </author>
    <author>
      <name>Pavan Kapanipathi</name>
    </author>
    <author>
      <name>Haque Ishfaq</name>
    </author>
    <author>
      <name>Salim Roukos</name>
    </author>
    <author>
      <name>Achille Fokoue</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02085v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02085v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02060v2</id>
    <updated>2019-11-22T00:20:31Z</updated>
    <published>2019-11-05T19:52:34Z</published>
    <title>Infusing Knowledge into the Textual Entailment Task Using Graph
  Convolutional Networks</title>
    <summary>  Textual entailment is a fundamental task in natural language processing. Most
approaches for solving the problem use only the textual content present in
training data. A few approaches have shown that information from external
knowledge sources like knowledge graphs (KGs) can add value, in addition to the
textual content, by providing background knowledge that may be critical for a
task. However, the proposed models do not fully exploit the information in the
usually large and noisy KGs, and it is not clear how it can be effectively
encoded to be useful for entailment. We present an approach that complements
text-based entailment models with information from KGs by (1) using
Personalized PageR- ank to generate contextual subgraphs with reduced noise and
(2) encoding these subgraphs using graph convolutional networks to capture KG
structure. Our technique extends the capability of text models exploiting
structural and semantic information found in KGs. We evaluate our approach on
multiple textual entailment datasets and show that the use of external
knowledge helps improve prediction accuracy. This is particularly evident in
the challenging BreakingNLI dataset, where we see an absolute improvement of
5-20% over multiple text-based entailment models.
</summary>
    <author>
      <name>Pavan Kapanipathi</name>
    </author>
    <author>
      <name>Veronika Thost</name>
    </author>
    <author>
      <name>Siva Sankalp Patel</name>
    </author>
    <author>
      <name>Spencer Whitehead</name>
    </author>
    <author>
      <name>Ibrahim Abdelaziz</name>
    </author>
    <author>
      <name>Avinash Balakrishnan</name>
    </author>
    <author>
      <name>Maria Chang</name>
    </author>
    <author>
      <name>Kshitij Fadnis</name>
    </author>
    <author>
      <name>Chulaka Gunasekara</name>
    </author>
    <author>
      <name>Bassem Makni</name>
    </author>
    <author>
      <name>Nicholas Mattei</name>
    </author>
    <author>
      <name>Kartik Talamadupula</name>
    </author>
    <author>
      <name>Achille Fokoue</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02060v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02060v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01917v1</id>
    <updated>2019-11-05T16:23:01Z</updated>
    <published>2019-11-05T16:23:01Z</published>
    <title>Scenarios and Recommendations for Ethical Interpretive AI</title>
    <summary>  Artificially intelligent systems, given a set of non-trivial ethical rules to
follow, will inevitably be faced with scenarios which call into question the
scope of those rules. In such cases, human reasoners typically will engage in
interpretive reasoning, where interpretive arguments are used to support or
attack claims that some rule should be understood a certain way. Artificially
intelligent reasoners, however, currently lack the ability to carry out
human-like interpretive reasoning, and we argue that bridging this gulf is of
tremendous importance to human-centered AI. In order to better understand how
future artificial reasoners capable of human-like interpretive reasoning must
be developed, we have collected a dataset of ethical rules, scenarios designed
to invoke interpretive reasoning, and interpretations of those scenarios. We
perform a qualitative analysis of our dataset, and summarize our findings in
the form of practical recommendations.
</summary>
    <author>
      <name>John Licato</name>
    </author>
    <author>
      <name>Zaid Marji</name>
    </author>
    <author>
      <name>Sophia Abraham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the Proceedings of the Human-Centered AI:
  Trustworthiness of AI Models &amp; Data (HAI) track at AAAI Fall Symposium, DC,
  November 7-9, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01892v1</id>
    <updated>2019-11-05T15:55:19Z</updated>
    <published>2019-11-05T15:55:19Z</published>
    <title>Focus on What's Informative and Ignore What's not: Communication
  Strategies in a Referential Game</title>
    <summary>  Research in multi-agent cooperation has shown that artificial agents are able
to learn to play a simple referential game while developing a shared lexicon.
This lexicon is not easy to analyze, as it does not show many properties of a
natural language. In a simple referential game with two neural network-based
agents, we analyze the object-symbol mapping trying to understand what kind of
strategy was used to develop the emergent language. We see that, when the
environment is uniformly distributed, the agents rely on a random subset of
features to describe the objects. When we modify the objects making one feature
non-uniformly distributed,the agents realize it is less informative and start
to ignore it, and, surprisingly, they make a better use of the remaining
features. This interesting result suggests that more natural, less uniformly
distributed environments might aid in spurring the emergence of better-behaved
languages.
</summary>
    <author>
      <name>Roberto Dessì</name>
    </author>
    <author>
      <name>Diane Bouchacourt</name>
    </author>
    <author>
      <name>Davide Crepaldi</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3rd NeurIPS Workshop on Emergent Communication</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01680v1</id>
    <updated>2019-11-05T09:29:07Z</updated>
    <published>2019-11-05T09:29:07Z</published>
    <title>Improving Slot Filling by Utilizing Contextual Information</title>
    <summary>  Slot Filling is the task of extracting the semantic concept from a given
natural language utterance. Recently it has been shown that using contextual
information, either in work representations (e.g., BERT embedding) or in the
computation graph of the model, could improve the performance of the model.
However, recent work uses the contextual information in a restricted manner,
e.g., by concatenating the word representation and its context feature vector,
limiting the model from learning any direct association between the context and
the label of word. We introduce a new deep model utilizing the contextual
information for each work in the given sentence in a multi-task setting. Our
model enforce consistency between the feature vectors of the context and the
word while increasing the expressiveness of the context about the label of the
word. Our empirical analysis on a slot filling dataset proves the superiority
of the model over the baselines.
</summary>
    <author>
      <name>Amir Pouran Ben Veyseh</name>
    </author>
    <author>
      <name>Franck Dernonrcourt</name>
    </author>
    <author>
      <name>Thien Huu Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01680v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01680v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01678v3</id>
    <updated>2019-11-17T23:54:37Z</updated>
    <published>2019-11-05T09:23:58Z</published>
    <title>A Joint Model for Definition Extraction with Syntactic Connection and
  Semantic Consistency</title>
    <summary>  Definition Extraction (DE) is one of the well-known topics in Information
Extraction that aims to identify terms and their corresponding definitions in
unstructured texts. This task can be formalized either as a sentence
classification task (i.e., containing term-definition pairs or not) or a
sequential labeling task (i.e., identifying the boundaries of the terms and
definitions). The previous works for DE have only focused on one of the two
approaches, failing to model the inter-dependencies between the two tasks. In
this work, we propose a novel model for DE that simultaneously performs the two
tasks in a single framework to benefit from their inter-dependencies. Our model
features deep learning architectures to exploit the global structures of the
input sentences as well as the semantic consistencies between the terms and the
definitions, thereby improving the quality of the representation vectors for
DE. Besides the joint inference between sentence classification and sequential
labeling, the proposed model is fundamentally different from the prior work for
DE in that the prior work has only employed the local structures of the input
sentences (i.e., word-to-word relations), and not yet considered the semantic
consistencies between terms and definitions. In order to implement these novel
ideas, our model presents a multi-task learning framework that employs graph
convolutional neural networks and predicts the dependency paths between the
terms and the definitions. We also seek to enforce the consistency between the
representations of the terms and definitions both globally (i.e., increasing
semantic consistency between the representations of the entire sentences and
the terms/definitions) and locally (i.e., promoting the similarity between the
representations of the terms and the definitions).
</summary>
    <author>
      <name>Amir Pouran Ben Veyseh</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Dejing Dou</name>
    </author>
    <author>
      <name>Thien Huu Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01678v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01678v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01599v1</id>
    <updated>2019-11-05T03:49:20Z</updated>
    <published>2019-11-05T03:49:20Z</published>
    <title>LIDA: Lightweight Interactive Dialogue Annotator</title>
    <summary>  Dialogue systems have the potential to change how people interact with
machines but are highly dependent on the quality of the data used to train
them. It is therefore important to develop good dialogue annotation tools which
can improve the speed and quality of dialogue data annotation. With this in
mind, we introduce LIDA, an annotation tool designed specifically for
conversation data. As far as we know, LIDA is the first dialogue annotation
system that handles the entire dialogue annotation pipeline from raw text, as
may be the output of transcription services, to structured conversation data.
Furthermore it supports the integration of arbitrary machine learning models as
annotation recommenders and also has a dedicated interface to resolve
inter-annotator disagreements such as after crowdsourcing annotations for a
dataset. LIDA is fully open source, documented and publicly available [
https://github.com/Wluper/lida ]
</summary>
    <author>
      <name>Edward Collins</name>
    </author>
    <author>
      <name>Nikolai Rozanov</name>
    </author>
    <author>
      <name>Bingbing Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, 1 table, EMNLP 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL, EMNLP(D19-3021), 121--126, (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.01599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01485v1</id>
    <updated>2019-11-04T20:57:54Z</updated>
    <published>2019-11-04T20:57:54Z</published>
    <title>Assessing Social and Intersectional Biases in Contextualized Word
  Representations</title>
    <summary>  Social bias in machine learning has drawn significant attention, with work
ranging from demonstrations of bias in a multitude of applications, curating
definitions of fairness for different contexts, to developing algorithms to
mitigate bias. In natural language processing, gender bias has been shown to
exist in context-free word embeddings. Recently, contextual word
representations have outperformed word embeddings in several downstream NLP
tasks. These word representations are conditioned on their context within a
sentence, and can also be used to encode the entire sentence. In this paper, we
analyze the extent to which state-of-the-art models for contextual word
representations, such as BERT and GPT-2, encode biases with respect to gender,
race, and intersectional identities. Towards this, we propose assessing bias at
the contextual word level. This novel approach captures the contextual effects
of bias missing in context-free word embeddings, yet avoids confounding effects
that underestimate bias at the sentence encoding level. We demonstrate evidence
of bias at the corpus level, find varying evidence of bias in embedding
association tests, show in particular that racial bias is strongly encoded in
contextual word models, and observe that bias effects for intersectional
minorities are exacerbated beyond their constituent minority identities.
Further, evaluating bias effects at the contextual word level captures biases
that are not captured at the sentence level, confirming the need for our novel
approach.
</summary>
    <author>
      <name>Yi Chern Tan</name>
    </author>
    <author>
      <name>L. Elisa Celis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01474v1</id>
    <updated>2019-11-04T20:21:32Z</updated>
    <published>2019-11-04T20:21:32Z</published>
    <title>VASTA: A Vision and Language-assisted Smartphone Task Automation System</title>
    <summary>  We present VASTA, a novel vision and language-assisted Programming By
Demonstration (PBD) system for smartphone task automation. Development of a
robust PBD automation system requires overcoming three key challenges: first,
how to make a particular demonstration robust to positional and visual changes
in the user interface (UI) elements; secondly, how to recognize changes in the
automation parameters to make the demonstration as generalizable as possible;
and thirdly, how to recognize from the user utterance what automation the user
wishes to carry out. To address the first challenge, VASTA leverages
state-of-the-art computer vision techniques, including object detection and
optical character recognition, to accurately label interactions demonstrated by
a user, without relying on the underlying UI structures. To address the second
and third challenges, VASTA takes advantage of advanced natural language
understanding algorithms for analyzing the user utterance to trigger the VASTA
automation scripts, and to determine the automation parameters for
generalization. We run an initial user study that demonstrates the
effectiveness of VASTA at clustering user utterances, understanding changes in
the automation parameters, detecting desired UI elements, and, most
importantly, automating various tasks. A demo video of the system is available
here: http://y2u.be/kr2xE-FixjI
</summary>
    <author>
      <name>Alborz Rezazadeh Sereshkeh</name>
    </author>
    <author>
      <name>Gary Leung</name>
    </author>
    <author>
      <name>Krish Perumal</name>
    </author>
    <author>
      <name>Caleb Phillips</name>
    </author>
    <author>
      <name>Minfan Zhang</name>
    </author>
    <author>
      <name>Afsaneh Fazly</name>
    </author>
    <author>
      <name>Iqbal Mohomed</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM IUI'20, 10 figures, 11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00891v2</id>
    <updated>2019-11-05T12:25:55Z</updated>
    <published>2019-11-03T14:05:55Z</published>
    <title>Interpreting Verbal Irony: Linguistic Strategies and the Connection to
  the Type of Semantic Incongruity</title>
    <summary>  Human communication often involves the use of verbal irony or sarcasm, where
the speakers usually mean the opposite of what they say. To better understand
how verbal irony is expressed by the speaker and interpreted by the hearer we
conduct a crowdsourcing task: given an utterance expressing verbal irony, users
are asked to verbalize their interpretation of the speaker's ironic message. We
propose a typology of linguistic strategies for verbal irony interpretation and
link it to various theoretical linguistic frameworks. We design computational
models to capture these strategies and present empirical studies aimed to
answer three questions: (1) what is the distribution of linguistic strategies
used by hearers to interpret ironic messages?; (2) do hearers adopt similar
strategies for interpreting the speaker's ironic intent?; and (3) does the type
of semantic incongruity in the ironic message (explicit vs. implicit) influence
the choice of interpretation strategies by the hearers?
</summary>
    <author>
      <name>Debanjan Ghosh</name>
    </author>
    <author>
      <name>Elena Musi</name>
    </author>
    <author>
      <name>Kartikeya Upasani</name>
    </author>
    <author>
      <name>Smaranda Muresan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Society for Computation in Linguistics (SCiL), 2020
  Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00891v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00891v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00850v1</id>
    <updated>2019-11-03T08:00:38Z</updated>
    <published>2019-11-03T08:00:38Z</published>
    <title>Scene Graph based Image Retrieval -- A case study on the CLEVR Dataset</title>
    <summary>  With the prolification of multimodal interaction in various domains, recently
there has been much interest in text based image retrieval in the computer
vision community. However most of the state of the art techniques model this
problem in a purely neural way, which makes it difficult to incorporate
pragmatic strategies in searching a large scale catalog especially when the
search requirements are insufficient and the model needs to resort to an
interactive retrieval process through multiple iterations of
question-answering. Motivated by this, we propose a neural-symbolic approach
for a one-shot retrieval of images from a large scale catalog, given the
caption description. To facilitate this, we represent the catalog and caption
as scene-graphs and model the retrieval task as a learnable graph matching
problem, trained end-to-end with a REINFORCE algorithm. Further, we briefly
describe an extension of this pipeline to an iterative retrieval framework,
based on interactive questioning and answering.
</summary>
    <author>
      <name>Sahana Ramnath</name>
    </author>
    <author>
      <name>Amrita Saha</name>
    </author>
    <author>
      <name>Soumen Chakrabarti</name>
    </author>
    <author>
      <name>Mitesh M. Khapra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages including references, Accepted at the ICCV 2019 Workshop -
  'Linguistics Meets Image and Video Retrieval' (received Best Paper Award)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00773v1</id>
    <updated>2019-11-02T19:19:28Z</updated>
    <published>2019-11-02T19:19:28Z</published>
    <title>Design and Challenges of Cloze-Style Reading Comprehension Tasks on
  Multiparty Dialogue</title>
    <summary>  This paper analyzes challenges in cloze-style reading comprehension on
multiparty dialogue and suggests two new tasks for more comprehensive
predictions of personal entities in daily conversations. We first demonstrate
that there are substantial limitations to the evaluation methods of previous
work, namely that randomized assignment of samples to training and test data
substantially decreases the complexity of cloze-style reading comprehension.
According to our analysis, replacing the random data split with a chronological
data split reduces test accuracy on previous single-variable passage completion
task from 72\% to 34\%, that leaves much more room to improve. Our proposed
tasks extend the previous single-variable passage completion task by replacing
more character mentions with variables. Several deep learning models are
developed to validate these three tasks. A thorough error analysis is provided
to understand the challenges and guide the future direction of this research.
</summary>
    <author>
      <name>Changmao Li</name>
    </author>
    <author>
      <name>Tianhao Liu</name>
    </author>
    <author>
      <name>Jinho Choi</name>
    </author>
    <link href="http://arxiv.org/abs/1911.00773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00523v1</id>
    <updated>2019-11-01T18:00:05Z</updated>
    <published>2019-11-01T18:00:05Z</published>
    <title>What Gets Echoed? Understanding the "Pointers" in Explanations of
  Persuasive Arguments</title>
    <summary>  Explanations are central to everyday life, and are a topic of growing
interest in the AI community. To investigate the process of providing natural
language explanations, we leverage the dynamics of the /r/ChangeMyView
subreddit to build a dataset with 36K naturally occurring explanations of why
an argument is persuasive. We propose a novel word-level prediction task to
investigate how explanations selectively reuse, or echo, information from what
is being explained (henceforth, explanandum). We develop features to capture
the properties of a word in the explanandum, and show that our proposed
features not only have relatively strong predictive power on the echoing of a
word in an explanation, but also enhance neural methods of generating
explanations. In particular, while the non-contextual properties of a word
itself are more valuable for stopwords, the interaction between the constituent
parts of an explanandum is crucial in predicting the echoing of content words.
We also find intriguing patterns of a word being echoed. For example, although
nouns are generally less likely to be echoed, subjects and objects can,
depending on their source, be more likely to be echoed in the explanations.
</summary>
    <author>
      <name>David Atkinson</name>
    </author>
    <author>
      <name>Kumar Bhargav Srinivasan</name>
    </author>
    <author>
      <name>Chenhao Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 3 figures, EMNLP 2019, the code and dataset are available
  at https://chenhaot.com/papers/explanation-pointers.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00492v1</id>
    <updated>2019-11-01T17:59:38Z</updated>
    <published>2019-11-01T17:59:38Z</published>
    <title>Reasoning Over Paths via Knowledge Base Completion</title>
    <summary>  Reasoning over paths in large scale knowledge graphs is an important problem
for many applications. In this paper we discuss a simple approach to
automatically build and rank paths between a source and target entity pair with
learned embeddings using a knowledge base completion model (KBC). We assembled
a knowledge graph by mining the available biomedical scientific literature and
extracted a set of high frequency paths to use for validation. We demonstrate
that our method is able to effectively rank a list of known paths between a
pair of entities and also come up with plausible paths that are not present in
the knowledge graph. For a given entity pair we are able to reconstruct the
highest ranking path 60% of the time within the the top 10 ranked paths and
achieve 49% mean average precision. Our approach is compositional since any KBC
model that can produce vector representations of entities can be used.
</summary>
    <author>
      <name>Saatviga Sudhahar</name>
    </author>
    <author>
      <name>Ian Roberts</name>
    </author>
    <author>
      <name>Andrea Pierleoni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted at the TextGraphs2019 Workshop at EMNLP 2019 Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00473v1</id>
    <updated>2019-11-01T17:30:21Z</updated>
    <published>2019-11-01T17:30:21Z</published>
    <title>BERT Goes to Law School: Quantifying the Competitive Advantage of Access
  to Large Legal Corpora in Contract Understanding</title>
    <summary>  Fine-tuning language models, such as BERT, on domain specific corpora has
proven to be valuable in domains like scientific papers and biomedical text. In
this paper, we show that fine-tuning BERT on legal documents similarly provides
valuable improvements on NLP tasks in the legal domain. Demonstrating this
outcome is significant for analyzing commercial agreements, because obtaining
large legal corpora is challenging due to their confidential nature. As such,
we show that having access to large legal corpora is a competitive advantage
for commercial applications, and academic research on analyzing contracts.
</summary>
    <author>
      <name>Emad Elwany</name>
    </author>
    <author>
      <name>Dave Moore</name>
    </author>
    <author>
      <name>Gaurav Oberoi</name>
    </author>
    <link href="http://arxiv.org/abs/1911.00473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00229v1</id>
    <updated>2019-11-01T07:01:52Z</updated>
    <published>2019-11-01T07:01:52Z</published>
    <title>Engaging in Dialogue about an Agent's Norms and Behaviors</title>
    <summary>  We present a set of capabilities allowing an agent planning with moral and
social norms represented in temporal logic to respond to queries about its
norms and behaviors in natural language, and for the human user to add and
remove norms directly in natural language. The user may also pose hypothetical
modifications to the agent's norms and inquire about their effects.
</summary>
    <author>
      <name>Daniel Kasenberg</name>
    </author>
    <author>
      <name>Antonio Roque</name>
    </author>
    <author>
      <name>Ravenna Thielstrom</name>
    </author>
    <author>
      <name>Matthias Scheutz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 1st Workshop on Interactive Natural Language
  Technology for Explainable Artificial Intelligence (NL4XAI)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00226v1</id>
    <updated>2019-11-01T06:53:12Z</updated>
    <published>2019-11-01T06:53:12Z</published>
    <title>Generating Justifications for Norm-Related Agent Decisions</title>
    <summary>  We present an approach to generating natural language justifications of
decisions derived from norm-based reasoning. Assuming an agent which maximally
satisfies a set of rules specified in an object-oriented temporal logic, the
user can ask factual questions (about the agent's rules, actions, and the
extent to which the agent violated the rules) as well as "why" questions that
require the agent comparing actual behavior to counterfactual trajectories with
respect to these rules. To produce natural-sounding explanations, we focus on
the subproblem of producing natural language clauses from statements in a
fragment of temporal logic, and then describe how to embed these clauses into
explanatory sentences. We use a human judgment evaluation on a testbed task to
compare our approach to variants in terms of intelligibility, mental model and
perceived trust.
</summary>
    <author>
      <name>Daniel Kasenberg</name>
    </author>
    <author>
      <name>Antonio Roque</name>
    </author>
    <author>
      <name>Ravenna Thielstrom</name>
    </author>
    <author>
      <name>Meia Chita-Tegmark</name>
    </author>
    <author>
      <name>Matthias Scheutz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the Proceedings of the 12th International Conference on
  Natural Language Generation (INLG 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00497v1</id>
    <updated>2019-10-31T22:37:54Z</updated>
    <published>2019-10-31T22:37:54Z</published>
    <title>A Narration-based Reward Shaping Approach using Grounded Natural
  Language Commands</title>
    <summary>  While deep reinforcement learning techniques have led to agents that are
successfully able to learn to perform a number of tasks that had been
previously unlearnable, these techniques are still susceptible to the
longstanding problem of reward sparsity. This is especially true for tasks such
as training an agent to play StarCraft II, a real-time strategy game where
reward is only given at the end of a game which is usually very long. While
this problem can be addressed through reward shaping, such approaches typically
require a human expert with specialized knowledge. Inspired by the vision of
enabling reward shaping through the more-accessible paradigm of
natural-language narration, we develop a technique that can provide the
benefits of reward shaping using natural language commands. Our
narration-guided RL agent projects sequences of natural-language commands into
the same high-dimensional representation space as corresponding goal states. We
show that we can get improved performance with our method compared to
traditional reward-shaping approaches. Additionally, we demonstrate the ability
of our method to generalize to unseen natural-language commands.
</summary>
    <author>
      <name>Nicholas Waytowich</name>
    </author>
    <author>
      <name>Sean L. Barton</name>
    </author>
    <author>
      <name>Vernon Lawhern</name>
    </author>
    <author>
      <name>Garrett Warnell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the Imitation, Intent and Interaction (I3) workshop,
  ICML 2019. arXiv admin note: substantial text overlap with arXiv:1906.02671</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.14464v2</id>
    <updated>2019-11-01T15:27:05Z</updated>
    <published>2019-10-31T13:38:01Z</published>
    <title>What Question Answering can Learn from Trivia Nerds</title>
    <summary>  In addition to the traditional task of getting machines to answer questions,
a major research question in question answering is to create interesting,
challenging questions that can help systems learn how to answer questions and
also reveal which systems are the best at answering questions. We argue that
creating a question answering dataset---and the ubiquitous leaderboard that
goes with it---closely resembles running a trivia tournament: you write
questions, have agents (either humans or machines) answer the questions, and
declare a winner. However, the research community has ignored the decades of
hard-learned lessons from decades of the trivia community creating vibrant,
fair, and effective question answering competitions. After detailing problems
with existing QA datasets, we outline the key lessons---removing ambiguity,
discriminating skill, and adjudicating disputes---that can transfer to QA
research and how they might be implemented for the QA community.
</summary>
    <author>
      <name>Jordan Boyd-Graber</name>
    </author>
    <link href="http://arxiv.org/abs/1910.14464v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.14464v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.14229v1</id>
    <updated>2019-10-31T03:08:10Z</updated>
    <published>2019-10-31T03:08:10Z</published>
    <title>Cascaded LSTMs based Deep Reinforcement Learning for Goal-driven
  Dialogue</title>
    <summary>  This paper proposes a deep neural network model for joint modeling Natural
Language Understanding (NLU) and Dialogue Management (DM) in goal-driven
dialogue systems. There are three parts in this model. A Long Short-Term Memory
(LSTM) at the bottom of the network encodes utterances in each dialogue turn
into a turn embedding. Dialogue embeddings are learned by a LSTM at the middle
of the network, and updated by the feeding of all turn embeddings. The top part
is a forward Deep Neural Network which converts dialogue embeddings into the
Q-values of different dialogue actions. The cascaded LSTMs based reinforcement
learning network is jointly optimized by making use of the rewards received at
each dialogue turn as the only supervision information. There is no explicit
NLU and dialogue states in the network. Experimental results show that our
model outperforms both traditional Markov Decision Process (MDP) model and
single LSTM with Deep Q-Network on meeting room booking tasks. Visualization of
dialogue embeddings illustrates that the model can learn the representation of
dialogue states.
</summary>
    <author>
      <name>Yue Ma</name>
    </author>
    <author>
      <name>Xiaojie Wang</name>
    </author>
    <author>
      <name>Zhenjiang Dong</name>
    </author>
    <author>
      <name>Hong Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, appear in NLPCC 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.14229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.14229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.13114v2</id>
    <updated>2019-10-30T05:33:27Z</updated>
    <published>2019-10-29T06:56:46Z</published>
    <title>Contrastive Attention Mechanism for Abstractive Sentence Summarization</title>
    <summary>  We propose a contrastive attention mechanism to extend the
sequence-to-sequence framework for abstractive sentence summarization task,
which aims to generate a brief summary of a given source sentence. The proposed
contrastive attention mechanism accommodates two categories of attention: one
is the conventional attention that attends to relevant parts of the source
sentence, the other is the opponent attention that attends to irrelevant or
less relevant parts of the source sentence. Both attentions are trained in an
opposite way so that the contribution from the conventional attention is
encouraged and the contribution from the opponent attention is discouraged
through a novel softmax and softmin functionality. Experiments on benchmark
datasets show that, the proposed contrastive attention mechanism is more
focused on the relevant parts for the summary than the conventional attention
mechanism, and greatly advances the state-of-the-art performance on the
abstractive sentence summarization task. We release the code at
https://github.com/travel-go/Abstractive-Text-Summarization
</summary>
    <author>
      <name>Xiangyu Duan</name>
    </author>
    <author>
      <name>Hoongfei Yu</name>
    </author>
    <author>
      <name>Mingming Yin</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <author>
      <name>Weihua Luo</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by EMNLP2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.13114v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13114v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.13108v1</id>
    <updated>2019-10-29T06:45:24Z</updated>
    <published>2019-10-29T06:45:24Z</published>
    <title>Generating Questions for Knowledge Bases via Incorporating Diversified
  Contexts and Answer-Aware Loss</title>
    <summary>  We tackle the task of question generation over knowledge bases. Conventional
methods for this task neglect two crucial research issues: 1) the given
predicate needs to be expressed; 2) the answer to the generated question needs
to be definitive. In this paper, we strive toward the above two issues via
incorporating diversified contexts and answer-aware loss. Specifically, we
propose a neural encoder-decoder model with multi-level copy mechanisms to
generate such questions. Furthermore, the answer aware loss is introduced to
make generated questions corresponding to more definitive answers. Experiments
demonstrate that our model achieves state-of-the-art performance. Meanwhile,
such generated question can express the given predicate and correspond to a
definitive answer.
</summary>
    <author>
      <name>Cao Liu</name>
    </author>
    <author>
      <name>Kang Liu</name>
    </author>
    <author>
      <name>Shizhu He</name>
    </author>
    <author>
      <name>Zaiqing Nie</name>
    </author>
    <author>
      <name>Jun Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.13108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.13105v2</id>
    <updated>2020-02-29T08:15:00Z</updated>
    <published>2019-10-29T06:41:30Z</published>
    <title>JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge
  Alignment</title>
    <summary>  Abstract. Cross-lingual knowledge alignment is the cornerstone in building a
comprehensive knowledge graph (KG), which can benefit various knowledge-driven
applications. As the structures of KGs are usually sparse, attributes of
entities may play an important role in aligning the entities. However, the
heterogeneity of the attributes across KGs prevents from accurately embedding
and comparing entities. To deal with the issue, we propose to model the
interactions between attributes, instead of globally embedding an entity with
all the attributes. We further propose a joint framework to merge the
alignments inferred from the attributes and the structures. Experimental
results show that the proposed model outperforms the state-of-art baselines by
up to 38.48% HitRatio@1. The results also demonstrate that our model can infer
the alignments between attributes, relationships and values, in addition to
entities.
</summary>
    <author>
      <name>Bo Chen</name>
    </author>
    <author>
      <name>Jing Zhang</name>
    </author>
    <author>
      <name>Xiaobin Tang</name>
    </author>
    <author>
      <name>Hong Chen</name>
    </author>
    <author>
      <name>Cuiping Li</name>
    </author>
    <link href="http://arxiv.org/abs/1910.13105v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13105v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01217v1</id>
    <updated>2019-10-29T01:42:22Z</updated>
    <published>2019-10-29T01:42:22Z</published>
    <title>Detect Toxic Content to Improve Online Conversations</title>
    <summary>  Social media is filled with toxic content. The aim of this paper is to build
a model that can detect insincere questions. We use the 'Quora Insincere
Questions Classification' dataset for our analysis. The dataset is composed of
sincere and insincere questions, with the majority of sincere questions. The
dataset is processed and analyzed using Python and its libraries such as
sklearn, numpy, pandas, keras etc. The dataset is converted to vector form
using word embeddings such as GloVe, Wiki-news and TF-IDF. The imbalance in the
dataset is handled by resampling techniques. We train and compare various
machine learning and deep learning models to come up with the best results.
Models discussed include SVM, Naive Bayes, GRU and LSTM.
</summary>
    <author>
      <name>Deepshi Mediratta</name>
    </author>
    <author>
      <name>Nikhil Oswal</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12507v1</id>
    <updated>2019-10-28T09:06:00Z</updated>
    <published>2019-10-28T09:06:00Z</published>
    <title>A Survey on Knowledge Graph Embeddings with Literals: Which model links
  better Literal-ly?</title>
    <summary>  Knowledge Graphs (KGs) are composed of structured information about a
particular domain in the form of entities and relations. In addition to the
structured information KGs help in facilitating interconnectivity and
interoperability between different resources represented in the Linked Data
Cloud. KGs have been used in a variety of applications such as entity linking,
question answering, recommender systems, etc. However, KG applications suffer
from high computational and storage costs. Hence, there arises the necessity
for a representation able to map the high dimensional KGs into low dimensional
spaces, i.e., embedding space, preserving structural as well as relational
information. This paper conducts a survey of KG embedding models which not only
consider the structured information contained in the form of entities and
relations in a KG but also the unstructured information represented as literals
such as text, numerical values, images, etc. Along with a theoretical analysis
and comparison of the methods proposed so far for generating KG embeddings with
literals, an empirical evaluation of the different methods under identical
settings has been performed for the general task of link prediction.
</summary>
    <author>
      <name>Genet Asefa Gesese</name>
    </author>
    <author>
      <name>Russa Biswas</name>
    </author>
    <author>
      <name>Mehwish Alam</name>
    </author>
    <author>
      <name>Harald Sack</name>
    </author>
    <link href="http://arxiv.org/abs/1910.12507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12354v1</id>
    <updated>2019-10-27T21:11:42Z</updated>
    <published>2019-10-27T21:11:42Z</published>
    <title>Task-Oriented Language Grounding for Language Input with Multiple
  Sub-Goals of Non-Linear Order</title>
    <summary>  In this work, we analyze the performance of general deep reinforcement
learning algorithms for a task-oriented language grounding problem, where
language input contains multiple sub-goals and their order of execution is
non-linear.
  We generate a simple instructional language for the GridWorld environment,
that is built around three language elements (order connectors) defining the
order of execution: one linear - "comma" and two non-linear - "but first", "but
before". We apply one of the deep reinforcement learning baselines - Double DQN
with frame stacking and ablate several extensions such as Prioritized
Experience Replay and Gated-Attention architecture.
  Our results show that the introduction of non-linear order connectors
improves the success rate on instructions with a higher number of sub-goals in
2-3 times, but it still does not exceed 20%. Also, we observe that the usage of
Gated-Attention provides no competitive advantage against concatenation in this
setting. Source code and experiments' results are available at
https://github.com/vkurenkov/language-grounding-multigoal
</summary>
    <author>
      <name>Vladislav Kurenkov</name>
    </author>
    <author>
      <name>Bulat Maksudov</name>
    </author>
    <author>
      <name>Adil Khan</name>
    </author>
    <link href="http://arxiv.org/abs/1910.12354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12274v2</id>
    <updated>2019-11-03T18:00:36Z</updated>
    <published>2019-10-27T14:51:53Z</published>
    <title>Algorithmic Rewriting of Health-Related Ads to Improve their Performance</title>
    <summary>  Search advertising is one of the most commonly-used methods of advertising.
Past work has shown that search advertising can be employed to improve health
by eliciting positive behavioral change. However, writing effective
advertisements requires expertise and (possible expensive) experimentation,
both of which may not be available to public health authorities wishing to
elicit such behavioral changes, especially when dealing with a public health
crises such as epidemic outbreaks.
  Here we develop an algorithm which builds on past advertising data to train a
sequence-to-sequence Deep Neural Network which "translates" advertisements into
optimized ads that are more likely to be clicked. The network is trained using
more than 114 thousands ads shown on Microsoft Advertising. We apply this
translator to two health related domains: Medical Symptoms (MS) and
Preventative Healthcare (PH) and measure the improvements in click-through
rates (CTR).
  Our experiments show that the generated ads are predicted to have higher CTR
in 81% of MS ads and 76% of PH ads. To understand the differences between the
generated ads and the original ones we develop estimators for the affective
attributes of the ads. We show that the generated ads contain more
calls-to-action and that they reflect higher valence (36% increase) and higher
arousal (87%) on a sample of 1000 ads. Finally, we run an advertising campaign
where 10 random ads and their rephrased versions from each of the domains are
run in parallel. We show an average improvement in CTR of 68% for the generated
ads compared to the original ads.
  Our results demonstrate the ability to automatically optimize advertisement
for the health domain. We believe that our work offers health authorities an
improved ability to help nudge people towards healthier behaviors while saving
the time and cost needed to optimize advertising campaigns.
</summary>
    <author>
      <name>Brit Youngmann</name>
    </author>
    <author>
      <name>Ran Gilad-Bachrach</name>
    </author>
    <author>
      <name>Danny Karmon</name>
    </author>
    <author>
      <name>Elad Yom-Tov</name>
    </author>
    <link href="http://arxiv.org/abs/1910.12274v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12274v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12196v2</id>
    <updated>2019-11-10T11:20:10Z</updated>
    <published>2019-10-27T06:54:27Z</published>
    <title>Textual Adversarial Attack as Combinatorial Optimization</title>
    <summary>  Adversarial attack is carried out to reveal the vulnerability of deep neural
networks. Textual adversarial attack is challenging because text is discrete
and any perturbation might bring big semantic change. Word substitution is a
class of effective textual attack method and has been extensively explored.
However, all existing word substitution-based attack methods suffer the
problems of bad semantic preservation, insufficient adversarial examples or
suboptimal attack results. In this paper, we formalize the word
substitution-based attack as a combinatorial optimization problem. We also
propose a novel attack model, which comprises a sememe-based word substitution
strategy and the particle swarm optimization algorithm, to tackle the existing
problems. In experiments, we evaluate our attack model on the sentiment
analysis task. Experimental results demonstrate our model achieves higher
attack success rates and less modification than the baseline methods. The
ablation study also verifies the superiority of the two parts of our model over
previous ones.
</summary>
    <author>
      <name>Yuan Zang</name>
    </author>
    <author>
      <name>Chenghao Yang</name>
    </author>
    <author>
      <name>Fanchao Qi</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <author>
      <name>Meng Zhang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress. 6 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.12196v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12196v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11856v1</id>
    <updated>2019-10-25T17:30:20Z</updated>
    <published>2019-10-25T17:30:20Z</published>
    <title>On the Cross-lingual Transferability of Monolingual Representations</title>
    <summary>  State-of-the-art unsupervised multilingual models (e.g., multilingual BERT)
have been shown to generalize in a zero-shot cross-lingual setting. This
generalization ability has been attributed to the use of a shared subword
vocabulary and joint training across multiple languages giving rise to deep
multilingual abstractions. We evaluate this hypothesis by designing an
alternative approach that transfers a monolingual model to new languages at the
lexical level. More concretely, we first train a transformer-based masked
language model on one language, and transfer it to a new language by learning a
new embedding matrix with the same masked language modeling objective -freezing
parameters of all other layers. This approach does not rely on a shared
vocabulary or joint training. However, we show that it is competitive with
multilingual BERT on standard cross-lingual classification benchmarks and on a
new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict
common beliefs of the basis of the generalization ability of multilingual
models and suggest that deep monolingual models learn some abstractions that
generalize across languages. We also release XQuAD as a more comprehensive
cross-lingual benchmark, which comprises 240 paragraphs and 1190
question-answer pairs from SQuAD v1.1 translated into ten languages by
professional translators.
</summary>
    <author>
      <name>Mikel Artetxe</name>
    </author>
    <author>
      <name>Sebastian Ruder</name>
    </author>
    <author>
      <name>Dani Yogatama</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12619v1</id>
    <updated>2019-10-25T12:26:32Z</updated>
    <published>2019-10-25T12:26:32Z</published>
    <title>Is it a Fruit, an Apple or a Granny Smith? Predicting the Basic Level in
  a Concept Hierarchy</title>
    <summary>  The "basic level", according to experiments in cognitive psychology, is the
level of abstraction in a hierarchy of concepts at which humans perform tasks
quicker and with greater accuracy than at other levels. We argue that
applications that use concept hierarchies - such as knowledge graphs,
ontologies or taxonomies - could significantly improve their user interfaces if
they `knew' which concepts are the basic level concepts. This paper examines to
what extent the basic level can be learned from data. We test the utility of
three types of concept features, that were inspired by the basic level theory:
lexical features, structural features and frequency features. We evaluate our
approach on WordNet, and create a training set of manually labelled examples
that includes concepts from different domains. Our findings include that the
basic level concepts can be accurately identified within one domain. Concepts
that are difficult to label for humans are also harder to classify
automatically. Our experiments provide insight into how classification
performance across domains could be improved, which is necessary for
identification of basic level concepts on a larger scale.
</summary>
    <author>
      <name>Laura Hollink</name>
    </author>
    <author>
      <name>Aysenur Bilgin</name>
    </author>
    <author>
      <name>Jacco van Ossenbruggen</name>
    </author>
    <link href="http://arxiv.org/abs/1910.12619v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12619v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11471v1</id>
    <updated>2019-10-25T00:46:07Z</updated>
    <published>2019-10-25T00:46:07Z</published>
    <title>Machine Translation from Natural Language to Code using Long-Short Term
  Memory</title>
    <summary>  Making computer programming language more understandable and easy for the
human is a longstanding problem. From assembly language to present day's
object-oriented programming, concepts came to make programming easier so that a
programmer can focus on the logic and the architecture rather than the code and
language itself. To go a step further in this journey of removing
human-computer language barrier, this paper proposes machine learning approach
using Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) to
convert human language into programming language code. The programmer will
write expressions for codes in layman's language, and the machine learning
model will translate it to the targeted programming language. The proposed
approach yields result with 74.40% accuracy. This can be further improved by
incorporating additional techniques, which are also discussed in this paper.
</summary>
    <author>
      <name>K. M. Tahsin Hassan Rahit</name>
    </author>
    <author>
      <name>Rashidul Hasan Nabil</name>
    </author>
    <author>
      <name>Md Hasibul Huq</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32520-6_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32520-6_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Future Technologies Conference (FTC) 2019.
  Advances in Intelligent Systems and Computing, vol 1069. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.11471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.4; I.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11424v2</id>
    <updated>2020-02-01T22:36:24Z</updated>
    <published>2019-10-24T21:06:38Z</published>
    <title>Capacity, Bandwidth, and Compositionality in Emergent Language Learning</title>
    <summary>  Many recent works have discussed the propensity, or lack thereof, for
emergent languages to exhibit properties of natural languages. A favorite in
the literature is learning compositionality. We note that most of those works
have focused on communicative bandwidth as being of primary importance. While
important, it is not the only contributing factor. In this paper, we
investigate the learning biases that affect the efficacy and compositionality
of emergent languages. Our foremost contribution is to explore how capacity of
a neural network impacts its ability to learn a compositional language. We
additionally introduce a set of evaluation metrics with which we analyze the
learned languages. Our hypothesis is that there should be a specific range of
model capacity and channel bandwidth that induces compositional structure in
the resulting language and consequently encourages systematic generalization.
While we empirically see evidence for the bottom of this range, we curiously do
not find evidence for the top part of the range and believe that this is an
open question for the community.
</summary>
    <author>
      <name>Cinjon Resnick</name>
    </author>
    <author>
      <name>Abhinav Gupta</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Andrew M. Dai</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally. Accepted at AAMAS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.11424v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11424v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11292v2</id>
    <updated>2019-10-25T01:29:32Z</updated>
    <published>2019-10-24T17:10:34Z</published>
    <title>Predicting In-game Actions From the Language of NBA Players</title>
    <summary>  Sports competitions are widely researched in computer and social science,
with the goal of understanding how players act under uncertainty. While there
is an abundance of computational work on player metrics prediction based on
past performance, very few attempts to incorporate out-of-game signals have
been made. Specifically, it was previously unclear whether linguistic signals
gathered from players' interviews can add information which does not appear in
performance metrics. To bridge that gap, we define text classification tasks of
predicting deviations from mean in NBA players' in-game actions, which are
associated with strategic choices, player behavior and risk, using their choice
of language prior to the game. We collected a dataset of transcripts from key
NBA players' pre-game interviews and their in-game performance metrics,
totaling in 5,226 interview-metric pairs. We design neural models for players'
action prediction based on increasingly more complex aspects of the language
signals in their open-ended interviews. Our models can make their predictions
based on the textual signal alone, or on a combination with signals from
past-performance metrics. Our text-based models outperform strong baselines
trained on performance metrics only, demonstrating the importance of language
usage for action prediction. Moreover, the models that employ both textual
input and past-performance metrics produced the best results. Finally, as
neural networks are notoriously difficult to interpret, we propose a method for
gaining further insight into what our models have learned. Particularly, we
present an LDA-based analysis, where we interpret model predictions in terms of
correlated topics. We find that our best performing textual model is most
associated with topics that are intuitively related to each prediction task and
that better models yield higher correlation with more informative topics.
</summary>
    <author>
      <name>Nadav Oved</name>
    </author>
    <author>
      <name>Amir Feder</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First two authors contributed equally. Under review for the
  Computational Linguistics journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.11292v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11292v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11161v1</id>
    <updated>2019-10-24T14:18:55Z</updated>
    <published>2019-10-24T14:18:55Z</published>
    <title>Diversifying Topic-Coherent Response Generation for Natural Multi-turn
  Conversations</title>
    <summary>  Although response generation (RG) diversification for single-turn dialogs has
been well developed, it is less investigated for natural multi-turn
conversations. Besides, past work focused on diversifying responses without
considering topic coherence to the context, producing uninformative replies. In
this paper, we propose the Topic-coherent Hierarchical Recurrent
Encoder-Decoder model (THRED) to diversify the generated responses without
deviating the contextual topics for multi-turn conversations. In overall, we
build a sequence-to-sequence net (Seq2Seq) to model multi-turn conversations.
And then we resort to the latent Variable Hierarchical Recurrent
Encoder-Decoder model (VHRED) to learn global contextual distribution of
dialogs. Besides, we construct a dense topic matrix which implies word-level
correlations of the conversation corpora. The topic matrix is used to learn
local topic distribution of the contextual utterances. By incorporating both
the global contextual distribution and the local topic distribution, THRED
produces both diversified and topic-coherent replies. In addition, we propose
an explicit metric (\emph{TopicDiv}) to measure the topic divergence between
the post and generated response, and we also propose an overall metric
combining the diversification metric (\emph{Distinct}) and \emph{TopicDiv}. We
evaluate our model comparing with three baselines (Seq2Seq, HRED and VHRED) on
two real-world corpora, respectively, and demonstrate its outstanding
performance in both diversification and topic coherence.
</summary>
    <author>
      <name>Fei Hu</name>
    </author>
    <author>
      <name>Wei Liu</name>
    </author>
    <author>
      <name>Ajmal Saeed Mian</name>
    </author>
    <author>
      <name>Li Li</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.10843v1</id>
    <updated>2019-10-23T23:55:23Z</updated>
    <published>2019-10-23T23:55:23Z</published>
    <title>Relation Module for Non-answerable Prediction on Question Answering</title>
    <summary>  Machine reading comprehension(MRC) has attracted significant amounts of
research attention recently, due to an increase of challenging reading
comprehension datasets. In this paper, we aim to improve a MRC model's ability
to determine whether a question has an answer in a given context (e.g. the
recently proposed SQuAD 2.0 task). Our solution is a relation module that is
adaptable to any MRC model. The relation module consists of both semantic
extraction and relational information. We first extract high level semantics as
objects from both question and context with multi-head self-attentive pooling.
These semantic objects are then passed to a relation network, which generates
relationship scores for each object pair in a sentence. These scores are used
to determine whether a question is non-answerable. We test the relation module
on the SQuAD 2.0 dataset using both BiDAF and BERT models as baseline readers.
We obtain 1.8% gain of F1 on top of the BiDAF reader, and 1.0% on top of the
BERT base model. These results show the effectiveness of our relation module on
MRC
</summary>
    <author>
      <name>Kevin Huang</name>
    </author>
    <author>
      <name>Yun Tang</name>
    </author>
    <author>
      <name>Jing Huang</name>
    </author>
    <author>
      <name>Xiaodong He</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1910.10843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.10363v2</id>
    <updated>2019-10-24T05:05:39Z</updated>
    <published>2019-10-23T05:41:39Z</published>
    <title>A Hybrid Semantic Parsing Approach for Tabular Data Analysis</title>
    <summary>  This paper presents a novel approach to translating natural language
questions to SQL queries for given tables, which meets three requirements as a
real-world data analysis application: cross-domain, multilingualism and
enabling quick-start. Our proposed approach consists of: (1) a novel data
abstraction step before the parser to make parsing table-agnosticism; (2) a set
of semantic rules for parsing abstracted data-analysis questions to
intermediate logic forms as tree derivations to reduce the search space; (3) a
neural-based model as a local scoring function on a span-based semantic parser
for structured optimization and efficient inference. Experiments show that our
approach outperforms state-of-the-art algorithms on a large open benchmark
dataset WikiSQL. We also achieve promising results on a small dataset for more
complex queries in both English and Chinese, which demonstrates our language
expansion and quick-start ability.
</summary>
    <author>
      <name>Yan Gao</name>
    </author>
    <author>
      <name>Jian-Guang Lou</name>
    </author>
    <author>
      <name>Dongmei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10363v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10363v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.12611v1</id>
    <updated>2019-10-23T02:10:42Z</updated>
    <published>2019-10-23T02:10:42Z</published>
    <title>Suicidal Ideation Detection: A Review of Machine Learning Methods and
  Applications</title>
    <summary>  Suicide is a critical issue in the modern society. Early detection and
prevention of suicide attempt should be addressed to save people's life.
Current suicidal ideation detection methods include clinical methods based on
the interaction between social workers or experts and the targeted individuals,
and machine learning techniques with feature engineering or deep learning for
automatic detection based on online social contents. This is the first survey
that comprehensively introduces and discusses the methods from these
categories. Domain-specific applications of suicidal ideation detection are
also reviewed according to their data sources, i.e., questionnaires, electronic
health records, suicide notes, and online user content. To facilitate further
research, several specific tasks and datasets are introduced. Finally, we
summarize the limitations of current work and provide an outlook of further
research directions.
</summary>
    <author>
      <name>Shaoxiong Ji</name>
    </author>
    <author>
      <name>Shirui Pan</name>
    </author>
    <author>
      <name>Xue Li</name>
    </author>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Guodong Long</name>
    </author>
    <author>
      <name>Zi Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.12611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.12611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.10034v1</id>
    <updated>2019-10-22T15:09:02Z</updated>
    <published>2019-10-22T15:09:02Z</published>
    <title>Language-guided Semantic Mapping and Mobile Manipulation in Partially
  Observable Environments</title>
    <summary>  Recent advances in data-driven models for grounded language understanding
have enabled robots to interpret increasingly complex instructions. Two
fundamental limitations of these methods are that most require a full model of
the environment to be known a priori, and they attempt to reason over a world
representation that is flat and unnecessarily detailed, which limits
scalability. Recent semantic mapping methods address partial observability by
exploiting language as a sensor to infer a distribution over topological,
metric and semantic properties of the environment. However, maintaining a
distribution over highly detailed maps that can support grounding of diverse
instructions is computationally expensive and hinders real-time human-robot
collaboration. We propose a novel framework that learns to adapt perception
according to the task in order to maintain compact distributions over semantic
maps. Experiments with a mobile manipulator demonstrate more efficient
instruction following in a priori unknown environments.
</summary>
    <author>
      <name>Siddharth Patki</name>
    </author>
    <author>
      <name>Ethan Fahnestock</name>
    </author>
    <author>
      <name>Thomas M. Howard</name>
    </author>
    <author>
      <name>Matthew R. Walter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at 2019 Conference on Robot Learning (CoRL)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09879v2</id>
    <updated>2019-10-24T10:31:25Z</updated>
    <published>2019-10-22T10:35:41Z</published>
    <title>Towards Combinational Relation Linking over Knowledge Graphs</title>
    <summary>  Given a natural language phrase, relation linking aims to find a relation
(predicate or property) from the underlying knowledge graph to match the
phrase. It is very useful in many applications, such as natural language
question answering, personalized recommendation and text summarization.
However, the previous relation linking algorithms usually produce a single
relation for the input phrase and pay little attention to a more general and
challenging problem, i.e., combinational relation linking that extracts a
subgraph pattern to match the compound phrase (e.g. mother-in-law). In this
paper, we focus on the task of combinational relation linking over knowledge
graphs. To resolve the problem, we design a systematic method based on the
data-driven relation assembly technique, which is performed under the guidance
of meta patterns. We also introduce external knowledge to enhance the system
understanding ability. Finally, we conduct extensive experiments over the real
knowledge graph to study the performance of the proposed method.
</summary>
    <author>
      <name>Weiguo Zheng</name>
    </author>
    <author>
      <name>Mei Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.09879v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09879v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09760v2</id>
    <updated>2019-10-24T10:33:13Z</updated>
    <published>2019-10-22T04:21:06Z</published>
    <title>Question Answering over Knowledge Graphs via Structural Query Patterns</title>
    <summary>  Natural language question answering over knowledge graphs is an important and
interesting task as it enables common users to gain accurate answers in an easy
and intuitive manner. However, it remains a challenge to bridge the gap between
unstructured questions and structured knowledge graphs. To address the problem,
a natural discipline is building a structured query to represent the input
question. Searching the structured query over the knowledge graph can produce
answers to the question. Distinct from the existing methods that are based on
semantic parsing or templates, we propose an effective approach powered by a
novel notion, structural query pattern, in this paper. Given an input question,
we first generate its query sketch that is compatible with the underlying
structure of the knowledge graph. Then, we complete the query graph by labeling
the nodes and edges under the guidance of the structural query pattern.
Finally, answers can be retrieved by executing the constructed query graph over
the knowledge graph. Evaluations on three question answering benchmarks show
that our proposed approach outperforms state-of-the-art methods significantly.
</summary>
    <author>
      <name>Weiguo Zheng</name>
    </author>
    <author>
      <name>Mei Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.09760v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09760v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09664v1</id>
    <updated>2019-10-21T21:19:33Z</updated>
    <published>2019-10-21T21:19:33Z</published>
    <title>Learning to Map Natural Language Instructions to Physical Quadcopter
  Control using Simulated Flight</title>
    <summary>  We propose a joint simulation and real-world learning framework for mapping
navigation instructions and raw first-person observations to continuous
control. Our model estimates the need for environment exploration, predicts the
likelihood of visiting environment positions during execution, and controls the
agent to both explore and visit high-likelihood positions. We introduce
Supervised Reinforcement Asynchronous Learning (SuReAL). Learning uses both
simulation and real environments without requiring autonomous flight in the
physical environment during training, and combines supervised learning for
predicting positions to visit and reinforcement learning for continuous
control. We evaluate our approach on a natural language instruction-following
task with a physical quadcopter, and demonstrate effective execution and
exploration behavior.
</summary>
    <author>
      <name>Valts Blukis</name>
    </author>
    <author>
      <name>Yannick Terme</name>
    </author>
    <author>
      <name>Eyvind Niklasson</name>
    </author>
    <author>
      <name>Ross A. Knepper</name>
    </author>
    <author>
      <name>Yoav Artzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Robot Learning (CoRL) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.09664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02648v2</id>
    <updated>2020-03-03T21:07:13Z</updated>
    <published>2019-10-21T16:36:51Z</published>
    <title>Textual analysis of artificial intelligence manuscripts reveals features
  associated with peer review outcome</title>
    <summary>  We analysed a dataset of scientific manuscripts that were submitted to
various conferences in artificial intelligence. We performed a combination of
semantic, lexical and psycholinguistic analyses of the full text of the
manuscripts and compared them with the outcome of the peer review process. We
found that accepted manuscripts scored lower than rejected manuscripts on two
indicators of readability, and that they also used more scientific and
artificial intelligence jargon. We also found that accepted manuscripts were
written with words that are less frequent, that are acquired at an older age,
and that are more abstract than rejected manuscripts. The analysis of
references included in the manuscripts revealed that the subset of accepted
submissions were more likely to cite the same publications. This finding was
echoed by pairwise comparisons of the word content of the manuscripts (i.e. an
indicator or semantic similarity), which were more similar in the subset of
accepted manuscripts. Finally, we predicted the peer review outcome of
manuscripts with their word content, with words related to machine learning and
neural networks positively related with acceptance, whereas words related to
logic, symbolic processing and knowledge-based systems negatively related with
acceptance.
</summary>
    <author>
      <name>Philippe Vincent-Lamarre</name>
    </author>
    <author>
      <name>Vincent Larivière</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02648v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02648v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09329v1</id>
    <updated>2019-10-21T12:59:32Z</updated>
    <published>2019-10-21T12:59:32Z</published>
    <title>A Neural Entity Coreference Resolution Review</title>
    <summary>  Entity Coreference Resolution is the task of resolving all the mentions in a
document that refer to the same real world entity and is considered as one of
the most difficult tasks in natural language understanding. While in it is not
an end task, it has been proved to improve downstream natural language
processing tasks such as entity linking, machine translation, summarization and
chatbots. We conducted a systematic a review of neural-based approached and
provide a detailed appraisal of the datasets and evaluation metrics in the
field. Emphasis is given on Pronoun Resolution, a subtask of Coreference
Resolution, which has seen various improvements in the recent years. We
conclude the study by highlight the lack of agreed upon standards and propose a
way to expand the task even further.
</summary>
    <author>
      <name>Nikolaos Stylianou</name>
    </author>
    <author>
      <name>Ioannis Vlahavas</name>
    </author>
    <link href="http://arxiv.org/abs/1910.09329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09292v1</id>
    <updated>2019-10-21T12:23:48Z</updated>
    <published>2019-10-21T12:23:48Z</published>
    <title>On Semi-Supervised Multiple Representation Behavior Learning</title>
    <summary>  We propose a novel paradigm of semi-supervised learning (SSL)--the
semi-supervised multiple representation behavior learning (SSMRBL). SSMRBL aims
to tackle the difficulty of learning a grammar for natural language parsing
where the data are natural language texts and the 'labels' for marking data are
parsing trees and/or grammar rule pieces. We call such 'labels' as compound
structured labels which require a hard work for training. SSMRBL is an
incremental learning process that can learn more than one representation, which
is an appropriate solution for dealing with the scarce of labeled training data
in the age of big data and with the heavy workload of learning compound
structured labels. We also present a typical example of SSMRBL, regarding
behavior learning in form of a grammatical approach towards domain-based
multiple text summarization (DBMTS). DBMTS works under the framework of
rhetorical structure theory (RST). SSMRBL includes two representations: text
embedding (for representing information contained in the texts) and grammar
model (for representing parsing as a behavior). The first representation was
learned as embedded digital vectors called impacts in a low dimensional space.
The grammar model was learned in an iterative way. Then an automatic
domain-oriented multi-text summarization approach was proposed based on the two
representations discussed above. Experimental results on large-scale Chinese
dataset SogouCA indicate that the proposed method brings a good performance
even if only few labeled texts are used for training with respect to our
defined automated metrics.
</summary>
    <author>
      <name>Ruqian Lu</name>
    </author>
    <author>
      <name>Shengluan Hou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.09292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.09260v1</id>
    <updated>2019-10-21T10:55:46Z</updated>
    <published>2019-10-21T10:55:46Z</published>
    <title>Human-Like Decision Making: Document-level Aspect Sentiment
  Classification via Hierarchical Reinforcement Learning</title>
    <summary>  Recently, neural networks have shown promising results on Document-level
Aspect Sentiment Classification (DASC). However, these approaches often offer
little transparency w.r.t. their inner working mechanisms and lack
interpretability. In this paper, to simulating the steps of analyzing aspect
sentiment in a document by human beings, we propose a new Hierarchical
Reinforcement Learning (HRL) approach to DASC. This approach incorporates
clause selection and word selection strategies to tackle the data noise problem
in the task of DASC. First, a high-level policy is proposed to select
aspect-relevant clauses and discard noisy clauses. Then, a low-level policy is
proposed to select sentiment-relevant words and discard noisy words inside the
selected clauses. Finally, a sentiment rating predictor is designed to provide
reward signals to guide both clause and word selection. Experimental results
demonstrate the impressive effectiveness of the proposed approach to DASC over
the state-of-the-art baselines.
</summary>
    <author>
      <name>Jingjing Wang</name>
    </author>
    <author>
      <name>Changlong Sun</name>
    </author>
    <author>
      <name>Shoushan Li</name>
    </author>
    <author>
      <name>Jiancheng Wang</name>
    </author>
    <author>
      <name>Luo Si</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <author>
      <name>Xiaozhong Liu</name>
    </author>
    <author>
      <name>Guodong Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1910.09260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.09260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11124v2</id>
    <updated>2019-12-27T10:09:58Z</updated>
    <published>2019-10-21T02:33:18Z</published>
    <title>Enforcing Reasoning in Visual Commonsense Reasoning</title>
    <summary>  The task of Visual Commonsense Reasoning is extremely challenging in the
sense that the model has to not only be able to answer a question given an
image, but also be able to learn to reason. The baselines introduced in this
task are quite limiting because two networks are trained for predicting answers
and rationales separately. Question and image is used as input to train answer
prediction network while question, image and correct answer are used as input
in the rationale prediction network. As rationale is conditioned on the correct
answer, it is based on the assumption that we can solve Visual Question
Answering task without any error - which is over ambitious. Moreover, such an
approach makes both answer and rationale prediction two completely independent
VQA tasks rendering cognition task meaningless. In this paper, we seek to
address these issues by proposing an end-to-end trainable model which considers
both answers and their reasons jointly. Specifically, we first predict the
answer for the question and then use the chosen answer to predict the
rationale. However, a trivial design of such a model becomes non-differentiable
which makes it difficult to train. We solve this issue by proposing four
approaches - softmax, gumbel-softmax, reinforcement learning based sampling and
direct cross entropy against all pairs of answers and rationales. We
demonstrate through experiments that our model performs competitively against
current state-of-the-art. We conclude with an analysis of presented approaches
and discuss avenues for further work.
</summary>
    <author>
      <name>Hammad A. Ayyubi</name>
    </author>
    <author>
      <name>Md. Mehrab Tanjim</name>
    </author>
    <author>
      <name>David J. Kriegman</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11124v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11124v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08955v2</id>
    <updated>2020-01-13T12:32:15Z</updated>
    <published>2019-10-20T11:54:05Z</published>
    <title>Computer-supported Analysis of Positive Properties, Ultrafilters and
  Modal Collapse in Variants of Gödel's Ontological Argument</title>
    <summary>  Three variants of Kurt G\"odel's ontological argument, proposed by Dana
Scott, C. Anthony Anderson and Melvin Fitting, are encoded and rigorously
assessed on the computer. In contrast to Scott's version of G\"odel's argument
the two variants contributed by Anderson and Fitting avoid modal collapse.
Although they appear quite different on a cursory reading they are in fact
closely related. This has been revealed in the computer-supported formal
analysis presented in this article. Key to our formal analysis is the
utilization of suitably adapted notions of (modal) ultrafilters, and a careful
distinction between extensions and intensions of positive properties.
</summary>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <author>
      <name>David Fuenmayor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 6 figures; to appear in the Bulletin of the Section of
  Logic</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.08955v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08955v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08549v1</id>
    <updated>2019-10-18T15:20:38Z</updated>
    <published>2019-10-18T15:20:38Z</published>
    <title>Towards Learning Cross-Modal Perception-Trace Models</title>
    <summary>  Representation learning is a key element of state-of-the-art deep learning
approaches. It enables to transform raw data into structured vector space
embeddings. Such embeddings are able to capture the distributional semantics of
their context, e.g. by word windows on natural language sentences, graph walks
on knowledge graphs or convolutions on images. So far, this context is manually
defined, resulting in heuristics which are solely optimized for computational
performance on certain tasks like link-prediction. However, such heuristic
models of context are fundamentally different to how humans capture
information. For instance, when reading a multi-modal webpage (i) humans do not
perceive all parts of a document equally: Some words and parts of images are
skipped, others are revisited several times which makes the perception trace
highly non-sequential; (ii) humans construct meaning from a document's content
by shifting their attention between text and image, among other things, guided
by layout and design elements. In this paper we empirically investigate the
difference between human perception and context heuristics of basic embedding
models. We conduct eye tracking experiments to capture the underlying
characteristics of human perception of media documents containing a mixture of
text and images. Based on that, we devise a prototypical computational
perception-trace model, called CMPM. We evaluate empirically how CMPM can
improve a basic skip-gram embedding approach. Our results suggest, that even
with a basic human-inspired computational perception model, there is a huge
potential for improving embeddings since such a model does inherently capture
multiple modalities, as well as layout and design elements.
</summary>
    <author>
      <name>Achim Rettinger</name>
    </author>
    <author>
      <name>Viktoria Bogdanova</name>
    </author>
    <author>
      <name>Philipp Niemann</name>
    </author>
    <link href="http://arxiv.org/abs/1910.08549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08294v1</id>
    <updated>2019-10-18T07:56:08Z</updated>
    <published>2019-10-18T07:56:08Z</published>
    <title>Towards Computing Inferences from English News Headlines</title>
    <summary>  Newspapers are a popular form of written discourse, read by many people,
thanks to the novelty of the information provided by the news content in it. A
headline is the most widely read part of any newspaper due to its appearance in
a bigger font and sometimes in colour print. In this paper, we suggest and
implement a method for computing inferences from English news headlines,
excluding the information from the context in which the headlines appear. This
method attempts to generate the possible assumptions a reader formulates in
mind upon reading a fresh headline. The generated inferences could be useful
for assessing the impact of the news headline on readers including children.
The understandability of the current state of social affairs depends greatly on
the assimilation of the headlines. As the inferences that are independent of
the context depend mainly on the syntax of the headline, dependency trees of
headlines are used in this approach, to find the syntactical structure of the
headlines and to compute inferences out of them.
</summary>
    <author>
      <name>Elizabeth Jasmi George</name>
    </author>
    <author>
      <name>Radhika Mamidi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PACLING 2019 Long paper, 15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.08294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08293v2</id>
    <updated>2019-11-21T19:18:03Z</updated>
    <published>2019-10-18T07:52:01Z</published>
    <title>ALOHA: Artificial Learning of Human Attributes for Dialogue Agents</title>
    <summary>  For conversational AI and virtual assistants to communicate with humans in a
realistic way, they must exhibit human characteristics such as expression of
emotion and personality. Current attempts toward constructing human-like
dialogue agents have presented significant difficulties. We propose Human Level
Attributes (HLAs) based on tropes as the basis of a method for learning
dialogue agents that can imitate the personalities of fictional characters.
Tropes are characteristics of fictional personalities that are observed
recurrently and determined by viewers' impressions. By combining detailed HLA
data with dialogue data for specific characters, we present a dataset,
HLA-Chat, that models character profiles and gives dialogue agents the ability
to learn characters' language styles through their HLAs. We then introduce a
three-component system, ALOHA (which stands for Artificial Learning of Human
Attributes), that combines character space mapping, character community
detection, and language style retrieval to build a character (or personality)
specific language model. Our preliminary experiments demonstrate that two
variations of ALOHA, combined with our proposed dataset, can outperform
baseline models at identifying the correct dialogue responses of chosen target
characters, and are stable regardless of the character's identity, the genre of
the show, and the context of the dialogue.
</summary>
    <author>
      <name>Aaron W. Li</name>
    </author>
    <author>
      <name>Veronica Jiang</name>
    </author>
    <author>
      <name>Steven Y. Feng</name>
    </author>
    <author>
      <name>Julia Sprague</name>
    </author>
    <author>
      <name>Wei Zhou</name>
    </author>
    <author>
      <name>Jesse Hoey</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.08293v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08293v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08282v2</id>
    <updated>2019-10-30T11:41:45Z</updated>
    <published>2019-10-18T06:49:55Z</published>
    <title>Unsupervised Context Rewriting for Open Domain Conversation</title>
    <summary>  Context modeling has a pivotal role in open domain conversation. Existing
works either use heuristic methods or jointly learn context modeling and
response generation with an encoder-decoder framework. This paper proposes an
explicit context rewriting method, which rewrites the last utterance by
considering context history. We leverage pseudo-parallel data and elaborate a
context rewriting network, which is built upon the CopyNet with the
reinforcement learning method. The rewritten utterance is beneficial to
candidate retrieval, explainable context modeling, as well as enabling to
employ a single-turn framework to the multi-turn scenario. The empirical
results show that our model outperforms baselines in terms of the rewriting
quality, the multi-turn response generation, and the end-to-end retrieval-based
chatbots.
</summary>
    <author>
      <name>Kun Zhou</name>
    </author>
    <author>
      <name>Kai Zhang</name>
    </author>
    <author>
      <name>Yu Wu</name>
    </author>
    <author>
      <name>Shujie Liu</name>
    </author>
    <author>
      <name>Jingsong Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1910.08282v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08282v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08210v5</id>
    <updated>2020-02-12T20:22:15Z</updated>
    <published>2019-10-18T00:49:15Z</published>
    <title>RTFM: Generalising to Novel Environment Dynamics via Reading</title>
    <summary>  Obtaining policies that can generalise to new environments in reinforcement
learning is challenging. In this work, we demonstrate that language
understanding via a reading policy learner is a promising vehicle for
generalisation to new environments. We propose a grounded policy learning
problem, Read to Fight Monsters (RTFM), in which the agent must jointly reason
over a language goal, relevant dynamics described in a document, and
environment observations. We procedurally generate environment dynamics and
corresponding language descriptions of the dynamics, such that agents must read
to understand new environment dynamics instead of memorising any particular
information. In addition, we propose txt2$\pi$, a model that captures three-way
interactions between the goal, document, and observations. On RTFM, txt2$\pi$
generalises to new environments with dynamics not seen during training via
reading. Furthermore, our model outperforms baselines such as FiLM and
language-conditioned CNNs on RTFM. Through curriculum learning, txt2$\pi$
produces policies that excel on complex RTFM tasks requiring several reasoning
and coreference steps.
</summary>
    <author>
      <name>Victor Zhong</name>
    </author>
    <author>
      <name>Tim Rocktäschel</name>
    </author>
    <author>
      <name>Edward Grefenstette</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020; 17 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.08210v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08210v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.08194v1</id>
    <updated>2019-10-17T23:02:34Z</updated>
    <published>2019-10-17T23:02:34Z</published>
    <title>HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree
  Expansion</title>
    <summary>  Taxonomies are of great value to many knowledge-rich applications. As the
manual taxonomy curation costs enormous human effects, automatic taxonomy
construction is in great demand. However, most existing automatic taxonomy
construction methods can only build hypernymy taxonomies wherein each edge is
limited to expressing the "is-a" relation. Such a restriction limits their
applicability to more diverse real-world tasks where the parent-child may carry
different relations. In this paper, we aim to construct a task-guided taxonomy
from a domain-specific corpus and allow users to input a "seed" taxonomy,
serving as the task guidance. We propose an expansion-based taxonomy
construction framework, namely HiExpan, which automatically generates key term
list from the corpus and iteratively grows the seed taxonomy. Specifically,
HiExpan views all children under each taxonomy node forming a coherent set and
builds the taxonomy by recursively expanding all these sets. Furthermore,
HiExpan incorporates a weakly-supervised relation extraction module to extract
the initial children of a newly-expanded node and adjusts the taxonomy tree by
optimizing its global structure. Our experiments on three real datasets from
different domains demonstrate the effectiveness of HiExpan for building
task-guided taxonomies.
</summary>
    <author>
      <name>Jiaming Shen</name>
    </author>
    <author>
      <name>Zeqiu Wu</name>
    </author>
    <author>
      <name>Dongming Lei</name>
    </author>
    <author>
      <name>Chao Zhang</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <author>
      <name>Michelle T. Vanni</name>
    </author>
    <author>
      <name>Brian M. Sadler</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">KDD 2018 accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.08194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.08194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.10486v1</id>
    <updated>2019-10-16T22:17:02Z</updated>
    <published>2019-10-16T22:17:02Z</published>
    <title>Does Gender Matter? Towards Fairness in Dialogue Systems</title>
    <summary>  Recently there are increasing concerns about the fairness of Artificial
Intelligence (AI) in real-world applications such as computer vision and
recommendations. For example, recognition algorithms in computer vision are
unfair to black people such as poorly detecting their faces and inappropriately
identifying them as "gorillas". As one crucial application of AI, dialogue
systems have been extensively applied in our society. They are usually built
with real human conversational data; thus they could inherit some fairness
issues which are held in the real world. However, the fairness of dialogue
systems has not been investigated. In this paper, we perform the initial study
about the fairness issues in dialogue systems. In particular, we construct the
first dataset and propose quantitative measures to understand fairness in
dialogue models. Our studies demonstrate that popular dialogue models show
significant prejudice towards different genders and races. We will release the
dataset and the measurement code later to foster the fairness research in
dialogue systems.
</summary>
    <author>
      <name>Haochen Liu</name>
    </author>
    <author>
      <name>Jamell Dacon</name>
    </author>
    <author>
      <name>Wenqi Fan</name>
    </author>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Zitao Liu</name>
    </author>
    <author>
      <name>Jiliang Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10486v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10486v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.07601v1</id>
    <updated>2019-10-16T20:36:41Z</updated>
    <published>2019-10-16T20:36:41Z</published>
    <title>Contextual Joint Factor Acoustic Embeddings</title>
    <summary>  Embedding acoustic information into fixed length representations is of
interest for a whole range of applications in speech and audio technology. We
propose two novel unsupervised approaches to generate acoustic embeddings by
modelling of acoustic context. The first approach is a contextual joint factor
synthesis encoder, where the encoder in an encoder/decoder framework is trained
to extract joint factors from surrounding audio frames to best generate the
target output. The second approach is a contextual joint factor analysis
encoder, where the encoder is trained to analyse joint factors from the source
signal that correlates best with the neighbouring audio. To evaluate the
effectiveness of our approaches compared to prior work, we chose two tasks -
phone classification and speaker recognition - and test on different TIMIT data
sets. Experimental results show that one of our proposed approaches outperforms
phone classification baselines, yielding a classification accuracy of 74.1%.
When using additional out-of-domain data for training, an additional 2-3%
improvements can be obtained, for both for phone classification and speaker
recognition tasks.
</summary>
    <author>
      <name>Yanpei Shi</name>
    </author>
    <author>
      <name>Qiang Huang</name>
    </author>
    <author>
      <name>Thomas Hain</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07601v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07601v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.07475v2</id>
    <updated>2019-11-07T05:46:56Z</updated>
    <published>2019-10-16T17:05:21Z</published>
    <title>MLQA: Evaluating Cross-lingual Extractive Question Answering</title>
    <summary>  Question answering (QA) models have shown rapid progress enabled by the
availability of large, high-quality benchmark datasets. Such annotated datasets
are difficult and costly to collect, and rarely exist in languages other than
English, making training QA systems in other languages challenging. An
alternative to building large monolingual training datasets is to develop
cross-lingual systems which can transfer to a target language without requiring
training data in that language. In order to develop such systems, it is crucial
to invest in high quality multilingual evaluation benchmarks to measure
progress. We present MLQA, a multi-way aligned extractive QA evaluation
benchmark intended to spur research in this area. MLQA contains QA instances in
7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and
Simplified Chinese. It consists of over 12K QA instances in English and 5K in
each other language, with each QA instance being parallel between 4 languages
on average. MLQA is built using a novel alignment context strategy on Wikipedia
articles, and serves as a cross-lingual extension to existing extractive QA
datasets. We evaluate current state-of-the-art cross-lingual representations on
MLQA, and also provide machine-translation-based baselines. In all cases,
transfer results are shown to be significantly behind training-language
performance.
</summary>
    <author>
      <name>Patrick Lewis</name>
    </author>
    <author>
      <name>Barlas Oğuz</name>
    </author>
    <author>
      <name>Ruty Rinott</name>
    </author>
    <author>
      <name>Sebastian Riedel</name>
    </author>
    <author>
      <name>Holger Schwenk</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07475v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07475v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.07323v1</id>
    <updated>2019-10-16T12:55:34Z</updated>
    <published>2019-10-16T12:55:34Z</published>
    <title>Lead2Gold: Towards exploiting the full potential of noisy transcriptions
  for speech recognition</title>
    <summary>  The transcriptions used to train an Automatic Speech Recognition (ASR) system
may contain errors. Usually, either a quality control stage discards
transcriptions with too many errors, or the noisy transcriptions are used as
is. We introduce Lead2Gold, a method to train an ASR system that exploits the
full potential of noisy transcriptions. Based on a noise model of transcription
errors, Lead2Gold searches for better transcriptions of the training data with
a beam search that takes this noise model into account. The beam search is
differentiable and does not require a forced alignment step, thus the whole
system is trained end-to-end. Lead2Gold can be viewed as a new loss function
that can be used on top of any sequence-to-sequence deep neural network. We
conduct proof-of-concept experiments on noisy transcriptions generated from
letter corruptions with different noise levels. We show that Lead2Gold obtains
a better ASR accuracy than a competitive baseline which does not account for
the (artificially-introduced) transcription noise.
</summary>
    <author>
      <name>Adrien Dufraux</name>
    </author>
    <author>
      <name>Emmanuel Vincent</name>
    </author>
    <author>
      <name>Awni Hannun</name>
    </author>
    <author>
      <name>Armelle Brun</name>
    </author>
    <author>
      <name>Matthijs Douze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 tables, Accepted for publication in ASRU 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.07323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.07150v1</id>
    <updated>2019-10-16T03:28:14Z</updated>
    <published>2019-10-16T03:28:14Z</published>
    <title>Joint Learning of Word and Label Embeddings for Sequence Labelling in
  Spoken Language Understanding</title>
    <summary>  We propose an architecture to jointly learn word and label embeddings for
slot filling in spoken language understanding. The proposed approach encodes
labels using a combination of word embeddings and straightforward word-label
association from the training data. Compared to the state-of-the-art methods,
our approach does not require label embeddings as part of the input and
therefore lends itself nicely to a wide range of model architectures. In
addition, our architecture computes contextual distances between words and
labels to avoid adding contextual windows, thus reducing memory footprint. We
validate the approach on established spoken dialogue datasets and show that it
can achieve state-of-the-art performance with much fewer trainable parameters.
</summary>
    <author>
      <name>Jiewen Wu</name>
    </author>
    <author>
      <name>Luis Fernando D'Haro</name>
    </author>
    <author>
      <name>Nancy F. Chen</name>
    </author>
    <author>
      <name>Pavitra Krishnaswamy</name>
    </author>
    <author>
      <name>Rafael E. Banchs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at ASRU 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.07150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.07117v3</id>
    <updated>2019-10-29T19:43:05Z</updated>
    <published>2019-10-16T01:10:10Z</published>
    <title>Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for
  Neural Language Generation Models</title>
    <summary>  In this work, we study how the large-scale pretrain-finetune framework
changes the behavior of a neural language generator. We focus on the
transformer encoder-decoder model for the open-domain dialogue response
generation task. We find that after standard fine-tuning, the model forgets
important language generation skills acquired during large-scale pre-training.
We demonstrate the forgetting phenomenon through a detailed behavior analysis
from the perspectives of context sensitivity and knowledge transfer. Adopting
the concept of data mixing, we propose an intuitive fine-tuning strategy named
"mix-review". We find that mix-review effectively regularize the fine-tuning
process, and the forgetting problem is largely alleviated. Finally, we discuss
interesting behavior of the resulting dialogue model and its implications.
</summary>
    <author>
      <name>Tianxing He</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <author>
      <name>Myle Ott</name>
    </author>
    <author>
      <name>Bing Liu</name>
    </author>
    <author>
      <name>James Glass</name>
    </author>
    <author>
      <name>Fuchun Peng</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07117v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07117v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.06048v1</id>
    <updated>2019-10-14T11:39:45Z</updated>
    <published>2019-10-14T11:39:45Z</published>
    <title>STANCY: Stance Classification Based on Consistency Cues</title>
    <summary>  Controversial claims are abundant in online media and discussion forums. A
better understanding of such claims requires analyzing them from different
perspectives. Stance classification is a necessary step for inferring these
perspectives in terms of supporting or opposing the claim. In this work, we
present a neural network model for stance classification leveraging BERT
representations and augmenting them with a novel consistency constraint.
Experiments on the Perspectrum dataset, consisting of claims and users'
perspectives from various debate websites, demonstrate the effectiveness of our
approach over state-of-the-art baselines.
</summary>
    <author>
      <name>Kashyap Popat</name>
    </author>
    <author>
      <name>Subhabrata Mukherjee</name>
    </author>
    <author>
      <name>Andrew Yates</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.05915v1</id>
    <updated>2019-10-14T04:48:16Z</updated>
    <published>2019-10-14T04:48:16Z</published>
    <title>Knowledge-guided Unsupervised Rhetorical Parsing for Text Summarization</title>
    <summary>  Automatic text summarization (ATS) has recently achieved impressive
performance thanks to recent advances in deep learning and the availability of
large-scale corpora. To make the summarization results more faithful, this
paper presents an unsupervised approach that combines rhetorical structure
theory, deep neural model and domain knowledge concern for ATS. This
architecture mainly contains three components: domain knowledge base
construction based on representation learning, attentional encoder-decoder
model for rhetorical parsing and subroutine-based model for text summarization.
Domain knowledge can be effectively used for unsupervised rhetorical parsing
thus rhetorical structure trees for each document can be derived. In the
unsupervised rhetorical parsing module, the idea of translation was adopted to
alleviate the problem of data scarcity. The subroutine-based summarization
model purely depends on the derived rhetorical structure trees and can generate
content-balanced results. To evaluate the summary results without golden
standard, we proposed an unsupervised evaluation metric, whose hyper-parameters
were tuned by supervised learning. Experimental results show that, on a
large-scale Chinese dataset, our proposed approach can obtain comparable
performances compared with existing methods.
</summary>
    <author>
      <name>Shengluan Hou</name>
    </author>
    <author>
      <name>Ruqian Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.05915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.05915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.05389v1</id>
    <updated>2019-10-11T19:56:47Z</updated>
    <published>2019-10-11T19:56:47Z</published>
    <title>Model-based Interactive Semantic Parsing: A Unified Framework and A
  Text-to-SQL Case Study</title>
    <summary>  As a promising paradigm, interactive semantic parsing has shown to improve
both semantic parsing accuracy and user confidence in the results. In this
paper, we propose a new, unified formulation of the interactive semantic
parsing problem, where the goal is to design a model-based intelligent agent.
The agent maintains its own state as the current predicted semantic parse,
decides whether and where human intervention is needed, and generates a
clarification question in natural language. A key part of the agent is a world
model: it takes a percept (either an initial question or subsequent feedback
from the user) and transitions to a new state. We then propose a simple yet
remarkably effective instantiation of our framework, demonstrated on two
text-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base
semantic parsers. Compared to an existing interactive semantic parsing approach
that treats the base parser as a black box, our approach solicits less user
feedback but yields higher run-time accuracy.
</summary>
    <author>
      <name>Ziyu Yao</name>
    </author>
    <author>
      <name>Yu Su</name>
    </author>
    <author>
      <name>Huan Sun</name>
    </author>
    <author>
      <name>Wen-tau Yih</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures, accepted to EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.05389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.05389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.05291v1</id>
    <updated>2019-10-11T16:34:01Z</updated>
    <published>2019-10-11T16:34:01Z</published>
    <title>The Emergence of Compositional Languages for Numeric Concepts Through
  Iterated Learning in Neural Agents</title>
    <summary>  Since first introduced, computer simulation has been an increasingly
important tool in evolutionary linguistics. Recently, with the development of
deep learning techniques, research in grounded language learning has also
started to focus on facilitating the emergence of compositional languages
without pre-defined elementary linguistic knowledge. In this work, we explore
the emergence of compositional languages for numeric concepts in multi-agent
communication systems. We demonstrate that compositional language for encoding
numeric concepts can emerge through iterated learning in populations of deep
neural network agents. However, language properties greatly depend on the input
representations given to agents. We found that compositional languages only
emerge if they require less iterations to be fully learnt than other
non-degenerate languages for agents on a given input representation.
</summary>
    <author>
      <name>Shangmin Guo</name>
    </author>
    <author>
      <name>Yi Ren</name>
    </author>
    <author>
      <name>Serhii Havrylov</name>
    </author>
    <author>
      <name>Stella Frank</name>
    </author>
    <author>
      <name>Ivan Titov</name>
    </author>
    <author>
      <name>Kenny Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1910.05291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.05291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.05040v1</id>
    <updated>2019-10-11T09:16:29Z</updated>
    <published>2019-10-11T09:16:29Z</published>
    <title>BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual
  Reading Comprehension on Novels</title>
    <summary>  This paper presents BiPaR, a bilingual parallel novel-style machine reading
comprehension (MRC) dataset, developed to support multilingual and
cross-lingual reading comprehension. The biggest difference between BiPaR and
existing reading comprehension datasets is that each triple (Passage, Question,
Answer) in BiPaR is written parallelly in two languages. We collect 3,667
bilingual parallel paragraphs from Chinese and English novels, from which we
construct 14,668 parallel question-answer pairs via crowdsourced workers
following a strict quality control procedure. We analyze BiPaR in depth and
find that BiPaR offers good diversification in prefixes of questions, answer
types and relationships between questions and passages. We also observe that
answering questions of novels requires reading comprehension skills of
coreference resolution, multi-sentence reasoning, and understanding of implicit
causality, etc. With BiPaR, we build monolingual, multilingual, and
cross-lingual MRC baseline models. Even for the relatively simple monolingual
MRC on this dataset, experiments show that a strong BERT baseline is over 30
points behind human in terms of both EM and F1 score, indicating that BiPaR
provides a challenging testbed for monolingual, multilingual and cross-lingual
MRC on novels. The dataset is available at https://multinlp.github.io/BiPaR/.
</summary>
    <author>
      <name>Yimin Jing</name>
    </author>
    <author>
      <name>Deyi Xiong</name>
    </author>
    <author>
      <name>Yan Zhen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a long paper at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.05040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.05040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.04519v1</id>
    <updated>2019-10-10T12:42:19Z</updated>
    <published>2019-10-10T12:42:19Z</published>
    <title>Language Transfer for Early Warning of Epidemics from Social Media</title>
    <summary>  Statements on social media can be analysed to identify individuals who are
experiencing red flag medical symptoms, allowing early detection of the spread
of disease such as influenza. Since disease does not respect cultural borders
and may spread between populations speaking different languages, we would like
to build multilingual models. However, the data required to train models for
every language may be difficult, expensive and time-consuming to obtain,
particularly for low-resource languages. Taking Japanese as our target
language, we explore methods by which data in one language might be used to
build models for a different language. We evaluate strategies of training on
machine translated data and of zero-shot transfer through the use of
multilingual models. We find that the choice of source language impacts the
performance, with Chinese-Japanese being a better language pair than
English-Japanese. Training on machine translated data shows promise, especially
when used in conjunction with a small amount of target language data.
</summary>
    <author>
      <name>Mattias Appelgren</name>
    </author>
    <author>
      <name>Patrick Schrempf</name>
    </author>
    <author>
      <name>Matúš Falis</name>
    </author>
    <author>
      <name>Satoshi Ikeda</name>
    </author>
    <author>
      <name>Alison Q O'Neil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Artificial Intelligence for Humanitarian Assistance and Disaster
  Response Workshop (AI+HADR) at NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.04519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.04424v1</id>
    <updated>2019-10-10T08:25:42Z</updated>
    <published>2019-10-10T08:25:42Z</published>
    <title>Contract Statements Knowledge Service for Chatbots</title>
    <summary>  Towards conversational agents that are capable of handling more complex
questions on contractual conditions, formalizing contract statements in a
machine readable way is crucial. However, constructing a formal model which
captures the full scope of a contract proves difficult due to the overall
complexity its set of rules represent. Instead, this paper presents a top-down
approach to the problem. After identifying the most relevant contract
statements, we model their underlying rules in a novel knowledge engineering
method. A user-friendly tool we developed for this purpose allows to do so
easily and at scale. Then, we expose the statements as service so they can get
smoothly integrated in any chatbot framework.
</summary>
    <author>
      <name>Boris Ruf</name>
    </author>
    <author>
      <name>Matteo Sammarco</name>
    </author>
    <author>
      <name>Marcin Detyniecki</name>
    </author>
    <link href="http://arxiv.org/abs/1910.04424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.06707v1</id>
    <updated>2019-10-09T15:34:28Z</updated>
    <published>2019-10-09T15:34:28Z</published>
    <title>A Deep Learning Based Chatbot for Campus Psychological Therapy</title>
    <summary>  In this paper, we propose Evebot, an innovative, sequence to sequence
(Seq2seq) based, fully generative conversational system for the diagnosis of
negative emotions and prevention of depression through positively suggestive
responses. The system consists of an assembly of deep-learning based models,
including Bi-LSTM based model for detecting negative emotions of users and
obtaining psychological counselling related corpus for training the chatbot,
anti-language sequence to sequence neural network, and maximum mutual
information (MMI) model. As adolescents are reluctant to show their negative
emotions in physical interaction, traditional methods of emotion analysis and
comforting methods may not work. Therefore, this system puts emphasis on using
virtual platform to detect signs of depression or anxiety, channel adolescents'
stress and mood, and thus prevent the emergence of mental illness. We launched
the integrated chatbot system onto an online platform for real-world campus
applications. Through a one-month user study, we observe better results in the
increase in positivity than other public chatbots in the control group.
</summary>
    <author>
      <name>Junjie Yin</name>
    </author>
    <author>
      <name>Zixun Chen</name>
    </author>
    <author>
      <name>Kelai Zhou</name>
    </author>
    <author>
      <name>Chongyuan Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.04023v4</id>
    <updated>2019-12-04T16:56:56Z</updated>
    <published>2019-10-09T14:33:37Z</published>
    <title>On the Possibility of Rewarding Structure Learning Agents: Mutual
  Information on Linguistic Random Sets</title>
    <summary>  We present a first attempt to elucidate a theoretical and empirical approach
to design the reward provided by a natural language environment to some
structure learning agent. To this end, we revisit the Information Theory of
unsupervised induction of phrase-structure grammars to characterize the
behavior of simulated actions modeled as set-valued random variables (random
sets of linguistic samples) constituting semantic structures. Our results
showed empirical evidence of that simulated semantic structures (Open
Information Extraction triplets) can be distinguished from randomly constructed
ones by observing the Mutual Information among their constituents. This
suggests the possibility of rewarding structure learning agents without using
pretrained structural analyzers (oracle actors/experts).
</summary>
    <author>
      <name>Ignacio Arroyo-Fernández</name>
    </author>
    <author>
      <name>Mauricio Carrasco-Ruíz</name>
    </author>
    <author>
      <name>J. Anibal Arias-Aguilar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted to the Workshop on Sets &amp; Partitions (NeurIPS 2019,
  Vancouver, Canada)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.04023v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04023v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03891v2</id>
    <updated>2019-10-10T02:58:00Z</updated>
    <published>2019-10-09T10:33:59Z</published>
    <title>Learning High-order Structural and Attribute information by Knowledge
  Graph Attention Networks for Enhancing Knowledge Graph Embedding</title>
    <summary>  The goal of representation learning of knowledge graph is to encode both
entities and relations into a low-dimensional embedding spaces. Many recent
works have demonstrated the benefits of knowledge graph embedding on knowledge
graph completion task, such as relation extraction. However, we observe that:
1) existing method just take direct relations between entities into
consideration and fails to express high-order structural relationship between
entities; 2) these methods just leverage relation triples of KGs while ignoring
a large number of attribute triples that encoding rich semantic information. To
overcome these limitations, this paper propose a novel knowledge graph
embedding method, named KANE, which is inspired by the recent developments of
graph convolutional networks (GCN). KANE can capture both high-order structural
and attribute information of KGs in an efficient, explicit and unified manner
under the graph convolutional networks framework. Empirical results on three
datasets show that KANE significantly outperforms seven state-of-arts methods.
Further analysis verify the efficiency of our method and the benefits brought
by the attention mechanism.
</summary>
    <author>
      <name>Wenqiang Liu</name>
    </author>
    <author>
      <name>Hongyun Cai</name>
    </author>
    <author>
      <name>Xu Cheng</name>
    </author>
    <author>
      <name>Sifa Xie</name>
    </author>
    <author>
      <name>Yipeng Yu</name>
    </author>
    <author>
      <name>Hanyu Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.03891v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03891v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03756v2</id>
    <updated>2019-11-10T02:01:13Z</updated>
    <published>2019-10-09T02:31:37Z</published>
    <title>Alternating Roles Dialog Model with Large-scale Pre-trained Language
  Models</title>
    <summary>  Existing dialog system models require extensive human annotations and are
difficult to generalize to different tasks. The recent success of large
pre-trained language models such as BERT and GPT-2 (Devlin et al., 2019;
Radford et al., 2019) have suggested the effectiveness of incorporating
language priors in down-stream NLP tasks. However, how much pre-trained
language models can help dialog response generation is still under exploration.
In this paper, we propose a simple, general, and effective framework:
Alternating Roles Dialog Model (ARDM). ARDM models each speaker separately and
takes advantage of the large pre-trained language model. It requires no
supervision from human annotations such as belief states or dialog acts to
achieve effective conversations. ARDM outperforms or is on par with
state-of-the-art methods on two popular task-oriented dialog datasets:
CamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging,
non-collaborative tasks such as persuasion. In persuasion tasks, ARDM is
capable of generating human-like responses to persuade people to donate to a
charity.
</summary>
    <author>
      <name>Qingyang Wu</name>
    </author>
    <author>
      <name>Yichi Zhang</name>
    </author>
    <author>
      <name>Yu Li</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1910.03756v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03756v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03655v3</id>
    <updated>2020-01-08T15:27:46Z</updated>
    <published>2019-10-08T19:22:58Z</published>
    <title>Executing Instructions in Situated Collaborative Interactions</title>
    <summary>  We study a collaborative scenario where a user not only instructs a system to
complete tasks, but also acts alongside it. This allows the user to adapt to
the system abilities by changing their language or deciding to simply
accomplish some tasks themselves, and requires the system to effectively
recover from errors as the user strategically assigns it new goals. We build a
game environment to study this scenario, and learn to map user instructions to
system actions. We introduce a learning approach focused on recovery from
cascading errors between instructions, and modeling methods to explicitly
reason about instructions with multiple goals. We evaluate with a new
evaluation protocol using recorded interactions and online games with human
users, and observe how users adapt to the system abilities.
</summary>
    <author>
      <name>Alane Suhr</name>
    </author>
    <author>
      <name>Claudia Yan</name>
    </author>
    <author>
      <name>Jacob Schluger</name>
    </author>
    <author>
      <name>Stanley Yu</name>
    </author>
    <author>
      <name>Hadi Khader</name>
    </author>
    <author>
      <name>Marwa Mouallem</name>
    </author>
    <author>
      <name>Iris Zhang</name>
    </author>
    <author>
      <name>Yoav Artzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.03655v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03655v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.06710v1</id>
    <updated>2019-10-08T17:28:16Z</updated>
    <published>2019-10-08T17:28:16Z</published>
    <title>Knowledge-based Biomedical Data Science 2019</title>
    <summary>  Knowledge-based biomedical data science (KBDS) involves the design and
implementation of computer systems that act as if they knew about biomedicine.
Such systems depend on formally represented knowledge in computer systems,
often in the form of knowledge graphs. Here we survey the progress in the last
year in systems that use formally represented knowledge to address data science
problems in both clinical and biological domains, as well as on approaches for
creating knowledge graphs. Major themes include the relationships between
knowledge graphs and machine learning, the use of natural language processing,
and the expansion of knowledge-based approaches to novel domains, such as
Chinese Traditional Medicine and biodiversity.
</summary>
    <author>
      <name>Tiffany J. Callahan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Bioscience Program, Department of Pharmacology, University of Colorado Denver Anschutz Medical Campus</arxiv:affiliation>
    </author>
    <author>
      <name>Harrison Pielke-Lombardo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Bioscience Program, Department of Pharmacology, University of Colorado Denver Anschutz Medical Campus</arxiv:affiliation>
    </author>
    <author>
      <name>Ignacio J. Tripodi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Bioscience Program, Department of Pharmacology, University of Colorado Denver Anschutz Medical Campus</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Science, University of Colorado Boulder</arxiv:affiliation>
    </author>
    <author>
      <name>Lawrence E. Hunter</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Bioscience Program, Department of Pharmacology, University of Colorado Denver Anschutz Medical Campus</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Manuscript 43 pages with 3 tables; Supplemental material 43 pages
  with 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.0; I.2.1; I.2.4; I.2.7; I.2.m; I.5.0; I.7.0; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03544v2</id>
    <updated>2019-10-10T08:04:12Z</updated>
    <published>2019-10-08T17:08:39Z</published>
    <title>Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking</title>
    <summary>  Dialog State Tracking (DST) is a core component in task-oriented dialog
systems. Existing approaches for DST usually fall into two categories, i.e, the
picklist-based and span-based. From one hand, the picklist-based methods
perform classifications for each slot over a candidate-value list, under the
condition that a pre-defined ontology is accessible. However, it is impractical
in industry since it is hard to get full access to the ontology. On the other
hand, the span-based methods track values for each slot through finding text
spans in the dialog context. However, due to the diversity of value
descriptions, it is hard to find a particular string in the dialog context. To
mitigate these issues, this paper proposes a Dual Strategy for DST (DS-DST) to
borrow advantages from both the picklist-based and span-based methods, by
classifying over a picklist or finding values from a slot span. Empirical
results show that DS-DST achieves the state-of-the-art scores in terms of joint
accuracy, i.e., 51.2% on the MultiWOZ 2.1 dataset, and 53.3% when the full
ontology is accessible.
</summary>
    <author>
      <name>Jian-Guo Zhang</name>
    </author>
    <author>
      <name>Kazuma Hashimoto</name>
    </author>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Yao Wan</name>
    </author>
    <author>
      <name>Philip S. Yu</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <link href="http://arxiv.org/abs/1910.03544v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03544v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03065v2</id>
    <updated>2019-10-09T14:56:58Z</updated>
    <published>2019-10-07T20:14:23Z</published>
    <title>Make Up Your Mind! Adversarial Generation of Inconsistent Natural
  Language Explanations</title>
    <summary>  To increase trust in artificial intelligence systems, a growing amount of
works are enhancing these systems with the capability of producing natural
language explanations that support their predictions. In this work, we show
that such appealing frameworks are nonetheless prone to generating inconsistent
explanations, such as "A dog is an animal" and "A dog is not an animal", which
are likely to decrease users' trust in these systems. To detect such
inconsistencies, we introduce a simple but effective adversarial framework for
generating a complete target sequence, a scenario that has not been addressed
so far. Finally, we apply our framework to a state-of-the-art neural model that
provides natural language explanations on SNLI, and we show that this model is
capable of generating a significant amount of inconsistencies.
</summary>
    <author>
      <name>Oana-Maria Camburu</name>
    </author>
    <author>
      <name>Brendan Shillingford</name>
    </author>
    <author>
      <name>Pasquale Minervini</name>
    </author>
    <author>
      <name>Thomas Lukasiewicz</name>
    </author>
    <author>
      <name>Phil Blunsom</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019 Workshop on Safety and Robustness in Decision Making,
  Vancouver, Canada</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.03065v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03065v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03042v1</id>
    <updated>2019-10-07T19:24:36Z</updated>
    <published>2019-10-07T19:24:36Z</published>
    <title>Gunrock: A Social Bot for Complex and Engaging Long Conversations</title>
    <summary>  Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by
coherence and engagement from both real users and Amazon-selected expert
conversationalists. We focus on understanding complex sentences and having
in-depth conversations in open domains. In this paper, we introduce some
innovative system designs and related validation analysis. Overall, we found
that users produce longer sentences to Gunrock, which are directly related to
users' engagement (e.g., ratings, number of turns). Additionally, users'
backstory queries about Gunrock are positively correlated to user satisfaction.
Finally, we found dialog flows that interleave facts and personal opinions and
stories lead to better user satisfaction.
</summary>
    <author>
      <name>Dian Yu</name>
    </author>
    <author>
      <name>Michelle Cohn</name>
    </author>
    <author>
      <name>Yi Mang Yang</name>
    </author>
    <author>
      <name>Chun-Yen Chen</name>
    </author>
    <author>
      <name>Weiming Wen</name>
    </author>
    <author>
      <name>Jiaping Zhang</name>
    </author>
    <author>
      <name>Mingyang Zhou</name>
    </author>
    <author>
      <name>Kevin Jesse</name>
    </author>
    <author>
      <name>Austin Chau</name>
    </author>
    <author>
      <name>Antara Bhowmick</name>
    </author>
    <author>
      <name>Shreenath Iyer</name>
    </author>
    <author>
      <name>Giritheja Sreenivasulu</name>
    </author>
    <author>
      <name>Sam Davidson</name>
    </author>
    <author>
      <name>Ashwin Bhandare</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.03042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02915v2</id>
    <updated>2019-12-19T20:02:50Z</updated>
    <published>2019-10-07T17:16:04Z</published>
    <title>Commonsense Knowledge Base Completion with Structural and Semantic
  Context</title>
    <summary>  Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and
ConceptNet) poses unique challenges compared to the much studied conventional
knowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form
text to represent nodes, resulting in orders of magnitude more nodes compared
to conventional KBs (18x more nodes in ATOMIC compared to Freebase
(FB15K-237)). Importantly, this implies significantly sparser graph structures
- a major challenge for existing KB completion methods that assume densely
connected graphs over a relatively smaller set of nodes. In this paper, we
present novel KB completion models that can address these challenges by
exploiting the structural and semantic context of nodes. Specifically, we
investigate two key ideas: (1) learning from local graph structure, using graph
convolutional networks and automatic graph densification and (2) transfer
learning from pre-trained language models to knowledge graphs for enhanced
contextual representation of knowledge. We describe our method to incorporate
information from both these sources in a joint model and provide the first
empirical results for KB completion on ATOMIC and evaluation with ranking
metrics on ConceptNet. Our results demonstrate the effectiveness of language
model representations in boosting link prediction performance and the
advantages of learning from local graph structure (+1.5 points in MRR for
ConceptNet) when training on subgraphs for computational efficiency. Further
analysis on model predictions shines light on the types of commonsense
knowledge that language models capture well.
</summary>
    <author>
      <name>Chaitanya Malaviya</name>
    </author>
    <author>
      <name>Chandra Bhagavatula</name>
    </author>
    <author>
      <name>Antoine Bosselut</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02915v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02915v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02610v1</id>
    <updated>2019-10-07T04:58:43Z</updated>
    <published>2019-10-07T04:58:43Z</published>
    <title>Multi-hop Question Answering via Reasoning Chains</title>
    <summary>  Multi-hop question answering requires models to gather information from
different parts of a text to answer a question. Most current approaches learn
to address this task in an end-to-end way with neural networks, without
maintaining an explicit representation of the reasoning process. We propose a
method to extract a discrete reasoning chain over the text, which consists of a
series of sentences leading to the answer. We then feed the extracted chains to
a BERT-based QA model to do final answer prediction. Critically, we do not rely
on gold annotated chains or "supporting facts:" at training time, we derive
pseudogold reasoning chains using heuristics based on named entity recognition
and coreference resolution. Nor do we rely on these annotations at test time,
as our model learns to extract chains from raw text alone. We test our approach
on two recently proposed large multi-hop question answering datasets: WikiHop
and HotpotQA, and achieve state-of-art performance on WikiHop and strong
performance on HotpotQA. Our analysis shows the properties of chains that are
crucial for high performance: in particular, modeling extraction sequentially
is important, as is dealing with each candidate sentence in a context-aware
way. Furthermore, human evaluation shows that our extracted chains allow humans
to give answers with high confidence, indicating that these are a strong
intermediate abstraction for this task.
</summary>
    <author>
      <name>Jifan Chen</name>
    </author>
    <author>
      <name>Shih-ting Lin</name>
    </author>
    <author>
      <name>Greg Durrett</name>
    </author>
    <link href="http://arxiv.org/abs/1910.02610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02517v1</id>
    <updated>2019-10-06T20:26:12Z</updated>
    <published>2019-10-06T20:26:12Z</published>
    <title>Fine-Grained Analysis of Propaganda in News Articles</title>
    <summary>  Propaganda aims at influencing people's mindset with the purpose of advancing
a specific agenda. Previous work has addressed propaganda detection at the
document level, typically labelling all articles from a propagandistic news
outlet as propaganda. Such noisy gold labels inevitably affect the quality of
any learning system trained on them. A further issue with most existing systems
is the lack of explainability. To overcome these limitations, we propose a
novel task: performing fine-grained analysis of texts by detecting all
fragments that contain propaganda techniques as well as their type. In
particular, we create a corpus of news articles manually annotated at the
fragment level with eighteen propaganda techniques and we propose a suitable
evaluation measure. We further design a novel multi-granularity neural network,
and we show that it outperforms several strong BERT-based baselines.
</summary>
    <author>
      <name>Giovanni Da San Martino</name>
    </author>
    <author>
      <name>Seunghak Yu</name>
    </author>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Rostislav Petrov</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.02517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02365v1</id>
    <updated>2019-10-06T04:02:55Z</updated>
    <published>2019-10-06T04:02:55Z</published>
    <title>Multilingual Dialogue Generation with Shared-Private Memory</title>
    <summary>  Existing dialog systems are all monolingual, where features shared among
different languages are rarely explored. In this paper, we introduce a novel
multilingual dialogue system. Specifically, we augment the sequence to sequence
framework with improved shared-private memory. The shared memory learns common
features among different languages and facilitates a cross-lingual transfer to
boost dialogue systems, while the private memory is owned by each separate
language to capture its unique feature. Experiments conducted on Chinese and
English conversation corpora of different scales show that our proposed
architecture outperforms the individually learned model with the help of the
other language, where the improvement is particularly distinct when the
training data is limited.
</summary>
    <author>
      <name>Chen Chen</name>
    </author>
    <author>
      <name>Lisong Qiu</name>
    </author>
    <author>
      <name>Zhenxin Fu</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Junfei Liu</name>
    </author>
    <author>
      <name>Rui Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by NLPCC 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02202v1</id>
    <updated>2019-10-05T03:23:45Z</updated>
    <published>2019-10-05T03:23:45Z</published>
    <title>Learning from Fact-checkers: Analysis and Generation of Fact-checking
  Language</title>
    <summary>  In fighting against fake news, many fact-checking systems comprised of
human-based fact-checking sites (e.g., snopes.com and politifact.com) and
automatic detection systems have been developed in recent years. However,
online users still keep sharing fake news even when it has been debunked. It
means that early fake news detection may be insufficient and we need another
complementary approach to mitigate the spread of misinformation. In this paper,
we introduce a novel application of text generation for combating fake news. In
particular, we (1) leverage online users named \emph{fact-checkers}, who cite
fact-checking sites as credible evidences to fact-check information in public
discourse; (2) analyze linguistic characteristics of fact-checking tweets; and
(3) propose and build a deep learning framework to generate responses with
fact-checking intention to increase the fact-checkers' engagement in
fact-checking activities. Our analysis reveals that the fact-checkers tend to
refute misinformation and use formal language (e.g. few swear words and
Internet slangs). Our framework successfully generates relevant responses, and
outperforms competing models by achieving up to 30\% improvements. Our
qualitative study also confirms that the superiority of our generated responses
compared with responses generated from the existing models.
</summary>
    <author>
      <name>Nguyen Vo</name>
    </author>
    <author>
      <name>Kyumin Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02001v1</id>
    <updated>2019-10-04T15:50:30Z</updated>
    <published>2019-10-04T15:50:30Z</published>
    <title>Predicting the Role of Political Trolls in Social Media</title>
    <summary>  We investigate the political roles of "Internet trolls" in social media.
Political trolls, such as the ones linked to the Russian Internet Research
Agency (IRA), have recently gained enormous attention for their ability to sway
public opinion and even influence elections. Analysis of the online traces of
trolls has shown different behavioral patterns, which target different slices
of the population. However, this analysis is manual and labor-intensive, thus
making it impractical as a first-response tool for newly-discovered troll
farms. In this paper, we show how to automate this analysis by using machine
learning in a realistic setting. In particular, we show how to classify trolls
according to their political role ---left, news feed, right--- by using
features extracted from social media, i.e., Twitter, in two scenarios: (i) in a
traditional supervised learning scenario, where labels for trolls are
available, and (ii) in a distant supervision scenario, where labels for trolls
are not available, and we rely on more-commonly-available labels for news
outlets mentioned by the trolls. Technically, we leverage the community
structure and the text of the messages in the online social network of trolls
represented as a graph, from which we extract several types of learned
representations, i.e.,~embeddings, for the trolls. Experiments on the "IRA
Russian Troll" dataset show that our methodology improves over the
state-of-the-art in the first scenario, while providing a compelling case for
the second scenario, which has not been explored in the literature thus far.
</summary>
    <author>
      <name>Atanas Atanasov</name>
    </author>
    <author>
      <name>Gianmarco De Francisci Morales</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CoNLL-2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.02001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.01990v1</id>
    <updated>2019-10-04T15:28:01Z</updated>
    <published>2019-10-04T15:28:01Z</published>
    <title>Detecting Deception in Political Debates Using Acoustic and Textual
  Features</title>
    <summary>  We present work on deception detection, where, given a spoken claim, we aim
to predict its factuality. While previous work in the speech community has
relied on recordings from staged setups where people were asked to tell the
truth or to lie and their statements were recorded, here we use real-world
political debates. Thanks to the efforts of fact-checking organizations, it is
possible to obtain annotations for statements in the context of a political
discourse as true, half-true, or false. Starting with such data from the
CLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to
the corresponding videos, thus producing a multimodal dataset. We further
developed a multimodal deep-learning architecture for the task of deception
detection, which yielded sizable improvements over the state of the art for the
CLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal
consistently helped to improve the performance compared to using textual and
metadata features only, based on several different evaluation measures. We
release the new dataset to the research community, hoping to help advance the
overall field of multimodal deception detection.
</summary>
    <author>
      <name>Daniel Kopev</name>
    </author>
    <author>
      <name>Ahmed Ali</name>
    </author>
    <author>
      <name>Ivan Koychev</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ASRU-2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.01990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.01990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.01442v2</id>
    <updated>2020-03-08T00:09:07Z</updated>
    <published>2019-10-03T13:16:36Z</published>
    <title>CLEVRER: CoLlision Events for Video REpresentation and Reasoning</title>
    <summary>  The ability to reason about temporal and causal events from videos lies at
the core of human intelligence. Most video reasoning benchmarks, however, focus
on pattern recognition from complex visual and language input, instead of on
causal structure. We study the complementary problem, exploring the temporal
and causal structures behind videos of objects with simple visual appearance.
To this end, we introduce the CoLlision Events for Video REpresentation and
Reasoning (CLEVRER), a diagnostic video dataset for systematic evaluation of
computational models on a wide range of reasoning tasks. Motivated by the
theory of human casual judgment, CLEVRER includes four types of questions:
descriptive (e.g., "what color"), explanatory ("what is responsible for"),
predictive ("what will happen next"), and counterfactual ("what if"). We
evaluate various state-of-the-art models for visual reasoning on our benchmark.
While these models thrive on the perception-based task (descriptive), they
perform poorly on the causal tasks (explanatory, predictive and
counterfactual), suggesting that a principled approach for causal reasoning
should incorporate the capability of both perceiving complex visual and
language inputs, and understanding the underlying dynamics and causal
relations. We also study an oracle model that explicitly combines these
components via symbolic representations.
</summary>
    <author>
      <name>Kexin Yi</name>
    </author>
    <author>
      <name>Chuang Gan</name>
    </author>
    <author>
      <name>Yunzhu Li</name>
    </author>
    <author>
      <name>Pushmeet Kohli</name>
    </author>
    <author>
      <name>Jiajun Wu</name>
    </author>
    <author>
      <name>Antonio Torralba</name>
    </author>
    <author>
      <name>Joshua B. Tenenbaum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally to this work. Accepted as
  Oral Spotlight as ICLR 2020. Project page: http://clevrer.csail.mit.edu/</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.01442v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.01442v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.02789v2</id>
    <updated>2020-02-05T07:16:02Z</updated>
    <published>2019-10-02T11:06:17Z</published>
    <title>Language is Power: Representing States Using Natural Language in
  Reinforcement Learning</title>
    <summary>  Recent advances in reinforcement learning have shown its potential to tackle
complex real-life tasks. However, as the dimensionality of the task increases,
reinforcement learning methods tend to struggle. To overcome this, we explore
methods for representing the semantic information embedded in the state. While
previous methods focused on information in its raw form (e.g., raw visual
input), we propose to represent the state using natural language. Language can
represent complex scenarios and concepts, making it a favorable candidate for
representation. Empirical evidence, within the domain of ViZDoom, suggests that
natural language based agents are more robust, converge faster and perform
better than vision based agents, showing the benefit of using natural language
representations for reinforcement learning.
</summary>
    <author>
      <name>Erez Schwartz</name>
    </author>
    <author>
      <name>Guy Tennenholtz</name>
    </author>
    <author>
      <name>Chen Tessler</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1910.02789v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02789v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00861v1</id>
    <updated>2019-10-02T10:17:28Z</updated>
    <published>2019-10-02T10:17:28Z</published>
    <title>Clinical Text Generation through Leveraging Medical Concept and
  Relations</title>
    <summary>  With a neural sequence generation model, this study aims to develop a method
of writing the patient clinical texts given a brief medical history. As a
proof-of-a-concept, we have demonstrated that it can be workable to use medical
concept embedding in clinical text generation. Our model was based on the
Sequence-to-Sequence architecture and trained with a large set of de-identified
clinical text data. The quantitative result shows that our concept embedding
method decreased the perplexity of the baseline architecture. Also, we discuss
the analyzed results from a human evaluation performed by medical doctors.
</summary>
    <author>
      <name>Wangjin Lee</name>
    </author>
    <author>
      <name>Hyeryun Park</name>
    </author>
    <author>
      <name>Jooyoung Yoon</name>
    </author>
    <author>
      <name>Kyeongmo Kim</name>
    </author>
    <author>
      <name>Jinwook Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a revised version of one uploaded in openreview.net
  (https://openreview.net/forum?id=Skg6L9ZTpV)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.00861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00610v1</id>
    <updated>2019-10-01T18:29:08Z</updated>
    <published>2019-10-01T18:29:08Z</published>
    <title>DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic
  Knowledge Graphs</title>
    <summary>  Data-driven, knowledge-grounded neural conversation models are capable of
generating more informative responses. However, these models have not yet
demonstrated that they can zero-shot adapt to updated, unseen knowledge graphs.
This paper proposes a new task about how to apply dynamic knowledge graphs in
neural conversation model and presents a novel TV series conversation corpus
(DyKgChat) for the task. Our new task and corpus aids in understanding the
influence of dynamic knowledge graphs on responses generation. Also, we propose
a preliminary model that selects an output from two networks at each time step:
a sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in
order to support dynamic knowledge graphs. To benchmark this new task and
evaluate the capability of adaptation, we introduce several evaluation metrics
and the experiments show that our proposed approach outperforms previous
knowledge-grounded conversation models. The proposed corpus and model can
motivate the future research directions.
</summary>
    <author>
      <name>Yi-Lin Tuan</name>
    </author>
    <author>
      <name>Yun-Nung Chen</name>
    </author>
    <author>
      <name>Hung-yi Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.00610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00334v1</id>
    <updated>2019-10-01T12:18:42Z</updated>
    <published>2019-10-01T12:18:42Z</published>
    <title>Towards French Smart Building Code: Compliance Checking Based on
  Semantic Rules</title>
    <summary>  Manually checking models for compliance against building regulation is a
time-consuming task for architects and construction engineers. There is thus a
need for algorithms that process information from construction projects and
report non-compliant elements. Still automated code-compliance checking raises
several obstacles. Building regulations are usually published as human readable
texts and their content is often ambiguous or incomplete. Also, the vocabulary
used for expressing such regulations is very different from the vocabularies
used to express Building Information Models (BIM). Furthermore, the high level
of details associated to BIM-contained geometries induces complex calculations.
Finally, the level of complexity of the IFC standard also hinders the
automation of IFC processing tasks. Model chart, formal rules and
pre-processors approach allows translating construction regulations into
semantic queries. We further demonstrate the usefulness of this approach
through several use cases. We argue our approach is a step forward in bridging
the gap between regulation texts and automated checking algorithms. Finally
with the recent building ontology BOT recommended by the W3C Linked Building
Data Community Group, we identify perspectives for standardizing and extending
our approach.
</summary>
    <author>
      <name>Nicolas Bus</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CSTB</arxiv:affiliation>
    </author>
    <author>
      <name>Ana Roxin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Le2i</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Picinbono</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CSTB</arxiv:affiliation>
    </author>
    <author>
      <name>Muhammad Fahad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CSTB</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Linked Data for Architecture and Construction (LDAC'2018), Jun
  2018, Londres, United Kingdom</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.00334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00290v1</id>
    <updated>2019-10-01T10:26:08Z</updated>
    <published>2019-10-01T10:26:08Z</published>
    <title>Identifying Supporting Facts for Multi-hop Question Answering with
  Document Graph Networks</title>
    <summary>  Recent advances in reading comprehension have resulted in models that surpass
human performance when the answer is contained in a single, continuous passage
of text. However, complex Question Answering (QA) typically requires multi-hop
reasoning - i.e. the integration of supporting facts from different sources, to
infer the correct answer. This paper proposes Document Graph Network (DGN), a
message passing architecture for the identification of supporting facts over a
graph-structured representation of text. The evaluation on HotpotQA shows that
DGN obtains competitive results when compared to a reading comprehension
baseline operating on raw text, confirming the relevance of structured
representations for supporting multi-hop reasoning.
</summary>
    <author>
      <name>Mokanarangan Thayaparan</name>
    </author>
    <author>
      <name>Marco Valentino</name>
    </author>
    <author>
      <name>Viktor Schlegel</name>
    </author>
    <author>
      <name>Andre Freitas</name>
    </author>
    <link href="http://arxiv.org/abs/1910.00290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00192v1</id>
    <updated>2019-10-01T04:07:15Z</updated>
    <published>2019-10-01T04:07:15Z</published>
    <title>Writing habits and telltale neighbors: analyzing clinical concept usage
  patterns with sublanguage embeddings</title>
    <summary>  Natural language processing techniques are being applied to increasingly
diverse types of electronic health records, and can benefit from in-depth
understanding of the distinguishing characteristics of medical document types.
We present a method for characterizing the usage patterns of clinical concepts
among different document types, in order to capture semantic differences beyond
the lexical level. By training concept embeddings on clinical documents of
different types and measuring the differences in their nearest neighborhood
structures, we are able to measure divergences in concept usage while
correcting for noise in embedding learning. Experiments on the MIMIC-III corpus
demonstrate that our approach captures clinically-relevant differences in
concept usage and provides an intuitive way to explore semantic characteristics
of clinical document collections.
</summary>
    <author>
      <name>Denis Newman-Griffis</name>
    </author>
    <author>
      <name>Eric Fosler-Lussier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LOUHI 2019 (co-located with EMNLP)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.00192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.00084v1</id>
    <updated>2019-09-30T20:20:48Z</updated>
    <published>2019-09-30T20:20:48Z</published>
    <title>Contextual Graph Attention for Answering Logical Queries over Incomplete
  Knowledge Graphs</title>
    <summary>  Recently, several studies have explored methods for using KG embedding to
answer logical queries. These approaches either treat embedding learning and
query answering as two separated learning tasks, or fail to deal with the
variability of contributions from different query paths. We proposed to
leverage a graph attention mechanism to handle the unequal contribution of
different query paths. However, commonly used graph attention assumes that the
center node embedding is provided, which is unavailable in this task since the
center node is to be predicted. To solve this problem we propose a multi-head
attention-based end-to-end logical query answering model, called Contextual
Graph Attention model(CGA), which uses an initial neighborhood aggregation
layer to generate the center embedding, and the whole model is trained jointly
on the original KG structure as well as the sampled query-answer pairs. We also
introduce two new datasets, DB18 and WikiGeo19, which are rather large in size
compared to the existing datasets and contain many more relation types, and use
them to evaluate the performance of the proposed model. Our result shows that
the proposed CGA with fewer learnable parameters consistently outperforms the
baseline models on both datasets as well as Bio dataset.
</summary>
    <author>
      <name>Gengchen Mai</name>
    </author>
    <author>
      <name>Krzysztof Janowicz</name>
    </author>
    <author>
      <name>Bo Yan</name>
    </author>
    <author>
      <name>Rui Zhu</name>
    </author>
    <author>
      <name>Ling Cai</name>
    </author>
    <author>
      <name>Ni Lao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3360901.3364432</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3360901.3364432" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, camera ready version of article accepted to K-CAP
  2019, Marina del Rey, California, United States</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">K-CAP 2019, Nov. 19 - 21, 2019, Marina del Rey, CA, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.00084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.00084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.13434v1</id>
    <updated>2019-09-30T02:40:48Z</updated>
    <published>2019-09-30T02:40:48Z</published>
    <title>Generating Diverse Story Continuations with Controllable Semantics</title>
    <summary>  We propose a simple and effective modeling framework for controlled
generation of multiple, diverse outputs. We focus on the setting of generating
the next sentence of a story given its context. As controllable dimensions, we
consider several sentence attributes, including sentiment, length, predicates,
frames, and automatically-induced clusters. Our empirical results demonstrate:
(1) our framework is accurate in terms of generating outputs that match the
target control values; (2) our model yields increased maximum metric scores
compared to standard n-best list generation via beam search; (3) controlling
generation with semantic frames leads to a stronger combination of diversity
and quality than other control variables as measured by automatic metrics. We
also conduct a human evaluation to assess the utility of providing multiple
suggestions for creative writing, demonstrating promising results for the
potential of controllable, diverse generation in a collaborative writing
system.
</summary>
    <author>
      <name>Lifu Tu</name>
    </author>
    <author>
      <name>Xiaoan Ding</name>
    </author>
    <author>
      <name>Dong Yu</name>
    </author>
    <author>
      <name>Kevin Gimpel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 Workshop on Neural Generation and Translation (WNGT2019),
  and non-archival acceptance in NeuralGen 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.13434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.13434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12868v1</id>
    <updated>2019-09-27T18:40:23Z</updated>
    <published>2019-09-27T18:40:23Z</published>
    <title>Automatically Learning Data Augmentation Policies for Dialogue Tasks</title>
    <summary>  Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for
optimal perturbation policies via a controller trained using performance
rewards of a sampled policy on the target task, hence reducing data-level model
bias. While being a powerful algorithm, their work has focused on computer
vision tasks, where it is comparatively easy to apply imperceptible
perturbations without changing an image's semantic meaning. In our work, we
adapt AutoAugment to automatically discover effective perturbation policies for
natural language processing (NLP) tasks such as dialogue generation. We start
with a pool of atomic operations that apply subtle semantic-preserving
perturbations to the source inputs of a dialogue task (e.g., different POS-tag
types of stopword dropout, grammatical errors, and paraphrasing). Next, we
allow the controller to learn more complex augmentation policies by searching
over the space of the various combinations of these atomic operations.
Moreover, we also explore conditioning the controller on the source inputs of
the target task, since certain strategies may not apply to inputs that do not
contain that strategy's required linguistic features. Empirically, we
demonstrate that both our input-agnostic and input-aware controllers discover
useful data augmentation policies, and achieve significant improvements over
the previous state-of-the-art, including trained on manually-designed policies.
</summary>
    <author>
      <name>Tong Niu</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages (EMNLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.12868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12434v2</id>
    <updated>2020-02-14T22:32:46Z</updated>
    <published>2019-09-26T23:25:25Z</published>
    <title>Learning the Difference that Makes a Difference with
  Counterfactually-Augmented Data</title>
    <summary>  Despite alarm over the reliance of machine learning systems on so-called
spurious patterns, the term lacks coherent meaning in standard statistical
frameworks. However, the language of causality offers clarity: spurious
associations are due to confounding (e.g., a common cause), but not direct or
indirect causal effects. In this paper, we focus on natural language
processing, introducing methods and resources for training models less
sensitive to spurious patterns. Given documents and their initial labels, we
task humans with revising each document so that it (i) accords with a
counterfactual target label; (ii) retains internal coherence; and (iii) avoids
unnecessary changes. Interestingly, on sentiment analysis and natural language
inference tasks, classifiers trained on original data fail on their
counterfactually-revised counterparts and vice versa. Classifiers trained on
combined datasets perform remarkably well, just shy of those specialized to
either domain. While classifiers trained on either original or manipulated data
alone are sensitive to spurious features (e.g., mentions of genre), models
trained on the combined data are less sensitive to this signal. Both datasets
are publicly available.
</summary>
    <author>
      <name>Divyansh Kaushik</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <author>
      <name>Zachary C. Lipton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.12434v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12434v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12086v1</id>
    <updated>2019-09-26T13:34:26Z</updated>
    <published>2019-09-26T13:34:26Z</published>
    <title>GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution
  Model for Task-Oriented Dialogue</title>
    <summary>  Ellipsis and co-reference are common and ubiquitous especially in multi-turn
dialogues. In this paper, we treat the resolution of ellipsis and co-reference
in dialogue as a problem of generating omitted or referred expressions from the
dialogue context. We therefore propose a unified end-to-end Generative Ellipsis
and CO-reference Resolution model (GECOR) in the context of dialogue. The model
can generate a new pragmatically complete user utterance by alternating the
generation and copy mode for each user utterance. A multi-task learning
framework is further proposed to integrate the GECOR into an end-to-end
task-oriented dialogue. In order to train both the GECOR and the multi-task
learning framework, we manually construct a new dataset on the basis of the
public dataset CamRest676 with both ellipsis and co-reference annotation. On
this dataset, intrinsic evaluations on the resolution of ellipsis and
co-reference show that the GECOR model significantly outperforms the
sequence-to-sequence (seq2seq) baseline model in terms of EM, BLEU and F1 while
extrinsic evaluations on the downstream dialogue task demonstrate that our
multi-task learning framework with GECOR achieves a higher success rate of task
completion than TSCP, a state-of-the-art end-to-end task-oriented dialogue
model.
</summary>
    <author>
      <name>Jun Quan</name>
    </author>
    <author>
      <name>Deyi Xiong</name>
    </author>
    <author>
      <name>Bonnie Webber</name>
    </author>
    <author>
      <name>Changjian Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted to appear at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.12086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12066v1</id>
    <updated>2019-09-26T12:55:14Z</updated>
    <published>2019-09-26T12:55:14Z</published>
    <title>Towards a Metric for Automated Conversational Dialogue System Evaluation
  and Improvement</title>
    <summary>  We present "AutoJudge", an automated evaluation method for conversational
dialogue systems. The method works by first generating dialogues based on
self-talk, i.e. dialogue systems talking to itself. Then, it uses human ratings
on these dialogues to train an automated judgement model. Our experiments show
that AutoJudge correlates well with the human ratings and can be used to
automatically evaluate dialogue systems, even in deployed systems. In a second
part, we attempt to apply AutoJudge to improve existing systems. This works
well for re-ranking a set of candidate utterances. However, our experiments
show that AutoJudge cannot be applied as reward for reinforcement learning,
although the metric can distinguish good from bad dialogues. We discuss
potential reasons, but state here already that this is still an open question
for further research.
</summary>
    <author>
      <name>Jan Deriu</name>
    </author>
    <author>
      <name>Mark Cieliebak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, To be published at the INLG 2019 converence</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.12066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11980v1</id>
    <updated>2019-09-26T08:46:02Z</updated>
    <published>2019-09-26T08:46:02Z</published>
    <title>Spoken Conversational Search for General Knowledge</title>
    <summary>  We present a spoken conversational question answering proof of concept that
is able to answer questions about general knowledge from Wikidata. The dialogue
component does not only orchestrate various components but also solve
coreferences and ellipsis.
</summary>
    <author>
      <name>Lina M. Rojas-Barahona</name>
    </author>
    <author>
      <name>Pascal Bellec</name>
    </author>
    <author>
      <name>Benoit Besset</name>
    </author>
    <author>
      <name>Martinho Dos-Santos</name>
    </author>
    <author>
      <name>Johannes Heinecke</name>
    </author>
    <author>
      <name>Munshi Asadullah</name>
    </author>
    <author>
      <name>Olivier Le-Blouch</name>
    </author>
    <author>
      <name>Jean Y. Lancien</name>
    </author>
    <author>
      <name>Géraldine Damnati</name>
    </author>
    <author>
      <name>Emmanuel Mory</name>
    </author>
    <author>
      <name>Frédéric Herledan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGDial2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11942v6</id>
    <updated>2020-02-09T03:00:18Z</updated>
    <published>2019-09-26T07:06:13Z</published>
    <title>ALBERT: A Lite BERT for Self-supervised Learning of Language
  Representations</title>
    <summary>  Increasing model size when pretraining natural language representations often
results in improved performance on downstream tasks. However, at some point
further model increases become harder due to GPU/TPU memory limitations and
longer training times. To address these problems, we present two
parameter-reduction techniques to lower memory consumption and increase the
training speed of BERT. Comprehensive empirical evidence shows that our
proposed methods lead to models that scale much better compared to the original
BERT. We also use a self-supervised loss that focuses on modeling
inter-sentence coherence, and show it consistently helps downstream tasks with
multi-sentence inputs. As a result, our best model establishes new
state-of-the-art results on the GLUE, RACE, and \squad benchmarks while having
fewer parameters compared to BERT-large. The code and the pretrained models are
available at https://github.com/google-research/ALBERT.
</summary>
    <author>
      <name>Zhenzhong Lan</name>
    </author>
    <author>
      <name>Mingda Chen</name>
    </author>
    <author>
      <name>Sebastian Goodman</name>
    </author>
    <author>
      <name>Kevin Gimpel</name>
    </author>
    <author>
      <name>Piyush Sharma</name>
    </author>
    <author>
      <name>Radu Soricut</name>
    </author>
    <link href="http://arxiv.org/abs/1909.11942v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11942v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11288v1</id>
    <updated>2019-09-25T04:47:49Z</updated>
    <published>2019-09-25T04:47:49Z</published>
    <title>Annotated Guidelines and Building Reference Corpus for Myanmar-English
  Word Alignment</title>
    <summary>  Reference corpus for word alignment is an important resource for developing
and evaluating word alignment methods. For Myanmar-English language pairs,
there is no reference corpus to evaluate the word alignment tasks. Therefore,
we created the guidelines for Myanmar-English word alignment annotation between
two languages over contrastive learning and built the Myanmar-English reference
corpus consisting of verified alignments from Myanmar ALT of the Asian Language
Treebank (ALT). This reference corpus contains confident labels sure (S) and
possible (P) for word alignments which are used to test for the purpose of
evaluation of the word alignments tasks. We discuss the most linking
ambiguities to define consistent and systematic instructions to align manual
words. We evaluated the results of annotators agreement using our reference
corpus in terms of alignment error rate (AER) in word alignment tasks and
discuss the words relationships in terms of BLEU scores.
</summary>
    <author>
      <name>Nway Nway Han</name>
    </author>
    <author>
      <name>Aye Thida</name>
    </author>
    <link href="http://arxiv.org/abs/1909.11288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11287v1</id>
    <updated>2019-09-25T04:40:27Z</updated>
    <published>2019-09-25T04:40:27Z</published>
    <title>Task-Oriented Conversation Generation Using Heterogeneous Memory
  Networks</title>
    <summary>  How to incorporate external knowledge into a neural dialogue model is
critically important for dialogue systems to behave like real humans. To handle
this problem, memory networks are usually a great choice and a promising way.
However, existing memory networks do not perform well when leveraging
heterogeneous information from different sources. In this paper, we propose a
novel and versatile external memory networks called Heterogeneous Memory
Networks (HMNs), to simultaneously utilize user utterances, dialogue history
and background knowledge tuples. In our method, historical sequential dialogues
are encoded and stored into the context-aware memory enhanced by gating
mechanism while grounding knowledge tuples are encoded and stored into the
context-free memory. During decoding, the decoder augmented with HMNs
recurrently selects each word in one response utterance from these two memories
and a general vocabulary. Experimental results on multiple real-world datasets
show that HMNs significantly outperform the state-of-the-art data-driven
task-oriented dialogue models in most domains.
</summary>
    <author>
      <name>Zehao Lin</name>
    </author>
    <author>
      <name>Xinjing Huang</name>
    </author>
    <author>
      <name>Feng Ji</name>
    </author>
    <author>
      <name>Haiqing Chen</name>
    </author>
    <author>
      <name>Ying Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a long paper at EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11287v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11287v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11200v1</id>
    <updated>2019-09-24T21:46:42Z</updated>
    <published>2019-09-24T21:46:42Z</published>
    <title>Improving Robustness In Speaker Identification Using A Two-Stage
  Attention Model</title>
    <summary>  In this paper a novel framework to tackle speaker recognition using a
two-stage attention model is proposed. In recent years, the use of deep neural
networks, such as time delay neural network (TDNN), and attention model have
boosted speaker recognition performance. However, it is still a challenging
task to tackle speaker recognition in severe acoustic environments. To build a
robust speaker recognition system against noise, we employ a two-stage
attention model and combine it with a TDNN model. In this framework, the
attention mechanism is used in two aspects: embedding space and temporal space.
The embedding attention model built in embedding space is to highlight the
importance of each embedding element by weighting them using self attention.
The frame attention model built in temporal space aims to find which frames are
significant for speaker recognition. To evaluate the effectiveness and
robustness of our approach, we use the TIMIT dataset and test our approach in
the condition of five kinds of noise and different signal-noise-ratios (SNRs).
In comparison with three strong baselines, CNN, TDNN and TDNN+attention, the
experimental results show that the use of our approach outperforms them in
different conditions. The correct recognition rate obtained using our approach
can still reach 49.1%, better than any baselines, even if the noise is Gaussian
white Noise and the SNR is 0dB.
</summary>
    <author>
      <name>Yanpei Shi</name>
    </author>
    <author>
      <name>Qiang Huang</name>
    </author>
    <author>
      <name>Thomas Hain</name>
    </author>
    <link href="http://arxiv.org/abs/1909.11200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.11060v1</id>
    <updated>2019-09-24T17:18:48Z</updated>
    <published>2019-09-24T17:18:48Z</published>
    <title>Paying Attention to Function Words</title>
    <summary>  All natural languages exhibit a distinction between content words (like nouns
and adjectives) and function words (like determiners, auxiliaries,
prepositions). Yet surprisingly little has been said about the emergence of
this universal architectural feature of natural languages. Why have human
languages evolved to exhibit this division of labor between content and
function words? How could such a distinction have emerged in the first place?
This paper takes steps towards answering these questions by showing how the
distinction can emerge through reinforcement learning in agents playing a
signaling game across contexts which contain multiple objects that possess
multiple perceptually salient gradable properties.
</summary>
    <author>
      <name>Shane Steinert-Threlkeld</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Emergent Communication Workshop @ NeurIPS 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10838v1</id>
    <updated>2019-09-24T12:29:27Z</updated>
    <published>2019-09-24T12:29:27Z</published>
    <title>Talk2Car: Taking Control of Your Self-Driving Car</title>
    <summary>  A long-term goal of artificial intelligence is to have an agent execute
commands communicated through natural language. In many cases the commands are
grounded in a visual environment shared by the human who gives the command and
the agent. Execution of the command then requires mapping the command into the
physical visual space, after which the appropriate action can be taken. In this
paper we consider the former. Or more specifically, we consider the problem in
an autonomous driving setting, where a passenger requests an action that can be
associated with an object found in a street scene. Our work presents the
Talk2Car dataset, which is the first object referral dataset that contains
commands written in natural language for self-driving cars. We provide a
detailed comparison with related datasets such as ReferIt, RefCOCO, RefCOCO+,
RefCOCOg, Cityscape-Ref and CLEVR-Ref. Additionally, we include a performance
analysis using strong state-of-the-art models. The results show that the
proposed object referral task is a challenging one for which the models show
promising results but still require additional research in natural language
processing, computer vision and the intersection of these fields. The dataset
can be found on our website: http://macchina-ai.eu/
</summary>
    <author>
      <name>Thierry Deruyttere</name>
    </author>
    <author>
      <name>Simon Vandenhende</name>
    </author>
    <author>
      <name>Dusan Grujicic</name>
    </author>
    <author>
      <name>Luc Van Gool</name>
    </author>
    <author>
      <name>Marie-Francine Moens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, accepted at emnlp-ijcnlp 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10838v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10838v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10705v1</id>
    <updated>2019-09-24T04:26:27Z</updated>
    <published>2019-09-24T04:26:27Z</published>
    <title>Do Massively Pretrained Language Models Make Better Storytellers?</title>
    <summary>  Large neural language models trained on massive amounts of text have emerged
as a formidable strategy for Natural Language Understanding tasks. However, the
strength of these models as Natural Language Generators is less clear. Though
anecdotal evidence suggests that these models generate better quality text,
there has been no detailed study characterizing their generation abilities. In
this work, we compare the performance of an extensively pretrained model,
OpenAI GPT2-117 (Radford et al., 2019), to a state-of-the-art neural story
generation model (Fan et al., 2018). By evaluating the generated text across a
wide variety of automatic metrics, we characterize the ways in which pretrained
models do, and do not, make better storytellers. We find that although GPT2-117
conditions more strongly on context, is more sensitive to ordering of events,
and uses more unusual words, it is just as likely to produce repetitive and
under-diverse text when using likelihood-maximizing decoding algorithms.
</summary>
    <author>
      <name>Abigail See</name>
    </author>
    <author>
      <name>Aneesh Pappu</name>
    </author>
    <author>
      <name>Rohun Saxena</name>
    </author>
    <author>
      <name>Akhila Yerukola</name>
    </author>
    <author>
      <name>Christopher D. Manning</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to CoNLL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10681v2</id>
    <updated>2019-10-01T14:00:22Z</updated>
    <published>2019-09-24T02:08:29Z</published>
    <title>Knowledge-Enriched Transformer for Emotion Detection in Textual
  Conversations</title>
    <summary>  Messages in human conversations inherently convey emotions. The task of
detecting emotions in textual conversations leads to a wide range of
applications such as opinion mining in social networks. However, enabling
machines to analyze emotions in conversations is challenging, partly because
humans often rely on the context and commonsense knowledge to express emotions.
In this paper, we address these challenges by proposing a Knowledge-Enriched
Transformer (KET), where contextual utterances are interpreted using
hierarchical self-attention and external commonsense knowledge is dynamically
leveraged using a context-aware affective graph attention mechanism.
Experiments on multiple textual conversation datasets demonstrate that both
context and commonsense knowledge are consistently beneficial to the emotion
detection performance. In addition, the experimental results show that our KET
model outperforms the state-of-the-art models on most of the tested datasets in
F1 score.
</summary>
    <author>
      <name>Peixiang Zhong</name>
    </author>
    <author>
      <name>Di Wang</name>
    </author>
    <author>
      <name>Chunyan Miao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10681v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10681v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10572v2</id>
    <updated>2019-11-22T22:40:23Z</updated>
    <published>2019-09-23T18:54:52Z</published>
    <title>Hypernym Detection Using Strict Partial Order Networks</title>
    <summary>  This paper introduces Strict Partial Order Networks (SPON), a novel neural
network architecture designed to enforce asymmetry and transitive properties as
soft constraints. We apply it to induce hypernymy relations by training with
is-a pairs. We also present an augmented variant of SPON that can generalize
type information learned for in-vocabulary terms to previously unseen ones. An
extensive evaluation over eleven benchmarks across different tasks shows that
SPON consistently either outperforms or attains the state of the art on all but
one of these benchmarks.
</summary>
    <author>
      <name>Sarthak Dash</name>
    </author>
    <author>
      <name>Md Faisal Mahbub Chowdhury</name>
    </author>
    <author>
      <name>Alfio Gliozzo</name>
    </author>
    <author>
      <name>Nandana Mihindukulasooriya</name>
    </author>
    <author>
      <name>Nicolas Rodolfo Fauceglia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.10572v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10572v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10470v2</id>
    <updated>2019-10-03T03:01:48Z</updated>
    <published>2019-09-23T16:47:15Z</published>
    <title>Improving Generative Visual Dialog by Answering Diverse Questions</title>
    <summary>  Prior work on training generative Visual Dialog models with reinforcement
learning(Das et al.) has explored a Qbot-Abot image-guessing game and shown
that this 'self-talk' approach can lead to improved performance at the
downstream dialog-conditioned image-guessing task. However, this improvement
saturates and starts degrading after a few rounds of interaction, and does not
lead to a better Visual Dialog model. We find that this is due in part to
repeated interactions between Qbot and Abot during self-talk, which are not
informative with respect to the image. To improve this, we devise a simple
auxiliary objective that incentivizes Qbot to ask diverse questions, thus
reducing repetitions and in turn enabling Abot to explore a larger state space
during RL ie. be exposed to more visual concepts to talk about, and varied
questions to answer. We evaluate our approach via a host of automatic metrics
and human studies, and demonstrate that it leads to better dialog, ie. dialog
that is more diverse (ie. less repetitive), consistent (ie. has fewer
conflicting exchanges), fluent (ie. more human-like),and detailed, while still
being comparably image-relevant as prior work and ablations.
</summary>
    <author>
      <name>Vishvak Murahari</name>
    </author>
    <author>
      <name>Prithvijit Chattopadhyay</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Abhishek Das</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10470v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10470v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10351v4</id>
    <updated>2019-12-04T01:50:34Z</updated>
    <published>2019-09-23T13:05:35Z</published>
    <title>TinyBERT: Distilling BERT for Natural Language Understanding</title>
    <summary>  Language model pre-training, such as BERT, has significantly improved the
performances of many natural language processing tasks. However, pre-trained
language models are usually computationally expensive and memory intensive, so
it is difficult to effectively execute them on some resource-restricted
devices. To accelerate inference and reduce model size while maintaining
accuracy, we firstly propose a novel transformer distillation method that is a
specially designed knowledge distillation (KD) method for transformer-based
models. By leveraging this new KD method, the plenty of knowledge encoded in a
large teacher BERT can be well transferred to a small student TinyBERT.
Moreover, we introduce a new two-stage learning framework for TinyBERT, which
performs transformer distillation at both the pre-training and task-specific
learning stages. This framework ensures that TinyBERT can capture both the
general-domain and task-specific knowledge of the teacher BERT.TinyBERT is
empirically effective and achieves more than 96% the performance of teacher
BERTBASE on GLUE benchmark while being 7.5x smaller and 9.4x faster on
inference. TinyBERT is also significantly better than state-of-the-art
baselines on BERT distillation, with only about 28% parameters and about 31%
inference time of them.
</summary>
    <author>
      <name>Xiaoqi Jiao</name>
    </author>
    <author>
      <name>Yichun Yin</name>
    </author>
    <author>
      <name>Lifeng Shang</name>
    </author>
    <author>
      <name>Xin Jiang</name>
    </author>
    <author>
      <name>Xiao Chen</name>
    </author>
    <author>
      <name>Linlin Li</name>
    </author>
    <author>
      <name>Fang Wang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">code and model:
  https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT
  ; 13 pages, 2 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10351v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10351v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10166v1</id>
    <updated>2019-09-23T05:29:04Z</updated>
    <published>2019-09-23T05:29:04Z</published>
    <title>Automatic Short Answer Grading via Multiway Attention Networks</title>
    <summary>  Automatic short answer grading (ASAG), which autonomously score student
answers according to reference answers, provides a cost-effective and
consistent approach to teaching professionals and can reduce their monotonous
and tedious grading workloads. However, ASAG is a very challenging task due to
two reasons: (1) student answers are made up of free text which requires a deep
semantic understanding; and (2) the questions are usually open-ended and across
many domains in K-12 scenarios. In this paper, we propose a generalized
end-to-end ASAG learning framework which aims to (1) autonomously extract
linguistic information from both student and reference answers; and (2)
accurately model the semantic relations between free-text student and reference
answers in open-ended domain. The proposed ASAG model is evaluated on a large
real-world K-12 dataset and can outperform the state-of-the-art baselines in
terms of various evaluation metrics.
</summary>
    <author>
      <name>Tiaoqiao Liu</name>
    </author>
    <author>
      <name>Wenbiao Ding</name>
    </author>
    <author>
      <name>Zhiwei Wang</name>
    </author>
    <author>
      <name>Jiliang Tang</name>
    </author>
    <author>
      <name>Gale Yan Huang</name>
    </author>
    <author>
      <name>Zitao Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 20th International Conference on Artificial Intelligence in
  Education(AIED), 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09922v2</id>
    <updated>2020-02-12T03:41:14Z</updated>
    <published>2019-09-22T01:12:18Z</published>
    <title>Using Chinese Glyphs for Named Entity Recognition</title>
    <summary>  Most Named Entity Recognition (NER) systems use additional features like
part-of-speech (POS) tags, shallow parsing, gazetteers, etc. Such kind of
information requires external knowledge like unlabeled texts and trained
taggers. Adding these features to NER systems have been shown to have a
positive impact. However, sometimes creating gazetteers or taggers can take a
lot of time and may require extensive data cleaning. In this paper for Chinese
NER systems, we do not use these traditional features but we use lexicographic
features of Chinese characters. Chinese characters are composed of graphical
components called radicals and these components often have some semantic
indicators. We propose CNN based models that incorporate this semantic
information and use them for NER. Our models show an improvement over the
baseline BERT-BiLSTM-CRF model. We set a new baseline score for Chinese
OntoNotes v5.0 and show an improvement of +.64 F1 score. We present a
state-of-the-art F1 score on Weibo dataset of 71.81 and show a competitive
improvement of +0.72 over baseline on ResumeNER dataset.
</summary>
    <author>
      <name>Arijit Sehanobish</name>
    </author>
    <author>
      <name>Chan Hee Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended abstract accepted to AAAI-2020, student track</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09922v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09922v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09788v1</id>
    <updated>2019-09-21T07:56:09Z</updated>
    <published>2019-09-21T07:56:09Z</published>
    <title>Visuallly Grounded Generation of Entailments from Premises</title>
    <summary>  Natural Language Inference (NLI) is the task of determining the semantic
relationship between a premise and a hypothesis. In this paper, we focus on the
{\em generation} of hypotheses from premises in a multimodal setting, to
generate a sentence (hypothesis) given an image and/or its description
(premise) as the input. The main goals of this paper are (a) to investigate
whether it is reasonable to frame NLI as a generation task; and (b) to consider
the degree to which grounding textual premises in visual information is
beneficial to generation. We compare different neural architectures, showing
through automatic and human evaluation that entailments can indeed be generated
successfully. We also show that multimodal models outperform unimodal models in
this task, albeit marginally.
</summary>
    <author>
      <name>Somaye Jafaritazehjani</name>
    </author>
    <author>
      <name>Albert Gatt</name>
    </author>
    <author>
      <name>Marc Tanti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th International Conference on Natural Language
  Generation (INLG 2019), 11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09708v1</id>
    <updated>2019-09-20T20:22:15Z</updated>
    <published>2019-09-20T20:22:15Z</published>
    <title>Measuring Conceptual Entanglement in Collections of Documents</title>
    <summary>  Conceptual entanglement is a crucial phenomenon in quantum cognition because
it implies that classical probabilities cannot model non--compositional
conceptual phenomena. While several psychological experiments have been
developed to test conceptual entanglement, this has not been explored in the
context of Natural Language Processing. In this paper, we apply the hypothesis
that words of a document are traces of the concepts that a person has in mind
when writing the document. Therefore, if these concepts are entangled, we
should be able to observe traces of their entanglement in the documents. In
particular, we test conceptual entanglement by contrasting language simulations
with results obtained from a text corpus. Our analysis indicates that
conceptual entanglement is strongly linked to the way in which language is
structured. We discuss the implications of this finding in the context of
conceptual modeling and of Natural Language Processing.
</summary>
    <author>
      <name>Tomas Veloz</name>
    </author>
    <author>
      <name>Xiazhao Zhao</name>
    </author>
    <author>
      <name>Diederik Aerts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, Symposium Quantum Interaction 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In International Symposium on Quantum Interaction (pp. 134-146).
  Springer, Berlin, Heidelberg (2013, July)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.09708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09268v2</id>
    <updated>2019-10-30T19:56:02Z</updated>
    <published>2019-09-20T00:24:59Z</published>
    <title>Towards Neural Language Evaluators</title>
    <summary>  We review three limitations of BLEU and ROUGE -- the most popular metrics
used to assess reference summaries against hypothesis summaries, come up with
criteria for what a good metric should behave like and propose concrete ways to
use recent Transformers-based Language Models to assess reference summaries
against hypothesis summaries.
</summary>
    <author>
      <name>Hassan Kané</name>
    </author>
    <author>
      <name>Yusuf Kocyigit</name>
    </author>
    <author>
      <name>Pelkins Ajanoh</name>
    </author>
    <author>
      <name>Ali Abdalla</name>
    </author>
    <author>
      <name>Mohamed Coulibali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to NeurIPS 2019 Document Intelligence Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09268v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09268v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09220v1</id>
    <updated>2019-09-19T20:12:10Z</updated>
    <published>2019-09-19T20:12:10Z</published>
    <title>Goal-Embedded Dual Hierarchical Model for Task-Oriented Dialogue
  Generation</title>
    <summary>  Hierarchical neural networks are often used to model inherent structures
within dialogues. For goal-oriented dialogues, these models miss a mechanism
adhering to the goals and neglect the distinct conversational patterns between
two interlocutors. In this work, we propose Goal-Embedded Dual Hierarchical
Attentional Encoder-Decoder (G-DuHA) able to center around goals and capture
interlocutor-level disparity while modeling goal-oriented dialogues.
Experiments on dialogue generation, response generation, and human evaluations
demonstrate that the proposed model successfully generates higher-quality, more
diverse and goal-centric dialogues. Moreover, we apply data augmentation via
goal-oriented dialogue generation for task-oriented dialog systems with better
performance achieved.
</summary>
    <author>
      <name>Yi-An Lai</name>
    </author>
    <author>
      <name>Arshit Gupta</name>
    </author>
    <author>
      <name>Yi Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by CoNLL-2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09070v1</id>
    <updated>2019-09-19T16:10:15Z</updated>
    <published>2019-09-19T16:10:15Z</published>
    <title>Look, Read and Enrich. Learning from Scientific Figures and their
  Captions</title>
    <summary>  Compared to natural images, understanding scientific figures is particularly
hard for machines. However, there is a valuable source of information in
scientific literature that until now has remained untapped: the correspondence
between a figure and its caption. In this paper we investigate what can be
learnt by looking at a large number of figures and reading their captions, and
introduce a figure-caption correspondence learning task that makes use of our
observations. Training visual and language networks without supervision other
than pairs of unconstrained figures and captions is shown to successfully solve
this task. We also show that transferring lexical and semantic knowledge from a
knowledge graph significantly enriches the resulting features. Finally, we
demonstrate the positive impact of such features in other tasks involving
scientific text and figures, like multi-modal classification and machine
comprehension for question answering, outperforming supervised baselines and
ad-hoc approaches.
</summary>
    <author>
      <name>Jose Manuel Gomez-Perez</name>
    </author>
    <author>
      <name>Raul Ortega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in the 10th International Conference on Knowledge capture
  (K-CAP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08975v1</id>
    <updated>2019-09-19T13:24:29Z</updated>
    <published>2019-09-19T13:24:29Z</published>
    <title>Analysing Neural Language Models: Contextual Decomposition Reveals
  Default Reasoning in Number and Gender Assignment</title>
    <summary>  Extensive research has recently shown that recurrent neural language models
are able to process a wide range of grammatical phenomena. How these models are
able to perform these remarkable feats so well, however, is still an open
question. To gain more insight into what information LSTMs base their decisions
on, we propose a generalisation of Contextual Decomposition (GCD). In
particular, this setup enables us to accurately distil which part of a
prediction stems from semantic heuristics, which part truly emanates from
syntactic cues and which part arise from the model biases themselves instead.
We investigate this technique on tasks pertaining to syntactic agreement and
co-reference resolution and discover that the model strongly relies on a
default reasoning effect to perform these tasks.
</summary>
    <author>
      <name>Jaap Jumelet</name>
    </author>
    <author>
      <name>Willem Zuidema</name>
    </author>
    <author>
      <name>Dieuwke Hupkes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at CoNLL2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.08975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08927v1</id>
    <updated>2019-09-19T11:54:55Z</updated>
    <published>2019-09-19T11:54:55Z</published>
    <title>Extracting Conceptual Knowledge from Natural Language Text Using Maximum
  Likelihood Principle</title>
    <summary>  Domain-specific knowledge graphs constructed from natural language text are
ubiquitous in today's world. In many such scenarios the base text, from which
the knowledge graph is constructed, concerns itself with practical, on-hand,
actual or ground-reality information about the domain. Product documentation in
software engineering domain are one example of such base texts. Other examples
include blogs and texts related to digital artifacts, reports on emerging
markets and business models, patient medical records, etc. Though the above
sources contain a wealth of knowledge about their respective domains, the
conceptual knowledge on which they are based is often missing or unclear.
Access to this conceptual knowledge can enormously increase the utility of
available data and assist in several tasks such as knowledge graph completion,
grounding, querying, etc.
  Our contributions in this paper are twofold. First, we propose a novel
Markovian stochastic model for document generation from conceptual knowledge.
The uniqueness of our approach lies in the fact that the conceptual knowledge
in the writer's mind forms a component of the parameter set of our stochastic
model. Secondly, we solve the inverse problem of learning the best conceptual
knowledge from a given document, by finding model parameters which maximize the
likelihood of generating the specific document over all possible parameter
values. This likelihood maximization is done using an application of Baum-Welch
algorithm, which is a known special case of Expectation-Maximization (EM)
algorithm. We run our conceptualization algorithm on several well-known natural
language sources and obtain very encouraging results. The results of our
extensive experiments concur with the hypothesis that the information contained
in these sources has a well-defined and rigorous underlying conceptual
structure, which can be discovered using our method.
</summary>
    <author>
      <name>Shipra Sharma</name>
    </author>
    <author>
      <name>Balwinder Sodhi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, Under review in IEEE TKDE</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.08927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08905v1</id>
    <updated>2019-09-19T10:16:21Z</updated>
    <published>2019-09-19T10:16:21Z</published>
    <title>A Split-and-Recombine Approach for Follow-up Query Analysis</title>
    <summary>  Context-dependent semantic parsing has proven to be an important yet
challenging task. To leverage the advances in context-independent semantic
parsing, we propose to perform follow-up query analysis, aiming to restate
context-dependent natural language queries with contextual information. To
accomplish the task, we propose STAR, a novel approach with a well-designed
two-phase process. It is parser-independent and able to handle multifarious
follow-up scenarios in different domains. Experiments on the FollowUp dataset
show that STAR outperforms the state-of-the-art baseline by a large margin of
nearly 8%. The superiority on parsing results verifies the feasibility of
follow-up query analysis. We also explore the extensibility of STAR on the SQA
dataset, which is very promising.
</summary>
    <author>
      <name>Qian Liu</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Haoyan Liu</name>
    </author>
    <author>
      <name>Lei Fang</name>
    </author>
    <author>
      <name>Jian-Guang Lou</name>
    </author>
    <author>
      <name>Bin Zhou</name>
    </author>
    <author>
      <name>Dongmei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.08905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08824v3</id>
    <updated>2019-12-01T07:31:56Z</updated>
    <published>2019-09-19T06:46:02Z</published>
    <title>Modeling Event Background for If-Then Commonsense Reasoning Using
  Context-aware Variational Autoencoder</title>
    <summary>  Understanding event and event-centered commonsense reasoning are crucial for
natural language processing (NLP). Given an observed event, it is trivial for
human to infer its intents and effects, while this type of If-Then reasoning
still remains challenging for NLP systems. To facilitate this, a If-Then
commonsense reasoning dataset Atomic is proposed, together with an RNN-based
Seq2Seq model to conduct such reasoning. However, two fundamental problems
still need to be addressed: first, the intents of an event may be multiple,
while the generations of RNN-based Seq2Seq models are always semantically
close; second, external knowledge of the event background may be necessary for
understanding events and conducting the If-Then reasoning. To address these
issues, we propose a novel context-aware variational autoencoder effectively
learning event background information to guide the If-Then reasoning.
Experimental results show that our approach improves the accuracy and diversity
of inferences compared with state-of-the-art baseline methods.
</summary>
    <author>
      <name>Li Du</name>
    </author>
    <author>
      <name>Xiao Ding</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Zhongyang Li</name>
    </author>
    <link href="http://arxiv.org/abs/1909.08824v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08824v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08663v2</id>
    <updated>2019-10-09T19:30:15Z</updated>
    <published>2019-09-18T19:02:53Z</published>
    <title>Do We Need Neural Models to Explain Human Judgments of Acceptability?</title>
    <summary>  Native speakers can judge whether a sentence is an acceptable instance of
their language. Acceptability provides a means of evaluating whether
computational language models are processing language in a human-like manner.
We test the ability of computational language models, simple language features,
and word embeddings to predict native English speakers judgments of
acceptability on English-language essays written by non-native speakers. We
find that much of the sentence acceptability variance can be captured by a
combination of features including misspellings, word order, and word similarity
(Pearson's r = 0.494). While predictive neural models fit acceptability
judgments well (r = 0.527), we find that a 4-gram model with statistical
smoothing is just as good (r = 0.528). Thanks to incorporating a count of
misspellings, our 4-gram model surpasses both the previous unsupervised
state-of-the art (Lau et al., 2015; r = 0.472), and the average non-expert
native speaker (r = 0.46). Our results demonstrate that acceptability is well
captured by n-gram statistics and simple language features.
</summary>
    <author>
      <name>Wang Jing</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Beijing Normal University</arxiv:affiliation>
    </author>
    <author>
      <name>M. A. Kelly</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Pennsylvania State University</arxiv:affiliation>
    </author>
    <author>
      <name>David Reitter</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Google Research</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages (8 pages + 2 pages of references), 1 figure, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.08663v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08663v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09018v1</id>
    <updated>2019-09-18T10:07:01Z</updated>
    <published>2019-09-18T10:07:01Z</published>
    <title>Corporate IT-support Help-Desk Process Hybrid-Automation Solution with
  Machine Learning Approach</title>
    <summary>  Comprehensive IT support teams in large scale organizations require more man
power for handling engagement and requests of employees from different channels
on a 24*7 basis. Automated email technical queries help desk is proposed to
have instant real-time quick solutions and email categorisation. Email topic
modelling with various machine learning, deep-learning approaches are compared
with different features for a scalable, generalised solution along with
sure-shot static rules. Email's title, body, attachment, OCR text, and some
feature engineered custom features are given as input elements. XGBoost
cascaded hierarchical models, Bi-LSTM model with word embeddings perform well
showing 77.3 overall accuracy For the real world corporate email data set. By
introducing the thresholding techniques, the overall automation system
architecture provides 85.6 percentage of accuracy for real world corporate
emails. Combination of quick fixes, static rules, ML categorization as a low
cost inference solution reduces 81 percentage of the human effort in the
process of automation and real time implementation.
</summary>
    <author>
      <name>Kuruparan Shanmugalingam</name>
    </author>
    <author>
      <name>Nisal Chandrasekara</name>
    </author>
    <author>
      <name>Calvin Hindle</name>
    </author>
    <author>
      <name>Gihan Fernando</name>
    </author>
    <author>
      <name>Chanaka Gunawardhana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 Figures, 2 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Conference on Digital Image Computing:
  Techniques and Applications (DICTA) 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.09018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08250v1</id>
    <updated>2019-09-18T07:09:07Z</updated>
    <published>2019-09-18T07:09:07Z</published>
    <title>Natural Language Generation for Non-Expert Users</title>
    <summary>  Motivated by the difficulty in presenting computational results, especially
when the results are a collection of atoms in a logical language, to users, who
are not proficient in computer programming and/or the logical representation of
the results, we propose a system for automatic generation of natural language
descriptions for applications targeting mainstream users. Differently from many
earlier systems with the same aim, the proposed system does not employ
templates for the generation task. It assumes that there exist some natural
language sentences in the application domain and uses this repository for the
natural language description. It does not require, however, a large corpus as
it is often required in machine learning approaches. The systems consist of two
main components. The first one aims at analyzing the sentences and constructs a
Grammatical Framework (GF) for given sentences and is implemented using the
Stanford parser and an answer set program. The second component is for sentence
construction and relies on GF Library. The paper includes two use cases to
demostrate the capability of the system. As the sentence construction is done
via GF, the paper includes a use case evaluation showing that the proposed
system could also be utilized in addressing a challenge to create an abstract
Wikipedia, which is recently discussed in the BlueSky session of the 2018
International Semantic Web Conference.
</summary>
    <author>
      <name>Van Duc Nguyen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">New Mexico State University</arxiv:affiliation>
    </author>
    <author>
      <name>Tran Cao Son</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">New Mexico State University</arxiv:affiliation>
    </author>
    <author>
      <name>Enrico Pontelli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">New Mexico State University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.306.33</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.306.33" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ICLP 2019, arXiv:1909.07646</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 306, 2019, pp. 280-294</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.08250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.07930v1</id>
    <updated>2019-09-17T16:54:29Z</updated>
    <published>2019-09-17T16:54:29Z</published>
    <title>Ludwig: a type-based declarative deep learning toolbox</title>
    <summary>  In this work we present Ludwig, a flexible, extensible and easy to use
toolbox which allows users to train deep learning models and use them for
obtaining predictions without writing code. Ludwig implements a novel approach
to deep learning model building based on two main abstractions: data types and
declarative configuration files. The data type abstraction allows for easier
code and sub-model reuse, and the standardized interfaces imposed by this
abstraction allow for encapsulation and make the code easy to extend.
Declarative model definition configuration files enable inexperienced users to
obtain effective models and increase the productivity of expert users.
Alongside these two innovations, Ludwig introduces a general modularized deep
learning architecture called Encoder-Combiner-Decoder that can be instantiated
to perform a vast amount of machine learning tasks. These innovations make it
possible for engineers, scientists from other fields and, in general, a much
broader audience to adopt deep learning models for their tasks, concretely
helping in its democratization.
</summary>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Yaroslav Dudin</name>
    </author>
    <author>
      <name>Sai Sumanth Miryala</name>
    </author>
    <link href="http://arxiv.org/abs/1909.07930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09484v1</id>
    <updated>2019-09-17T15:50:56Z</updated>
    <published>2019-09-17T15:50:56Z</published>
    <title>Generative Dialog Policy for Task-oriented Dialog Systems</title>
    <summary>  There is an increasing demand for task-oriented dialogue systems which can
assist users in various activities such as booking tickets and restaurant
reservations. In order to complete dialogues effectively, dialogue policy plays
a key role in task-oriented dialogue systems. As far as we know, the existing
task-oriented dialogue systems obtain the dialogue policy through
classification, which can assign either a dialogue act and its corresponding
parameters or multiple dialogue acts without their corresponding parameters for
a dialogue action. In fact, a good dialogue policy should construct multiple
dialogue acts and their corresponding parameters at the same time. However,
it's hard for existing classification-based methods to achieve this goal. Thus,
to address the issue above, we propose a novel generative dialogue policy
learning method. Specifically, the proposed method uses attention mechanism to
find relevant segments of given dialogue context and input utterance and then
constructs the dialogue policy by a seq2seq way for task-oriented dialogue
systems. Extensive experiments on two benchmark datasets show that the proposed
model significantly outperforms the state-of-the-art baselines. In addition, we
have publicly released our codes.
</summary>
    <author>
      <name>Tian Lan</name>
    </author>
    <author>
      <name>Xianling Mao</name>
    </author>
    <author>
      <name>Heyan Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1909.09484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.07739v1</id>
    <updated>2019-09-17T12:07:22Z</updated>
    <published>2019-09-17T12:07:22Z</published>
    <title>Course Concept Expansion in MOOCs with External Knowledge and
  Interactive Game</title>
    <summary>  As Massive Open Online Courses (MOOCs) become increasingly popular, it is
promising to automatically provide extracurricular knowledge for MOOC users.
Suffering from semantic drifts and lack of knowledge guidance, existing methods
can not effectively expand course concepts in complex MOOC environments. In
this paper, we first build a novel boundary during searching for new concepts
via external knowledge base and then utilize heterogeneous features to verify
the high-quality results. In addition, to involve human efforts in our model,
we design an interactive optimization mechanism based on a game. Our
experiments on the four datasets from Coursera and XuetangX show that the
proposed method achieves significant improvements(+0.19 by MAP) over existing
methods. The source code and datasets have been published.
</summary>
    <author>
      <name>Jifan Yu</name>
    </author>
    <author>
      <name>Chenyu Wang</name>
    </author>
    <author>
      <name>Gan Luo</name>
    </author>
    <author>
      <name>Lei Hou</name>
    </author>
    <author>
      <name>Juanzi Li</name>
    </author>
    <author>
      <name>Jie Tang</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/P19-1421</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/P19-1421" rel="related"/>
    <link href="http://arxiv.org/abs/1909.07739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.07583v1</id>
    <updated>2019-09-17T04:41:12Z</updated>
    <published>2019-09-17T04:41:12Z</published>
    <title>Inverse Visual Question Answering with Multi-Level Attentions</title>
    <summary>  In this paper, we propose a novel deep multi-level attention model to address
inverse visual question answering. The proposed model generates regional visual
and semantic features at the object level and then enhances them with the
answer cue by using attention mechanisms. Two levels of multiple attentions are
employed in the model, including the dual attention at the partial question
encoding step and the dynamic attention at the next question word generation
step. We evaluate the proposed model on the VQA V1 dataset. It demonstrates
state-of-the-art performance in terms of multiple commonly used metrics.
</summary>
    <author>
      <name>Yaser Alwatter</name>
    </author>
    <author>
      <name>Yuhong Guo</name>
    </author>
    <link href="http://arxiv.org/abs/1909.07583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.08191v1</id>
    <updated>2019-09-17T04:32:00Z</updated>
    <published>2019-09-17T04:32:00Z</published>
    <title>Exploring Scholarly Data by Semantic Query on Knowledge Graph Embedding
  Space</title>
    <summary>  The trends of open science have enabled several open scholarly datasets which
include millions of papers and authors. Managing, exploring, and utilizing such
large and complicated datasets effectively are challenging. In recent years,
the knowledge graph has emerged as a universal data format for representing
knowledge about heterogeneous entities and their relationships. The knowledge
graph can be modeled by knowledge graph embedding methods, which represent
entities and relations as embedding vectors in semantic space, then model the
interactions between these embedding vectors. However, the semantic structures
in the knowledge graph embedding space are not well-studied, thus knowledge
graph embedding methods are usually only used for knowledge graph completion
but not data representation and analysis. In this paper, we propose to analyze
these semantic structures based on the well-studied word embedding space and
use them to support data exploration. We also define the semantic queries,
which are algebraic operations between the embedding vectors in the knowledge
graph embedding space, to solve queries such as similarity and analogy between
the entities on the original datasets. We then design a general framework for
data exploration by semantic queries and discuss the solution to some
traditional scholarly data exploration tasks. We also propose some new
interesting tasks that can be solved based on the uncanny semantic structures
of the embedding space.
</summary>
    <author>
      <name>Hung Nghiep Tran</name>
    </author>
    <author>
      <name>Atsuhiro Takasu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TPDL 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Theory and Practice of Digital
  Libraries (TPDL 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.08191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.07063v2</id>
    <updated>2019-09-19T19:40:01Z</updated>
    <published>2019-09-16T08:46:30Z</published>
    <title>Global Autoregressive Models for Data-Efficient Sequence Learning</title>
    <summary>  Standard autoregressive seq2seq models are easily trained by max-likelihood,
but tend to show poor results under small-data conditions. We introduce a class
of seq2seq models, GAMs (Global Autoregressive Models), which combine an
autoregressive component with a log-linear component, allowing the use of
global \textit{a priori} features to compensate for lack of data. We train
these models in two steps. In the first step, we obtain an \emph{unnormalized}
GAM that maximizes the likelihood of the data, but is improper for fast
inference or evaluation. In the second step, we use this GAM to train (by
distillation) a second autoregressive model that approximates the
\emph{normalized} distribution associated with the GAM, and can be used for
fast inference and evaluation. Our experiments focus on language modelling
under synthetic conditions and show a strong perplexity reduction of using the
second autoregressive model over the standard one.
</summary>
    <author>
      <name>Tetiana Parshakova</name>
    </author>
    <author>
      <name>Jean-Marc Andreoli</name>
    </author>
    <author>
      <name>Marc Dymetman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in CONLL (The SIGNLL Conference on Computational Natural
  Language Learning) Hong Kong, Nov. 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.07063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06414v1</id>
    <updated>2019-09-13T19:16:53Z</updated>
    <published>2019-09-13T19:16:53Z</published>
    <title>Learning Household Task Knowledge from WikiHow Descriptions</title>
    <summary>  Commonsense procedural knowledge is important for AI agents and robots that
operate in a human environment. While previous attempts at constructing
procedural knowledge are mostly rule- and template-based, recent advances in
deep learning provide the possibility of acquiring such knowledge directly from
natural language sources. As a first step in this direction, we propose a model
to learn embeddings for tasks, as well as the individual steps that need to be
taken to solve them, based on WikiHow articles. We learn these embeddings such
that they are predictive of both step relevance and step ordering. We also
experiment with the use of integer programming for inferring consistent global
step orderings from noisy pairwise predictions.
</summary>
    <author>
      <name>Yilun Zhou</name>
    </author>
    <author>
      <name>Julie A. Shah</name>
    </author>
    <author>
      <name>Steven Schockaert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCAI 2019 Workshop on Semantic Deep Learning</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06356v1</id>
    <updated>2019-09-13T17:59:03Z</updated>
    <published>2019-09-13T17:59:03Z</published>
    <title>Addressing Semantic Drift in Question Generation for Semi-Supervised
  Question Answering</title>
    <summary>  Text-based Question Generation (QG) aims at generating natural and relevant
questions that can be answered by a given answer in some context. Existing QG
models suffer from a "semantic drift" problem, i.e., the semantics of the
model-generated question drifts away from the given context and answer. In this
paper, we first propose two semantics-enhanced rewards obtained from downstream
question paraphrasing and question answering tasks to regularize the QG model
to generate semantically valid questions. Second, since the traditional
evaluation metrics (e.g., BLEU) often fall short in evaluating the quality of
generated questions, we propose a QA-based evaluation method which measures the
QG model's ability to mimic human annotators in generating QA training data.
Experiments show that our method achieves the new state-of-the-art performance
w.r.t. traditional metrics, and also performs best on our QA-based evaluation
metrics. Further, we investigate how to use our QG model to augment QA datasets
and enable semi-supervised QA. We propose two ways to generate synthetic QA
pairs: generate new questions from existing articles or collect QA pairs from
new articles. We also propose two empirically effective strategies, a data
filter and mixing mini-batch training, to properly use the QG-generated data
for QA. Experiments show that our method improves over both BiDAF and BERT QA
baselines, even without introducing new articles.
</summary>
    <author>
      <name>Shiyue Zhang</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages (EMNLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09696v1</id>
    <updated>2019-09-13T17:56:58Z</updated>
    <published>2019-09-13T17:56:58Z</published>
    <title>A Gated Self-attention Memory Network for Answer Selection</title>
    <summary>  Answer selection is an important research problem, with applications in many
areas. Previous deep learning based approaches for the task mainly adopt the
Compare-Aggregate architecture that performs word-level comparison followed by
aggregation. In this work, we take a departure from the popular
Compare-Aggregate architecture, and instead, propose a new gated self-attention
memory network for the task. Combined with a simple transfer learning technique
from a large-scale online corpus, our model outperforms previous methods by a
large margin, achieving new state-of-the-art results on two standard answer
selection datasets: TrecQA and WikiQA.
</summary>
    <author>
      <name>Tuan Lai</name>
    </author>
    <author>
      <name>Quan Hung Tran</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Daisuke Kihara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 2019 Conference on Empirical Methods in Natural
  Language Processing (EMNLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.09696v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09696v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06283v3</id>
    <updated>2019-11-17T00:36:59Z</updated>
    <published>2019-09-13T15:10:06Z</published>
    <title>Toward Automated Quest Generation in Text-Adventure Games</title>
    <summary>  Interactive fictions, or text-adventures, are games in which a player
interacts with a world entirely through textual descriptions and text actions.
Text-adventure games are typically structured as puzzles or quests wherein the
player must execute certain actions in a certain order to succeed. In this
paper, we consider the problem of procedurally generating a quest, defined as a
series of actions required to progress towards a goal, in a text-adventure
game. Quest generation in text environments is challenging because they must be
semantically coherent. We present and evaluate two quest generation techniques:
(1) a Markov model, and (2) a neural generative model. We specifically look at
generating quests about cooking and train our models on recipe data. We
evaluate our techniques with human participant studies looking at perceived
creativity and coherence.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>William Broniec</name>
    </author>
    <author>
      <name>Alex Mueller</name>
    </author>
    <author>
      <name>Jeremy Paul</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In the CCNLG Workshop in International Conference on Natural Language
  Generation 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06283v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06283v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06273v1</id>
    <updated>2019-09-13T14:54:37Z</updated>
    <published>2019-09-13T14:54:37Z</published>
    <title>Scene Graph Parsing by Attention Graph</title>
    <summary>  Scene graph representations, which form a graph of visual object nodes
together with their attributes and relations, have proved useful across a
variety of vision and language applications. Recent work in the area has used
Natural Language Processing dependency tree methods to automatically build
scene graphs.
  In this work, we present an 'Attention Graph' mechanism that can be trained
end-to-end, and produces a scene graph structure that can be lifted directly
from the top layer of a standard Transformer model.
  The scene graphs generated by our model achieve an F-score similarity of
52.21% to ground-truth graphs on the evaluation set using the SPICE metric,
surpassing the best previous approaches by 2.5%.
</summary>
    <author>
      <name>Martin Andrews</name>
    </author>
    <author>
      <name>Yew Ken Chia</name>
    </author>
    <author>
      <name>Sam Witteveen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper for the ViGIL workshop at NeurIPS 2018. (4 pages +
  references)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06273v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06273v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06200v2</id>
    <updated>2019-09-16T03:56:02Z</updated>
    <published>2019-09-13T13:05:27Z</published>
    <title>A Neural Approach to Irony Generation</title>
    <summary>  Ironies can not only express stronger emotions but also show a sense of
humor. With the development of social media, ironies are widely used in public.
Although many prior research studies have been conducted in irony detection,
few studies focus on irony generation. The main challenges for irony generation
are the lack of large-scale irony dataset and difficulties in modeling the
ironic pattern. In this work, we first systematically define irony generation
based on style transfer task. To address the lack of data, we make use of
twitter and build a large-scale dataset. We also design a combination of
rewards for reinforcement learning to control the generation of ironic
sentences. Experimental results demonstrate the effectiveness of our model in
terms of irony accuracy, sentiment preservation, and content preservation.
</summary>
    <author>
      <name>Mengdi Zhu</name>
    </author>
    <author>
      <name>Zhiwei Yu</name>
    </author>
    <author>
      <name>Xiaojun Wan</name>
    </author>
    <link href="http://arxiv.org/abs/1909.06200v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06200v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06092v2</id>
    <updated>2020-01-03T17:22:06Z</updated>
    <published>2019-09-13T08:57:14Z</published>
    <title>A General Framework for Implicit and Explicit Debiasing of
  Distributional Word Vector Spaces</title>
    <summary>  Distributional word vectors have recently been shown to encode many of the
human biases, most notably gender and racial biases, and models for attenuating
such biases have consequently been proposed. However, existing models and
studies (1) operate on under-specified and mutually differing bias definitions,
(2) are tailored for a particular bias (e.g., gender bias) and (3) have been
evaluated inconsistently and non-rigorously. In this work, we introduce a
general framework for debiasing word embeddings. We operationalize the
definition of a bias by discerning two types of bias specification: explicit
and implicit. We then propose three debiasing models that operate on explicit
or implicit bias specifications and that can be composed towards more robust
debiasing. Finally, we devise a full-fledged evaluation framework in which we
couple existing bias metrics with newly proposed ones. Experimental findings
across three embedding methods suggest that the proposed debiasing models are
robust and widely applicable: they often completely remove the bias both
implicitly and explicitly without degradation of semantic information encoded
in any of the input distributional spaces. Moreover, we successfully transfer
debiasing models, by means of cross-lingual embedding spaces, and remove or
attenuate biases in distributional word vector spaces of languages that lack
readily available bias specifications.
</summary>
    <author>
      <name>Anne Lauscher</name>
    </author>
    <author>
      <name>Goran Glavaš</name>
    </author>
    <author>
      <name>Simone Paolo Ponzetto</name>
    </author>
    <author>
      <name>Ivan Vulić</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06092v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06092v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06044v3</id>
    <updated>2019-09-27T00:43:28Z</updated>
    <published>2019-09-13T05:50:50Z</published>
    <title>Say What I Want: Towards the Dark Side of Neural Dialogue Models</title>
    <summary>  Neural dialogue models have been widely adopted in various chatbot
applications because of their good performance in simulating and generalizing
human conversations. However, there exists a dark side of these models -- due
to the vulnerability of neural networks, a neural dialogue model can be
manipulated by users to say what they want, which brings in concerns about the
security of practical chatbot services. In this work, we investigate whether we
can craft inputs that lead a well-trained black-box neural dialogue model to
generate targeted outputs. We formulate this as a reinforcement learning (RL)
problem and train a Reverse Dialogue Generator which efficiently finds such
inputs for targeted outputs. Experiments conducted on a representative neural
dialogue model show that our proposed model is able to discover such desired
inputs in a considerable portion of cases. Overall, our work reveals this
weakness of neural dialogue models and may prompt further researches of
developing corresponding solutions to avoid it.
</summary>
    <author>
      <name>Haochen Liu</name>
    </author>
    <author>
      <name>Tyler Derr</name>
    </author>
    <author>
      <name>Zitao Liu</name>
    </author>
    <author>
      <name>Jiliang Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06044v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06044v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09700v1</id>
    <updated>2019-09-12T22:35:53Z</updated>
    <published>2019-09-12T22:35:53Z</published>
    <title>Retrofitting Contextualized Word Embeddings with Paraphrases</title>
    <summary>  Contextualized word embedding models, such as ELMo, generate meaningful
representations of words and their context. These models have been shown to
have a great impact on downstream applications. However, in many cases, the
contextualized embedding of a word changes drastically when the context is
paraphrased. As a result, the downstream model is not robust to paraphrasing
and other linguistic variations. To enhance the stability of contextualized
word embedding models, we propose an approach to retrofitting contextualized
embedding models with paraphrase contexts. Our method learns an orthogonal
transformation on the input space, which seeks to minimize the variance of word
representations on paraphrased contexts. Experiments show that the retrofitted
model significantly outperforms the original ELMo on various sentence
classification and language inference tasks.
</summary>
    <author>
      <name>Weijia Shi</name>
    </author>
    <author>
      <name>Muhao Chen</name>
    </author>
    <author>
      <name>Pei Zhou</name>
    </author>
    <author>
      <name>Kai-Wei Chang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-IJCNLP2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.09700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05863v1</id>
    <updated>2019-09-12T18:00:00Z</updated>
    <published>2019-09-12T18:00:00Z</published>
    <title>Finding Generalizable Evidence by Learning to Convince Q&amp;A Models</title>
    <summary>  We propose a system that finds the strongest supporting evidence for a given
answer to a question, using passage-based question-answering (QA) as a testbed.
We train evidence agents to select the passage sentences that most convince a
pretrained QA model of a given answer, if the QA model received those sentences
instead of the full passage. Rather than finding evidence that convinces one
model alone, we find that agents select evidence that generalizes; agent-chosen
evidence increases the plausibility of the supported answer, as judged by other
QA models and humans. Given its general nature, this approach improves QA in a
robust manner: using agent-selected evidence (i) humans can correctly answer
questions with only ~20% of the full passage and (ii) QA models can generalize
to longer passages and harder questions.
</summary>
    <author>
      <name>Ethan Perez</name>
    </author>
    <author>
      <name>Siddharth Karamcheti</name>
    </author>
    <author>
      <name>Rob Fergus</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019. Code available at https://github.com/ethanjperez/convince</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09704v2</id>
    <updated>2019-09-24T09:23:45Z</updated>
    <published>2019-09-12T17:25:24Z</published>
    <title>Measuring Domain Portability and ErrorPropagation in Biomedical QA</title>
    <summary>  In this work we present Google's submission to the BioASQ 7 biomedical
question answering (QA) task (specifically Task 7b, Phase B). The core of our
systems are based on BERT QA models, specifically the model of
\cite{alberti2019bert}. In this report, and via our submissions, we aimed to
investigate two research questions. We start by studying how domain portable
are QA systems that have been pre-trained and fine-tuned on general texts,
e.g., Wikipedia. We measure this via two submissions. The first is a
non-adapted model that uses a public pre-trained BERT model and is fine-tuned
on the Natural Questions data set \cite{kwiatkowski2019natural}. The second
system takes this non-adapted model and fine-tunes it with the BioASQ training
data. Next, we study the impact of error propagation in end-to-end retrieval
and QA systems. Again we test this via two submissions. The first uses human
annotated relevant documents and snippets as input to the model and the second
predicted documents and snippets. Our main findings are that domain specific
fine-tuning can benefit Biomedical QA. However, the biggest quality bottleneck
is at the retrieval stage, where we see large drops in metrics -- over 10pts
absolute -- when using non gold inputs to the QA model.
</summary>
    <author>
      <name>Stefan Hosein</name>
    </author>
    <author>
      <name>Daniel Andor</name>
    </author>
    <author>
      <name>Ryan McDonald</name>
    </author>
    <link href="http://arxiv.org/abs/1909.09704v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09704v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05803v2</id>
    <updated>2019-10-30T21:11:19Z</updated>
    <published>2019-09-12T17:00:45Z</published>
    <title>Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning</title>
    <summary>  Multi-hop QA requires a model to connect multiple pieces of evidence
scattered in a long context to answer the question. The recently proposed
HotpotQA (Yang et al., 2018) dataset is comprised of questions embodying four
different multi-hop reasoning paradigms (two bridge entity setups, checking
multiple properties, and comparing two entities), making it challenging for a
single neural network to handle all four. In this work, we present an
interpretable, controller-based Self-Assembling Neural Modular Network (Hu et
al., 2017, 2018) for multi-hop reasoning, where we design four novel modules
(Find, Relocate, Compare, NoOp) to perform unique types of language reasoning.
Based on a question, our layout controller RNN dynamically infers a series of
reasoning modules to construct the entire network. Empirically, we show that
our dynamic, multi-hop modular network achieves significant improvements over
the static, single-hop baseline (on both regular and adversarial evaluation).
We further demonstrate the interpretability of our model via three analyses.
First, the controller can softly decompose the multi-hop question into multiple
single-hop sub-questions to promote compositional reasoning behavior of the
main network. Second, the controller can predict layouts that conform to the
layouts designed by human experts. Finally, the intermediate module can infer
the entity that connects two distantly-located supporting facts by addressing
the sub-question from the controller.
</summary>
    <author>
      <name>Yichen Jiang</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages (EMNLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05803v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05803v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05780v2</id>
    <updated>2020-01-08T17:50:10Z</updated>
    <published>2019-09-12T16:29:24Z</published>
    <title>Fine-Grained Entity Typing for Domain Independent Entity Linking</title>
    <summary>  Neural entity linking models are very powerful, but run the risk of
overfitting to the domain they are trained in. For this problem, a domain is
characterized not just by genre of text but even by factors as specific as the
particular distribution of entities, as neural models tend to overfit by
memorizing properties of frequent entities in a dataset. We tackle the problem
of building robust entity linking models that generalize effectively and do not
rely on labeled entity linking data with a specific entity distribution. Rather
than predicting entities directly, our approach models fine-grained entity
properties, which can help disambiguate between even closely related entities.
We derive a large inventory of types (tens of thousands) from Wikipedia
categories, and use hyperlinked mentions in Wikipedia to distantly label data
and train an entity typing model. At test time, we classify a mention with this
typing model and use soft type predictions to link the mention to the most
similar candidate entity. We evaluate our entity linking system on the
CoNLL-YAGO dataset (Hoffart et al., 2011) and show that our approach
outperforms prior domain-independent entity linking systems. We also test our
approach in a harder setting derived from the WikilinksNED dataset (Eshel et
al., 2017) where all the mention-entity pairs are unseen during test time.
Results indicate that our approach generalizes better than a state-of-the-art
neural model on the dataset.
</summary>
    <author>
      <name>Yasumasa Onoe</name>
    </author>
    <author>
      <name>Greg Durrett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05780v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05780v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.09690v2</id>
    <updated>2019-09-24T06:20:11Z</updated>
    <published>2019-09-12T16:29:14Z</published>
    <title>A Deep Learning-Based Approach for Measuring the Domain Similarity of
  Persian Texts</title>
    <summary>  In this paper, we propose a novel approach for measuring the degree of
similarity between categories of two pieces of Persian text, which were
published as descriptions of two separate advertisements. We built an
appropriate dataset for this work using a dataset which consists of
advertisements posted on an e-commerce website. We generated a significant
number of paired texts from this dataset and assigned each pair a score from 0
to 3, which demonstrates the degree of similarity between the domains of the
pair. In this work, we represent words with word embedding vectors derived from
word2vec. Then deep neural network models are used to represent texts.
Eventually, we employ concatenation of absolute difference and bit-wise
multiplication and a fully-connected neural network to produce a probability
distribution vector for the score of the pairs. Through a supervised learning
approach, we trained our model on a GPU, and our best model achieved an F1
score of 0.9865.
</summary>
    <author>
      <name>Hossein Keshavarz</name>
    </author>
    <author>
      <name>Shohreh Tabatabayi Seifi</name>
    </author>
    <author>
      <name>Mohammad Izadi</name>
    </author>
    <link href="http://arxiv.org/abs/1909.09690v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.09690v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05608v1</id>
    <updated>2019-09-12T12:50:34Z</updated>
    <published>2019-09-12T12:50:34Z</published>
    <title>ABSApp: A Portable Weakly-Supervised Aspect-Based Sentiment Extraction
  System</title>
    <summary>  We present ABSApp, a portable system for weakly-supervised aspect-based
sentiment extraction. The system is interpretable and user friendly and does
not require labeled training data, hence can be rapidly and cost-effectively
used across different domains in applied setups. The system flow includes three
stages: First, it generates domain-specific aspect and opinion lexicons based
on an unlabeled dataset; second, it enables the user to view and edit those
lexicons (weak supervision); and finally, it enables the user to select an
unlabeled target dataset from the same domain, classify it, and generate an
aspect-based sentiment report. ABSApp has been successfully used in a number of
real-life use cases, among them movie review analysis and convention impact
analysis.
</summary>
    <author>
      <name>Oren Pereg</name>
    </author>
    <author>
      <name>Daniel Korat</name>
    </author>
    <author>
      <name>Moshe Wasserblat</name>
    </author>
    <author>
      <name>Jonathan Mamou</name>
    </author>
    <author>
      <name>Ido Dagan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, demo paper at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05528v1</id>
    <updated>2019-09-12T09:27:37Z</updated>
    <published>2019-09-12T09:27:37Z</published>
    <title>MOSS: End-to-End Dialog System Framework with Modular Supervision</title>
    <summary>  A major bottleneck in training end-to-end task-oriented dialog system is the
lack of data. To utilize limited training data more efficiently, we propose
Modular Supervision Network (MOSS), an encoder-decoder training framework that
could incorporate supervision from various intermediate dialog system modules
including natural language understanding, dialog state tracking, dialog policy
learning, and natural language generation. With only 60% of the training data,
MOSS-all (i.e., MOSS with supervision from all four dialog modules) outperforms
state-of-the-art models on CamRest676. Moreover, introducing modular
supervision has even bigger benefits when the dialog task has a more complex
dialog state and action space. With only 40% of the training data, MOSS-all
outperforms the state-of-the-art model on a complex laptop network
troubleshooting dataset, LaptopNetwork, that we introduced. LaptopNetwork
consists of conversations between real customers and customer service agents in
Chinese. Moreover, MOSS framework can accommodate dialogs that have supervision
from different dialog modules at both the framework level and model level.
Therefore, MOSS is extremely flexible to update in a real-world deployment.
</summary>
    <author>
      <name>Weixin Liang</name>
    </author>
    <author>
      <name>Youzhi Tian</name>
    </author>
    <author>
      <name>Chengcai Chen</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1909.05528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05398v3</id>
    <updated>2020-02-25T19:36:33Z</updated>
    <published>2019-09-11T22:41:00Z</published>
    <title>Interactive Fiction Games: A Colossal Adventure</title>
    <summary>  A hallmark of human intelligence is the ability to understand and communicate
with language. Interactive Fiction games are fully text-based simulation
environments where a player issues text commands to effect change in the
environment and progress through the story. We argue that IF games are an
excellent testbed for studying language-based autonomous agents. In particular,
IF games combine challenges of combinatorial action spaces, language
understanding, and commonsense reasoning. To facilitate rapid development of
language-based agents, we introduce Jericho, a learning environment for
man-made IF games and conduct a comprehensive study of text-agents across a
rich set of games, highlighting directions in which agents can improve.
</summary>
    <author>
      <name>Matthew Hausknecht</name>
    </author>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Marc-Alexandre Côté</name>
    </author>
    <author>
      <name>Xingdi Yuan</name>
    </author>
    <link href="http://arxiv.org/abs/1909.05398v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05398v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05378v1</id>
    <updated>2019-09-11T21:15:47Z</updated>
    <published>2019-09-11T21:15:47Z</published>
    <title>CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain
  Natural Language Interfaces to Databases</title>
    <summary>  We present CoSQL, a corpus for building cross-domain, general-purpose
database (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+
annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k
dialogues querying 200 complex DBs spanning 138 domains. Each dialogue
simulates a real-world DB query scenario with a crowd worker as a user
exploring the DB and a SQL expert retrieving answers with SQL, clarifying
ambiguous questions, or otherwise informing of unanswerable questions. When
user questions are answerable by SQL, the expert describes the SQL and
execution results to the user, hence maintaining a natural interaction flow.
CoSQL introduces new challenges compared to existing task-oriented dialogue
datasets:(1) the dialogue states are grounded in SQL, a domain-independent
executable representation, instead of domain-specific slot-value pairs, and (2)
because testing is done on unseen databases, success requires generalizing to
new domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking,
response generation from query results, and user dialogue act prediction. We
evaluate a set of strong baselines for each task and show that CoSQL presents
significant challenges for future research. The dataset, baselines, and
leaderboard will be released at https://yale-lily.github.io/cosql.
</summary>
    <author>
      <name>Tao Yu</name>
    </author>
    <author>
      <name>Rui Zhang</name>
    </author>
    <author>
      <name>He Yang Er</name>
    </author>
    <author>
      <name>Suyi Li</name>
    </author>
    <author>
      <name>Eric Xue</name>
    </author>
    <author>
      <name>Bo Pang</name>
    </author>
    <author>
      <name>Xi Victoria Lin</name>
    </author>
    <author>
      <name>Yi Chern Tan</name>
    </author>
    <author>
      <name>Tianze Shi</name>
    </author>
    <author>
      <name>Zihan Li</name>
    </author>
    <author>
      <name>Youxuan Jiang</name>
    </author>
    <author>
      <name>Michihiro Yasunaga</name>
    </author>
    <author>
      <name>Sungrok Shim</name>
    </author>
    <author>
      <name>Tao Chen</name>
    </author>
    <author>
      <name>Alexander Fabbri</name>
    </author>
    <author>
      <name>Zifan Li</name>
    </author>
    <author>
      <name>Luyao Chen</name>
    </author>
    <author>
      <name>Yuwen Zhang</name>
    </author>
    <author>
      <name>Shreya Dixit</name>
    </author>
    <author>
      <name>Vincent Zhang</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Walter S Lasecki</name>
    </author>
    <author>
      <name>Dragomir Radev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019, long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04849v1</id>
    <updated>2019-09-11T04:47:36Z</updated>
    <published>2019-09-11T04:47:36Z</published>
    <title>A Discrete Hard EM Approach for Weakly Supervised Question Answering</title>
    <summary>  Many question answering (QA) tasks only provide weak supervision for how the
answer should be computed. For example, TriviaQA answers are entities that can
be mentioned multiple times in supporting documents, while DROP answers can be
computed by deriving many different equations from numbers in the reference
text. In this paper, we show it is possible to convert such tasks into discrete
latent variable learning problems with a precomputed, task-specific set of
possible "solutions" (e.g. different mentions or equations) that contains one
correct option. We then develop a hard EM learning scheme that computes
gradients relative to the most likely solution at each update. Despite its
simplicity, we show that this approach significantly outperforms previous
methods on six QA tasks, including absolute gains of 2--10%, and achieves the
state-of-the-art on five of them. Using hard updates instead of maximizing
marginal likelihood is key to these results as it encourages the model to find
the one correct answer, which we show through detailed qualitative analysis.
</summary>
    <author>
      <name>Sewon Min</name>
    </author>
    <author>
      <name>Danqi Chen</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at EMNLP 2019 (long). Code available
  at https://github.com/shmsw25/qa-hard-em</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04745v2</id>
    <updated>2019-09-18T23:55:04Z</updated>
    <published>2019-09-10T20:46:56Z</published>
    <title>Everything Happens for a Reason: Discovering the Purpose of Actions in
  Procedural Text</title>
    <summary>  Our goal is to better comprehend procedural text, e.g., a paragraph about
photosynthesis, by not only predicting what happens, but why some actions need
to happen before others. Our approach builds on a prior process comprehension
framework for predicting actions' effects, to also identify subsequent steps
that those effects enable. We present our new model (XPAD) that biases effect
predictions towards those that (1) explain more of the actions in the paragraph
and (2) are more plausible with respect to background knowledge. We also extend
an existing benchmark dataset for procedural text comprehension, ProPara, by
adding the new task of explaining actions by predicting their dependencies. We
find that XPAD significantly outperforms prior systems on this task, while
maintaining the performance on the original task in ProPara. The dataset is
available at http://data.allenai.org/propara
</summary>
    <author>
      <name>Bhavana Dalvi Mishra</name>
    </author>
    <author>
      <name>Niket Tandon</name>
    </author>
    <author>
      <name>Antoine Bosselut</name>
    </author>
    <author>
      <name>Wen-tau Yih</name>
    </author>
    <author>
      <name>Peter Clark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019 as a long paper. This revision fixed a typo in
  an author name in references</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04745v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04745v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04739v1</id>
    <updated>2019-09-10T20:37:39Z</updated>
    <published>2019-09-10T20:37:39Z</published>
    <title>WIQA: A dataset for "What if..." reasoning over procedural text</title>
    <summary>  We introduce WIQA, the first large-scale dataset of "What if..." questions
over procedural text. WIQA contains three parts: a collection of paragraphs
each describing a process, e.g., beach erosion; a set of crowdsourced influence
graphs for each paragraph, describing how one change affects another; and a
large (40k) collection of "What if...?" multiple-choice questions derived from
the graphs. For example, given a paragraph about beach erosion, would stormy
weather result in more or less erosion (or have no effect)? The task is to
answer the questions, given their associated paragraph. WIQA contains three
kinds of questions: perturbations to steps mentioned in the paragraph; external
(out-of-paragraph) perturbations requiring commonsense knowledge; and
irrelevant (no effect) perturbations. We find that state-of-the-art models
achieve 73.8% accuracy, well below the human performance of 96.3%. We analyze
the challenges, in particular tracking chains of influences, and present the
dataset as an open challenge to the community.
</summary>
    <author>
      <name>Niket Tandon</name>
    </author>
    <author>
      <name>Bhavana Dalvi Mishra</name>
    </author>
    <author>
      <name>Keisuke Sakaguchi</name>
    </author>
    <author>
      <name>Antoine Bosselut</name>
    </author>
    <author>
      <name>Peter Clark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04625v1</id>
    <updated>2019-09-10T17:02:15Z</updated>
    <published>2019-09-10T17:02:15Z</published>
    <title>Representation of Constituents in Neural Language Models: Coordination
  Phrase as a Case Study</title>
    <summary>  Neural language models have achieved state-of-the-art performances on many
NLP tasks, and recently have been shown to learn a number of
hierarchically-sensitive syntactic dependencies between individual words.
However, equally important for language processing is the ability to combine
words into phrasal constituents, and use constituent-level features to drive
downstream expectations. Here we investigate neural models' ability to
represent constituent-level features, using coordinated noun phrases as a case
study. We assess whether different neural language models trained on English
and French represent phrase-level number and gender features, and use those
features to drive downstream expectations. Our results suggest that models use
a linear combination of NP constituent number to drive CoordNP/verb number
agreement. This behavior is highly regular and even sensitive to local
syntactic context, however it differs crucially from observed human behavior.
Models have less success with gender agreement. Models trained on large corpora
perform best, and there is no obvious advantage for models trained using
explicit syntactic supervision.
</summary>
    <author>
      <name>Aixiu An</name>
    </author>
    <author>
      <name>Peng Qian</name>
    </author>
    <author>
      <name>Ethan Wilcox</name>
    </author>
    <author>
      <name>Roger Levy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04455v1</id>
    <updated>2019-09-10T13:01:27Z</updated>
    <published>2019-09-10T13:01:27Z</published>
    <title>Learning review representations from user and product level information
  for spam detection</title>
    <summary>  Opinion spam has become a widespread problem in social media, where hired
spammers write deceptive reviews to promote or demote products to mislead the
consumers for profit or fame. Existing works mainly focus on manually designing
discrete textual or behavior features, which cannot capture complex semantics
of reviews. Although recent works apply deep learning methods to learn
review-level semantic features, their models ignore the impact of the
user-level and product-level information on learning review semantics and the
inherent user-review-product relationship information. In this paper, we
propose a Hierarchical Fusion Attention Network (HFAN) to automatically learn
the semantics of reviews from the user and product level. Specifically, we
design a multi-attention unit to extract user(product)-related review
information. Then, we use orthogonal decomposition and fusion attention to
learn a user, review, and product representation from the review information.
Finally, we take the review as a relation between user and product entity and
apply TransH to jointly encode this relationship into review representation.
Experimental results obtained more than 10\% absolute precision improvement
over the state-of-the-art performances on four real-world datasets, which show
the effectiveness and versatility of the model.
</summary>
    <author>
      <name>Chunyuan Yuan</name>
    </author>
    <author>
      <name>Wei Zhou</name>
    </author>
    <author>
      <name>Qianwen Ma</name>
    </author>
    <author>
      <name>Shangwen Lv</name>
    </author>
    <author>
      <name>Jizhong Han</name>
    </author>
    <author>
      <name>Songlin Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. Accepted as IEEE ICDM 2019, Short Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04386v1</id>
    <updated>2019-09-10T10:12:01Z</updated>
    <published>2019-09-10T10:12:01Z</published>
    <title>Attesting Biases and Discrimination using Language Semantics</title>
    <summary>  AI agents are increasingly deployed and used to make automated decisions that
affect our lives on a daily basis. It is imperative to ensure that these
systems embed ethical principles and respect human values. We focus on how we
can attest to whether AI agents treat users fairly without discriminating
against particular individuals or groups through biases in language. In
particular, we discuss human unconscious biases, how they are embedded in
language, and how AI systems inherit those biases by learning from and
processing human language. Then, we outline a roadmap for future research to
better understand and attest problematic AI biases derived from language.
</summary>
    <author>
      <name>Xavier Ferrer Aran</name>
    </author>
    <author>
      <name>Jose M. Such</name>
    </author>
    <author>
      <name>Natalia Criado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Author's copy of the manuscript accepted in the Responsible
  Artificial Intelligence Agents workshop of the International Conference on
  Autonomous Agents and Multiagent Systems (AAMAS'19)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04303v2</id>
    <updated>2019-09-12T07:02:03Z</updated>
    <published>2019-09-10T05:51:12Z</published>
    <title>Core Semantic First: A Top-down Approach for AMR Parsing</title>
    <summary>  We introduce a novel scheme for parsing a piece of text into its Abstract
Meaning Representation (AMR): Graph Spanning based Parsing (GSP). One novel
characteristic of GSP is that it constructs a parse graph incrementally in a
top-down fashion. Starting from the root, at each step, a new node and its
connections to existing nodes will be jointly predicted. The output graph spans
the nodes by the distance to the root, following the intuition of first
grasping the main ideas then digging into more details. The \textit{core
semantic first} principle emphasizes capturing the main ideas of a sentence,
which is of great interest. We evaluate our model on the latest AMR sembank and
achieve the state-of-the-art performance in the sense that no heuristic graph
re-categorization is adopted. More importantly, the experiments show that our
parser is especially good at obtaining the core semantics.
</summary>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Wai Lam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04303v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04303v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04251v1</id>
    <updated>2019-09-10T03:00:58Z</updated>
    <published>2019-09-10T03:00:58Z</published>
    <title>A Benchmark Dataset for Learning to Intervene in Online Hate Speech</title>
    <summary>  Countering online hate speech is a critical yet challenging task, but one
which can be aided by the use of Natural Language Processing (NLP) techniques.
Previous research has primarily focused on the development of NLP methods to
automatically and effectively detect online hate speech while disregarding
further action needed to calm and discourage individuals from using hate speech
in the future. In addition, most existing hate speech datasets treat each post
as an isolated instance, ignoring the conversational context. In this paper, we
propose a novel task of generative hate speech intervention, where the goal is
to automatically generate responses to intervene during online conversations
that contain hate speech. As a part of this work, we introduce two
fully-labeled large-scale hate speech intervention datasets collected from Gab
and Reddit. These datasets provide conversation segments, hate speech labels,
as well as intervention responses written by Mechanical Turk Workers. In this
paper, we also analyze the datasets to understand the common intervention
strategies and explore the performance of common automatic response generation
methods on these new datasets to provide a benchmark for future research.
</summary>
    <author>
      <name>Jing Qian</name>
    </author>
    <author>
      <name>Anna Bethke</name>
    </author>
    <author>
      <name>Yinyin Liu</name>
    </author>
    <author>
      <name>Elizabeth Belding</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1909.04251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05017v2</id>
    <updated>2019-09-14T20:02:20Z</updated>
    <published>2019-09-09T19:48:53Z</published>
    <title>Question Generation by Transformers</title>
    <summary>  A machine learning model was developed to automatically generate questions
from Wikipedia passages using transformers, an attention-based model eschewing
the paradigm of existing recurrent neural networks (RNNs). The model was
trained on the inverted Stanford Question Answering Dataset (SQuAD), which is a
reading comprehension dataset consisting of 100,000+ questions posed by
crowdworkers on a set of Wikipedia articles. After training, the question
generation model is able to generate simple questions relevant to unseen
passages and answers containing an average of 8 words per question. The word
error rate (WER) was used as a metric to compare the similarity between SQuAD
questions and the model-generated questions. Although the high average WER
suggests that the questions generated differ from the original SQuAD questions,
the questions generated are mostly grammatically correct and plausible in their
own right.
</summary>
    <author>
      <name>Kettip Kriangchaivech</name>
    </author>
    <author>
      <name>Artit Wangperawong</name>
    </author>
    <link href="http://arxiv.org/abs/1909.05017v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05017v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04120v1</id>
    <updated>2019-09-09T19:32:31Z</updated>
    <published>2019-09-09T19:32:31Z</published>
    <title>Span Selection Pre-training for Question Answering</title>
    <summary>  BERT (Bidirectional Encoder Representations from Transformers) and related
pre-trained Transformers have provided large gains across many language
understanding tasks, achieving a new state-of-the-art (SOTA). BERT is
pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence
Prediction. In this paper we introduce a new pre-training task inspired by
reading comprehension and an effort to avoid encoding general knowledge in the
transformer network itself. We find significant and consistent improvements
over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and
paraphrasing datasets. Specifically, our proposed model has strong empirical
evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC
dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We
also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1
points and supporting fact prediction by 1 F1 point. Moreover, we show that our
pre-training approach is particularly effective when training data is limited,
improving the learning curve by a large amount.
</summary>
    <author>
      <name>Michael Glass</name>
    </author>
    <author>
      <name>Alfio Gliozzo</name>
    </author>
    <author>
      <name>Rishav Chakravarti</name>
    </author>
    <author>
      <name>Anthony Ferritto</name>
    </author>
    <author>
      <name>Lin Pan</name>
    </author>
    <author>
      <name>G P Shrivatsa Bhargav</name>
    </author>
    <author>
      <name>Dinesh Garg</name>
    </author>
    <author>
      <name>Avirup Sil</name>
    </author>
    <link href="http://arxiv.org/abs/1909.04120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04076v2</id>
    <updated>2019-09-12T06:19:50Z</updated>
    <published>2019-09-09T18:08:35Z</published>
    <title>Counterfactual Story Reasoning and Generation</title>
    <summary>  Counterfactual reasoning requires predicting how alternative events, contrary
to what actually happened, might have resulted in different outcomes. Despite
being considered a necessary component of AI-complete systems, few resources
have been developed for evaluating counterfactual reasoning in narratives.
  In this paper, we propose Counterfactual Story Rewriting: given an original
story and an intervening counterfactual event, the task is to minimally revise
the story to make it compatible with the given counterfactual event. Solving
this task will require deep understanding of causal narrative chains and
counterfactual invariance, and integration of such story reasoning capabilities
into conditional language generation models.
  We present TimeTravel, a new dataset of 29,849 counterfactual rewritings,
each with the original story, a counterfactual event, and human-generated
revision of the original story compatible with the counterfactual event.
Additionally, we include 80,115 counterfactual "branches" without a rewritten
storyline to support future work on semi- or un-supervised approaches to
counterfactual story rewriting.
  Finally, we evaluate the counterfactual rewriting capacities of several
competitive baselines based on pretrained language models, and assess whether
common overlap and model-based automatic metrics for text generation correlate
well with human scores for counterfactual rewriting.
</summary>
    <author>
      <name>Lianhui Qin</name>
    </author>
    <author>
      <name>Antoine Bosselut</name>
    </author>
    <author>
      <name>Ari Holtzman</name>
    </author>
    <author>
      <name>Chandra Bhagavatula</name>
    </author>
    <author>
      <name>Elizabeth Clark</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04076v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04076v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03922v1</id>
    <updated>2019-09-09T15:19:56Z</updated>
    <published>2019-09-09T15:19:56Z</published>
    <title>Recommendation as a Communication Game: Self-Supervised Bot-Play for
  Goal-oriented Dialogue</title>
    <summary>  Traditional recommendation systems produce static rather than interactive
recommendations invariant to a user's specific requests, clarifications, or
current mood, and can suffer from the cold-start problem if their tastes are
unknown. These issues can be alleviated by treating recommendation as an
interactive dialogue task instead, where an expert recommender can sequentially
ask about someone's preferences, react to their requests, and recommend more
appropriate items. In this work, we collect a goal-driven recommendation
dialogue dataset (GoRecDial), which consists of 9,125 dialogue games and 81,260
conversation turns between pairs of human workers recommending movies to each
other. The task is specifically designed as a cooperative game between two
players working towards a quantifiable common goal. We leverage the dataset to
develop an end-to-end dialogue system that can simultaneously converse and
recommend. Models are first trained to imitate the behavior of human players
without considering the task goal itself (supervised training). We then
finetune our models on simulated bot-bot conversations between two paired
pre-trained models (bot-play), in order to achieve the dialogue goal. Our
experiments show that models finetuned with bot-play learn improved dialogue
strategies, reach the dialogue goal more often when paired with a human, and
are rated as more consistent by humans compared to models trained without
bot-play. The dataset and code are publicly available through the ParlAI
framework.
</summary>
    <author>
      <name>Dongyeop Kang</name>
    </author>
    <author>
      <name>Anusha Balakrishnan</name>
    </author>
    <author>
      <name>Pararth Shah</name>
    </author>
    <author>
      <name>Paul Crook</name>
    </author>
    <author>
      <name>Y-Lan Boureau</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03881v1</id>
    <updated>2019-09-09T14:20:05Z</updated>
    <published>2019-09-09T14:20:05Z</published>
    <title>Nearly-Unsupervised Hashcode Representations for Relation Extraction</title>
    <summary>  Recently, kernelized locality sensitive hashcodes have been successfully
employed as representations of natural language text, especially showing high
relevance to biomedical relation extraction tasks. In this paper, we propose to
optimize the hashcode representations in a nearly unsupervised manner, in which
we only use data points, but not their class labels, for learning. The
optimized hashcode representations are then fed to a supervised classifier
following the prior work. This nearly unsupervised approach allows fine-grained
optimization of each hash function, which is particularly suitable for building
hashcode representations generalizing from a training set to a test set. We
empirically evaluate the proposed approach for biomedical relation extraction
tasks, obtaining significant accuracy improvements w.r.t. state-of-the-art
supervised and semi-supervised approaches.
</summary>
    <author>
      <name>Sahil Garg</name>
    </author>
    <author>
      <name>Aram Galstyan</name>
    </author>
    <author>
      <name>Greg Ver Steeg</name>
    </author>
    <author>
      <name>Guillermo Cecchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EMNLP-19</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03862v2</id>
    <updated>2019-10-30T02:50:03Z</updated>
    <published>2019-09-09T13:49:10Z</published>
    <title>Out-of-domain Detection for Natural Language Understanding in Dialog
  Systems</title>
    <summary>  Natural Language Understanding (NLU) is a vital component of dialogue
systems, and its ability to detect Out-of-Domain (OOD) inputs is critical in
practical applications, since the acceptance of the OOD input that is
unsupported by the current system may lead to catastrophic failure. However,
most existing OOD detection methods rely heavily on manually labeled OOD
samples and cannot take full advantage of unlabeled data. This limits the
feasibility of these models in practical applications.
  In this paper, we propose a novel model to generate high-quality pseudo OOD
samples that are akin to IN-Domain (IND) input utterances, and thereby improves
the performance of OOD detection. To this end, an autoencoder is trained to map
an input utterance into a latent code. and the codes of IND and OOD samples are
trained to be indistinguishable by utilizing a generative adversarial network.
To provide more supervision signals, an auxiliary classifier is introduced to
regularize the generated OOD samples to have indistinguishable intent labels.
Experiments show that these pseudo OOD samples generated by our model can be
used to effectively improve OOD detection in NLU. Besides, we also demonstrate
that the effectiveness of these pseudo OOD data can be further improved by
efficiently utilizing unlabeled data.
</summary>
    <author>
      <name>Yinhe Zheng</name>
    </author>
    <author>
      <name>Guanyi Chen</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03862v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03862v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03821v2</id>
    <updated>2019-09-10T10:00:41Z</updated>
    <published>2019-09-09T12:58:16Z</published>
    <title>Combination of Unified Embedding Model and Observed Features for
  Knowledge Graph Completion</title>
    <summary>  Knowledge graphs are useful for many artificial intelligence tasks but often
have missing data. Hence, a method for completing knowledge graphs is required.
Existing approaches include embedding models, the Path Ranking Algorithm, and
rule evaluation models. However, these approaches have limitations. For
example, all the information is mixed and difficult to interpret in embedding
models, and traditional rule evaluation models are basically slow. In this
paper, we provide an integrated view of various approaches and combine them to
compensate for their limitations. We first unify state-of-the-art embedding
models, such as ComplEx and TorusE, reinterpreting them as a variant of
translation-based models. Then, we show that these models utilize paths for
link prediction and propose a method for evaluating rules based on this idea.
Finally, we combine an embedding model and observed feature models to predict
missing triples. This is possible because all of these models utilize paths. We
also conduct experiments, including link prediction tasks, with standard
datasets to evaluate our method and framework. The experiments show that our
method can evaluate rules faster than traditional methods and that our
framework outperforms state-of-the-art models in terms of link prediction.
</summary>
    <author>
      <name>Takuma Ebisu</name>
    </author>
    <author>
      <name>Ryutaro Ichise</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">under review</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03821v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03821v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03794v1</id>
    <updated>2019-09-09T12:22:28Z</updated>
    <published>2019-09-09T12:22:28Z</published>
    <title>Composing Knowledge Graph Embeddings via Word Embeddings</title>
    <summary>  Learning knowledge graph embedding from an existing knowledge graph is very
important to knowledge graph completion. For a fact $(h,r,t)$ with the head
entity $h$ having a relation $r$ with the tail entity $t$, the current
approaches aim to learn low dimensional representations
$(\mathbf{h},\mathbf{r},\mathbf{t})$, each of which corresponds to the elements
in $(h, r, t)$, respectively. As $(\mathbf{h},\mathbf{r},\mathbf{t})$ is
learned from the existing facts within a knowledge graph, these representations
can not be used to detect unknown facts (if the entities or relations never
occur in the knowledge graph).
  This paper proposes a new approach called TransW, aiming to go beyond the
current work by composing knowledge graph embeddings using word embeddings.
Given the fact that an entity or a relation contains one or more words (quite
often), it is sensible to learn a mapping function from word embedding spaces
to knowledge embedding spaces, which shows how entities are constructed using
human words. More importantly, composing knowledge embeddings using word
embeddings makes it possible to deal with the emerging new facts (either new
entities or relations). Experimental results using three public datasets show
the consistency and outperformance of the proposed TransW.
</summary>
    <author>
      <name>Lianbo Ma</name>
    </author>
    <author>
      <name>Peng Sun</name>
    </author>
    <author>
      <name>Zhiwei Lin</name>
    </author>
    <author>
      <name>Hui Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1909.03794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03759v1</id>
    <updated>2019-09-09T11:05:15Z</updated>
    <published>2019-09-09T11:05:15Z</published>
    <title>Neural Conversational QA: Learning to Reason v.s. Exploiting Patterns</title>
    <summary>  In this paper we work on the recently introduced ShARC task - a challenging
form of conversational QA that requires reasoning over rules expressed in
natural language. Attuned to the risk of superficial patterns in data being
exploited by neural models to do well on benchmark tasks (Niven and Kao 2019),
we conduct a series of probing experiments and demonstrate how current
state-of-the-art models rely heavily on such patterns. To prevent models from
learning based on the superficial clues, we modify the dataset by automatically
generating new instances reducing the occurrences of those patterns. We also
present a simple yet effective model that learns embedding representations to
incorporate dialog history along with the previous answers to follow-up
questions. We find that our model outperforms existing methods on all metrics,
and the results show that the proposed model is more robust in dealing with
spurious patterns and learns to reason meaningfully.
</summary>
    <author>
      <name>Abhishek Sharma</name>
    </author>
    <author>
      <name>Danish Contractor</name>
    </author>
    <author>
      <name>Harshit Kumar</name>
    </author>
    <author>
      <name>Sachindra Joshi</name>
    </author>
    <link href="http://arxiv.org/abs/1909.03759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03745v2</id>
    <updated>2019-09-13T07:33:15Z</updated>
    <published>2019-09-09T10:34:09Z</published>
    <title>Reasoning Over Semantic-Level Graph for Fact Checking</title>
    <summary>  We study fact-checking in this paper, which aims to verify a textual claim
given textual evidence (e.g., retrieved sentences from Wikipedia). Existing
studies typically either concatenate retrieved sentences as a single string or
use feature fusion on the top of features of sentences, while ignoring
semantic-level information including participants, location, and temporality of
an event occurred in a sentence and relationships among multiple events. Such
semantic-level information is crucial for understanding the relational
structure of evidence and the deep reasoning procedure over that. In this
paper, we address this issue by proposing a graph-based reasoning framework,
called the Dynamic REAsoning Machine (DREAM) framework. We first construct a
semantic-level graph, where nodes are extracted by semantic role labeling
toolkits and are connected by inner- and inter- sentence edges. After having
the automatically constructed graph, we use XLNet as the backbone of our
approach and propose a graph-based contextual word representation learning
module and a graph-based reasoning module to leverage the information of
graphs. The first module is designed by considering a claim as a sequence, in
which case we use the graph structure to re-define the relative distance of
words. On top of this, we propose the second module by considering both the
claim and the evidence as graphs and use a graph neural network to capture the
semantic relationship at a more abstract level. We conduct experiments on
FEVER, a large-scale benchmark dataset for fact-checking. Results show that
both of the graph-based modules improve performance. Our system is the
state-of-the-art system on the public leaderboard in terms of both accuracy and
FEVER score.
</summary>
    <author>
      <name>Wanjun Zhong</name>
    </author>
    <author>
      <name>Jingjing Xu</name>
    </author>
    <author>
      <name>Duyu Tang</name>
    </author>
    <author>
      <name>Zenan Xu</name>
    </author>
    <author>
      <name>Nan Duan</name>
    </author>
    <author>
      <name>Ming Zhou</name>
    </author>
    <author>
      <name>Jiahai Wang</name>
    </author>
    <author>
      <name>Jian Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03745v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03745v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05190v1</id>
    <updated>2019-09-09T03:00:39Z</updated>
    <published>2019-09-09T03:00:39Z</published>
    <title>Event Representation Learning Enhanced with External Commonsense
  Knowledge</title>
    <summary>  Prior work has proposed effective methods to learn event representations that
can capture syntactic and semantic information over text corpus, demonstrating
their effectiveness for downstream tasks such as script event prediction. On
the other hand, events extracted from raw texts lacks of commonsense knowledge,
such as the intents and emotions of the event participants, which are useful
for distinguishing event pairs when there are only subtle differences in their
surface realizations. To address this issue, this paper proposes to leverage
external commonsense knowledge about the intent and sentiment of the event.
Experiments on three event-related tasks, i.e., event similarity, script event
prediction and stock market prediction, show that our model obtains much better
event embeddings for the tasks, achieving 78% improvements on hard similarity
task, yielding more precise inferences on subsequent events under given
contexts, and better accuracies in predicting the volatilities of the stock
market.
</summary>
    <author>
      <name>Xiao Ding</name>
    </author>
    <author>
      <name>Kuo Liao</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Zhongyang Li</name>
    </author>
    <author>
      <name>Junwen Duan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1711.07611, 1805.02474 by
  other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03553v1</id>
    <updated>2019-09-08T22:05:19Z</updated>
    <published>2019-09-08T22:05:19Z</published>
    <title>QuaRTz: An Open-Domain Dataset of Qualitative Relationship Questions</title>
    <summary>  We introduce the first open-domain dataset, called QuaRTz, for reasoning
about textual qualitative relationships. QuaRTz contains general qualitative
statements, e.g., "A sunscreen with a higher SPF protects the skin longer.",
twinned with 3864 crowdsourced situated questions, e.g., "Billy is wearing
sunscreen with a lower SPF than Lucy. Who will be best protected from the
sun?", plus annotations of the properties being compared. Unlike previous
datasets, the general knowledge is textual and not tied to a fixed set of
relationships, and tests a system's ability to comprehend and apply textual
qualitative knowledge in a novel setting. We find state-of-the-art results are
substantially (20%) below human performance, presenting an open challenge to
the NLP community.
</summary>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Matt Gardner</name>
    </author>
    <author>
      <name>Kevin Lin</name>
    </author>
    <author>
      <name>Peter Clark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03527v1</id>
    <updated>2019-09-08T18:35:03Z</updated>
    <published>2019-09-08T18:35:03Z</published>
    <title>Large Scale Question Answering using Tourism Data</title>
    <summary>  Real world question answering can be significantly more complex than what
most existing QA datasets reflect. Questions posed by users on websites, such
as online travel forums, may consist of multiple sentences and not everything
mentioned in a question may be relevant for finding its answer. Such questions
typically have a huge candidate answer space and require complex reasoning over
large knowledge corpora. We introduce the novel task of answering
entity-seeking recommendation questions using a collection of reviews that
describe candidate answer entities. We harvest a QA dataset that contains
48,147 paragraph-sized real user questions from travelers seeking
recommendations for hotels, attractions and restaurants. Each candidate answer
is associated with a collection of unstructured reviews. This dataset is
challenging because commonly used neural architectures for QA are prohibitively
expensive for a task of this scale. As a solution, we design a scalable
cluster-select-rerank approach. It first clusters text for each entity to
identify exemplar sentences describing an entity. It then uses a scalable
neural information retrieval (IR) module to subselect a set of potential
entities from the large candidate set. A reranker uses a deeper attention-based
architecture to pick the best answers from the selected entities. This strategy
performs better than a pure IR or a pure attention-based reasoning approach
yielding nearly 10% relative improvement in Accuracy@3 over both approaches.
</summary>
    <author>
      <name>Danish Contractor</name>
    </author>
    <author>
      <name>Krunal Shah</name>
    </author>
    <author>
      <name>Aditi Partap</name>
    </author>
    <author>
      <name> Mausam</name>
    </author>
    <author>
      <name>Parag Singla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, 4 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03480v2</id>
    <updated>2019-11-21T18:32:23Z</updated>
    <published>2019-09-08T15:09:32Z</published>
    <title>Story Realization: Expanding Plot Events into Sentences</title>
    <summary>  Neural network based approaches to automated story plot generation attempt to
learn how to generate novel plots from a corpus of natural language plot
summaries. Prior work has shown that a semantic abstraction of sentences called
events improves neural plot generation and and allows one to decompose the
problem into: (1) the generation of a sequence of events (event-to-event) and
(2) the transformation of these events into natural language sentences
(event-to-sentence). However, typical neural language generation approaches to
event-to-sentence can ignore the event details and produce
grammatically-correct but semantically-unrelated sentences. We present an
ensemble-based model that generates natural language guided by events.We
provide results---including a human subjects study---for a full end-to-end
automated story generation system showing that our method generates more
coherent and plausible stories than baseline approaches.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Ethan Tien</name>
    </author>
    <author>
      <name>Wesley Cheung</name>
    </author>
    <author>
      <name>Zhaochen Luo</name>
    </author>
    <author>
      <name>William Ma</name>
    </author>
    <author>
      <name>Lara J. Martin</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In proceedings of AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03480v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03480v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03409v1</id>
    <updated>2019-09-08T09:31:20Z</updated>
    <published>2019-09-08T09:31:20Z</published>
    <title>c-TextGen: Conditional Text Generation for Harmonious Human-Machine
  Interaction</title>
    <summary>  In recent years, with the development of deep learning technology, text
generation technology has undergone great changes and provided many kinds of
services for human beings, such as restaurant reservation and daily
communication. The automatically generated text is becoming more and more
fluent so researchers begin to consider more anthropomorphic text generation
technology, that is the conditional text generation, including emotional text
generation, personalized text generation, and so on. Conditional text
generation (c-TextGen) has thus become a research hotspot. As a promising
research field, we find that many efforts have been paid to researches of
c-TextGen. Therefore, we aim to give a comprehensive review of the new research
trends of c-TextGen. We first give a brief literature review of text generation
technology, based on which we formalize the concept model of c-TextGen. We
further make an investigation of several different c-TextGen techniques, and
illustrate the advantages and disadvantages of commonly used neural network
models. Finally, we discuss the open issues and promising research directions
of c-TextGen.
</summary>
    <author>
      <name>Bin Guo</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Yasan Ding</name>
    </author>
    <author>
      <name>Shaoyang Hao</name>
    </author>
    <author>
      <name>Yueqi Sun</name>
    </author>
    <author>
      <name>Zhiwen Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM Computing Surveys</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03329v2</id>
    <updated>2019-12-23T04:36:52Z</updated>
    <published>2019-09-07T20:17:34Z</published>
    <title>LAMOL: LAnguage MOdeling for Lifelong Language Learning</title>
    <summary>  Most research on lifelong learning applies to images or games, but not
language. We present LAMOL, a simple yet effective method for lifelong language
learning (LLL) based on language modeling. LAMOL replays pseudo-samples of
previous tasks while requiring no extra memory or model capacity. Specifically,
LAMOL is a language model that simultaneously learns to solve the tasks and
generate training samples. When the model is trained for a new task, it
generates pseudo-samples of previous tasks for training alongside data for the
new task. The results show that LAMOL prevents catastrophic forgetting without
any sign of intransigence and can perform five very different language tasks
sequentially with only one model. Overall, LAMOL outperforms previous methods
by a considerable margin and is only 2-3% worse than multitasking, which is
usually considered the LLL upper bound. The source code is available at
https://github.com/jojotenya/LAMOL.
</summary>
    <author>
      <name>Fan-Keng Sun</name>
    </author>
    <author>
      <name>Cheng-Hao Ho</name>
    </author>
    <author>
      <name>Hung-Yi Lee</name>
    </author>
    <link href="http://arxiv.org/abs/1909.03329v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03329v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03317v1</id>
    <updated>2019-09-07T18:32:28Z</updated>
    <published>2019-09-07T18:32:28Z</published>
    <title>Dependency Parsing for Spoken Dialog Systems</title>
    <summary>  Dependency parsing of conversational input can play an important role in
language understanding for dialog systems by identifying the relationships
between entities extracted from user utterances. Additionally, effective
dependency parsing can elucidate differences in language structure and usage
for discourse analysis of human-human versus human-machine dialogs. However,
models trained on datasets based on news articles and web data do not perform
well on spoken human-machine dialog, and currently available annotation schemes
do not adapt well to dialog data. Therefore, we propose the Spoken Conversation
Universal Dependencies (SCUD) annotation scheme that extends the Universal
Dependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine
dialogs. We also provide ConvBank, a conversation dataset between humans and an
open-domain conversational dialog system with SCUD annotation. Finally, to
demonstrate the utility of the dataset, we train a dependency parser on the
ConvBank dataset. We demonstrate that by pre-training a dependency parser on a
set of larger public datasets and fine-tuning on ConvBank data, we achieved the
best result, 85.05% unlabeled and 77.82% labeled attachment accuracy.
</summary>
    <author>
      <name>Sam Davidson</name>
    </author>
    <author>
      <name>Dian Yu</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03315v1</id>
    <updated>2019-09-07T18:24:57Z</updated>
    <published>2019-09-07T18:24:57Z</published>
    <title>Relationships from Entity Stream</title>
    <summary>  Relational reasoning is a central component of intelligent behavior, but has
proven difficult for neural networks to learn. The Relation Network (RN) module
was recently proposed by DeepMind to solve such problems, and demonstrated
state-of-the-art results on a number of datasets. However, the RN module scales
quadratically in the size of the input, since it calculates relationship
factors between every patch in the visual field, including those that do not
correspond to entities. In this paper, we describe an architecture that enables
relationships to be determined from a stream of entities obtained by an
attention mechanism over the input field. The model is trained end-to-end, and
demonstrates equivalent performance with greater interpretability while
requiring only a fraction of the model parameters of the original RN module.
</summary>
    <author>
      <name>Martin Andrews</name>
    </author>
    <author>
      <name>Sam Witteveen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper for the ViGIL workshop at NIPS 2017. (4 pages +
  references)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03193v2</id>
    <updated>2019-09-11T06:03:30Z</updated>
    <published>2019-09-07T06:09:25Z</published>
    <title>KG-BERT: BERT for Knowledge Graph Completion</title>
    <summary>  Knowledge graphs are important resources for many artificial intelligence
tasks but often suffer from incompleteness. In this work, we propose to use
pre-trained language models for knowledge graph completion. We treat triples in
knowledge graphs as textual sequences and propose a novel framework named
Knowledge Graph Bidirectional Encoder Representations from Transformer
(KG-BERT) to model these triples. Our method takes entity and relation
descriptions of a triple as input and computes scoring function of the triple
with the KG-BERT language model. Experimental results on multiple benchmark
knowledge graphs show that our method can achieve state-of-the-art performance
in triple classification, link prediction and relation prediction tasks.
</summary>
    <author>
      <name>Liang Yao</name>
    </author>
    <author>
      <name>Chengsheng Mao</name>
    </author>
    <author>
      <name>Yuan Luo</name>
    </author>
    <link href="http://arxiv.org/abs/1909.03193v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03193v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03099v2</id>
    <updated>2019-09-13T02:50:17Z</updated>
    <published>2019-09-06T19:39:37Z</published>
    <title>Abductive Reasoning as Self-Supervision for Common Sense Question
  Answering</title>
    <summary>  Question answering has seen significant advances in recent times, especially
with the introduction of increasingly bigger transformer-based models
pre-trained on massive amounts of data. While achieving impressive results on
many benchmarks, their performances appear to be proportional to the amount of
training data available in the target domain. In this work, we explore the
ability of current question-answering models to generalize - to both other
domains as well as with restricted training data. We find that large amounts of
training data are necessary, both for pre-training as well as fine-tuning to a
task, for the models to perform well on the designated task. We introduce a
novel abductive reasoning approach based on Grenander's Pattern Theory
framework to provide self-supervised domain adaptation cues or "pseudo-labels,"
which can be used instead of expensive human annotations. The proposed
self-supervised training regimen allows for effective domain adaptation without
losing performance compared to fully supervised baselines. Extensive
experiments on two publicly available benchmarks show the efficacy of the
proposed approach. We show that neural networks models trained using
self-labeled data can retain up to $75\%$ of the performance of models trained
on large amounts of human-annotated training data.
</summary>
    <author>
      <name>Sathyanarayanan N. Aakur</name>
    </author>
    <author>
      <name>Sudeep Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 4 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.03099v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03099v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02965v1</id>
    <updated>2019-09-06T15:10:37Z</updated>
    <published>2019-09-06T15:10:37Z</published>
    <title>User Evaluation of a Multi-dimensional Statistical Dialogue System</title>
    <summary>  We present the first complete spoken dialogue system driven by a
multi-dimensional statistical dialogue manager. This framework has been shown
to substantially reduce data needs by leveraging domain-independent dimensions,
such as social obligations or feedback, which (as we show) can be transferred
between domains. In this paper, we conduct a user study and show that the
performance of a multi-dimensional system, which can be adapted from a source
domain, is equivalent to that of a one-dimensional baseline, which can only be
trained from scratch.
</summary>
    <author>
      <name>Simon Keizer</name>
    </author>
    <author>
      <name>Ondřej Dušek</name>
    </author>
    <author>
      <name>Xingkun Liu</name>
    </author>
    <author>
      <name>Verena Rieser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGdial 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02930v1</id>
    <updated>2019-09-06T14:29:00Z</updated>
    <published>2019-09-06T14:29:00Z</published>
    <title>Structured Query Construction via Knowledge Graph Embedding</title>
    <summary>  In order to facilitate the accesses of general users to knowledge graphs, an
increasing effort is being exerted to construct graph-structured queries of
given natural language questions. At the core of the construction is to deduce
the structure of the target query and determine the vertices/edges which
constitute the query. Existing query construction methods rely on question
understanding and conventional graph-based algorithms which lead to inefficient
and degraded performances facing complex natural language questions over
knowledge graphs with large scales. In this paper, we focus on this problem and
propose a novel framework standing on recent knowledge graph embedding
techniques. Our framework first encodes the underlying knowledge graph into a
low-dimensional embedding space by leveraging generalized local knowledge
graphs. Given a natural language question, the learned embedding
representations of the knowledge graph are utilized to compute the query
structure and assemble vertices/edges into the target query. Extensive
experiments were conducted on the benchmark dataset, and the results
demonstrate that our framework outperforms state-of-the-art baseline models
regarding effectiveness and efficiency.
</summary>
    <author>
      <name>Ruijie Wang</name>
    </author>
    <author>
      <name>Meng Wang</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <author>
      <name>Michael Cochez</name>
    </author>
    <author>
      <name>Stefan Decker</name>
    </author>
    <link href="http://arxiv.org/abs/1909.02930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02809v1</id>
    <updated>2019-09-06T10:36:33Z</updated>
    <published>2019-09-06T10:36:33Z</published>
    <title>#MeTooMaastricht: Building a chatbot to assist survivors of sexual
  harassment</title>
    <summary>  Inspired by the recent social movement of #MeToo, we are building a chatbot
to assist survivors of sexual harassment cases (designed for the city of
Maastricht but can easily be extended). The motivation behind this work is
twofold: properly assist survivors of such events by directing them to
appropriate institutions that can offer them help and increase the incident
documentation so as to gather more data about harassment cases which are
currently under reported. We break down the problem into three data
science/machine learning components: harassment type identification (treated as
a classification problem), spatio-temporal information extraction (treated as
Named Entity Recognition problem) and dialogue with the users (treated as a
slot-filling based chatbot). We are able to achieve a success rate of more than
98% for the identification of a harassment-or-not case and around 80% for the
specific type harassment identification. Locations and dates are identified
with more than 90% accuracy and time occurrences prove more challenging with
almost 80%. Finally, initial validation of the chatbot shows great potential
for the further development and deployment of such a beneficial for the whole
society tool.
</summary>
    <author>
      <name>Tobias Bauer</name>
    </author>
    <author>
      <name>Emre Devrim</name>
    </author>
    <author>
      <name>Misha Glazunov</name>
    </author>
    <author>
      <name>William Lopez Jaramillo</name>
    </author>
    <author>
      <name>Balaganesh Mohan</name>
    </author>
    <author>
      <name>Gerasimos Spanakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, accepted at SoGood2019 workshop (ECMLPKDD2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04493v1</id>
    <updated>2019-09-06T07:47:20Z</updated>
    <published>2019-09-06T07:47:20Z</published>
    <title>Context-aware Deep Model for Entity Recommendation in Search Engine at
  Alibaba</title>
    <summary>  Entity recommendation, providing search users with an improved experience via
assisting them in finding related entities for a given query, has become an
indispensable feature of today's search engines. Existing studies typically
only consider the queries with explicit entities. They usually fail to handle
complex queries that without entities, such as "what food is good for cold
weather", because their models could not infer the underlying meaning of the
input text. In this work, we believe that contexts convey valuable evidence
that could facilitate the semantic modeling of queries, and take them into
consideration for entity recommendation. In order to better model the semantics
of queries and entities, we learn the representation of queries and entities
jointly with attentive deep neural networks. We evaluate our approach using
large-scale, real-world search logs from a widely used commercial Chinese
search engine. Our system has been deployed in ShenMa Search Engine and you can
fetch it in UC Browser of Alibaba. Results from online A/B test suggest that
the impression efficiency of click-through rate increased by 5.1% and page view
increased by 5.5%.
</summary>
    <author>
      <name>Qianghuai Jia</name>
    </author>
    <author>
      <name>Ningyu Zhang</name>
    </author>
    <author>
      <name>Nengwei Hua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CIKM2019 International Workshop on Entity Retrieval. arXiv admin
  note: text overlap with arXiv:1511.08996 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04493v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04493v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05365v2</id>
    <updated>2019-10-28T19:45:17Z</updated>
    <published>2019-09-06T01:28:34Z</published>
    <title>Building Task-Oriented Visual Dialog Systems Through Alternative
  Optimization Between Dialog Policy and Language Generation</title>
    <summary>  Reinforcement learning (RL) is an effective approach to learn an optimal
dialog policy for task-oriented visual dialog systems. A common practice is to
apply RL on a neural sequence-to-sequence (seq2seq) framework with the action
space being the output vocabulary in the decoder. However, it is difficult to
design a reward function that can achieve a balance between learning an
effective policy and generating a natural dialog response. This paper proposes
a novel framework that alternatively trains a RL policy for image guessing and
a supervised seq2seq model to improve dialog generation quality. We evaluate
our framework on the GuessWhich task and the framework achieves the
state-of-the-art performance in both task completion and dialog quality.
</summary>
    <author>
      <name>Mingyang Zhou</name>
    </author>
    <author>
      <name>Josh Arnold</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">updated with acknowledgement and minor typo fixes on tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05365v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05365v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05364v1</id>
    <updated>2019-09-05T14:03:35Z</updated>
    <published>2019-09-05T14:03:35Z</published>
    <title>TransSent: Towards Generation of Structured Sentences with Discourse
  Marker</title>
    <summary>  This paper focuses on the task of generating long structured sentences with
explicit discourse markers, by proposing a new task Sentence Transfer and a
novel model architecture TransSent. Previous works on text generation fused
semantic and structure information in one mixed hidden representation. However,
the structure was difficult to maintain properly when the generated sentence
became longer. In this work, we explicitly separate the modeling process of
semantic information and structure information. Intuitively, humans produce
long sentences by directly connecting discourses with discourse markers like
and, but, etc. We thus define a new task called Sentence Transfer. This task
represents a long sentence as (head discourse, discourse marker, tail
discourse) and aims at tail discourse generation based on head discourse and
discourse marker. Then, by connecting original head discourse and generated
tail discourse with a discourse marker, we generate a long structured sentence.
We also propose a model architecture called TransSent, which models relations
between two discourses by interpreting them as transferring from one discourse
to the other in the embedding space. Experiment results show that our model
achieves better performance in automatic evaluations, and can generate
structured sentences with high quality. The datasets can be accessed by
https://github.com/1024er/TransSent dataset.
</summary>
    <author>
      <name>Xing Wu</name>
    </author>
    <author>
      <name>Tao Zhang</name>
    </author>
    <author>
      <name>Liangjun Zang</name>
    </author>
    <author>
      <name>Jizhong Han</name>
    </author>
    <author>
      <name>Songlin Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02314v2</id>
    <updated>2019-09-06T16:46:34Z</updated>
    <published>2019-09-05T10:54:03Z</published>
    <title>Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis</title>
    <summary>  We describe a detailed analysis of a sample of large benchmark of commonsense
reasoning problems that has been automatically obtained from WordNet, SUMO and
their mapping. The objective is to provide a better assessment of the quality
of both the benchmark and the involved knowledge resources for advanced
commonsense reasoning tasks. By means of this analysis, we are able to detect
some knowledge misalignments, mapping errors and lack of knowledge and
resources. Our final objective is the extraction of some guidelines towards a
better exploitation of this commonsense knowledge framework by the improvement
of the included resources.
</summary>
    <author>
      <name>Javier Álvez</name>
    </author>
    <author>
      <name>Itziar Gonzalez-Dios</name>
    </author>
    <author>
      <name>German Rigau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures, 2 tables; 10th Global WordNet Conference - GWC
  2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02314v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02314v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02195v2</id>
    <updated>2019-09-06T20:40:28Z</updated>
    <published>2019-09-05T03:30:26Z</published>
    <title>Automated Let's Play Commentary</title>
    <summary>  Let's Plays of video games represent a relatively unexplored area for
experimental AI in games. In this short paper, we discuss an approach to
generate automated commentary for Let's Play videos, drawing on convolutional
deep neural networks. We focus on Let's Plays of the popular game Minecraft. We
compare our approach and a prior approach and demonstrate the generation of
automated, artificial commentary.
</summary>
    <author>
      <name>Shukan Shah</name>
    </author>
    <author>
      <name>Matthew Guzdial</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2019 Experimental AI in Games Workshop</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.02195v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02195v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05363v1</id>
    <updated>2019-09-05T01:13:41Z</updated>
    <published>2019-09-05T01:13:41Z</published>
    <title>Identifying and Explaining Discriminative Attributes</title>
    <summary>  Identifying what is at the center of the meaning of a word and what
discriminates it from other words is a fundamental natural language inference
task. This paper describes an explicit word vector representation model (WVM)
to support the identification of discriminative attributes. A core contribution
of the paper is a quantitative and qualitative comparative analysis of
different types of data sources and Knowledge Bases in the construction of
explainable and explicit WVMs: (i) knowledge graphs built from dictionary
definitions, (ii) entity-attribute-relationships graphs derived from images and
(iii) commonsense knowledge graphs. Using a detailed quantitative and
qualitative analysis, we demonstrate that these data sources have complementary
semantic aspects, supporting the creation of explicit semantic vector spaces.
The explicit vector spaces are evaluated using the task of discriminative
attribute identification, showing comparable performance to the
state-of-the-art systems in the task (F1-score = 0.69), while delivering full
model transparency and explainability.
</summary>
    <author>
      <name>Armins Stepanjans</name>
    </author>
    <author>
      <name>André Freitas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-IJCNLP 2019, source code available at
  https://github.com/ab-10/hawk</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02164v4</id>
    <updated>2019-12-31T17:16:32Z</updated>
    <published>2019-09-05T00:25:17Z</published>
    <title>TabFact: A Large-scale Dataset for Table-based Fact Verification</title>
    <summary>  The problem of verifying whether a textual hypothesis holds based on the
given evidence, also known as fact verification, plays an important role in the
study of natural language understanding and semantic representation. However,
existing studies are mainly restricted to dealing with unstructured evidence
(e.g., natural language sentences and documents, news, etc), while verification
under structured evidence, such as tables, graphs, and databases, remains
under-explored. This paper specifically aims to study the fact verification
given semi-structured data as evidence. To this end, we construct a large-scale
dataset called TabFact with 16k Wikipedia tables as the evidence for 118k
human-annotated natural language statements, which are labeled as either
ENTAILED or REFUTED. TabFact is challenging since it involves both soft
linguistic reasoning and hard symbolic reasoning. To address these reasoning
challenges, we design two different models: Table-BERT and Latent Program
Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language
model to encode the linearized tables and statements into continuous vectors
for verification. LPA parses statements into programs and executes them against
the tables to obtain the returned binary value for verification. Both methods
achieve similar accuracy but still lag far behind human performance. We also
perform a comprehensive analysis to demonstrate great future opportunities. The
data and code of the dataset are provided in
\url{https://github.com/wenhuchen/Table-Fact-Checking}.
</summary>
    <author>
      <name>Wenhu Chen</name>
    </author>
    <author>
      <name>Hongmin Wang</name>
    </author>
    <author>
      <name>Jianshu Chen</name>
    </author>
    <author>
      <name>Yunkai Zhang</name>
    </author>
    <author>
      <name>Hong Wang</name>
    </author>
    <author>
      <name>Shiyang Li</name>
    </author>
    <author>
      <name>Xiyou Zhou</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR 2020, 17 pages, 15 figures. Main paper has 9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02164v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02164v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02151v1</id>
    <updated>2019-09-04T23:37:25Z</updated>
    <published>2019-09-04T23:37:25Z</published>
    <title>KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning</title>
    <summary>  Commonsense reasoning aims to empower machines with the human ability to make
presumptions about ordinary situations in our daily life. In this paper, we
propose a textual inference framework for answering commonsense questions,
which effectively utilizes external, structured commonsense knowledge graphs to
perform explainable inferences. The framework first grounds a question-answer
pair from the semantic space to the knowledge-based symbolic space as a schema
graph, a related sub-graph of external knowledge graphs. It represents schema
graphs with a novel knowledge-aware graph network module named KagNet, and
finally scores answers with graph representations. Our model is based on graph
convolutional networks and LSTMs, with a hierarchical path-based attention
mechanism. The intermediate attention scores make it transparent and
interpretable, which thus produce trustworthy inferences. Using ConceptNet as
the only external resource for Bert-based models, we achieved state-of-the-art
performance on the CommonsenseQA, a large-scale dataset for commonsense
reasoning.
</summary>
    <author>
      <name>Bill Yuchen Lin</name>
    </author>
    <author>
      <name>Xinyue Chen</name>
    </author>
    <author>
      <name>Jamin Chen</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures, in Proc. of EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02059v1</id>
    <updated>2019-09-04T19:07:29Z</updated>
    <published>2019-09-04T19:07:29Z</published>
    <title>An Entity-Driven Framework for Abstractive Summarization</title>
    <summary>  Abstractive summarization systems aim to produce more coherent and concise
summaries than their extractive counterparts. Popular neural models have
achieved impressive results for single-document summarization, yet their
outputs are often incoherent and unfaithful to the input. In this paper, we
introduce SENECA, a novel System for ENtity-drivEn Coherent Abstractive
summarization framework that leverages entity information to generate
informative and coherent abstracts. Our framework takes a two-step approach:
(1) an entity-aware content selection module first identifies salient sentences
from the input, then (2) an abstract generation module conducts cross-sentence
information compression and abstraction to generate the final summary, which is
trained with rewards to promote coherence, conciseness, and clarity. The two
components are further connected using reinforcement learning. Automatic
evaluation shows that our model significantly outperforms previous
state-of-the-art on ROUGE and our proposed coherence measures on New York Times
and CNN/Daily Mail datasets. Human judges further rate our system summaries as
more informative and coherent than those by popular summarization models.
</summary>
    <author>
      <name>Eva Sharma</name>
    </author>
    <author>
      <name>Luyang Huang</name>
    </author>
    <author>
      <name>Zhe Hu</name>
    </author>
    <author>
      <name>Lu Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2019 Empirical Methods in Natural Language
  Processing Conference and 9th International Joint Conference on Natural
  Language Processing (EMNLP-IJCNLP-2019) (19 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02027v1</id>
    <updated>2019-09-04T18:04:56Z</updated>
    <published>2019-09-04T18:04:56Z</published>
    <title>An Evaluation Dataset for Intent Classification and Out-of-Scope
  Prediction</title>
    <summary>  Task-oriented dialog systems need to know when a query falls outside their
range of supported intents, but current text classification corpora only define
label sets that cover every example. We introduce a new dataset that includes
queries that are out-of-scope---i.e., queries that do not fall into any of the
system's supported intents. This poses a new challenge because models cannot
assume that every query at inference time belongs to a system-supported intent
class. Our dataset also covers 150 intent classes over 10 domains, capturing
the breadth that a production task-oriented agent must handle. We evaluate a
range of benchmark classifiers on our dataset along with several different
out-of-scope identification schemes. We find that while the classifiers perform
well on in-scope intent classification, they struggle to identify out-of-scope
queries. Our dataset and evaluation fill an important gap in the field,
offering a way of more rigorously and realistically benchmarking text
classification in task-driven dialog systems.
</summary>
    <author>
      <name>Stefan Larson</name>
    </author>
    <author>
      <name>Anish Mahendran</name>
    </author>
    <author>
      <name>Joseph J. Peper</name>
    </author>
    <author>
      <name>Christopher Clarke</name>
    </author>
    <author>
      <name>Andrew Lee</name>
    </author>
    <author>
      <name>Parker Hill</name>
    </author>
    <author>
      <name>Jonathan K. Kummerfeld</name>
    </author>
    <author>
      <name>Kevin Leach</name>
    </author>
    <author>
      <name>Michael A. Laurenzano</name>
    </author>
    <author>
      <name>Lingjia Tang</name>
    </author>
    <author>
      <name>Jason Mars</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01958v2</id>
    <updated>2019-09-11T20:51:37Z</updated>
    <published>2019-09-04T17:33:42Z</published>
    <title>From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the
  Aristo Project</title>
    <summary>  AI has achieved remarkable mastery over games such as Chess, Go, and Poker,
and even Jeopardy, but the rich variety of standardized exams has remained a
landmark challenge. Even in 2016, the best AI system achieved merely 59.3% on
an 8th Grade science exam challenge.
  This paper reports unprecedented success on the Grade 8 New York Regents
Science Exam, where for the first time a system scores more than 90% on the
exam's non-diagram, multiple choice (NDMC) questions. In addition, our Aristo
system, building upon the success of recent language models, exceeded 83% on
the corresponding Grade 12 Science Exam NDMC questions. The results, on unseen
test questions, are robust across different test years and different variations
of this kind of test. They demonstrate that modern NLP methods can result in
mastery on this task. While not a full solution to general question-answering
(the questions are multiple choice, and the domain is restricted to 8th Grade
science), it represents a significant milestone for the field.
</summary>
    <author>
      <name>Peter Clark</name>
    </author>
    <author>
      <name>Oren Etzioni</name>
    </author>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <author>
      <name>Tushar Khot</name>
    </author>
    <author>
      <name>Bhavana Dalvi Mishra</name>
    </author>
    <author>
      <name>Kyle Richardson</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Carissa Schoenick</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Niket Tandon</name>
    </author>
    <author>
      <name>Sumithra Bhakthavatsalam</name>
    </author>
    <author>
      <name>Dirk Groeneveld</name>
    </author>
    <author>
      <name>Michal Guerquin</name>
    </author>
    <author>
      <name>Michael Schmitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v2 add authors (content unchanged)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01958v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01958v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01871v6</id>
    <updated>2019-11-22T16:11:17Z</updated>
    <published>2019-09-04T15:20:01Z</published>
    <title>Help, Anna! Visual Navigation with Natural Multimodal Assistance via
  Retrospective Curiosity-Encouraging Imitation Learning</title>
    <summary>  Mobile agents that can leverage help from humans can potentially accomplish
more complex tasks than they could entirely on their own. We develop "Help,
Anna!" (HANNA), an interactive photo-realistic simulator in which an agent
fulfills object-finding tasks by requesting and interpreting natural
language-and-vision assistance. An agent solving tasks in a HANNA environment
can leverage simulated human assistants, called ANNA (Automatic Natural
Navigation Assistants), which, upon request, provide natural language and
visual instructions to direct the agent towards the goals. To address the HANNA
problem, we develop a memory-augmented neural agent that hierarchically models
multiple levels of decision-making, and an imitation learning algorithm that
teaches the agent to avoid repeating past mistakes while simultaneously
predicting its own chances of making future progress. Empirically, our approach
is able to ask for help more effectively than competitive baselines and, thus,
attains higher task success rate on both previously seen and previously unseen
environments. We publicly release code and data at
https://github.com/khanhptnk/hanna . A video demo is available at
https://youtu.be/18P94aaaLKg .
</summary>
    <author>
      <name>Khanh Nguyen</name>
    </author>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01871v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01871v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01610v1</id>
    <updated>2019-09-04T08:20:31Z</updated>
    <published>2019-09-04T08:20:31Z</published>
    <title>Answers Unite! Unsupervised Metrics for Reinforced Summarization Models</title>
    <summary>  Abstractive summarization approaches based on Reinforcement Learning (RL)
have recently been proposed to overcome classical likelihood maximization. RL
enables to consider complex, possibly non-differentiable, metrics that globally
assess the quality and relevance of the generated outputs. ROUGE, the most used
summarization metric, is known to suffer from bias towards lexical similarity
as well as from suboptimal accounting for fluency and readability of the
generated abstracts. We thus explore and propose alternative evaluation
measures: the reported human-evaluation analysis shows that the proposed
metrics, based on Question Answering, favorably compares to ROUGE -- with the
additional property of not requiring reference summaries. Training a RL-based
model on these metrics leads to improvements (both in terms of human or
automated metrics) over current approaches that use ROUGE as a reward.
</summary>
    <author>
      <name>Thomas Scialom</name>
    </author>
    <author>
      <name>Sylvain Lamprier</name>
    </author>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <author>
      <name>Jacopo Staiano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01567v1</id>
    <updated>2019-09-04T06:26:05Z</updated>
    <published>2019-09-04T06:26:05Z</published>
    <title>A Non-commutative Bilinear Model for Answering Path Queries in Knowledge
  Graphs</title>
    <summary>  Bilinear diagonal models for knowledge graph embedding (KGE), such as
DistMult and ComplEx, balance expressiveness and computational efficiency by
representing relations as diagonal matrices. Although they perform well in
predicting atomic relations, composite relations (relation paths) cannot be
modeled naturally by the product of relation matrices, as the product of
diagonal matrices is commutative and hence invariant with the order of
relations. In this paper, we propose a new bilinear KGE model, called
BlockHolE, based on block circulant matrices. In BlockHolE, relation matrices
can be non-commutative, allowing composite relations to be modeled by matrix
product. The model is parameterized in a way that covers a spectrum ranging
from diagonal to full relation matrices. A fast computation technique is
developed on the basis of the duality of the Fourier transform of circulant
matrices.
</summary>
    <author>
      <name>Katsuhiko Hayashi</name>
    </author>
    <author>
      <name>Masashi Shimbo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01388v1</id>
    <updated>2019-09-03T18:22:24Z</updated>
    <published>2019-09-03T18:22:24Z</published>
    <title>How to Build User Simulators to Train RL-based Dialog Systems</title>
    <summary>  User simulators are essential for training reinforcement learning (RL) based
dialog models. The performance of the simulator directly impacts the RL policy.
However, building a good user simulator that models real user behaviors is
challenging. We propose a method of standardizing user simulator building that
can be used by the community to compare dialog system quality using the same
set of user simulators fairly. We present implementations of six user
simulators trained with different dialog planning and generation methods. We
then calculate a set of automatic metrics to evaluate the quality of these
simulators both directly and indirectly. We also ask human users to assess the
simulators directly and indirectly by rating the simulated dialogs and
interacting with the trained systems. This paper presents a comprehensive
evaluation framework for user simulator study and provides a better
understanding of the pros and cons of different user simulators, as well as
their impacts on the trained systems.
</summary>
    <author>
      <name>Weiyan Shi</name>
    </author>
    <author>
      <name>Kun Qian</name>
    </author>
    <author>
      <name>Xuewei Wang</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long Paper Accepted by EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05361v1</id>
    <updated>2019-09-03T18:11:58Z</updated>
    <published>2019-09-03T18:11:58Z</published>
    <title>Structuring Latent Spaces for Stylized Response Generation</title>
    <summary>  Generating responses in a targeted style is a useful yet challenging task,
especially in the absence of parallel data. With limited data, existing methods
tend to generate responses that are either less stylized or less
context-relevant. We propose StyleFusion, which bridges conversation modeling
and non-parallel style transfer by sharing a structured latent space. This
structure allows the system to generate stylized relevant responses by sampling
in the neighborhood of the conversation model prediction, and continuously
control the style level. We demonstrate this method using dialogues from Reddit
data and two sets of sentences with distinct styles (arXiv and Sherlock Holmes
novels). Automatic and human evaluation show that, without sacrificing
appropriateness, the system generates responses of the targeted style and
outperforms competitive baselines.
</summary>
    <author>
      <name>Xiang Gao</name>
    </author>
    <author>
      <name>Yizhe Zhang</name>
    </author>
    <author>
      <name>Sungjin Lee</name>
    </author>
    <author>
      <name>Michel Galley</name>
    </author>
    <author>
      <name>Chris Brockett</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Bill Dolan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted to appear at EMNLP 2019 (long)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.05361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01362v1</id>
    <updated>2019-09-03T18:00:05Z</updated>
    <published>2019-09-03T18:00:05Z</published>
    <title>Trouble on the Horizon: Forecasting the Derailment of Online
  Conversations as they Develop</title>
    <summary>  Online discussions often derail into toxic exchanges between participants.
Recent efforts mostly focused on detecting antisocial behavior after the fact,
by analyzing single comments in isolation. To provide more timely notice to
human moderators, a system needs to preemptively detect that a conversation is
heading towards derailment before it actually turns toxic. This means modeling
derailment as an emerging property of a conversation rather than as an isolated
utterance-level event.
  Forecasting emerging conversational properties, however, poses several
inherent modeling challenges. First, since conversations are dynamic, a
forecasting model needs to capture the flow of the discussion, rather than
properties of individual comments. Second, real conversations have an unknown
horizon: they can end or derail at any time; thus a practical forecasting model
needs to assess the risk in an online fashion, as the conversation develops. In
this work we introduce a conversational forecasting model that learns an
unsupervised representation of conversational dynamics and exploits it to
predict future derailment as the conversation develops. By applying this model
to two new diverse datasets of online conversations with labels for antisocial
events, we show that it outperforms state-of-the-art systems at forecasting
derailment.
</summary>
    <author>
      <name>Jonathan P. Chang</name>
    </author>
    <author>
      <name>Cristian Danescu-Niculescu-Mizil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of EMNLP 2019. Data and code to be released
  as part of the Cornell Conversational Analysis Toolkit (convokit.cornell.edu)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01326v2</id>
    <updated>2019-10-23T18:55:16Z</updated>
    <published>2019-09-03T17:50:44Z</published>
    <title>The Woman Worked as a Babysitter: On Biases in Language Generation</title>
    <summary>  We present a systematic study of biases in natural language generation (NLG)
by analyzing text generated from prompts that contain mentions of different
demographic groups. In this work, we introduce the notion of the regard towards
a demographic, use the varying levels of regard towards different demographics
as a defining metric for bias in NLG, and analyze the extent to which sentiment
scores are a relevant proxy metric for regard. To this end, we collect
strategically-generated text from language models and manually annotate the
text with both sentiment and regard scores. Additionally, we build an automatic
regard classifier through transfer learning, so that we can analyze biases in
unseen text. Together, these methods reveal the extent of the biased nature of
language model generations. Our analysis provides a study of biases in NLG,
bias metrics and correlated human judgments, and empirical evidence on the
usefulness of our annotated dataset.
</summary>
    <author>
      <name>Emily Sheng</name>
    </author>
    <author>
      <name>Kai-Wei Chang</name>
    </author>
    <author>
      <name>Premkumar Natarajan</name>
    </author>
    <author>
      <name>Nanyun Peng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 short paper (5 pages); Updated references and examples,
  changed figure 2 &amp; 3 order, fixed grammar, results unmodified</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01326v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01326v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01063v2</id>
    <updated>2019-09-11T02:10:38Z</updated>
    <published>2019-09-03T11:04:19Z</published>
    <title>A Smart Sliding Chinese Pinyin Input Method Editor on Touchscreen</title>
    <summary>  This paper presents a smart sliding Chinese pinyin Input Method Editor (IME)
for touchscreen devices which allows user finger sliding from one key to
another on the touchscreen instead of tapping keys one by one, while the target
Chinese character sequence will be predicted during the sliding process to help
user input Chinese characters efficiently. Moreover, the layout of the virtual
keyboard of our IME adapts to user sliding for more efficient inputting. The
layout adaption process is utilized with Recurrent Neural Networks (RNN) and
deep reinforcement learning. The pinyin-to-character converter is implemented
with a sequence-to-sequence (Seq2Seq) model to predict the target Chinese
sequence. A sliding simulator is built to automatically produce sliding samples
for model training and virtual keyboard test. The key advantage of our proposed
IME is that nearly all its built-in tactics can be optimized automatically with
deep learning algorithms only following user behavior. Empirical studies verify
the effectiveness of the proposed model and show a better user input
efficiency.
</summary>
    <author>
      <name>Zhuosheng Zhang</name>
    </author>
    <author>
      <name>Zhen Meng</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">There are some insufficient explanations that may confuse readers. We
  will continue the research, but it will take a lot of time. After discussing
  with co-authors, we decide to withdraw this version from ArXiv, instead of
  replacement. We may re-upload a new version of this work in the future</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05359v1</id>
    <updated>2019-09-03T08:27:37Z</updated>
    <published>2019-09-03T08:27:37Z</published>
    <title>From Textual Information Sources to Linked Data in the Agatha Project</title>
    <summary>  Automatic reasoning about textual information is a challenging task in modern
Natural Language Processing (NLP) systems. In this work we describe our
proposal for representing and reasoning about Portuguese documents by means of
Linked Data like ontologies and thesauri. Our approach resorts to a specialized
pipeline of natural language processing (part-of-speech tagger, named entity
recognition, semantic role labeling) to populate an ontology for the domain of
criminal investigations. The provided architecture and ontology are language
independent. Although some of the NLP modules are language dependent, they can
be built using adequate AI methodologies.
</summary>
    <author>
      <name>Paulo Quaresma</name>
    </author>
    <author>
      <name>Vitor Beires Nogueira</name>
    </author>
    <author>
      <name>Kashyap Raiyani</name>
    </author>
    <author>
      <name>Roy Bayot</name>
    </author>
    <author>
      <name>Teresa Gonçalves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of DECLARE 19 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00997v3</id>
    <updated>2020-02-01T06:56:30Z</updated>
    <published>2019-09-03T08:23:51Z</published>
    <title>PlotQA: Reasoning over Scientific Plots</title>
    <summary>  Existing synthetic datasets (FigureQA, DVQA) for reasoning over plots do not
contain variability in data labels, real-valued data, or complex reasoning
questions. Consequently, proposed models for these datasets do not fully
address the challenge of reasoning over plots. In particular, they assume that
the answer comes either from a small fixed size vocabulary or from a bounding
box within the image. However, in practice, this is an unrealistic assumption
because many questions require reasoning and thus have real-valued answers
which appear neither in a small fixed size vocabulary nor in the image. In this
work, we aim to bridge this gap between existing datasets and real-world plots.
Specifically, we propose PlotQA with 28.9 million question-answer pairs over
224,377 plots on data from real-world sources and questions based on
crowd-sourced question templates. Further, 80.76% of the out-of-vocabulary
(OOV) questions in PlotQA have answers that are not in a fixed vocabulary.
Analysis of existing models on PlotQA reveals that they cannot deal with OOV
questions: their overall accuracy on our dataset is in single digits. This is
not surprising given that these models were not designed for such questions. As
a step towards a more holistic model which can address fixed vocabulary as well
as OOV questions, we propose a hybrid approach: Specific questions are answered
by choosing the answer from a fixed vocabulary or by extracting it from a
predicted bounding box in the plot, while other questions are answered with a
table question-answering engine which is fed with a structured table generated
by detecting visual elements from the image. On the existing DVQA dataset, our
model has an accuracy of 58%, significantly improving on the highest reported
accuracy of 46%. On PlotQA, our model has an accuracy of 22.52%, which is
significantly better than state of the art models.
</summary>
    <author>
      <name>Nitesh Methani</name>
    </author>
    <author>
      <name>Pritha Ganguly</name>
    </author>
    <author>
      <name>Mitesh M. Khapra</name>
    </author>
    <author>
      <name>Pratyush Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an extension of our previous arxiv paper "Data Interpretation
  over Plots" and it is to be presented at WACV 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00997v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00997v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00923v1</id>
    <updated>2019-09-03T02:31:47Z</updated>
    <published>2019-09-03T02:31:47Z</published>
    <title>Attributed Rhetorical Structure Grammar for Domain Text Summarization</title>
    <summary>  This paper presents a new approach of automatic text summarization which
combines domain oriented text analysis (DoTA) and rhetorical structure theory
(RST) in a grammar form: the attributed rhetorical structure grammar (ARSG),
where the non-terminal symbols are domain keywords, called domain relations,
while the rhetorical relations serve as attributes. We developed machine
learning algorithms for learning such a grammar from a corpus of sample domain
texts, as well as parsing algorithms for the learned grammar, together with
adjustable text summarization algorithms for generating domain specific
summaries. Our practical experiments have shown that with support of domain
knowledge the drawback of missing very large training data set can be
effectively compensated. We have also shown that the knowledge based approach
may be made more powerful by introducing grammar parsing and RST as inference
engine. For checking the feasibility of model transfer, we introduced a
technique for mapping a grammar from one domain to others with acceptable cost.
We have also made a comprehensive comparison of our approach with some others.
</summary>
    <author>
      <name>Ruqian Lu</name>
    </author>
    <author>
      <name>Shengluan Hou</name>
    </author>
    <author>
      <name>Chuanqing Wang</name>
    </author>
    <author>
      <name>Yu Huang</name>
    </author>
    <author>
      <name>Chaoqun Fei</name>
    </author>
    <author>
      <name>Songmao Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05360v1</id>
    <updated>2019-09-02T18:00:43Z</updated>
    <published>2019-09-02T18:00:43Z</published>
    <title>Joint Event and Temporal Relation Extraction with Shared Representations
  and Structured Prediction</title>
    <summary>  We propose a joint event and temporal relation extraction model with shared
representation learning and structured prediction. The proposed method has two
advantages over existing work. First, it improves event representation by
allowing the event and relation modules to share the same contextualized
embeddings and neural representation learner. Second, it avoids error
propagation in the conventional pipeline systems by leveraging structured
inference and learning methods to assign both the event labels and the temporal
relation labels jointly. Experiments show that the proposed method can improve
both event extraction and temporal relation extraction over state-of-the-art
systems, with the end-to-end F1 improved by 10% and 6.8% on two benchmark
datasets respectively.
</summary>
    <author>
      <name>Rujun Han</name>
    </author>
    <author>
      <name>Qiang Ning</name>
    </author>
    <author>
      <name>Nanyun Peng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper will be published in EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00754v2</id>
    <updated>2019-10-18T04:25:31Z</updated>
    <published>2019-09-02T15:00:08Z</published>
    <title>Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence
  Generation</title>
    <summary>  Existing approaches to dialogue state tracking rely on pre-defined ontologies
consisting of a set of all possible slot types and values. Though such
approaches exhibit promising performance on single-domain benchmarks, they
suffer from computational complexity that increases proportionally to the
number of pre-defined slots that need tracking. This issue becomes more severe
when it comes to multi-domain dialogues which include larger numbers of slots.
In this paper, we investigate how to approach DST using a generation framework
without the pre-defined ontology list. Given each turn of user utterance and
system response, we directly generate a sequence of belief states by applying a
hierarchical encoder-decoder structure. In this way, the computational
complexity of our model will be a constant regardless of the number of
pre-defined slots. Experiments on both the multi-domain and the single domain
dialogue state tracking dataset show that our model not only scales easily with
the increasing number of pre-defined domains and slots but also reaches the
state-of-the-art performance.
</summary>
    <author>
      <name>Liliang Ren</name>
    </author>
    <author>
      <name>Jianmo Ni</name>
    </author>
    <author>
      <name>Julian McAuley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 2019 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2019); Updated empirical results</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00754v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00754v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00672v1</id>
    <updated>2019-09-02T11:28:35Z</updated>
    <published>2019-09-02T11:28:35Z</published>
    <title>PrTransH: Embedding Probabilistic Medical Knowledge from Real World EMR
  Data</title>
    <summary>  This paper proposes an algorithm named as PrTransH to learn embedding vectors
from real world EMR data based medical knowledge. The unique challenge in
embedding medical knowledge graph from real world EMR data is that the
uncertainty of knowledge triplets blurs the border between "correct triplet"
and "wrong triplet", changing the fundamental assumption of many existing
algorithms. To address the challenge, some enhancements are made to existing
TransH algorithm, including: 1) involve probability of medical knowledge
triplet into training objective; 2) replace the margin-based ranking loss with
unified loss calculation considering both valid and corrupted triplets; 3)
augment training data set with medical background knowledge. Verifications on
real world EMR data based medical knowledge graph prove that PrTransH
outperforms TransH in link prediction task. To the best of our survey, this
paper is the first one to learn and verify knowledge embedding on probabilistic
knowledge graphs.
</summary>
    <author>
      <name>Linfeng Li</name>
    </author>
    <author>
      <name>Peng Wang</name>
    </author>
    <author>
      <name>Yao Wang</name>
    </author>
    <author>
      <name>Jinpeng Jiang</name>
    </author>
    <author>
      <name>Buzhou Tang</name>
    </author>
    <author>
      <name>Jun Yan</name>
    </author>
    <author>
      <name>Shenghui Wang</name>
    </author>
    <author>
      <name>Yuting Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1909.00672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00519v2</id>
    <updated>2019-10-10T08:58:05Z</updated>
    <published>2019-09-02T03:10:14Z</published>
    <title>Toward Understanding The Effect Of Loss function On Then Performance Of
  Knowledge Graph Embedding</title>
    <summary>  Knowledge graphs (KGs) represent world's facts in structured forms. KG
completion exploits the existing facts in a KG to discover new ones.
Translation-based embedding model (TransE) is a prominent formulation to do KG
completion. Despite the efficiency of TransE in memory and time, it suffers
from several limitations in encoding relation patterns such as symmetric,
reflexive etc. To resolve this problem, most of the attempts have circled
around the revision of the score function of TransE i.e., proposing a more
complicated score function such as Trans(A, D, G, H, R, etc) to mitigate the
limitations. In this paper, we tackle this problem from a different
perspective. We show that existing theories corresponding to the limitations of
TransE are inaccurate because they ignore the effect of loss function.
Accordingly, we pose theoretical investigations of the main limitations of
TransE in the light of loss function. To the best of our knowledge, this has
not been investigated so far comprehensively. We show that by a proper
selection of the loss function for training the TransE model, the main
limitations of the model are mitigated. This is explained by setting
upper-bound for the scores of positive samples, showing the region of truth
(i.e., the region that a triple is considered positive by the model). Our
theoretical proofs with experimental results fill the gap between the
capability of translation-based class of embedding models and the loss
function. The theories emphasise the importance of the selection of the loss
functions for training the models. Our experimental evaluations on different
loss functions used for training the models justify our theoretical proofs and
confirm the importance of the loss functions on the performance.
</summary>
    <author>
      <name>Mojtaba Nayyeri</name>
    </author>
    <author>
      <name>Chengjin Xu</name>
    </author>
    <author>
      <name>Yadollah Yaghoobzadeh</name>
    </author>
    <author>
      <name>Hamed Shariat Yazdi</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <link href="http://arxiv.org/abs/1909.00519v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00519v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00505v1</id>
    <updated>2019-09-02T01:41:00Z</updated>
    <published>2019-09-02T01:41:00Z</published>
    <title>Commonsense Knowledge Mining from Pretrained Models</title>
    <summary>  Inferring commonsense knowledge is a key challenge in natural language
processing, but due to the sparsity of training data, previous work has shown
that supervised methods for commonsense knowledge mining underperform when
evaluated on novel data. In this work, we develop a method for generating
commonsense knowledge using a large, pre-trained bidirectional language model.
By transforming relational triples into masked sentences, we can use this model
to rank a triple's validity by the estimated pointwise mutual information
between the two entities. Since we do not update the weights of the
bidirectional model, our approach is not biased by the coverage of any one
commonsense knowledge base. Though this method performs worse on a test set
than models explicitly trained on a corresponding training set, it outperforms
these methods when mining commonsense knowledge from new sources, suggesting
that unsupervised techniques may generalize better than current supervised
approaches.
</summary>
    <author>
      <name>Joshua Feldman</name>
    </author>
    <author>
      <name>Joe Davison</name>
    </author>
    <author>
      <name>Alexander M. Rush</name>
    </author>
    <link href="http://arxiv.org/abs/1909.00505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05358v1</id>
    <updated>2019-09-01T22:18:39Z</updated>
    <published>2019-09-01T22:18:39Z</published>
    <title>Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset</title>
    <summary>  A significant barrier to progress in data-driven approaches to building
dialog systems is the lack of high quality, goal-oriented conversational data.
To help satisfy this elementary requirement, we introduce the initial release
of the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising
six domains. Two procedures were used to create this collection, each with
unique advantages. The first involves a two-person, spoken "Wizard of Oz" (WOz)
approach in which trained agents and crowdsourced workers interact to complete
the task while the second is "self-dialog" in which crowdsourced workers write
the entire dialog themselves. We do not restrict the workers to detailed
scripts or to a small knowledge base and hence we observe that our dataset
contains more realistic and diverse conversations in comparison to existing
datasets. We offer several baseline models including state of the art neural
seq2seq architectures with benchmark performance as well as qualitative human
evaluations. Dialogs are labeled with API calls and arguments, a simple and
cost effective approach which avoids the requirement of complex annotation
schema. The layer of abstraction between the dialog model and the service
provider API allows for a given model to interact with multiple services that
provide similar functionally. Finally, the dataset will evoke interest in
written vs. spoken language, discourse patterns, error handling and other
linguistic phenomena related to dialog system research, development and design.
</summary>
    <author>
      <name>Bill Byrne</name>
    </author>
    <author>
      <name>Karthik Krishnamoorthi</name>
    </author>
    <author>
      <name>Chinnadhurai Sankar</name>
    </author>
    <author>
      <name>Arvind Neelakantan</name>
    </author>
    <author>
      <name>Daniel Duckworth</name>
    </author>
    <author>
      <name>Semih Yavuz</name>
    </author>
    <author>
      <name>Ben Goodrich</name>
    </author>
    <author>
      <name>Amit Dubey</name>
    </author>
    <author>
      <name>Andy Cedilnik</name>
    </author>
    <author>
      <name>Kyu-Young Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05358v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05358v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00393v1</id>
    <updated>2019-09-01T13:24:35Z</updated>
    <published>2019-09-01T13:24:35Z</published>
    <title>A Dataset of General-Purpose Rebuttal</title>
    <summary>  In Natural Language Understanding, the task of response generation is usually
focused on responses to short texts, such as tweets or a turn in a dialog. Here
we present a novel task of producing a critical response to a long
argumentative text, and suggest a method based on general rebuttal arguments to
address it. We do this in the context of the recently-suggested task of
listening comprehension over argumentative content: given a speech on some
specified topic, and a list of relevant arguments, the goal is to determine
which of the arguments appear in the speech. The general rebuttals we describe
here (written in English) overcome the need for topic-specific arguments to be
provided, by proving to be applicable for a large set of topics. This allows
creating responses beyond the scope of topics for which specific arguments are
available. All data collected during this work is freely available for
research.
</summary>
    <author>
      <name>Matan Orbach</name>
    </author>
    <author>
      <name>Yonatan Bilu</name>
    </author>
    <author>
      <name>Ariel Gera</name>
    </author>
    <author>
      <name>Yoav Kantor</name>
    </author>
    <author>
      <name>Lena Dankin</name>
    </author>
    <author>
      <name>Tamar Lavee</name>
    </author>
    <author>
      <name>Lili Kotlerman</name>
    </author>
    <author>
      <name>Shachar Mirkin</name>
    </author>
    <author>
      <name>Michal Jacovi</name>
    </author>
    <author>
      <name>Ranit Aharonov</name>
    </author>
    <author>
      <name>Noam Slonim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00279v1</id>
    <updated>2019-08-31T20:07:25Z</updated>
    <published>2019-08-31T20:07:25Z</published>
    <title>Generating Classical Chinese Poems from Vernacular Chinese</title>
    <summary>  Classical Chinese poetry is a jewel in the treasure house of Chinese culture.
Previous poem generation models only allow users to employ keywords to
interfere the meaning of generated poems, leaving the dominion of generation to
the model. In this paper, we propose a novel task of generating classical
Chinese poems from vernacular, which allows users to have more control over the
semantic of generated poems. We adapt the approach of unsupervised machine
translation (UMT) to our task. We use segmentation-based padding and
reinforcement learning to address under-translation and over-translation
respectively. According to experiments, our approach significantly improve the
perplexity and BLEU compared with typical UMT models. Furthermore, we explored
guidelines on how to write the input vernacular to generate better poems. Human
evaluation showed our approach can generate high-quality poems which are
comparable to amateur poems.
</summary>
    <author>
      <name>Zhichao Yang</name>
    </author>
    <author>
      <name>Pengshan Cai</name>
    </author>
    <author>
      <name>Yansong Feng</name>
    </author>
    <author>
      <name>Fei Li</name>
    </author>
    <author>
      <name>Weijiang Feng</name>
    </author>
    <author>
      <name>Elena Suet-Ying Chiu</name>
    </author>
    <author>
      <name>Hong Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00277v2</id>
    <updated>2019-09-06T21:16:16Z</updated>
    <published>2019-08-31T19:55:44Z</published>
    <title>Cosmos QA: Machine Reading Comprehension with Contextual Commonsense
  Reasoning</title>
    <summary>  Understanding narratives requires reading between the lines, which in turn,
requires interpreting the likely causes and effects of events, even when they
are not mentioned explicitly. In this paper, we introduce Cosmos QA, a
large-scale dataset of 35,600 problems that require commonsense-based reading
comprehension, formulated as multiple-choice questions. In stark contrast to
most existing reading comprehension datasets where the questions focus on
factual and literal understanding of the context paragraph, our dataset focuses
on reading between the lines over a diverse collection of people's everyday
narratives, asking such questions as "what might be the possible reason of
...?", or "what would have happened if ..." that require reasoning beyond the
exact text spans in the context. To establish baseline performances on Cosmos
QA, we experiment with several state-of-the-art neural architectures for
reading comprehension, and also propose a new architecture that improves over
the competitive baselines. Experimental results demonstrate a significant gap
between machine (68.4%) and human performance (94%), pointing to avenues for
future research on commonsense machine comprehension. Dataset, code and
leaderboard is publicly available at https://wilburone.github.io/cosmos.
</summary>
    <author>
      <name>Lifu Huang</name>
    </author>
    <author>
      <name>Ronan Le Bras</name>
    </author>
    <author>
      <name>Chandra Bhagavatula</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP'2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00277v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00277v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05356v2</id>
    <updated>2019-09-13T06:44:24Z</updated>
    <published>2019-08-31T17:40:21Z</published>
    <title>Entity Projection via Machine Translation for Cross-Lingual NER</title>
    <summary>  Although over 100 languages are supported by strong off-the-shelf machine
translation systems, only a subset of them possess large annotated corpora for
named entity recognition. Motivated by this fact, we leverage machine
translation to improve annotation-projection approaches to cross-lingual named
entity recognition. We propose a system that improves over prior
entity-projection methods by: (a) leveraging machine translation systems twice:
first for translating sentences and subsequently for translating entities; (b)
matching entities based on orthographic and phonetic similarity; and (c)
identifying matches based on distributional statistics derived from the
dataset. Our approach improves upon current state-of-the-art methods for
cross-lingual named entity recognition on 5 diverse languages by an average of
4.1 points. Further, our method achieves state-of-the-art F_1 scores for
Armenian, outperforming even a monolingual model trained on Armenian source
data.
</summary>
    <author>
      <name>Alankar Jain</name>
    </author>
    <author>
      <name>Bhargavi Paranjape</name>
    </author>
    <author>
      <name>Zachary C. Lipton</name>
    </author>
    <link href="http://arxiv.org/abs/1909.05356v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05356v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00230v1</id>
    <updated>2019-08-31T15:46:05Z</updated>
    <published>2019-08-31T15:46:05Z</published>
    <title>Collaborative Policy Learning for Open Knowledge Graph Reasoning</title>
    <summary>  In recent years, there has been a surge of interests in interpretable graph
reasoning methods. However, these models often suffer from limited performance
when working on sparse and incomplete graphs, due to the lack of evidential
paths that can reach target entities. Here we study open knowledge graph
reasoning---a task that aims to reason for missing facts over a graph augmented
by a background text corpus. A key challenge of the task is to filter out
"irrelevant" facts extracted from corpus, in order to maintain an effective
search space during path inference. We propose a novel reinforcement learning
framework to train two collaborative agents jointly, i.e., a multi-hop graph
reasoner and a fact extractor. The fact extraction agent generates fact triples
from corpora to enrich the graph on the fly; while the reasoning agent provides
feedback to the fact extractor and guides it towards promoting facts that are
helpful for the interpretable reasoning. Experiments on two public datasets
demonstrate the effectiveness of the proposed approach. Source code and
datasets used in this paper can be downloaded at
https://github.com/shanzhenren/CPL
</summary>
    <author>
      <name>Cong Fu</name>
    </author>
    <author>
      <name>Tong Chen</name>
    </author>
    <author>
      <name>Meng Qu</name>
    </author>
    <author>
      <name>Woojeong Jin</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <link href="http://arxiv.org/abs/1909.00230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00215v1</id>
    <updated>2019-08-31T13:50:28Z</updated>
    <published>2019-08-31T13:50:28Z</published>
    <title>QAInfomax: Learning Robust Question Answering System by Mutual
  Information Maximization</title>
    <summary>  Standard accuracy metrics indicate that modern reading comprehension systems
have achieved strong performance in many question answering datasets. However,
the extent these systems truly understand language remains unknown, and
existing systems are not good at distinguishing distractor sentences, which
look related but do not actually answer the question. To address this problem,
we propose QAInfomax as a regularizer in reading comprehension systems by
maximizing mutual information among passages, a question, and its answer.
QAInfomax helps regularize the model to not simply learn the superficial
correlation for answering questions. The experiments show that our proposed
QAInfomax achieves the state-of-the-art performance on the benchmark
Adversarial-SQuAD dataset.
</summary>
    <author>
      <name>Yi-Ting Yeh</name>
    </author>
    <author>
      <name>Yun-Nung Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00160v1</id>
    <updated>2019-08-31T07:41:42Z</updated>
    <published>2019-08-31T07:41:42Z</published>
    <title>Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs</title>
    <summary>  Recently, biomedical version of embeddings obtained from language models such
as BioELMo have shown state-of-the-art results for the textual inference task
in the medical domain. In this paper, we explore how to incorporate structured
domain knowledge, available in the form of a knowledge graph (UMLS), for the
Medical NLI task. Specifically, we experiment with fusing embeddings obtained
from knowledge graph with the state-of-the-art approaches for NLI task (ESIM
model). We also experiment with fusing the domain-specific sentiment
information for the task. Experiments conducted on MedNLI dataset clearly show
that this strategy improves the baseline BioELMo architecture for the Medical
NLI task.
</summary>
    <author>
      <name>Soumya Sharma</name>
    </author>
    <author>
      <name>Bishal Santra</name>
    </author>
    <author>
      <name>Abhik Jana</name>
    </author>
    <author>
      <name>T. Y. S. S. Santosh</name>
    </author>
    <author>
      <name>Niloy Ganguly</name>
    </author>
    <author>
      <name>Pawan Goyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 accepted short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00141v2</id>
    <updated>2019-09-10T23:30:26Z</updated>
    <published>2019-08-31T06:13:33Z</published>
    <title>Deep Reinforcement Learning with Distributional Semantic Rewards for
  Abstractive Summarization</title>
    <summary>  Deep reinforcement learning (RL) has been a commonly-used strategy for the
abstractive summarization task to address both the exposure bias and
non-differentiable task issues. However, the conventional reward Rouge-L simply
looks for exact n-grams matches between candidates and annotated references,
which inevitably makes the generated sentences repetitive and incoherent. In
this paper, instead of Rouge-L, we explore the practicability of utilizing the
distributional semantics to measure the matching degrees. With distributional
semantics, sentence-level evaluation can be obtained, and semantically-correct
phrases can also be generated without being limited to the surface form of the
reference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets
show that our proposed distributional semantics reward (DSR) has distinct
superiority in capturing the lexical and compositional diversity of natural
language.
</summary>
    <author>
      <name>Siyao Li</name>
    </author>
    <author>
      <name>Deren Lei</name>
    </author>
    <author>
      <name>Pengda Qin</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00141v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00141v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00131v1</id>
    <updated>2019-08-31T05:28:51Z</updated>
    <published>2019-08-31T05:28:51Z</published>
    <title>Evaluating Pronominal Anaphora in Machine Translation: An Evaluation
  Measure and a Test Suite</title>
    <summary>  The ongoing neural revolution in machine translation has made it easier to
model larger contexts beyond the sentence-level, which can potentially help
resolve some discourse-level ambiguities such as pronominal anaphora, thus
enabling better translations. Unfortunately, even when the resulting
improvements are seen as substantial by humans, they remain virtually unnoticed
by traditional automatic evaluation measures like BLEU, as only a few words end
up being affected. Thus, specialized evaluation measures are needed. With this
aim in mind, we contribute an extensive, targeted dataset that can be used as a
test suite for pronoun translation, covering multiple source languages and
different pronoun errors drawn from real system translations, for English. We
further propose an evaluation measure to differentiate good and bad pronoun
translations. We also conduct a user study to report correlations with human
judgments.
</summary>
    <author>
      <name>Prathyusha Jwalapuram</name>
    </author>
    <author>
      <name>Shafiq Joty</name>
    </author>
    <author>
      <name>Irina Temnikova</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00126v4</id>
    <updated>2019-09-13T03:52:50Z</updated>
    <published>2019-08-31T04:38:06Z</published>
    <title>A Logic-Driven Framework for Consistency of Neural Models</title>
    <summary>  While neural models show remarkable accuracy on individual predictions, their
internal beliefs can be inconsistent across examples. In this paper, we
formalize such inconsistency as a generalization of prediction error. We
propose a learning framework for constraining models using logic rules to
regularize them away from inconsistency. Our framework can leverage both
labeled and unlabeled examples and is directly compatible with off-the-shelf
learning schemes without model redesign. We instantiate our framework on
natural language inference, where experiments show that enforcing invariants
stated in logic can help make the predictions of neural models both accurate
and consistent.
</summary>
    <author>
      <name>Tao Li</name>
    </author>
    <author>
      <name>Vivek Gupta</name>
    </author>
    <author>
      <name>Maitrey Mehta</name>
    </author>
    <author>
      <name>Vivek Srikumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in EMNLP 2019; Extra footnote after camera ready; Addressing
  R-fuzzy and S-fuzzy logic + extra acknowledgement</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00126v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00126v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.05355v1</id>
    <updated>2019-08-31T04:03:26Z</updated>
    <published>2019-08-31T04:03:26Z</published>
    <title>Let's Ask Again: Refine Network for Automatic Question Generation</title>
    <summary>  In this work, we focus on the task of Automatic Question Generation (AQG)
where given a passage and an answer the task is to generate the corresponding
question. It is desired that the generated question should be (i) grammatically
correct (ii) answerable from the passage and (iii) specific to the given
answer. An analysis of existing AQG models shows that they produce questions
which do not adhere to one or more of {the above-mentioned qualities}. In
particular, the generated questions look like an incomplete draft of the
desired question with a clear scope for refinement. {To alleviate this
shortcoming}, we propose a method which tries to mimic the human process of
generating questions by first creating an initial draft and then refining it.
More specifically, we propose Refine Network (RefNet) which contains two
decoders. The second decoder uses a dual attention network which pays attention
to both (i) the original passage and (ii) the question (initial draft)
generated by the first decoder. In effect, it refines the question generated by
the first decoder, thereby making it more correct and complete. We evaluate
RefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show
that it outperforms existing state-of-the-art methods by 7-16\% on all of these
datasets. Lastly, we show that we can improve the quality of the second decoder
on specific metrics, such as, fluency and answerability by explicitly rewarding
revisions that improve on the corresponding metric during training. The code
has been made publicly available
\footnote{https://github.com/PrekshaNema25/RefNet-QG}
</summary>
    <author>
      <name>Preksha Nema</name>
    </author>
    <author>
      <name>Akash Kumar Mohankumar</name>
    </author>
    <author>
      <name>Mitesh M. Khapra</name>
    </author>
    <author>
      <name>Balaji Vasan Srinivasan</name>
    </author>
    <author>
      <name>Balaraman Ravindran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted in EMNLP 2019 in Main Conference, (10 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.05355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.05355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00105v1</id>
    <updated>2019-08-31T01:50:42Z</updated>
    <published>2019-08-31T01:50:42Z</published>
    <title>Generating Personalized Recipes from Historical User Preferences</title>
    <summary>  Existing approaches to recipe generation are unable to create recipes for
users with culinary preferences but incomplete knowledge of ingredients in
specific dishes. We propose a new task of personalized recipe generation to
help these users: expanding a name and incomplete ingredient details into
complete natural-text instructions aligned with the user's historical
preferences. We attend on technique- and recipe-level representations of a
user's previously consumed recipes, fusing these 'user-aware' representations
in an attention fusion layer to control recipe text generation. Experiments on
a new dataset of 180K recipes and 700K interactions show our model's ability to
generate plausible and personalized recipes compared to non-personalized
baselines.
</summary>
    <author>
      <name>Bodhisattwa Prasad Majumder</name>
    </author>
    <author>
      <name>Shuyang Li</name>
    </author>
    <author>
      <name>Jianmo Ni</name>
    </author>
    <author>
      <name>Julian McAuley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in EMNLP 2019. Data and codes are available at
  https://github.com/majumderb/recipe-personalization</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.00105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01136v4</id>
    <updated>2019-10-24T12:19:14Z</updated>
    <published>2019-08-30T17:25:06Z</published>
    <title>Neural Language Model for Automated Classification of Electronic Medical
  Records at the Emergency Room. The Significant Benefit of Unsupervised
  Generative Pre-training</title>
    <summary>  In order to build a national injury surveillance system based on emergency
room (ER) visits we are developing a coding system to classify their causes
from clinical notes in free-text. Supervised learning techniques have shown
good results in this area but require large number of annotated dataset. New
levels of performance have been recently achieved in neural language models
(NLM) with models based on the Transformer architecture incorporating an
unsupervised generative pre-training step. Our hypothesis is that methods
involving a generative self-supervised pre-training step can significantly
reduce the required number of annotated samples for supervised fine-tuning. In
this case study, we assessed whether we could predict from free-text clinical
notes whether a visit was the consequence of a traumatic or non-traumatic
event. Using fully re-trained GPT-2 models (without OpenAI pre-trained
weightings), we compared two scenarios: Scenario A (26 study cases of different
training data sizes) consisted in training the GPT-2 on the trauma/non-trauma
labeled (up to 161 930) clinical notes. In Scenario B (19 study cases), a first
step of self-supervised pre-training phase with unlabeled (up to 151 930) notes
and the second step of supervised fine-tuning with labeled (up to 10 000)
notes. Results showed that, Scenario A needed to process &gt;6 000 notes to
achieve good performance (AUC&gt;0.95), Scenario B needed only 600 notes, gain of
a factor 10. At the end case of both scenarios, for 16 times more data (161 930
vs. 10 000), the gain from Scenario A compared to Scenario B is only an
improvement of 0.89% in AUC and 2.12% in F1 score. To conclude, it is possible
to adapt a multi-purpose NLM model such as the GPT-2 to create a powerful tool
for classification of free-text notes with only very small number of labeled
samples.
</summary>
    <author>
      <name>Binbin Xu</name>
    </author>
    <author>
      <name>Cédric Gil-Jardiné</name>
    </author>
    <author>
      <name>Frantz Thiessard</name>
    </author>
    <author>
      <name>Eric Tellier</name>
    </author>
    <author>
      <name>Marta Avalos</name>
    </author>
    <author>
      <name>Emmanuel Lagarde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Updates with Major Changes on Study Design, we thank sincerely the
  anonymous reviewers / readers whose comments/suggestions helped improve and
  clarify this manuscript. 12 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01136v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01136v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11790v1</id>
    <updated>2019-08-30T15:30:11Z</updated>
    <published>2019-08-30T15:30:11Z</published>
    <title>Linguistic Versus Latent Relations for Modeling Coherent Flow in
  Paragraphs</title>
    <summary>  Generating a long, coherent text such as a paragraph requires a high-level
control of different levels of relations between sentences (e.g., tense,
coreference). We call such a logical connection between sentences as a
(paragraph) flow. In order to produce a coherent flow of text, we explore two
forms of intersentential relations in a paragraph: one is a human-created
linguistical relation that forms a structure (e.g., discourse tree) and the
other is a relation from latent representation learned from the sentences
themselves. Our two proposed models incorporate each form of relations into
document-level language models: the former is a supervised model that jointly
learns a language model as well as discourse relation prediction, and the
latter is an unsupervised model that is hierarchically conditioned by a
recurrent neural network (RNN) over the latent information. Our proposed models
with both forms of relations outperform the baselines in partially conditioned
paragraph generation task. Our codes and data are publicly available.
</summary>
    <author>
      <name>Dongyeop Kang</name>
    </author>
    <author>
      <name>Hiroaki Hayashi</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11782v1</id>
    <updated>2019-08-30T15:21:28Z</updated>
    <published>2019-08-30T15:21:28Z</published>
    <title>Latent Part-of-Speech Sequences for Neural Machine Translation</title>
    <summary>  Learning target side syntactic structure has been shown to improve Neural
Machine Translation (NMT). However, incorporating syntax through latent
variables introduces additional complexity in inference, as the models need to
marginalize over the latent syntactic structures. To avoid this, models often
resort to greedy search which only allows them to explore a limited portion of
the latent space. In this work, we introduce a new latent variable model,
LaSyn, that captures the co-dependence between syntax and semantics, while
allowing for effective and efficient inference over the latent space. LaSyn
decouples direct dependence between successive latent variables, which allows
its decoder to exhaustively search through the latent syntactic choices, while
keeping decoding speed proportional to the size of the latent variable
vocabulary. We implement LaSyn by modifying a transformer-based NMT system and
design a neural expectation maximization algorithm that we regularize with
part-of-speech information as the latent sequences. Evaluations on four
different MT tasks show that incorporating target side syntax with LaSyn
improves both translation quality, and also provides an opportunity to improve
diversity.
</summary>
    <author>
      <name>Xuewen Yang</name>
    </author>
    <author>
      <name>Yingru Liu</name>
    </author>
    <author>
      <name>Dongliang Xie</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Niranjan Balasubramanian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In proceedings of EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11722v1</id>
    <updated>2019-08-30T13:12:21Z</updated>
    <published>2019-08-30T13:12:21Z</published>
    <title>Fact-Checking Meets Fauxtography: Verifying Claims About Images</title>
    <summary>  The recent explosion of false claims in social media and on the Web in
general has given rise to a lot of manual fact-checking initiatives.
Unfortunately, the number of claims that need to be fact-checked is several
orders of magnitude larger than what humans can handle manually. Thus, there
has been a lot of research aiming at automating the process. Interestingly,
previous work has largely ignored the growing number of claims about images.
This is despite the fact that visual imagery is more influential than text and
naturally appears alongside fake news. Here we aim at bridging this gap. In
particular, we create a new dataset for this problem, and we explore a variety
of features modeling the claim, the image, and the relationship between the
claim and the image. The evaluation results show sizable improvements over the
baseline. We release our dataset, hoping to enable further research on
fact-checking claims about images.
</summary>
    <author>
      <name>Dimitrina Zlatkova</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Ivan Koychev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.11722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11521v1</id>
    <updated>2019-08-30T03:44:10Z</updated>
    <published>2019-08-30T03:44:10Z</published>
    <title>Charge-Based Prison Term Prediction with Deep Gating Network</title>
    <summary>  Judgment prediction for legal cases has attracted much research efforts for
its practice use, of which the ultimate goal is prison term prediction. While
existing work merely predicts the total prison term, in reality a defendant is
often charged with multiple crimes. In this paper, we argue that charge-based
prison term prediction (CPTP) not only better fits realistic needs, but also
makes the total prison term prediction more accurate and interpretable. We
collect the first large-scale structured data for CPTP and evaluate several
competitive baselines. Based on the observation that fine-grained feature
selection is the key to achieving good performance, we propose the Deep Gating
Network (DGN) for charge-specific feature selection and aggregation.
Experiments show that DGN achieves the state-of-the-art performance.
</summary>
    <author>
      <name>Huajie Chen</name>
    </author>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Wei Dai</name>
    </author>
    <author>
      <name>Zehui Dai</name>
    </author>
    <author>
      <name>Yadong Ding</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11355v1</id>
    <updated>2019-08-29T17:12:04Z</updated>
    <published>2019-08-29T17:12:04Z</published>
    <title>Human-grounded Evaluations of Explanation Methods for Text
  Classification</title>
    <summary>  Due to the black-box nature of deep learning models, methods for explaining
the models' results are crucial to gain trust from humans and support
collaboration between AIs and humans. In this paper, we consider several
model-agnostic and model-specific explanation methods for CNNs for text
classification and conduct three human-grounded evaluations, focusing on
different purposes of explanations: (1) revealing model behavior, (2)
justifying model predictions, and (3) helping humans investigate uncertain
predictions. The results highlight dissimilar qualities of the various
explanation methods we consider and show the degree to which these methods
could serve for each purpose.
</summary>
    <author>
      <name>Piyawat Lertvittayakumjorn</name>
    </author>
    <author>
      <name>Francesca Toni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages including appendices; accepted to appear at EMNLP-IJCNLP
  2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11317v1</id>
    <updated>2019-08-29T16:00:25Z</updated>
    <published>2019-08-29T16:00:25Z</published>
    <title>Memorizing All for Implicit Discourse Relation Recognition</title>
    <summary>  Implicit discourse relation recognition is a challenging task due to the
absence of the necessary informative clue from explicit connectives. The
prediction of relations requires a deep understanding of the semantic meanings
of sentence pairs. As implicit discourse relation recognizer has to carefully
tackle the semantic similarity of the given sentence pairs and the severe data
sparsity issue exists in the meantime, it is supposed to be beneficial from
mastering the entire training data. Thus in this paper, we propose a novel
memory mechanism to tackle the challenges for further performance improvement.
The memory mechanism is adequately memorizing information by pairing
representations and discourse relations of all training instances, which right
fills the slot of the data-hungry issue in the current implicit discourse
relation recognizer. Our experiments show that our full model with memorizing
the entire training set reaches new state-of-the-art against strong baselines,
which especially for the first time exceeds the milestone of 60% accuracy in
the 4-way task.
</summary>
    <author>
      <name>Hongxiao Bai</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <author>
      <name>Junhan Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/1908.11317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11302v1</id>
    <updated>2019-08-29T15:36:40Z</updated>
    <published>2019-08-29T15:36:40Z</published>
    <title>HARE: a Flexible Highlighting Annotator for Ranking and Exploration</title>
    <summary>  Exploration and analysis of potential data sources is a significant challenge
in the application of NLP techniques to novel information domains. We describe
HARE, a system for highlighting relevant information in document collections to
support ranking and triage, which provides tools for post-processing and
qualitative analysis for model development and tuning. We apply HARE to the use
case of narrative descriptions of mobility information in clinical data, and
demonstrate its utility in comparing candidate embedding features. We provide a
web-based interface for annotation visualization and document ranking, with a
modular backend to support interoperability with existing annotation tools. Our
system is available online at https://github.com/OSU-slatelab/HARE.
</summary>
    <author>
      <name>Denis Newman-Griffis</name>
    </author>
    <author>
      <name>Eric Fosler-Lussier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 Systems Demonstration. Online version including
  supplementary material</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11302v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11302v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11216v3</id>
    <updated>2019-09-10T08:29:00Z</updated>
    <published>2019-08-29T13:34:50Z</published>
    <title>From the Token to the Review: A Hierarchical Multimodal approach to
  Opinion Mining</title>
    <summary>  The task of predicting fine grained user opinion based on spontaneous spoken
language is a key problem arising in the development of Computational Agents as
well as in the development of social network based opinion miners.
Unfortunately, gathering reliable data on which a model can be trained is
notoriously difficult and existing works rely only on coarsely labeled
opinions. In this work we aim at bridging the gap separating fine grained
opinion models already developed for written language and coarse grained models
developed for spontaneous multimodal opinion mining. We take advantage of the
implicit hierarchical structure of opinions to build a joint fine and coarse
grained opinion model that exploits different views of the opinion expression.
The resulting model shares some properties with attention-based models and is
shown to provide competitive results on a recently released multimodal fine
grained annotated corpus.
</summary>
    <author>
      <name>Alexandre Garcia</name>
    </author>
    <author>
      <name>Pierre Colombo</name>
    </author>
    <author>
      <name>Slim Essid</name>
    </author>
    <author>
      <name>Florence d'Alché-Buc</name>
    </author>
    <author>
      <name>Chloé Clavel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to 2019 Conference on Empirical Methods in Natural Language
  Processing (EMNLP) and 9th International Joint Conference on Natural Language
  Processing (IJCNLP)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11216v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11216v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11135v1</id>
    <updated>2019-08-29T10:14:40Z</updated>
    <published>2019-08-29T10:14:40Z</published>
    <title>KBSET -- Knowledge-Based Support for Scholarly Editing and Text
  Processing</title>
    <summary>  KBSET supports a practical workflow for scholarly editing, based on using
LaTeX with dedicated commands for semantics-oriented markup and a
Prolog-implemented core system. Prolog plays there various roles: as query
language and access mechanism for large Semantic Web fact bases, as data
representation of structured documents and as a workflow model for advanced
application tasks. The core system includes a LaTeX parser and a facility for
the identification of named entities. We also sketch future perspectives of
this approach to scholarly editing based on techniques of computational logic.
</summary>
    <author>
      <name>Jana Kittelmann</name>
    </author>
    <author>
      <name>Christoph Wernhard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of DECLARE 19 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11135v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11135v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11053v1</id>
    <updated>2019-08-29T05:03:57Z</updated>
    <published>2019-08-29T05:03:57Z</published>
    <title>Leveraging Frequent Query Substructures to Generate Formal Queries for
  Complex Question Answering</title>
    <summary>  Formal query generation aims to generate correct executable queries for
question answering over knowledge bases (KBs), given entity and relation
linking results. Current approaches build universal paraphrasing or ranking
models for the whole questions, which are likely to fail in generating queries
for complex, long-tail questions. In this paper, we propose SubQG, a new query
generation approach based on frequent query substructures, which helps rank the
existing (but nonsignificant) query structures or build new query structures.
Our experiments on two benchmark datasets show that our approach significantly
outperforms the existing ones, especially for complex questions. Also, it
achieves promising performance with limited training data and noisy
entity/relation linking results.
</summary>
    <author>
      <name>Jiwei Ding</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <author>
      <name>Qixin Xu</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 2019 Conference on Empirical Methods in Natural
  Language Processing (EMNLP 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10993v1</id>
    <updated>2019-08-29T00:25:38Z</updated>
    <published>2019-08-29T00:25:38Z</published>
    <title>Scientific Statement Classification over arXiv.org</title>
    <summary>  We introduce a new classification task for scientific statements and release
a large-scale dataset for supervised learning. Our resource is derived from a
machine-readable representation of the arXiv.org collection of preprint
articles. We explore fifty author-annotated categories and empirically motivate
a task design of grouping 10.5 million annotated paragraphs into thirteen
classes. We demonstrate that the task setup aligns with known success rates
from the state of the art, peaking at a 0.91 F1-score via a BiLSTM
encoder-decoder model. Additionally, we introduce a lexeme serialization for
mathematical formulas, and observe that context-aware models could improve when
also trained on the symbolic modality. Finally, we discuss the limitations of
both data and task design, and outline potential directions towards
increasingly complex models of scientific discourse, beyond isolated
statements.
</summary>
    <author>
      <name>Deyan Ginev</name>
    </author>
    <author>
      <name>Bruce R. Miller</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10784v1</id>
    <updated>2019-08-28T15:39:02Z</updated>
    <published>2019-08-28T15:39:02Z</published>
    <title>Semantic Hypergraphs</title>
    <summary>  Existing computational methods for the analysis of corpora of text in natural
language are still far from approaching a human level of understanding. We
attempt to advance the state of the art by introducing a model and algorithmic
framework to transform text into recursively structured data. We apply this to
the analysis of news titles extracted from a social news aggregation website.
We show that a recursive ordered hypergraph is a sufficiently generic structure
to represent significant number of fundamental natural language constructs,
with advantages over conventional approaches such as semantic graphs. We
present a pipeline of transformations from the output of conventional NLP
algorithms to such hypergraphs, which we denote as semantic hypergraphs. The
features of these transformations include the creation of new concepts from
existing ones, the organisation of statements into regular structures of
predicates followed by an arbitrary number of entities and the ability to
represent statements about other statements. We demonstrate knowledge inference
from the hypergraph, identifying claims and expressions of conflicts, along
with their participating actors and topics. We show how this enables the
actor-centric summarization of conflicts, comparison of topics of claims
between actors and networks of conflicts between actors in the context of a
given topic. On the whole, we propose a hypergraphic knowledge representation
model that can be used to provide effective overviews of a large corpus of text
in natural language.
</summary>
    <author>
      <name>Telmo Menezes</name>
    </author>
    <author>
      <name>Camille Roth</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10770v1</id>
    <updated>2019-08-28T15:17:33Z</updated>
    <published>2019-08-28T15:17:33Z</published>
    <title>Data Augmentation with Atomic Templates for Spoken Language
  Understanding</title>
    <summary>  Spoken Language Understanding (SLU) converts user utterances into structured
semantic representations. Data sparsity is one of the main obstacles of SLU due
to the high cost of human annotation, especially when domain changes or a new
domain comes. In this work, we propose a data augmentation method with atomic
templates for SLU, which involves minimum human efforts. The atomic templates
produce exemplars for fine-grained constituents of semantic representations. We
propose an encoder-decoder model to generate the whole utterance from atomic
exemplars. Moreover, the generator could be transferred from source domains to
help a new domain which has little data. Experimental results show that our
method achieves significant improvements on DSTC 2\&amp;3 dataset which is a domain
adaptation setting of SLU.
</summary>
    <author>
      <name>Zijian Zhao</name>
    </author>
    <author>
      <name>Su Zhu</name>
    </author>
    <author>
      <name>Kai Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.10770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10747v1</id>
    <updated>2019-08-28T14:29:13Z</updated>
    <published>2019-08-28T14:29:13Z</published>
    <title>Language Tasks and Language Games: On Methodology in Current Natural
  Language Processing Research</title>
    <summary>  "This paper introduces a new task and a new dataset", "we improve the state
of the art in X by Y" -- it is rare to find a current natural language
processing paper (or AI paper more generally) that does not contain such
statements. What is mostly left implicit, however, is the assumption that this
necessarily constitutes progress, and what it constitutes progress towards.
Here, we make more precise the normally impressionistically used notions of
language task and language game and ask how a research programme built on these
might make progress towards the goal of modelling general language competence.
</summary>
    <author>
      <name>David Schlangen</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10731v1</id>
    <updated>2019-08-28T14:03:44Z</updated>
    <published>2019-08-28T14:03:44Z</published>
    <title>DeepCopy: Grounded Response Generation with Hierarchical Pointer
  Networks</title>
    <summary>  Recent advances in neural sequence-to-sequence models have led to promising
results for several language generation-based tasks, including dialogue
response generation, summarization, and machine translation. However, these
models are known to have several problems, especially in the context of
chit-chat based dialogue systems: they tend to generate short and dull
responses that are often too generic. Furthermore, these models do not ground
conversational responses on knowledge and facts, resulting in turns that are
not accurate, informative and engaging for the users. In this paper, we propose
and experiment with a series of response generation models that aim to serve in
the general scenario where in addition to the dialogue context, relevant
unstructured external knowledge in the form of text is also assumed to be
available for models to harness. Our proposed approach extends
pointer-generator networks (See et al., 2017) by allowing the decoder to
hierarchically attend and copy from external knowledge in addition to the
dialogue context. We empirically show the effectiveness of the proposed model
compared to several baselines including (Ghazvininejad et al., 2018; Zhang et
al., 2018) through both automatic evaluation metrics and human evaluation on
CONVAI2 dataset.
</summary>
    <author>
      <name>Semih Yavuz</name>
    </author>
    <author>
      <name>Abhinav Rastogi</name>
    </author>
    <author>
      <name>Guan-Lin Chao</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10621v1</id>
    <updated>2019-08-28T10:06:19Z</updated>
    <published>2019-08-28T10:06:19Z</published>
    <title>Onto Word Segmentation of the Complete Tang Poems</title>
    <summary>  We aim at segmenting words in the Complete Tang Poems (CTP). Although it is
possible to do some research about CTP without doing full-scale word
segmentation, we must move forward to word-level analysis of CTP for conducting
advanced research topics. In November 2018 when we submitted the manuscript for
DH 2019 (ADHO), we collected only 2433 poems that were segmented by trained
experts, and used the segmented poems to evaluate the segmenter that considered
domain knowledge of Chinese poetry. We trained pointwise mutual information
(PMI) between Chinese characters based on the CTP poems (excluding the 2433
poems, which were used exclusively only for testing) and the domain knowledge.
The segmenter relied on the PMI information to the recover 85.7% of words in
the test poems. We could segment a poem completely correct only 17.8% of the
time, however. When we presented our work at DH 2019, we have annotated more
than 20000 poems. With a much larger amount of data, we were able to apply
biLSTM models for this word segmentation task, and we segmented a poem
completely correct above 20% of the time. In contrast, human annotators
completely agreed on their annotations about 40% of the time.
</summary>
    <author>
      <name>Chao-Lin Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 tables, presented at the 2019 International Conference on
  Digital Humanities (ADHO)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.10621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10422v1</id>
    <updated>2019-08-27T19:18:09Z</updated>
    <published>2019-08-27T19:18:09Z</published>
    <title>Ensemble-Based Deep Reinforcement Learning for Chatbots</title>
    <summary>  Trainable chatbots that exhibit fluent and human-like conversations remain a
big challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is
promising for addressing this challenge, but its successful application remains
an open question. This article describes a novel ensemble-based approach
applied to value-based DRL chatbots, which use finite action sets as a form of
meaning representation. In our approach, while dialogue actions are derived
from sentence clustering, the training datasets in our ensemble are derived
from dialogue clustering. The latter aim to induce specialised agents that
learn to interact in a particular style. In order to facilitate neural chatbot
training using our proposed approach, we assume dialogue data in raw text only
-- without any manually-labelled data. Experimental results using chitchat data
reveal that (1) near human-like dialogue policies can be induced, (2)
generalisation to unseen data is a difficult problem, and (3) training an
ensemble of chatbot agents is essential for improved performance over using a
single agent. In addition to evaluations using held-out data, our results are
further supported by a human evaluation that rated dialogues in terms of
fluency, engagingness and consistency -- which revealed that our proposed
dialogue rewards strongly correlate with human judgements.
</summary>
    <author>
      <name>Heriberto Cuayáhuitl</name>
    </author>
    <author>
      <name>Donghyeon Lee</name>
    </author>
    <author>
      <name>Seonghan Ryu</name>
    </author>
    <author>
      <name>Yongjin Cho</name>
    </author>
    <author>
      <name>Sungja Choi</name>
    </author>
    <author>
      <name>Satish Indurthi</name>
    </author>
    <author>
      <name>Seunghak Yu</name>
    </author>
    <author>
      <name>Hyungtak Choi</name>
    </author>
    <author>
      <name>Inchul Hwang</name>
    </author>
    <author>
      <name>Jihie Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neucom.2019.08.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neucom.2019.08.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1908.10331</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.10422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10331v1</id>
    <updated>2019-08-27T17:06:15Z</updated>
    <published>2019-08-27T17:06:15Z</published>
    <title>Deep Reinforcement Learning for Chatbots Using Clustered Actions and
  Human-Likeness Rewards</title>
    <summary>  Training chatbots using the reinforcement learning paradigm is challenging
due to high-dimensional states, infinite action spaces and the difficulty in
specifying the reward function. We address such problems using clustered
actions instead of infinite actions, and a simple but promising reward function
based on human-likeness scores derived from human-human dialogue data. We train
Deep Reinforcement Learning (DRL) agents using chitchat data in raw
text---without any manual annotations. Experimental results using different
splits of training data report the following. First, that our agents learn
reasonable policies in the environments they get familiarised with, but their
performance drops substantially when they are exposed to a test set of unseen
dialogues. Second, that the choice of sentence embedding size between 100 and
300 dimensions is not significantly different on test data. Third, that our
proposed human-likeness rewards are reasonable for training chatbots as long as
they use lengthy dialogue histories of &gt;=10 sentences.
</summary>
    <author>
      <name>Heriberto Cuayáhuitl</name>
    </author>
    <author>
      <name>Donghyeon Lee</name>
    </author>
    <author>
      <name>Seonghan Ryu</name>
    </author>
    <author>
      <name>Sungja Choi</name>
    </author>
    <author>
      <name>Inchul Hwang</name>
    </author>
    <author>
      <name>Jihie Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In International Joint Conference of Neural Networks (IJCNN), 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.10331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10322v1</id>
    <updated>2019-08-27T16:53:59Z</updated>
    <published>2019-08-27T16:53:59Z</published>
    <title>Bridging the Gap for Tokenizer-Free Language Models</title>
    <summary>  Purely character-based language models (LMs) have been lagging in quality on
large scale datasets, and current state-of-the-art LMs rely on word
tokenization. It has been assumed that injecting the prior knowledge of a
tokenizer into the model is essential to achieving competitive results. In this
paper, we show that contrary to this conventional wisdom, tokenizer-free LMs
with sufficient capacity can achieve competitive performance on a large scale
dataset. We train a vanilla transformer network with 40 self-attention layers
on the One Billion Word (lm1b) benchmark and achieve a new state of the art for
tokenizer-free LMs, pushing these models to be on par with their word-based
counterparts.
</summary>
    <author>
      <name>Dokook Choe</name>
    </author>
    <author>
      <name>Rami Al-Rfou</name>
    </author>
    <author>
      <name>Mandy Guo</name>
    </author>
    <author>
      <name>Heeyoung Lee</name>
    </author>
    <author>
      <name>Noah Constant</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.10285v1</id>
    <updated>2019-08-27T15:44:17Z</updated>
    <published>2019-08-27T15:44:17Z</published>
    <title>Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual
  Contexts</title>
    <summary>  This work aims at modeling how the meaning of gradable adjectives of size
(`big', `small') can be learned from visually-grounded contexts. Inspired by
cognitive and linguistic evidence showing that the use of these expressions
relies on setting a threshold that is dependent on a specific context, we
investigate the ability of multi-modal models in assessing whether an object is
`big' or `small' in a given visual scene. In contrast with the standard
computational approach that simplistically treats gradable adjectives as
`fixed' attributes, we pose the problem as relational: to be successful, a
model has to consider the full visual context. By means of four main tasks, we
show that state-of-the-art models (but not a relatively strong baseline) can
learn the function subtending the meaning of size adjectives, though their
performance is found to decrease while moving from simple to more complex
tasks. Crucially, models fail in developing abstract representations of
gradable adjectives that can be used compositionally.
</summary>
    <author>
      <name>Sandro Pezzelle</name>
    </author>
    <author>
      <name>Raquel Fernández</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.10285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01860v1</id>
    <updated>2019-08-27T07:03:03Z</updated>
    <published>2019-08-27T07:03:03Z</published>
    <title>Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis</title>
    <summary>  The Visual Question Answering (VQA) task combines challenges for processing
data with both Visual and Linguistic processing, to answer basic `common sense'
questions about given images. Given an image and a question in natural
language, the VQA system tries to find the correct answer to it using visual
elements of the image and inference gathered from textual questions. In this
survey, we cover and discuss the recent datasets released in the VQA domain
dealing with various types of question-formats and enabling robustness of the
machine-learning models. Next, we discuss about new deep learning models that
have shown promising results over the VQA datasets. At the end, we present and
discuss some of the results computed by us over the vanilla VQA models, Stacked
Attention Network and the VQA Challenge 2017 winner model. We also provide the
detailed analysis along with the challenges and future research directions.
</summary>
    <author>
      <name>Yash Srivastava</name>
    </author>
    <author>
      <name>Vaishnav Murali</name>
    </author>
    <author>
      <name>Shiv Ram Dubey</name>
    </author>
    <author>
      <name>Snehasis Mukherjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">VQA Survey Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09940v2</id>
    <updated>2019-08-29T00:21:32Z</updated>
    <published>2019-08-26T22:15:55Z</published>
    <title>Don't paraphrase, detect! Rapid and Effective Data Collection for
  Semantic Parsing</title>
    <summary>  A major hurdle on the road to conversational interfaces is the difficulty in
collecting data that maps language utterances to logical forms. One prominent
approach for data collection has been to automatically generate pseudo-language
paired with logical forms, and paraphrase the pseudo-language to natural
language through crowdsourcing (Wang et al., 2015). However, this data
collection procedure often leads to low performance on real data, due to a
mismatch between the true distribution of examples and the distribution induced
by the data collection procedure. In this paper, we thoroughly analyze two
sources of mismatch in this process: the mismatch in logical form distribution
and the mismatch in language distribution between the true and induced
distributions. We quantify the effects of these mismatches, and propose a new
data collection approach that mitigates them. Assuming access to unlabeled
utterances from the true distribution, we combine crowdsourcing with a
paraphrase model to detect correct logical forms for the unlabeled utterances.
On two datasets, our method leads to 70.6 accuracy on average on the true
distribution, compared to 51.3 in paraphrasing-based data collection.
</summary>
    <author>
      <name>Jonathan Herzig</name>
    </author>
    <author>
      <name>Jonathan Berant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09940v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09940v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09890v1</id>
    <updated>2019-08-26T19:41:21Z</updated>
    <published>2019-08-26T19:41:21Z</published>
    <title>Multi-Granularity Representations of Dialog</title>
    <summary>  Neural models of dialog rely on generalized latent representations of
language. This paper introduces a novel training procedure which explicitly
learns multiple representations of language at several levels of granularity.
The multi-granularity training algorithm modifies the mechanism by which
negative candidate responses are sampled in order to control the granularity of
learned latent representations. Strong performance gains are observed on the
next utterance retrieval task using both the MultiWOZ dataset and the Ubuntu
dialog corpus. Analysis significantly demonstrates that multiple granularities
of representation are being learned, and that multi-granularity training
facilitates better transfer to downstream tasks.
</summary>
    <author>
      <name>Shikib Mehri</name>
    </author>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a long paper at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09756v2</id>
    <updated>2020-02-22T03:23:48Z</updated>
    <published>2019-08-26T15:56:10Z</published>
    <title>Differentiable Product Quantization for End-to-End Embedding Compression</title>
    <summary>  Embedding layers are commonly used to map discrete symbols into continuous
embedding vectors that reflect their semantic meanings. Despite their
effectiveness, the number of parameters in an embedding layer increases
linearly with the number of symbols and poses a critical challenge on memory
and storage constraints. In this work, we propose a generic and end-to-end
learnable compression framework termed differentiable product quantization
(DPQ). We present two instantiations of DPQ that leverage different
approximation techniques to enable differentiability in end-to-end learning.
Our method can readily serve as a drop-in alternative for any existing
embedding layer. Empirically, DPQ offers significant compression ratios
(14-238X) at negligible or no performance cost on 10 datasets across three
different language tasks.
</summary>
    <author>
      <name>Ting Chen</name>
    </author>
    <author>
      <name>Lala Li</name>
    </author>
    <author>
      <name>Yizhou Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1908.09756v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09756v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09720v2</id>
    <updated>2019-08-28T10:14:45Z</updated>
    <published>2019-08-26T15:01:24Z</published>
    <title>Ensemble approach for natural language question answering problem</title>
    <summary>  Machine comprehension, answering a question depending on a given context
paragraph is a typical task of Natural Language Understanding. It requires to
model complex dependencies existing between the question and the context
paragraph. There are many neural network models attempting to solve the problem
of question answering. The best models have been selected, studied and compared
with each other. All the selected models are based on the neural attention
mechanism concept. Additionally, studies on a SQUAD dataset were performed. The
subsets of queries were extracted and then each model was analyzed how it deals
with specific group of queries. Based on these three model ensemble model was
created and tested on SQUAD dataset. It outperforms the best Mnemonic Reader
model.
</summary>
    <author>
      <name>Anna Aniol</name>
    </author>
    <author>
      <name>Marcin Pietron</name>
    </author>
    <link href="http://arxiv.org/abs/1908.09720v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09720v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09641v1</id>
    <updated>2019-08-26T12:35:28Z</updated>
    <published>2019-08-26T12:35:28Z</published>
    <title>Semi-supervised Learning for Word Sense Disambiguation</title>
    <summary>  This work is a study of the impact of multiple aspects in a classic
unsupervised word sense disambiguation algorithm. We identify relevant factors
in a decision rule algorithm, including the initial labeling of examples, the
formalization of the rule confidence, and the criteria for accepting a decision
rule. Some of these factors are only implicitly considered in the original
literature. We then propose a lightly supervised version of the algorithm, and
employ a pseudo-word-based strategy to evaluate the impact of these factors.
The obtained performances are comparable with those of highly optimized
formulations of the word sense disambiguation method.
</summary>
    <author>
      <name>Darío Garigliotti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work was awarded the Third Place in the EST 2013 Contest (ISSN
  1850-2946) at the 42nd JAIIO (Annals of 42nd JAIIO - Argentine Journals of
  Informatics - ISSN 1850-2776)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09528v2</id>
    <updated>2019-11-21T09:15:00Z</updated>
    <published>2019-08-26T08:52:33Z</published>
    <title>Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local
  Knowledge Selection for Background Based Conversation</title>
    <summary>  Background Based Conversations (BBCs) have been introduced to help
conversational systems avoid generating overly generic responses. In a BBC, the
conversation is grounded in a knowledge source. A key challenge in BBCs is
Knowledge Selection (KS): given a conversational context, try to find the
appropriate background knowledge (a text fragment containing related facts or
comments, etc.) based on which to generate the next response. Previous work
addresses KS by employing attention and/or pointer mechanisms. These mechanisms
use a local perspective, i.e., they select a token at a time based solely on
the current decoding state. We argue for the adoption of a global perspective,
i.e., pre-selecting some text fragments from the background knowledge that
could help determine the topic of the next response. We enhance KS in BBCs by
introducing a Global-to-Local Knowledge Selection (GLKS) mechanism. Given a
conversational context and background knowledge, we first learn a topic
transition vector to encode the most likely text fragments to be used in the
next response, which is then used to guide the local KS at each decoding
timestamp. In order to effectively learn the topic transition vector, we
propose a distantly supervised learning schema. Experimental results show that
the GLKS model significantly outperforms state-of-the-art methods in terms of
both automatic and human evaluation. More importantly, GLKS achieves this
without requiring any extra annotations, which demonstrates its high degree of
scalability.
</summary>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Zhumin Chen</name>
    </author>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Jun Ma</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09528v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09528v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09203v2</id>
    <updated>2019-11-13T03:54:12Z</updated>
    <published>2019-08-24T20:41:40Z</published>
    <title>Release Strategies and the Social Impacts of Language Models</title>
    <summary>  Large language models have a range of beneficial uses: they can assist in
prose, poetry, and programming; analyze dataset biases; and more. However,
their flexibility and generative capabilities also raise misuse concerns. This
report discusses OpenAI's work related to the release of its GPT-2 language
model. It discusses staged release, which allows time between model releases to
conduct risk and benefit analyses as model sizes increased. It also discusses
ongoing partnership-based research and provides recommendations for better
coordination and responsible publication in AI.
</summary>
    <author>
      <name>Irene Solaiman</name>
    </author>
    <author>
      <name>Miles Brundage</name>
    </author>
    <author>
      <name>Jack Clark</name>
    </author>
    <author>
      <name>Amanda Askell</name>
    </author>
    <author>
      <name>Ariel Herbert-Voss</name>
    </author>
    <author>
      <name>Jeff Wu</name>
    </author>
    <author>
      <name>Alec Radford</name>
    </author>
    <author>
      <name>Gretchen Krueger</name>
    </author>
    <author>
      <name>Jong Wook Kim</name>
    </author>
    <author>
      <name>Sarah Kreps</name>
    </author>
    <author>
      <name>Miles McCain</name>
    </author>
    <author>
      <name>Alex Newhouse</name>
    </author>
    <author>
      <name>Jason Blazakis</name>
    </author>
    <author>
      <name>Kris McGuffie</name>
    </author>
    <author>
      <name>Jasmine Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">71 pages, report</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09203v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09203v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; I.2.7; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09156v1</id>
    <updated>2019-08-24T15:52:57Z</updated>
    <published>2019-08-24T15:52:57Z</published>
    <title>A framework for anomaly detection using language modeling, and its
  applications to finance</title>
    <summary>  In the finance sector, studies focused on anomaly detection are often
associated with time-series and transactional data analytics. In this paper, we
lay out the opportunities for applying anomaly and deviation detection methods
to text corpora and challenges associated with them. We argue that language
models that use distributional semantics can play a significant role in
advancing these studies in novel directions, with new applications in risk
identification, predictive modeling, and trend analysis.
</summary>
    <author>
      <name>Armineh Nourbakhsh</name>
    </author>
    <author>
      <name>Grace Bang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, presented at the 2nd KDD Workshop on Anomaly
  Detection in Finance, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09137v2</id>
    <updated>2020-02-16T13:25:41Z</updated>
    <published>2019-08-24T13:37:35Z</published>
    <title>Propagate-Selector: Detecting Supporting Sentences for Question
  Answering via Graph Neural Networks</title>
    <summary>  In this study, we propose a novel graph neural network called
propagate-selector (PS), which propagates information over sentences to
understand information that cannot be inferred when considering sentences in
isolation. First, we design a graph structure in which each node represents an
individual sentence, and some pairs of nodes are selectively connected based on
the text structure. Then, we develop an iterative attentive aggregation and a
skip-combine method in which a node interacts with its neighborhood nodes to
accumulate the necessary information. To evaluate the performance of the
proposed approaches, we conduct experiments with the standard HotpotQA dataset.
The empirical results demonstrate the superiority of our proposed approach,
which obtains the best performances, compared to the widely used
answer-selection models that do not consider the intersentential relationship.
</summary>
    <author>
      <name>Seunghyun Yoon</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Doo Soon Kim</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Kyomin Jung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Accepted as a conference paper at LREC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09137v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09137v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09080v5</id>
    <updated>2019-11-30T23:23:09Z</updated>
    <published>2019-08-24T03:10:38Z</published>
    <title>DAST Model: Deciding About Semantic Complexity of a Text</title>
    <summary>  Measuring text complexity is an essential task in several fields and
applications (such as NLP, semantic web, smart education, etc.). The semantic
layer of text is more tacit than its syntactic structure and, as a result,
calculation of semantic complexity is more difficult than syntactic complexity.
While there are famous and powerful academic and commercial syntactic
complexity measures, the problem of measuring semantic complexity is still a
challenging one. In this paper, we introduce the DAST model, which stands for
Deciding About Semantic Complexity of a Text. DAST proposes an intuitionistic
approach to semantics that lets us have a well-defined model for the semantics
of a text and its complexity: semantic is considered as a lattice of intuitions
and, as a result, semantic complexity is defined as the result of a calculation
on this lattice. A set theoretic formal definition of semantic complexity, as a
6-tuple formal system, is provided. By using this formal system, a method for
measuring semantic complexity is presented. The evaluation of the proposed
approach is done by a set of three human-judgment experiments. The results show
that DAST model is capable of deciding about semantic complexity of text.
Furthermore, the analysis of the results leads us to introduce a Markovian
model for the process of common-sense, multiple-steps and semantic-complexity
reasoning in people. The results of Experiments demonstrate that our method
outperforms the random baseline with improvement in better precision and
competes with other methods by less error percentage.
</summary>
    <author>
      <name>MohammadReza Besharati</name>
    </author>
    <author>
      <name>Mohammad Izadi</name>
    </author>
    <link href="http://arxiv.org/abs/1908.09080v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09080v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09921v1</id>
    <updated>2019-08-23T11:04:48Z</updated>
    <published>2019-08-23T11:04:48Z</published>
    <title>Toward Dialogue Modeling: A Semantic Annotation Scheme for Questions and
  Answers</title>
    <summary>  The present study proposes an annotation scheme for classifying the content
and discourse contribution of question-answer pairs. We propose detailed
guidelines for using the scheme and apply them to dialogues in English,
Spanish, and Dutch. Finally, we report on initial machine learning experiments
for automatic annotation.
</summary>
    <author>
      <name>Maria-Andrea Cruz-Blandón</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDMC</arxiv:affiliation>
    </author>
    <author>
      <name>Gosse Minnema</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDMC</arxiv:affiliation>
    </author>
    <author>
      <name>Aria Nourbakhsh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDMC</arxiv:affiliation>
    </author>
    <author>
      <name>Maria Boritchev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ENS Lyon, LORIA, SEMAGRAMME</arxiv:affiliation>
    </author>
    <author>
      <name>Maxime Amblard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SEMAGRAMME, LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LAW XIII 2019 - Linguistic Annotation Workshop - ACL Workshop, Jul
  2019, Florence, Italy</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.09921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.08594v3</id>
    <updated>2019-08-29T23:11:08Z</updated>
    <published>2019-08-23T00:58:21Z</published>
    <title>Training Optimus Prime, M.D.: Generating Medical Certification Items by
  Fine-Tuning OpenAI's gpt2 Transformer Model</title>
    <summary>  This article describes new results of an application using transformer-based
language models to automated item generation (AIG), an area of ongoing interest
in the domain of certification testing as well as in educational measurement
and psychological testing. OpenAI's gpt2 pre-trained 345M parameter language
model was retrained using the public domain text mining set of PubMed articles
and subsequently used to generate item stems (case vignettes) as well as
distractor proposals for multiple-choice items. This case study shows promise
and produces draft text that can be used by human item writers as input for
authoring. Future experiments with more recent transformer models (such as
Grover, TransformerXL) using existing item pools are expected to improve
results further and to facilitate the development of assessment materials.
</summary>
    <author>
      <name>Matthias von Davier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.08594v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08594v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.08351v2</id>
    <updated>2020-02-23T15:42:10Z</updated>
    <published>2019-08-22T13:08:26Z</published>
    <title>Compositionality decomposed: how do neural networks generalise?</title>
    <summary>  Despite a multitude of empirical studies, little consensus exists on whether
neural networks are able to generalise compositionally, a controversy that, in
part, stems from a lack of agreement about what it means for a neural model to
be compositional. As a response to this controversy, we present a set of tests
that provide a bridge between, on the one hand, the vast amount of linguistic
and philosophical theory about compositionality of language and, on the other,
the successful neural models of language. We collect different interpretations
of compositionality and translate them into five theoretically grounded tests
for models that are formulated on a task-independent level. In particular, we
provide tests to investigate (i) if models systematically recombine known parts
and rules (ii) if models can extend their predictions beyond the length they
have seen in the training data (iii) if models' composition operations are
local or global (iv) if models' predictions are robust to synonym substitutions
and (v) if models favour rules or exceptions during training. To demonstrate
the usefulness of this evaluation paradigm, we instantiate these five tests on
a highly compositional data set which we dub PCFG SET and apply the resulting
tests to three popular sequence-to-sequence models: a recurrent, a
convolution-based and a transformer model. We provide an in-depth analysis of
the results, which uncover the strengths and weaknesses of these three
architectures and point to potential areas of improvement.
</summary>
    <author>
      <name>Dieuwke Hupkes</name>
    </author>
    <author>
      <name>Verna Dankers</name>
    </author>
    <author>
      <name>Mathijs Mul</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <link href="http://arxiv.org/abs/1908.08351v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08351v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.08167v2</id>
    <updated>2019-10-02T02:28:53Z</updated>
    <published>2019-08-22T02:00:53Z</published>
    <title>Multi-passage BERT: A Globally Normalized BERT Model for Open-domain
  Question Answering</title>
    <summary>  BERT model has been successfully applied to open-domain QA tasks. However,
previous work trains BERT by viewing passages corresponding to the same
question as independent training instances, which may cause incomparable scores
for answers from different passages. To tackle this issue, we propose a
multi-passage BERT model to globally normalize answer scores across all
passages of the same question, and this change enables our QA model find better
answers by utilizing more passages. In addition, we find that splitting
articles into passages with the length of 100 words by sliding window improves
performance by 4%. By leveraging a passage ranker to select high-quality
passages, multi-passage BERT gains additional 2%. Experiments on four standard
benchmarks showed that our multi-passage BERT outperforms all state-of-the-art
models on all benchmarks. In particular, on the OpenSQuAD dataset, our model
gains 21.4% EM and 21.5% $F_1$ over all non-BERT models, and 5.8% EM and 6.5%
$F_1$ over BERT-based models.
</summary>
    <author>
      <name>Zhiguo Wang</name>
    </author>
    <author>
      <name>Patrick Ng</name>
    </author>
    <author>
      <name>Xiaofei Ma</name>
    </author>
    <author>
      <name>Ramesh Nallapati</name>
    </author>
    <author>
      <name>Bing Xiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.08167v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08167v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07795v2</id>
    <updated>2019-11-18T03:21:21Z</updated>
    <published>2019-08-21T11:07:14Z</published>
    <title>Dialog State Tracking with Reinforced Data Augmentation</title>
    <summary>  Neural dialog state trackers are generally limited due to the lack of
quantity and diversity of annotated training data. In this paper, we address
this difficulty by proposing a reinforcement learning (RL) based framework for
data augmentation that can generate high-quality data to improve the neural
state tracker. Specifically, we introduce a novel contextual bandit generator
to learn fine-grained augmentation policies that can generate new effective
instances by choosing suitable replacements for the specific context. Moreover,
by alternately learning between the generator and the state tracker, we can
keep refining the generative policies to generate more high-quality training
data for neural state tracker. Experimental results on the WoZ and MultiWoZ
(restaurant) datasets demonstrate that the proposed framework significantly
improves the performance over the state-of-the-art models, especially with
limited training data.
</summary>
    <author>
      <name>Yichun Yin</name>
    </author>
    <author>
      <name>Lifeng Shang</name>
    </author>
    <author>
      <name>Xin Jiang</name>
    </author>
    <author>
      <name>Xiao Chen</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07795v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07795v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07281v1</id>
    <updated>2019-08-20T11:40:16Z</updated>
    <published>2019-08-20T11:40:16Z</published>
    <title>Unsupervised Hierarchical Grouping of Knowledge Graph Entities</title>
    <summary>  Knowledge graphs have attracted lots of attention in academic and industrial
environments. Despite their usefulness, popular knowledge graphs suffer from
incompleteness of information, especially in their type assertions. This has
encouraged research in the automatic discovery of entity types. In this
context, multiple works were developed to utilize logical inference on
ontologies and statistical machine learning methods to learn type assertion in
knowledge graphs. However, these approaches suffer from limited performance on
noisy data, limited scalability and the dependence on labeled training samples.
In this work, we propose a new unsupervised approach that learns to categorize
entities into a hierarchy of named groups. We show that our approach is able to
effectively learn entity groups using a scalable procedure in noisy and sparse
datasets. We experiment our approach on a set of popular knowledge graph
benchmarking datasets, and we publish a collection of the outcome group
hierarchies.
</summary>
    <author>
      <name>Sameh K. Mohamed</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages - LASCAR@ESWC'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07141v1</id>
    <updated>2019-08-20T03:12:13Z</updated>
    <published>2019-08-20T03:12:13Z</published>
    <title>LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical
  Rules</title>
    <summary>  Knowledge graph embedding models have gained significant attention in AI
research. Recent works have shown that the inclusion of background knowledge,
such as logical rules, can improve the performance of embeddings in downstream
machine learning tasks. However, so far, most existing models do not allow the
inclusion of rules. We address the challenge of including rules and present a
new neural based embedding model (LogicENN). We prove that LogicENN can learn
every ground truth of encoded rules in a knowledge graph. To the best of our
knowledge, this has not been proved so far for the neural based family of
embedding models. Moreover, we derive formulae for the inclusion of various
rules, including (anti-)symmetric, inverse, irreflexive and transitive,
implication, composition, equivalence and negation. Our formulation allows to
avoid grounding for implication and equivalence relations. Our experiments show
that LogicENN outperforms the state-of-the-art models in link prediction.
</summary>
    <author>
      <name>Mojtaba Nayyeri</name>
    </author>
    <author>
      <name>Chengjin Xu</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <author>
      <name>Hamed Shariat Yazdi</name>
    </author>
    <link href="http://arxiv.org/abs/1908.07141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07064v1</id>
    <updated>2019-08-19T20:58:24Z</updated>
    <published>2019-08-19T20:58:24Z</published>
    <title>Domain-Independent turn-level Dialogue Quality Evaluation via User
  Satisfaction Estimation</title>
    <summary>  An automated metric to evaluate dialogue quality is vital for optimizing data
driven dialogue management. The common approach of relying on explicit user
feedback during a conversation is intrusive and sparse. Current models to
estimate user satisfaction use limited feature sets and rely on annotation
schemes with low inter-rater reliability, limiting generalizability to
conversations spanning multiple domains. To address these gaps, we created a
new Response Quality annotation scheme, based on which we developed turn-level
User Satisfaction metric. We introduced five new domain-independent feature
sets and experimented with six machine learning models to estimate the new
satisfaction metric.
  Using Response Quality annotation scheme, across randomly sampled single and
multi-turn conversations from 26 domains, we achieved high inter-annotator
agreement (Spearman's rho 0.94). The Response Quality labels were highly
correlated (0.76) with explicit turn-level user ratings. Gradient boosting
regression achieved best correlation of ~0.79 between predicted and annotated
user satisfaction labels. Multi Layer Perceptron and Gradient Boosting
regression models generalized to an unseen domain better (linear correlation
0.67) than other models. Finally, our ablation study verified that our novel
features significantly improved model performance.
</summary>
    <author>
      <name>Praveen Kumar Bodigutla</name>
    </author>
    <author>
      <name>Longshaokan Wang</name>
    </author>
    <author>
      <name>Kate Ridgeway</name>
    </author>
    <author>
      <name>Joshua Levy</name>
    </author>
    <author>
      <name>Swanand Joshi</name>
    </author>
    <author>
      <name>Alborz Geramifard</name>
    </author>
    <author>
      <name>Spyros Matsoukas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Implications of Deep Learning for Dialog Modeling - Special session
  at SIGdial 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07912v1</id>
    <updated>2019-08-19T19:52:50Z</updated>
    <published>2019-08-19T19:52:50Z</published>
    <title>It Takes Nine to Smell a Rat: Neural Multi-Task Learning for
  Check-Worthiness Prediction</title>
    <summary>  We propose a multi-task deep-learning approach for estimating the
check-worthiness of claims in political debates. Given a political debate, such
as the 2016 US Presidential and Vice-Presidential ones, the task is to predict
which statements in the debate should be prioritized for fact-checking. While
different fact-checking organizations would naturally make different choices
when analyzing the same debate, we show that it pays to learn from multiple
sources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago
Tribune, The Guardian, and Washington Post) in a multi-task learning setup,
even when a particular source is chosen as a target to imitate. Our evaluation
shows state-of-the-art results on a standard dataset for the task of
check-worthiness prediction.
</summary>
    <author>
      <name>Slavena Vasileva</name>
    </author>
    <author>
      <name>Pepa Atanasova</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Check-worthiness; Fact-Checking; Veracity; Multi-task Learning;
  Neural Networks. arXiv admin note: text overlap with arXiv:1908.01328</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">RANLP-2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.07912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07846v3</id>
    <updated>2020-02-06T07:28:03Z</updated>
    <published>2019-08-19T17:28:29Z</published>
    <title>Representing text as abstract images enables image classifiers to also
  simultaneously classify text</title>
    <summary>  We introduce a novel method for converting text data into abstract image
representations, which allows image-based processing techniques (e.g. image
classification networks) to be applied to text-based comparison problems. We
apply the technique to entity disambiguation of inventor names in US patents.
The method involves converting text from each pairwise comparison between two
inventor name records into a 2D RGB (stacked) image representation. We then
train an image classification neural network to discriminate between such
pairwise comparison images, and use the trained network to label each pair of
records as either matched (same inventor) or non-matched (different inventors),
obtaining highly accurate results. Our new text-to-image representation method
could also be used more broadly for other NLP comparison problems, such as
disambiguation of academic publications, or for problems that require
simultaneous classification of both text and image datasets.
</summary>
    <author>
      <name>Stephen M. Petrie</name>
    </author>
    <author>
      <name>T'Mir D. Julius</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor changes in order to submit paper to a different conference
  (e.g. made minor changes to writing in several places and added extra data to
  Table 3 in order to make it clearer)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07846v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07846v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06917v1</id>
    <updated>2019-08-19T16:31:29Z</updated>
    <published>2019-08-19T16:31:29Z</published>
    <title>Message Passing for Complex Question Answering over Knowledge Graphs</title>
    <summary>  Question answering over knowledge graphs (KGQA) has evolved from simple
single-fact questions to complex questions that require graph traversal and
aggregation. We propose a novel approach for complex KGQA that uses
unsupervised message passing, which propagates confidence scores obtained by
parsing an input question and matching terms in the knowledge graph to a set of
possible answers. First, we identify entity, relationship, and class names
mentioned in a natural language question, and map these to their counterparts
in the graph. Then, the confidence scores of these mappings propagate through
the graph structure to locate the answer entities. Finally, these are
aggregated depending on the identified question type. This approach can be
efficiently implemented as a series of sparse matrix multiplications mimicking
joins over small local subgraphs. Our evaluation results show that the proposed
approach outperforms the state-of-the-art on the LC-QuAD benchmark. Moreover,
we show that the performance of the approach depends only on the quality of the
question interpretation results, i.e., given a correct relevance score
distribution, our approach always produces a correct answer ranking. Our error
analysis reveals correct answers missing from the benchmark dataset and
inconsistencies in the DBpedia knowledge graph. Finally, we provide a
comprehensive evaluation of the proposed approach accompanied with an ablation
study and an error analysis, which showcase the pitfalls for each of the
question answering components in more detail.
</summary>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <author>
      <name>Javier David Fernandez Garcia</name>
    </author>
    <author>
      <name>Axel Polleres</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <author>
      <name>Michael Cochez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in CIKM 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.06917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06820v1</id>
    <updated>2019-08-19T14:13:24Z</updated>
    <published>2019-08-19T14:13:24Z</published>
    <title>Are You for Real? Detecting Identity Fraud via Dialogue Interactions</title>
    <summary>  Identity fraud detection is of great importance in many real-world scenarios
such as the financial industry. However, few studies addressed this problem
before. In this paper, we focus on identity fraud detection in loan
applications and propose to solve this problem with a novel interactive
dialogue system which consists of two modules. One is the knowledge graph (KG)
constructor organizing the personal information for each loan applicant. The
other is structured dialogue management that can dynamically generate a series
of questions based on the personal KG to ask the applicants and determine their
identity states. We also present a heuristic user simulator based on problem
analysis to evaluate our method. Experiments have shown that the trainable
dialogue system can effectively detect fraudsters, and achieve higher
recognition accuracy compared with rule-based systems. Furthermore, our learned
dialogue strategies are interpretable and flexible, which can help promote
real-world applications.
</summary>
    <author>
      <name>Weikang Wang</name>
    </author>
    <author>
      <name>Jiajun Zhang</name>
    </author>
    <author>
      <name>Qian Li</name>
    </author>
    <author>
      <name>Chengqing Zong</name>
    </author>
    <author>
      <name>Zhifei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP-IJCNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.06820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06556v1</id>
    <updated>2019-08-19T01:52:00Z</updated>
    <published>2019-08-19T01:52:00Z</published>
    <title>Transfer in Deep Reinforcement Learning using Knowledge Graphs</title>
    <summary>  Text adventure games, in which players must make sense of the world through
text descriptions and declare actions through text descriptions, provide a
stepping stone toward grounding action in language. Prior work has demonstrated
that using a knowledge graph as a state representation and question-answering
to pre-train a deep Q-network facilitates faster control policy transfer. In
this paper, we explore the use of knowledge graphs as a representation for
domain knowledge transfer for training text-adventure playing reinforcement
learning agents. Our methods are tested across multiple computer generated and
human authored games, varying in domain and complexity, and demonstrate that
our transfer learning methods let us learn a higher-quality control policy
faster.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/1908.06556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06449v2</id>
    <updated>2019-11-23T07:56:45Z</updated>
    <published>2019-08-18T14:49:16Z</published>
    <title>RefNet: A Reference-aware Network for Background Based Conversation</title>
    <summary>  Existing conversational systems tend to generate generic responses. Recently,
Background Based Conversations (BBCs) have been introduced to address this
issue. Here, the generated responses are grounded in some background
information. The proposed methods for BBCs are able to generate more
informative responses, they either cannot generate natural responses or have
difficulty in locating the right background information. In this paper, we
propose a Reference-aware Network (RefNet) to address the two issues. Unlike
existing methods that generate responses token by token, RefNet incorporates a
novel reference decoder that provides an alternative way to learn to directly
cite a semantic unit (e.g., a span containing complete semantic information)
from the background. Experimental results show that RefNet significantly
outperforms state-of-the-art methods in terms of both automatic and human
evaluations, indicating that RefNet can generate more appropriate and
human-like responses.
</summary>
    <author>
      <name>Chuan Meng</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Zhumin Chen</name>
    </author>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Jun Ma</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2020 (Oral)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.06449v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06449v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07822v2</id>
    <updated>2019-09-08T02:29:09Z</updated>
    <published>2019-08-18T10:34:59Z</published>
    <title>A Multi-level Neural Network for Implicit Causality Detection in Web
  Texts</title>
    <summary>  Mining causality from text is a complex and crucial natural language
understanding task. Most of the early attempts at its solution can group into
two categories: 1) utilizing co-occurrence frequency and world knowledge for
causality detection; 2) extracting cause-effect pairs by using connectives and
syntax patterns directly. However, because causality has various linguistic
expressions, the noisy data and ignoring implicit expressions problems induced
by these methods cannot be avoided. In this paper, we present a neural
causality detection model, namely Multi-level Causality Detection Network
(MCDN), to address this problem. Specifically, we adopt multi-head
self-attention to acquire semantic feature at word level and integrate a novel
Relation Network to infer causality at segment level. To the best of our
knowledge, in touch with the causality tasks, this is the first time that the
Relation Network is applied. The experimental results on the AltLex dataset,
demonstrate that: a) MCDN is highly effective for the ambiguous and implicit
causality inference; b) comparing with the regular text classification task,
causality detection requires stronger inference capability; c) the proposed
approach achieved state-of-the-art performance.
</summary>
    <author>
      <name>Shining Liang</name>
    </author>
    <author>
      <name>Wanli Zuo</name>
    </author>
    <author>
      <name>Zhenkun Shi</name>
    </author>
    <author>
      <name>Sen Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07822v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07822v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06336v2</id>
    <updated>2019-10-22T19:03:21Z</updated>
    <published>2019-08-17T20:12:39Z</published>
    <title>What is needed for simple spatial language capabilities in VQA?</title>
    <summary>  Visual question answering (VQA) comprises a variety of language capabilities.
The diagnostic benchmark dataset CLEVR has fueled progress by helping to better
assess and distinguish models in basic abilities like counting, comparing and
spatial reasoning in vitro. Following this approach, we focus on spatial
language capabilities and investigate the question: what are the key
ingredients to handle simple visual-spatial relations? We look at the SAN,
RelNet, FiLM and MC models and evaluate their learning behavior on diagnostic
data which is solely focused on spatial relations. Via comparative analysis and
targeted model modification we identify what really is required to
substantially improve upon the CNN-LSTM baseline.
</summary>
    <author>
      <name>Alexander Kuhnle</name>
    </author>
    <author>
      <name>Ann Copestake</name>
    </author>
    <link href="http://arxiv.org/abs/1908.06336v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06336v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05859v3</id>
    <updated>2020-02-01T21:21:16Z</updated>
    <published>2019-08-16T06:15:18Z</published>
    <title>Dually Interactive Matching Network for Personalized Response Selection
  in Retrieval-Based Chatbots</title>
    <summary>  This paper proposes a dually interactive matching network (DIM) for
presenting the personalities of dialogue agents in retrieval-based chatbots.
This model develops from the interactive matching network (IMN) which models
the matching degree between a context composed of multiple utterances and a
response candidate. Compared with previous persona fusion approaches which
enhance the representation of a context by calculating its similarity with a
given persona, the DIM model adopts a dual matching architecture, which
performs interactive matching between responses and contexts and between
responses and personas respectively for ranking response candidates.
Experimental results on PERSONA-CHAT dataset show that the DIM model
outperforms its baseline model, i.e., IMN with persona fusion, by a margin of
14.5% and outperforms the current state-of-the-art model by a margin of 27.7%
in terms of top-1 accuracy hits@1.
</summary>
    <author>
      <name>Jia-Chen Gu</name>
    </author>
    <author>
      <name>Zhen-Hua Ling</name>
    </author>
    <author>
      <name>Xiaodan Zhu</name>
    </author>
    <author>
      <name>Quan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.05859v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05859v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05780v1</id>
    <updated>2019-08-15T21:54:06Z</updated>
    <published>2019-08-15T21:54:06Z</published>
    <title>Natural Language Processing of Clinical Notes on Chronic Diseases:
  Systematic Review</title>
    <summary>  Of the 2652 articles considered, 106 met the inclusion criteria. Review of
the included papers resulted in identification of 43 chronic diseases, which
were then further classified into 10 disease categories using ICD-10. The
majority of studies focused on diseases of the circulatory system (n=38) while
endocrine and metabolic diseases were fewest (n=14). This was due to the
structure of clinical records related to metabolic diseases, which typically
contain much more structured data, compared with medical records for diseases
of the circulatory system, which focus more on unstructured data and
consequently have seen a stronger focus of NLP. The review has shown that there
is a significant increase in the use of machine learning methods compared to
rule-based approaches; however, deep learning methods remain emergent (n=3).
Consequently, the majority of works focus on classification of disease
phenotype with only a handful of papers addressing extraction of comorbidities
from the free text or integration of clinical notes with structured data. There
is a notable use of relatively simple methods, such as shallow classifiers (or
combination with rule-based methods), due to the interpretability of
predictions, which still represents a significant issue for more complex
methods. Finally, scarcity of publicly available data may also have contributed
to insufficient development of more advanced methods, such as extraction of
word embeddings from clinical notes. Further efforts are still required to
improve (1) progression of clinical NLP methods from extraction toward
understanding; (2) recognition of relations among entities rather than entities
in isolation; (3) temporal extraction to understand past, current, and future
clinical events; (4) exploitation of alternative sources of clinical knowledge;
and (5) availability of large-scale, de-identified clinical corpora.
</summary>
    <author>
      <name>Seyedmostafa Sheikhalishahi</name>
    </author>
    <author>
      <name>Riccardo Miotto</name>
    </author>
    <author>
      <name>Joel T Dudley</name>
    </author>
    <author>
      <name>Alberto Lavelli</name>
    </author>
    <author>
      <name>Fabio Rinaldi</name>
    </author>
    <author>
      <name>Venet Osmani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2196/12239</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2196/12239" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplementary material detailing articles reviewed, classification of
  diseases and associated algorithms, can be found at:
  http://venetosmani.com/research/publications.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JMIR Medical Informatics 2019;7(2):e12239, PMID:31066697</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.05780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07816v2</id>
    <updated>2019-09-14T17:00:07Z</updated>
    <published>2019-08-15T12:52:53Z</published>
    <title>A Multi-Turn Emotionally Engaging Dialog Model</title>
    <summary>  Open-domain dialog systems (also known as chatbots) have increasingly drawn
attention in natural language processing. Some of the recent work aims at
incorporating affect information into sequence-to-sequence neural dialog
modeling, making the response emotionally richer, while others use hand-crafted
rules to determine the desired emotion response. However, they do not
explicitly learn the subtle emotional interactions captured in human dialogs.
In this paper, we propose a multi-turn dialog system aimed at learning and
generating emotional responses that so far only humans know how to do. Compared
with two baseline models, offline experiments show that our method performs the
best in perplexity scores. Further human evaluations confirm that our chatbot
can keep track of the conversation context and generate emotionally more
appropriate responses while performing equally well on grammar.
</summary>
    <author>
      <name>Yubo Xie</name>
    </author>
    <author>
      <name>Ekaterina Svikhnushina</name>
    </author>
    <author>
      <name>Pearl Pu</name>
    </author>
    <link href="http://arxiv.org/abs/1908.07816v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07816v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05490v1</id>
    <updated>2019-08-15T10:58:57Z</updated>
    <published>2019-08-15T10:58:57Z</published>
    <title>A Multivariate Model for Representing Semantic Non-compositionality</title>
    <summary>  Semantically non-compositional phrases constitute an intriguing research
topic in Natural Language Processing. Semantic non-compositionality --the
situation when the meaning of a phrase cannot be derived from the meaning of
its components, is the main characteristic of such phrases, however, they bear
other characteristics such as high statistical association and
non-substitutability. In this work, we present a model for identifying
non-compositional phrases that takes into account all of these characteristics.
We show that the presented model remarkably outperforms the existing models of
identifying non-compositional phrases that mostly focus only on one of these
characteristics.
</summary>
    <author>
      <name>Meghdad Farahmand</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 content pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.05490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05441v1</id>
    <updated>2019-08-15T07:00:16Z</updated>
    <published>2019-08-15T07:00:16Z</published>
    <title>Multi-class Hierarchical Question Classification for Multiple Choice
  Science Exams</title>
    <summary>  Prior work has demonstrated that question classification (QC), recognizing
the problem domain of a question, can help answer it more accurately. However,
developing strong QC algorithms has been hindered by the limited size and
complexity of annotated data available. To address this, we present the largest
challenge dataset for QC, containing 7,787 science exam questions paired with
detailed classification labels from a fine-grained hierarchical taxonomy of 406
problem domains. We then show that a BERT-based model trained on this dataset
achieves a large (+0.12 MAP) gain compared with previous methods, while also
achieving state-of-the-art performance on benchmark open-domain and biomedical
QC datasets. Finally, we show that using this model's predictions of question
topic significantly improves the accuracy of a question answering system by
+1.7% P@1, with substantial future gains possible as QC performance improves.
</summary>
    <author>
      <name>Dongfang Xu</name>
    </author>
    <author>
      <name>Peter Jansen</name>
    </author>
    <author>
      <name>Jaycie Martin</name>
    </author>
    <author>
      <name>Zhengnan Xie</name>
    </author>
    <author>
      <name>Vikas Yadav</name>
    </author>
    <author>
      <name>Harish Tayyar Madabushi</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Peter Clark</name>
    </author>
    <link href="http://arxiv.org/abs/1908.05441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05135v1</id>
    <updated>2019-08-14T14:10:21Z</updated>
    <published>2019-08-14T14:10:21Z</published>
    <title>Mastering emergent language: learning to guide in simulated navigation</title>
    <summary>  To cooperate with humans effectively, virtual agents need to be able to
understand and execute language instructions. A typical setup to achieve this
is with a scripted teacher which guides a virtual agent using language
instructions. However, such setup has clear limitations in scalability and,
more importantly, it is not interactive. Here, we introduce an autonomous agent
that uses discrete communication to interactively guide other agents to
navigate and act on a simulated environment. The developed communication
protocol is trainable, emergent and requires no additional supervision. The
emergent language speeds up learning of new agents, it generalizes across
incrementally more difficult tasks and, contrary to most other emergent
languages, it is highly interpretable. We demonstrate how the emitted messages
correlate with particular actions and observations, and how new agents become
less dependent on this guidance as training progresses. By exploiting the
correlations identified in our analysis, we manage to successfully address the
agents in their own language.
</summary>
    <author>
      <name>Mathijs Mul</name>
    </author>
    <author>
      <name>Diane Bouchacourt</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <link href="http://arxiv.org/abs/1908.05135v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05135v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05117v3</id>
    <updated>2020-01-17T08:47:23Z</updated>
    <published>2019-08-14T13:34:40Z</published>
    <title>FlowDelta: Modeling Flow Information Gain in Reasoning for
  Conversational Machine Comprehension</title>
    <summary>  Conversational machine comprehension requires deep understanding of the
dialogue flow, and the prior work proposed FlowQA to implicitly model the
context representations in reasoning for better understanding. This paper
proposes to explicitly model the information gain through dialogue reasoning in
order to allow the model to focus on more informative cues. The proposed model
achieves state-of-the-art performance in a conversational QA dataset QuAC and
sequential instruction understanding dataset SCONE, which shows the
effectiveness of the proposed mechanism and demonstrates its capability of
generalization to different QA models and tasks.
</summary>
    <author>
      <name>Yi-Ting Yeh</name>
    </author>
    <author>
      <name>Yun-Nung Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 2nd Workshop on Machine Reading for Question
  Answering (MRQA), EMNLP 2019 Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.05117v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05117v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04950v1</id>
    <updated>2019-08-14T04:44:26Z</updated>
    <published>2019-08-14T04:44:26Z</published>
    <title>VideoNavQA: Bridging the Gap between Visual and Embodied Question
  Answering</title>
    <summary>  Embodied Question Answering (EQA) is a recently proposed task, where an agent
is placed in a rich 3D environment and must act based solely on its egocentric
input to answer a given question. The desired outcome is that the agent learns
to combine capabilities such as scene understanding, navigation and language
understanding in order to perform complex reasoning in the visual world.
However, initial advancements combining standard vision and language methods
with imitation and reinforcement learning algorithms have shown EQA might be
too complex and challenging for these techniques. In order to investigate the
feasibility of EQA-type tasks, we build the VideoNavQA dataset that contains
pairs of questions and videos generated in the House3D environment. The goal of
this dataset is to assess question-answering performance from nearly-ideal
navigation paths, while considering a much more complete variety of questions
than current instantiations of the EQA task. We investigate several models,
adapted from popular VQA methods, on this new benchmark. This establishes an
initial understanding of how well VQA-style methods can perform within this
novel EQA paradigm.
</summary>
    <author>
      <name>Cătălina Cangea</name>
    </author>
    <author>
      <name>Eugene Belilovsky</name>
    </author>
    <author>
      <name>Pietro Liò</name>
    </author>
    <author>
      <name>Aaron Courville</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at BMVC 2019. 15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04926v1</id>
    <updated>2019-08-14T02:07:02Z</updated>
    <published>2019-08-14T02:07:02Z</published>
    <title>Reasoning-Driven Question-Answering for Natural Language Understanding</title>
    <summary>  Natural language understanding (NLU) of text is a fundamental challenge in
AI, and it has received significant attention throughout the history of NLP
research. This primary goal has been studied under different tasks, such as
Question Answering (QA) and Textual Entailment (TE). In this thesis, we
investigate the NLU problem through the QA task and focus on the aspects that
make it a challenge for the current state-of-the-art technology. This thesis is
organized into three main parts:
  In the first part, we explore multiple formalisms to improve existing machine
comprehension systems. We propose a formulation for abductive reasoning in
natural language and show its effectiveness, especially in domains with limited
training data. Additionally, to help reasoning systems cope with irrelevant or
redundant information, we create a supervised approach to learn and detect the
essential terms in questions.
  In the second part, we propose two new challenge datasets. In particular, we
create two datasets of natural language questions where (i) the first one
requires reasoning over multiple sentences; (ii) the second one requires
temporal common sense reasoning. We hope that the two proposed datasets will
motivate the field to address more complex problems.
  In the final part, we present the first formal framework for multi-step
reasoning algorithms, in the presence of a few important properties of language
use, such as incompleteness, ambiguity, etc. We apply this framework to prove
fundamental limitations for reasoning algorithms. These theoretical results
provide extra intuition into the existing empirical evidence in the field.
</summary>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Dissertation; Presented to Computer and Information Sciences
  department, at the University of Pennsylvania</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04895v2</id>
    <updated>2019-08-17T21:45:59Z</updated>
    <published>2019-08-14T00:24:54Z</published>
    <title>HyperKG: Hyperbolic Knowledge Graph Embeddings for Knowledge Base
  Completion</title>
    <summary>  Learning embeddings of entities and relations existing in knowledge bases
allows the discovery of hidden patterns in data. In this work, we examine the
geometrical space's contribution to the task of knowledge base completion. We
focus on the family of translational models, whose performance has been
lagging, and propose a model, dubbed HyperKG, which exploits the hyperbolic
space in order to better reflect the topological properties of knowledge bases.
We investigate the type of regularities that our model can capture and we show
that it is a prominent candidate for effectively representing a subset of
Datalog rules. We empirically show, using a variety of link prediction
datasets, that hyperbolic space allows to narrow down significantly the
performance gap between translational and bilinear models.
</summary>
    <author>
      <name>Prodromos Kolyvakis</name>
    </author>
    <author>
      <name>Alexandros Kalousis</name>
    </author>
    <author>
      <name>Dimitris Kiritsis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04895v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04895v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04777v2</id>
    <updated>2019-10-01T05:13:21Z</updated>
    <published>2019-08-13T17:48:10Z</published>
    <title>Learn How to Cook a New Recipe in a New House: Using Map
  Familiarization, Curriculum Learning, and Bandit Feedback to Learn Families
  of Text-Based Adventure Games</title>
    <summary>  We consider the task of learning to play families of text-based computer
adventure games, i.e., fully textual environments with a common theme (e.g.
cooking) and goal (e.g. prepare a meal from a recipe) but with different
specifics; new instances of such games are relatively straightforward for
humans to master after a brief exposure to the genre but have been curiously
difficult for computer agents to learn. We find that the deep Q-learning
strategies that have been successfully leveraged for superhuman performance in
single-instance action video games can be applied to learn families of text
video games when adopting simple strategies that correlate with human-like
learning behavior. Specifically, we build agents that learn to tackle simple
scenarios before more complex ones using curriculum learning, that familiarize
themselves in an unfamiliar environment by navigating before acting, and that
explore uncertain environment more thoroughly using multi-armed bandit decision
policies. We demonstrate improved task completion rates over reasonable
baselines when evaluating on never-before-seen games of that theme.
</summary>
    <author>
      <name>Xusen Yin</name>
    </author>
    <author>
      <name>Jonathan May</name>
    </author>
    <link href="http://arxiv.org/abs/1908.04777v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04777v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04755v1</id>
    <updated>2019-08-13T17:20:51Z</updated>
    <published>2019-08-13T17:20:51Z</published>
    <title>Fine-grained Information Status Classification Using Discourse
  Context-Aware Self-Attention</title>
    <summary>  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a discourse context-aware self-attention neural network model
for fine-grained IS classification. On the ISNotes corpus (Markert et al.,
2012), our model with the contextually-encoded word representations (BERT)
(Devlin et al., 2018) achieves new state-of-the-art performances on
fine-grained IS classification, obtaining a 4.1% absolute overall accuracy
improvement compared to Hou et al. (2013a). More importantly, we also show an
improvement of 3.9% F1 for bridging anaphora recognition without using any
complex hand-crafted semantic features designed for capturing the bridging
phenomenon.
</summary>
    <author>
      <name>Yufang Hou</name>
    </author>
    <link href="http://arxiv.org/abs/1908.04755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06008v1</id>
    <updated>2019-08-13T13:39:19Z</updated>
    <published>2019-08-13T13:39:19Z</published>
    <title>Variational Fusion for Multimodal Sentiment Analysis</title>
    <summary>  Multimodal fusion is considered a key step in multimodal tasks such as
sentiment analysis, emotion detection, question answering, and others. Most of
the recent work on multimodal fusion does not guarantee the fidelity of the
multimodal representation with respect to the unimodal representations. In this
paper, we propose a variational autoencoder-based approach for modality fusion
that minimizes information loss between unimodal and multimodal
representations. We empirically show that this method outperforms the
state-of-the-art methods by a significant margin on several popular datasets.
</summary>
    <author>
      <name>Navonil Majumder</name>
    </author>
    <author>
      <name>Soujanya Poria</name>
    </author>
    <author>
      <name>Gangeshwar Krishnamurthy</name>
    </author>
    <author>
      <name>Niyati Chhaya</name>
    </author>
    <author>
      <name>Rada Mihalcea</name>
    </author>
    <author>
      <name>Alexander Gelbukh</name>
    </author>
    <link href="http://arxiv.org/abs/1908.06008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04621v1</id>
    <updated>2019-08-13T13:03:58Z</updated>
    <published>2019-08-13T13:03:58Z</published>
    <title>Getting To Know You: User Attribute Extraction from Dialogues</title>
    <summary>  User attributes provide rich and useful information for user understanding,
yet structured and easy-to-use attributes are often sparsely populated. In this
paper, we leverage dialogues with conversational agents, which contain strong
suggestions of user information, to automatically extract user attributes.
Since no existing dataset is available for this purpose, we apply distant
supervision to train our proposed two-stage attribute extractor, which
surpasses several retrieval and generation baselines on human evaluation.
Meanwhile, we discuss potential applications (e.g., personalized recommendation
and dialogue systems) of such extracted user attributes, and point out current
limitations to cast light on future work.
</summary>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Zhaojiang Lin</name>
    </author>
    <author>
      <name>Peng Xu</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1st Workshop on NLP for Conversational AI @ ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.05758v1</id>
    <updated>2019-08-13T03:47:03Z</updated>
    <published>2019-08-13T03:47:03Z</published>
    <title>Building a Massive Corpus for Named Entity Recognition using Free Open
  Data Sources</title>
    <summary>  With the recent progress in machine learning, boosted by techniques such as
deep learning, many tasks can be successfully solved once a large enough
dataset is available for training. Nonetheless, human-annotated datasets are
often expensive to produce, especially when labels are fine-grained, as is the
case of Named Entity Recognition (NER), a task that operates with labels on a
word-level.
  In this paper, we propose a method to automatically generate labeled datasets
for NER from public data sources by exploiting links and structured data from
DBpedia and Wikipedia. Due to the massive size of these data sources, the
resulting dataset -- SESAME Available at https://sesame-pt.github.io -- is
composed of millions of labeled sentences. We detail the method to generate the
dataset, report relevant statistics, and design a baseline using a neural
network, showing that our dataset helps building better NER predictors.
</summary>
    <author>
      <name>Daniel Specht Menezes</name>
    </author>
    <author>
      <name>Pedro Savarese</name>
    </author>
    <author>
      <name>Ruy Luiz Milidiú</name>
    </author>
    <link href="http://arxiv.org/abs/1908.05758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.03645v1</id>
    <updated>2019-08-09T22:06:06Z</updated>
    <published>2019-08-09T22:06:06Z</published>
    <title>A Generate-Validate Approach to Answering Questions about Qualitative
  Relationships</title>
    <summary>  Qualitative relationships describe how increasing or decreasing one property
(e.g. altitude) affects another (e.g. temperature). They are an important
aspect of natural language question answering and are crucial for building
chatbots or voice agents where one may enquire about qualitative relationships.
Recently a dataset about question answering involving qualitative relationships
has been proposed, and a few approaches to answer such questions have been
explored, in the heart of which lies a semantic parser that converts the
natural language input to a suitable logical form. A problem with existing
semantic parsers is that they try to directly convert the input sentences to a
logical form. Since the output language varies with each application, it forces
the semantic parser to learn almost everything from scratch. In this paper, we
show that instead of using a semantic parser to produce the logical form, if we
apply the generate-validate framework i.e. generate a natural language
description of the logical form and validate if the natural language
description is followed from the input text, we get a better scope for transfer
learning and our method outperforms the state-of-the-art by a large margin of
7.93%.
</summary>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Aurgho Bhattacharjee</name>
    </author>
    <author>
      <name>Ishan Shrivastava</name>
    </author>
    <link href="http://arxiv.org/abs/1908.03645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.03645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.02402v1</id>
    <updated>2019-08-06T23:56:25Z</updated>
    <published>2019-08-06T23:56:25Z</published>
    <title>Flexibly-Structured Model for Task-Oriented Dialogues</title>
    <summary>  This paper proposes a novel end-to-end architecture for task-oriented
dialogue systems. It is based on a simple and practical yet very effective
sequence-to-sequence approach, where language understanding and state tracking
tasks are modeled jointly with a structured copy-augmented sequential decoder
and a multi-label decoder for each slot. The policy engine and language
generation tasks are modeled jointly following that. The copy-augmented
sequential decoder deals with new or unknown values in the conversation, while
the multi-label decoder combined with the sequential decoder ensures the
explicit assignment of values to slots. On the generation part, slot binary
classifiers are used to improve performance. This architecture is scalable to
real-world scenarios and is shown through an empirical evaluation to achieve
state-of-the-art performance on both the Cambridge Restaurant dataset and the
Stanford in-car assistant dataset\footnote{The code is available at
\url{https://github.com/uber-research/FSDM}}
</summary>
    <author>
      <name>Lei Shu</name>
    </author>
    <author>
      <name>Piero Molino</name>
    </author>
    <author>
      <name>Mahdi Namazifar</name>
    </author>
    <author>
      <name>Hu Xu</name>
    </author>
    <author>
      <name>Bing Liu</name>
    </author>
    <author>
      <name>Huaixiu Zheng</name>
    </author>
    <author>
      <name>Gokhan Tur</name>
    </author>
    <link href="http://arxiv.org/abs/1908.02402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01993v1</id>
    <updated>2019-08-06T07:28:43Z</updated>
    <published>2019-08-06T07:28:43Z</published>
    <title>Co-Attention Based Neural Network for Source-Dependent Essay Scoring</title>
    <summary>  This paper presents an investigation of using a co-attention based neural
network for source-dependent essay scoring. We use a co-attention mechanism to
help the model learn the importance of each part of the essay more accurately.
Also, this paper shows that the co-attention based neural network model
provides reliable score prediction of source-dependent responses. We evaluate
our model on two source-dependent response corpora. Results show that our model
outperforms the baseline on both corpora. We also show that the attention of
the model is similar to the expert opinions with examples.
</summary>
    <author>
      <name>Haoran Zhang</name>
    </author>
    <author>
      <name>Diane Litman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/W18-0549</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/W18-0549" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in BEA 13 workshop</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Thirteenth Workshop on Innovative Use of NLP
  for Building Educational Applications (2018) 399-409</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.01993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01992v1</id>
    <updated>2019-08-06T07:24:14Z</updated>
    <published>2019-08-06T07:24:14Z</published>
    <title>eRevise: Using Natural Language Processing to Provide Formative Feedback
  on Text Evidence Usage in Student Writing</title>
    <summary>  Writing a good essay typically involves students revising an initial paper
draft after receiving feedback. We present eRevise, a web-based writing and
revising environment that uses natural language processing features generated
for rubric-based essay scoring to trigger formative feedback messages regarding
students' use of evidence in response-to-text writing. By helping students
understand the criteria for using text evidence during writing, eRevise
empowers students to better revise their paper drafts. In a pilot deployment of
eRevise in 7 classrooms spanning grades 5 and 6, the quality of text evidence
usage in writing improved after students received formative feedback then
engaged in paper revision.
</summary>
    <author>
      <name>Haoran Zhang</name>
    </author>
    <author>
      <name>Ahmed Magooda</name>
    </author>
    <author>
      <name>Diane Litman</name>
    </author>
    <author>
      <name>Richard Correnti</name>
    </author>
    <author>
      <name>Elaine Wang</name>
    </author>
    <author>
      <name>Lindsay Clare Matsumura</name>
    </author>
    <author>
      <name>Emily Howe</name>
    </author>
    <author>
      <name>Rafael Quintana</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1609/aaai.v33i01.33019619</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1609/aaai.v33i01.33019619" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in IAAI 19</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the AAAI Conference on Artificial Intelligence
  (2019) vol. 33, 9619-9625</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.01992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01969v1</id>
    <updated>2019-08-06T05:58:06Z</updated>
    <published>2019-08-06T05:58:06Z</published>
    <title>Word Embedding for Response-To-Text Assessment of Evidence</title>
    <summary>  Manually grading the Response to Text Assessment (RTA) is labor intensive.
Therefore, an automatic method is being developed for scoring analytical
writing when the RTA is administered in large numbers of classrooms. Our
long-term goal is to also use this scoring method to provide formative feedback
to students and teachers about students' writing quality. As a first step
towards this goal, interpretable features for automatically scoring the
evidence rubric of the RTA have been developed. In this paper, we present a
simple but promising method for improving evidence scoring by employing the
word embedding model. We evaluate our method on corpora of responses written by
upper elementary students.
</summary>
    <author>
      <name>Haoran Zhang</name>
    </author>
    <author>
      <name>Diane Litman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/P17-3013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/P17-3013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the ACL 2017, Student Research Workshop</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL 2017, Student Research Workshop (2017) 75-81</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.01969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01801v1</id>
    <updated>2019-08-05T18:47:30Z</updated>
    <published>2019-08-05T18:47:30Z</published>
    <title>Answering Questions about Data Visualizations using Efficient Bimodal
  Fusion</title>
    <summary>  Chart question answering (CQA) is a newly proposed visual question answering
(VQA) task where an algorithm must answer questions about data visualizations,
e.g. bar charts, pie charts, and line graphs. CQA requires capabilities that
natural-image VQA algorithms lack: fine-grained measurements, optical character
recognition, and handling out-of-vocabulary words in both questions and
answers. Without modifications, state-of-the-art VQA algorithms perform poorly
on this task. Here, we propose a novel CQA algorithm called parallel recurrent
fusion of image and language (PReFIL). PReFIL first learns bimodal embeddings
by fusing question and image features and then intelligently aggregates these
learned embeddings to answer the given question. Despite its simplicity, PReFIL
greatly surpasses state-of-the art systems and human baselines on both the
FigureQA and DVQA datasets. Additionally, we demonstrate that PReFIL can be
used to reconstruct tables by asking a series of questions about a chart.
</summary>
    <author>
      <name>Kushal Kafle</name>
    </author>
    <author>
      <name>Robik Shrestha</name>
    </author>
    <author>
      <name>Brian Price</name>
    </author>
    <author>
      <name>Scott Cohen</name>
    </author>
    <author>
      <name>Christopher Kanan</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01798v1</id>
    <updated>2019-08-05T18:28:09Z</updated>
    <published>2019-08-05T18:28:09Z</published>
    <title>Unsupervised Context Retrieval for Long-tail Entities</title>
    <summary>  Monitoring entities in media streams often relies on rich entity
representations, like structured information available in a knowledge base
(KB). For long-tail entities, such monitoring is highly challenging, due to
their limited, if not entirely missing, representation in the reference KB. In
this paper, we address the problem of retrieving textual contexts for
monitoring long-tail entities. We propose an unsupervised method to overcome
the limited representation of long-tail entities by leveraging established
entities and their contexts as support information. Evaluation on a
purpose-built test collection shows the suitability of our approach and its
robustness for out-of-KB entities.
</summary>
    <author>
      <name>Darío Garigliotti</name>
    </author>
    <author>
      <name>Dyaa Albakour</name>
    </author>
    <author>
      <name>Miguel Martinez</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3341981.3344244</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3341981.3344244" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2019 ACM International Conference on Theory of
  Information Retrieval (ICTIR' 19)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.01798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.02282v1</id>
    <updated>2019-08-05T18:14:06Z</updated>
    <published>2019-08-05T18:14:06Z</published>
    <title>A Weakly-Supervised Attention-based Visualization Tool for Assessing
  Political Affiliation</title>
    <summary>  In this work, we seek to finetune a weakly-supervised expert-guided Deep
Neural Network (DNN) for the purpose of determining political affiliations. In
this context, stance detection is used for determining political affiliation or
ideology which is framed in the form of relative proximities between entities
in a low-dimensional space. An attention-based mechanism is used to provide
model interpretability. A Deep Neural Network for Natural Language
Understanding (NLU) using static and contextual embeddings is trained and
evaluated. Various techniques to visualize the projections generated from the
network are evaluated for visualization efficiency. An overview of the pipeline
from data ingestion, processing and generation of visualization is given here.
A web-based framework created to faciliate this interaction and exploration is
presented here. Preliminary results of this study are summarized and future
work is outlined.
</summary>
    <author>
      <name>Srijith Rajamohan</name>
    </author>
    <author>
      <name>Alana Romanella</name>
    </author>
    <author>
      <name>Amit Ramesh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.02282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.02367v1</id>
    <updated>2019-08-05T09:40:18Z</updated>
    <published>2019-08-05T09:40:18Z</published>
    <title>Semantic Role Labeling with Associated Memory Network</title>
    <summary>  Semantic role labeling (SRL) is a task to recognize all the
predicate-argument pairs of a sentence, which has been in a performance
improvement bottleneck after a series of latest works were presented. This
paper proposes a novel syntax-agnostic SRL model enhanced by the proposed
associated memory network (AMN), which makes use of inter-sentence attention of
label-known associated sentences as a kind of memory to further enhance
dependency-based SRL. In detail, we use sentences and their labels from train
dataset as an associated memory cue to help label the target sentence.
Furthermore, we compare several associated sentences selecting strategies and
label merging methods in AMN to find and utilize the label of associated
sentences while attending them. By leveraging the attentive memory from known
training data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark
datasets for syntax-agnostic setting, showing a new effective research line of
SRL enhancement other than exploiting external resources such as well
pre-trained language models.
</summary>
    <author>
      <name>Chaoyu Guan</name>
    </author>
    <author>
      <name>Yuhao Cheng</name>
    </author>
    <author>
      <name>Hai Zhao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/N19-1340</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/N19-1340" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at NAACL 2019; This is camera Ready version; Code is
  available at https://github.com/Frozenmad/AMN_SRL</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.02367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01767v3</id>
    <updated>2020-03-08T23:10:16Z</updated>
    <published>2019-08-04T16:48:24Z</published>
    <title>Exploring Neural Net Augmentation to BERT for Question Answering on
  SQUAD 2.0</title>
    <summary>  Enhancing machine capabilities to answer questions has been a topic of
considerable focus in recent years of NLP research. Language models like
Embeddings from Language Models (ELMo)[1] and Bidirectional Encoder
Representations from Transformers (BERT) [2] have been very successful in
developing general purpose language models that can be optimized for a large
number of downstream language tasks. In this work, we focused on augmenting the
pre-trained BERT language model with different output neural net architectures
and compared their performance on question answering task posed by the Stanford
Question Answering Dataset 2.0 (SQUAD 2.0) [3]. Additionally, we also
fine-tuned the pre-trained BERT model parameters to demonstrate its
effectiveness in adapting to specialized language tasks. Our best output
network, is the contextualized CNN that performs on both the unanswerable and
answerable question answering tasks with F1 scores of 75.32 and 64.85
respectively.
</summary>
    <author>
      <name>Suhas Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code bug found</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.01767v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01767v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01328v1</id>
    <updated>2019-08-04T12:40:28Z</updated>
    <published>2019-08-04T12:40:28Z</published>
    <title>Automatic Fact-Checking Using Context and Discourse Information</title>
    <summary>  We study the problem of automatic fact-checking, paying special attention to
the impact of contextual and discourse information. We address two related
tasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We
develop supervised systems based on neural networks, kernel-based support
vector machines, and combinations thereof, which make use of rich input
representations in terms of discourse cues and contextual features. For the
check-worthiness estimation task, we focus on political debates, and we model
the target claim in the context of the full intervention of a participant and
the previous and the following turns in the debate, taking into account
contextual meta information. For the fact-checking task, we focus on answer
verification in a community forum, and we model the veracity of the answer with
respect to the entire question--answer thread in which it occurs as well as
with respect to other related posts from the entire forum. We develop annotated
datasets for both tasks and we run extensive experimental evaluation,
confirming that both types of information ---but especially contextual
features--- play an important role.
</summary>
    <author>
      <name>Pepa Atanasova</name>
    </author>
    <author>
      <name>Preslav Nakov</name>
    </author>
    <author>
      <name>Lluís Màrquez</name>
    </author>
    <author>
      <name>Alberto Barrón-Cedeño</name>
    </author>
    <author>
      <name>Georgi Karadzhov</name>
    </author>
    <author>
      <name>Tsvetomila Mihaylova</name>
    </author>
    <author>
      <name>Mitra Mohtarami</name>
    </author>
    <author>
      <name>James Glass</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3297722</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3297722" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">JDIQ,Special Issue on Combating Digital Misinformation and
  Disinformation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Data and Information Quality, Volume 11 Issue 3, July 2019,
  Article No. 12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.01328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.00648v1</id>
    <updated>2019-08-01T22:42:36Z</updated>
    <published>2019-08-01T22:42:36Z</published>
    <title>Contrastive Reasons Detection and Clustering from Online Polarized
  Debate</title>
    <summary>  This work tackles the problem of unsupervised modeling and extraction of the
main contrastive sentential reasons conveyed by divergent viewpoints on
polarized issues. It proposes a pipeline approach centered around the detection
and clustering of phrases, assimilated to argument facets using a novel Phrase
Author Interaction Topic-Viewpoint model. The evaluation is based on the
informativeness, the relevance and the clustering accuracy of extracted
reasons. The pipeline approach shows a significant improvement over
state-of-the-art methods in contrastive summarization on online debate
datasets.
</summary>
    <author>
      <name>Amine Trabelsi</name>
    </author>
    <author>
      <name>Osmar R. Zaiane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Best paper award in CICLing 2019: International Conference on
  Computational Linguistics and Intelligent Text Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.00648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.00286v1</id>
    <updated>2019-08-01T09:19:27Z</updated>
    <published>2019-08-01T09:19:27Z</published>
    <title>Reinforcement Learning for Personalized Dialogue Management</title>
    <summary>  Language systems have been of great interest to the research community and
have recently reached the mass market through various assistant platforms on
the web. Reinforcement Learning methods that optimize dialogue policies have
seen successes in past years and have recently been extended into methods that
personalize the dialogue, e.g. take the personal context of users into account.
These works, however, are limited to personalization to a single user with whom
they require multiple interactions and do not generalize the usage of context
across users. This work introduces a problem where a generalized usage of
context is relevant and proposes two Reinforcement Learning (RL)-based
approaches to this problem. The first approach uses a single learner and
extends the traditional POMDP formulation of dialogue state with features that
describe the user context. The second approach segments users by context and
then employs a learner per context. We compare these approaches in a benchmark
of existing non-RL and RL-based methods in three established and one novel
application domain of financial product recommendation. We compare the
influence of context and training experiences on performance and find that
learning approaches generally outperform a handcrafted gold standard.
</summary>
    <author>
      <name>Floris den Hengst</name>
    </author>
    <author>
      <name>Mark Hoogendoorn</name>
    </author>
    <author>
      <name>Frank van Harmelen</name>
    </author>
    <author>
      <name>Joost Bosman</name>
    </author>
    <link href="http://arxiv.org/abs/1908.00286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.13528v1</id>
    <updated>2019-07-31T14:37:32Z</updated>
    <published>2019-07-31T14:37:32Z</published>
    <title>What BERT is not: Lessons from a new suite of psycholinguistic
  diagnostics for language models</title>
    <summary>  Pre-training by language modeling has become a popular and successful
approach to NLP tasks, but we have yet to understand exactly what linguistic
capacities these pre-training processes confer upon models. In this paper we
introduce a suite of diagnostics drawn from human language experiments, which
allow us to ask targeted questions about the information used by language
models for generating predictions in context. As a case study, we apply these
diagnostics to the popular BERT model, finding that it can generally
distinguish good from bad completions involving shared category or role
reversal, albeit with less sensitivity than humans, and it robustly retrieves
noun hypernyms, but it struggles with challenging inferences and role-based
event prediction -- and in particular, it shows clear insensitivity to the
contextual impacts of negation.
</summary>
    <author>
      <name>Allyson Ettinger</name>
    </author>
    <link href="http://arxiv.org/abs/1907.13528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.13528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.13295v2</id>
    <updated>2019-12-21T02:25:13Z</updated>
    <published>2019-07-31T03:11:33Z</published>
    <title>Lifelong and Interactive Learning of Factual Knowledge in Dialogues</title>
    <summary>  Dialogue systems are increasingly using knowledge bases (KBs) storing
real-world facts to help generate quality responses. However, as the KBs are
inherently incomplete and remain fixed during conversation, it limits dialogue
systems' ability to answer questions and to handle questions involving entities
or relations that are not in the KB. In this paper, we make an attempt to
propose an engine for Continuous and Interactive Learning of Knowledge (CILK)
for dialogue systems to give them the ability to continuously and interactively
learn and infer new knowledge during conversations. With more knowledge
accumulated over time, they will be able to learn better and answer more
questions. Our empirical evaluation shows that CILK is promising.
</summary>
    <author>
      <name>Sahisnu Mazumder</name>
    </author>
    <author>
      <name>Bing Liu</name>
    </author>
    <author>
      <name>Shuai Wang</name>
    </author>
    <author>
      <name>Nianzu Ma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/W19-5903</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/W19-5903" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in SIGDIAL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.13295v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.13295v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12667v1</id>
    <updated>2019-07-29T21:56:35Z</updated>
    <published>2019-07-29T21:56:35Z</published>
    <title>Reinforced Dynamic Reasoning for Conversational Question Generation</title>
    <summary>  This paper investigates a new task named Conversational Question Generation
(CQG) which is to generate a question based on a passage and a conversation
history (i.e., previous turns of question-answer pairs). CQG is a crucial task
for developing intelligent agents that can drive question-answering style
conversations or test user understanding of a given passage. Towards that end,
we propose a new approach named Reinforced Dynamic Reasoning (ReDR) network,
which is based on the general encoder-decoder framework but incorporates a
reasoning procedure in a dynamic manner to better understand what has been
asked and what to ask next about the passage. To encourage producing meaningful
questions, we leverage a popular question answering (QA) model to provide
feedback and fine-tune the question generator using a reinforcement learning
mechanism. Empirical results on the recently released CoQA dataset demonstrate
the effectiveness of our method in comparison with various baselines and model
variants. Moreover, to show the applicability of our method, we also apply it
to create multi-turn question-answering conversations for passages in SQuAD.
</summary>
    <author>
      <name>Boyuan Pan</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Ziyu Yao</name>
    </author>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Huan Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12477v2</id>
    <updated>2019-09-23T17:26:35Z</updated>
    <published>2019-07-29T15:27:50Z</published>
    <title>Semantic RL with Action Grammars: Data-Efficient Learning of
  Hierarchical Task Abstractions</title>
    <summary>  Hierarchical Reinforcement Learning algorithms have successfully been applied
to temporal credit assignment problems with sparse reward signals. However,
state-of-the-art algorithms require manual specification of sub-task
structures, a sample inefficient exploration phase or lack semantic
interpretability. Humans, on the other hand, efficiently detect hierarchical
sub-structures induced by their surroundings. It has been argued that this
inference process universally applies to language, logical reasoning as well as
motor control. Therefore, we propose a cognitive-inspired Reinforcement
Learning architecture which uses grammar induction to identify sub-goal
policies. By treating an on-policy trajectory as a sentence sampled from the
policy-conditioned language of the environment, we identify hierarchical
constituents with the help of unsupervised grammatical inference. The resulting
set of temporal abstractions is called action grammar (Pastra &amp; Aloimonos,
2012) and unifies symbolic and connectionist approaches to Reinforcement
Learning. It can be used to facilitate efficient imitation, transfer and online
learning.
</summary>
    <author>
      <name>Robert Tjarko Lange</name>
    </author>
    <author>
      <name>Aldo Faisal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12477v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12477v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12293v5</id>
    <updated>2020-01-16T11:46:28Z</updated>
    <published>2019-07-29T09:25:49Z</published>
    <title>A mathematical model for universal semantics</title>
    <summary>  We present a mathematical model to characterize the meaning of words with
language-independent numerical fingerprints. Approximating texts by Markov
processes on a long-range time scale, we are able to extract topics, discover
synonyms, and sketch semantic fields from a particular document of moderate
length, without consulting external knowledge-base or thesaurus. Our Markov
semantic model allows us to represent each topical concept by a low-dimensional
vector, interpretable as algebraic invariants in succinct statistical
operations on the document, targeting local environments of individual words.
These language-independent semantic representations enable a robot reader to
both understand short texts in a given language (automated question-answering)
and match medium-length texts across different languages (automated word
translation). Our semantic fingerprints quantify local meaning of words in 14
representative languages across 5 major language families, suggesting a
universal and cost-effective mechanism by which human languages are processed
at the semantic level.
</summary>
    <author>
      <name>Weinan E</name>
    </author>
    <author>
      <name>Yajun Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Main text (6 pages, 4 figures); Supplementary Information (iii+276
  pages, 21 figures, 12 tables, available as two ancillary files)</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12293v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12293v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01839v2</id>
    <updated>2020-01-30T04:20:44Z</updated>
    <published>2019-07-28T21:04:05Z</published>
    <title>Text-to-SQL Generation for Question Answering on Electronic Medical
  Records</title>
    <summary>  Electronic medical records (EMR) contain comprehensive patient information
and are typically stored in a relational database with multiple tables.
Effective and efficient patient information retrieval from EMR data is a
challenging task for medical experts. Question-to-SQL generation methods tackle
this problem by first predicting the SQL query for a given question about a
database, and then, executing the query on the database. However, most of the
existing approaches have not been adapted to the healthcare domain due to a
lack of healthcare Question-to-SQL dataset for learning models specific to this
domain. In addition, wide use of the abbreviation of terminologies and possible
typos in questions introduce additional challenges for accurately generating
the corresponding SQL queries. In this paper, we tackle these challenges by
developing a deep learning based TRanslate-Edit Model for Question-to-SQL
(TREQS) generation, which adapts the widely used sequence-to-sequence model to
directly generate the SQL query for a given question, and further performs the
required edits using an attentive-copying mechanism and task-specific look-up
tables. Based on the widely used publicly available electronic medical
database, we create a new large-scale Question-SQL pair dataset, named
MIMICSQL, in order to perform the Question-to-SQL generation task in healthcare
domain. An extensive set of experiments are conducted to evaluate the
performance of our proposed model on MIMICSQL. Both quantitative and
qualitative experimental results indicate the flexibility and efficiency of our
proposed method in predicting condition values and its robustness to random
questions with abbreviations and typos.
</summary>
    <author>
      <name>Ping Wang</name>
    </author>
    <author>
      <name>Tian Shi</name>
    </author>
    <author>
      <name>Chandan K. Reddy</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01839v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01839v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12021v1</id>
    <updated>2019-07-28T06:15:35Z</updated>
    <published>2019-07-28T06:15:35Z</published>
    <title>What Should I Ask? Using Conversationally Informative Rewards for
  Goal-Oriented Visual Dialog</title>
    <summary>  The ability to engage in goal-oriented conversations has allowed humans to
gain knowledge, reduce uncertainty, and perform tasks more efficiently.
Artificial agents, however, are still far behind humans in having goal-driven
conversations. In this work, we focus on the task of goal-oriented visual
dialogue, aiming to automatically generate a series of questions about an image
with a single objective. This task is challenging since these questions must
not only be consistent with a strategy to achieve a goal, but also consider the
contextual information in the image. We propose an end-to-end goal-oriented
visual dialogue system, that combines reinforcement learning with regularized
information gain. Unlike previous approaches that have been proposed for the
task, our work is motivated by the Rational Speech Act framework, which models
the process of human inquiry to reach a goal. We test the two versions of our
model on the GuessWhat?! dataset, obtaining significant results that outperform
the current state-of-the-art models in the task of generating questions to find
an undisclosed object in an image.
</summary>
    <author>
      <name>Pushkar Shukla</name>
    </author>
    <author>
      <name>Carlos Elmadjian</name>
    </author>
    <author>
      <name>Richika Sharan</name>
    </author>
    <author>
      <name>Vivek Kulkarni</name>
    </author>
    <author>
      <name>Matthew Turk</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.11932v4</id>
    <updated>2020-01-23T07:16:25Z</updated>
    <published>2019-07-27T15:07:04Z</published>
    <title>Is BERT Really Robust? A Strong Baseline for Natural Language Attack on
  Text Classification and Entailment</title>
    <summary>  Machine learning algorithms are often vulnerable to adversarial examples that
have imperceptible alterations from the original counterparts but can fool the
state-of-the-art models. It is helpful to evaluate or even improve the
robustness of these models by exposing the maliciously crafted adversarial
examples. In this paper, we present TextFooler, a simple but strong baseline to
generate natural adversarial text. By applying it to two fundamental natural
language tasks, text classification and textual entailment, we successfully
attacked three target models, including the powerful pre-trained BERT, and the
widely used convolutional and recurrent neural networks. We demonstrate the
advantages of this framework in three ways: (1) effective---it outperforms
state-of-the-art attacks in terms of success rate and perturbation rate, (2)
utility-preserving---it preserves semantic content and grammaticality, and
remains correctly classified by humans, and (3) efficient---it generates
adversarial text with computational complexity linear to the text length. *The
code, pre-trained target models, and test examples are available at
https://github.com/jind11/TextFooler.
</summary>
    <author>
      <name>Di Jin</name>
    </author>
    <author>
      <name>Zhijing Jin</name>
    </author>
    <author>
      <name>Joey Tianyi Zhou</name>
    </author>
    <author>
      <name>Peter Szolovits</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020 (Oral)</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.11932v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11932v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.11889v1</id>
    <updated>2019-07-27T10:19:19Z</updated>
    <published>2019-07-27T10:19:19Z</published>
    <title>Towards Effective Rebuttal: Listening Comprehension using Corpus-Wide
  Claim Mining</title>
    <summary>  Engaging in a live debate requires, among other things, the ability to
effectively rebut arguments claimed by your opponent. In particular, this
requires identifying these arguments. Here, we suggest doing so by
automatically mining claims from a corpus of news articles containing billions
of sentences, and searching for them in a given speech. This raises the
question of whether such claims indeed correspond to those made in spoken
speeches. To this end, we collected a large dataset of $400$ speeches in
English discussing $200$ controversial topics, mined claims for each topic, and
asked annotators to identify the mined claims mentioned in each speech. Results
show that in the vast majority of speeches debaters indeed make use of such
claims. In addition, we present several baselines for the automatic detection
of mined claims in speeches, forming the basis for future work. All collected
data is freely available for research.
</summary>
    <author>
      <name>Tamar Lavee</name>
    </author>
    <author>
      <name>Matan Orbach</name>
    </author>
    <author>
      <name>Lili Kotlerman</name>
    </author>
    <author>
      <name>Yoav Kantor</name>
    </author>
    <author>
      <name>Shai Gretz</name>
    </author>
    <author>
      <name>Lena Dankin</name>
    </author>
    <author>
      <name>Shachar Mirkin</name>
    </author>
    <author>
      <name>Michal Jacovi</name>
    </author>
    <author>
      <name>Yonatan Bilu</name>
    </author>
    <author>
      <name>Ranit Aharonov</name>
    </author>
    <author>
      <name>Noam Slonim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6th Argument Mining Workshop @ ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.11889v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11889v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.11184v1</id>
    <updated>2019-07-25T16:45:06Z</updated>
    <published>2019-07-25T16:45:06Z</published>
    <title>HEIDL: Learning Linguistic Expressions with Deep Learning and
  Human-in-the-Loop</title>
    <summary>  While the role of humans is increasingly recognized in machine learning
community, representation of and interaction with models in current
human-in-the-loop machine learning (HITL-ML) approaches are too low-level and
far-removed from human's conceptual models. We demonstrate HEIDL, a prototype
HITL-ML system that exposes the machine-learned model through high-level,
explainable linguistic expressions formed of predicates representing semantic
structure of text. In HEIDL, human's role is elevated from simply evaluating
model predictions to interpreting and even updating the model logic directly by
enabling interaction with rule predicates themselves. Raising the currency of
interaction to such semantic levels calls for new interaction paradigms between
humans and machines that result in improved productivity for text analytics
model development process. Moreover, by involving humans in the process, the
human-machine co-created models generalize better to unseen data as domain
experts are able to instill their expertise by extrapolating from what has been
learned by automated algorithms from few labelled data.
</summary>
    <author>
      <name>Yiwei Yang</name>
    </author>
    <author>
      <name>Eser Kandogan</name>
    </author>
    <author>
      <name>Yunyao Li</name>
    </author>
    <author>
      <name>Walter S. Lasecki</name>
    </author>
    <author>
      <name>Prithviraj Sen</name>
    </author>
    <link href="http://arxiv.org/abs/1907.11184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.11112v1</id>
    <updated>2019-07-25T14:45:04Z</updated>
    <published>2019-07-25T14:45:04Z</published>
    <title>Using Answer Set Programming for Commonsense Reasoning in the Winograd
  Schema Challenge</title>
    <summary>  The Winograd Schema Challenge (WSC) is a natural language understanding task
proposed as an alternative to the Turing test in 2011. In this work we attempt
to solve WSC problems by reasoning with additional knowledge. By using an
approach built on top of graph-subgraph isomorphism encoded using Answer Set
Programming (ASP) we were able to handle 240 out of 291 WSC problems. The ASP
encoding allows us to add additional constraints in an elaboration tolerant
manner. In the process we present a graph based representation of WSC problems
as well as relevant commonsense knowledge. This paper is under consideration
for acceptance in TPLP.
</summary>
    <author>
      <name>Arpit Sharma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper presented at the 35th International Conference on Logic
  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,
  16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.11112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.10761v1</id>
    <updated>2019-07-24T22:30:04Z</updated>
    <published>2019-07-24T22:30:04Z</published>
    <title>Bilingual Lexicon Induction through Unsupervised Machine Translation</title>
    <summary>  A recent research line has obtained strong results on bilingual lexicon
induction by aligning independently trained word embeddings in two languages
and using the resulting cross-lingual embeddings to induce word translation
pairs through nearest neighbor or related retrieval methods. In this paper, we
propose an alternative approach to this problem that builds on the recent work
on unsupervised machine translation. This way, instead of directly inducing a
bilingual lexicon from cross-lingual embeddings, we use them to build a
phrase-table, combine it with a language model, and use the resulting machine
translation system to generate a synthetic parallel corpus, from which we
extract the bilingual lexicon using statistical word alignment techniques. As
such, our method can work with any word embedding and cross-lingual mapping
technique, and it does not require any additional resource besides the
monolingual corpus used to train the embeddings. When evaluated on the exact
same cross-lingual embeddings, our proposed method obtains an average
improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS
retrieval, establishing a new state-of-the-art in the standard MUSE dataset.
</summary>
    <author>
      <name>Mikel Artetxe</name>
    </author>
    <author>
      <name>Gorka Labaka</name>
    </author>
    <author>
      <name>Eneko Agirre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.10761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.10739v1</id>
    <updated>2019-07-24T21:37:29Z</updated>
    <published>2019-07-24T21:37:29Z</published>
    <title>Visual Interaction with Deep Learning Models through Collaborative
  Semantic Inference</title>
    <summary>  Automation of tasks can have critical consequences when humans lose agency
over decision processes. Deep learning models are particularly susceptible
since current black-box approaches lack explainable reasoning. We argue that
both the visual interface and model structure of deep learning systems need to
take into account interaction design. We propose a framework of collaborative
semantic inference (CSI) for the co-design of interactions and models to enable
visual collaboration between humans and algorithms. The approach exposes the
intermediate reasoning process of models which allows semantic interactions
with the visual metaphors of a problem, which means that a user can both
understand and control parts of the model reasoning process. We demonstrate the
feasibility of CSI with a co-designed case study of a document summarization
system.
</summary>
    <author>
      <name>Sebastian Gehrmann</name>
    </author>
    <author>
      <name>Hendrik Strobelt</name>
    </author>
    <author>
      <name>Robert Krüger</name>
    </author>
    <author>
      <name>Hanspeter Pfister</name>
    </author>
    <author>
      <name>Alexander M. Rush</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE VIS 2019 (VAST)</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.10739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.10738v1</id>
    <updated>2019-07-24T21:37:16Z</updated>
    <published>2019-07-24T21:37:16Z</published>
    <title>Careful Selection of Knowledge to solve Open Book Question Answering</title>
    <summary>  Open book question answering is a type of natural language based QA (NLQA)
where questions are expected to be answered with respect to a given set of open
book facts, and common knowledge about a topic. Recently a challenge involving
such QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus
on linguistic understanding, OpenBookQA requires deeper reasoning involving
linguistic understanding as well as reasoning with common knowledge. In this
paper we address QA with respect to the OpenBookQA dataset and combine state of
the art language models with abductive information retrieval (IR), information
gain based re-ranking, passage selection and weighted scoring to achieve 72.0%
accuracy, an 11.6% improvement over the current state of the art.
</summary>
    <author>
      <name>Pratyay Banerjee</name>
    </author>
    <author>
      <name>Kuntal Kumar Pal</name>
    </author>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <author>
      <name>Chitta Baral</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.10738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.10016v1</id>
    <updated>2019-07-23T17:20:13Z</updated>
    <published>2019-07-23T17:20:13Z</published>
    <title>Structured Fusion Networks for Dialog</title>
    <summary>  Neural dialog models have exhibited strong performance, however their
end-to-end nature lacks a representation of the explicit structure of dialog.
This results in a loss of generalizability, controllability and a data-hungry
nature. Conversely, more traditional dialog systems do have strong models of
explicit structure. This paper introduces several approaches for explicitly
incorporating structure into neural models of dialog. Structured Fusion
Networks first learn neural dialog modules corresponding to the structured
components of traditional dialog systems and then incorporate these modules in
a higher-level generative model. Structured Fusion Networks obtain strong
results on the MultiWOZ dataset, both with and without reinforcement learning.
Structured Fusion Networks are shown to have several valuable properties,
including better domain generalizability, improved performance in reduced data
scenarios and robustness to divergence during reinforcement learning.
</summary>
    <author>
      <name>Shikib Mehri</name>
    </author>
    <author>
      <name>Tejas Srinivasan</name>
    </author>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to SIGDial 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.10016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09692v1</id>
    <updated>2019-07-23T04:27:57Z</updated>
    <published>2019-07-23T04:27:57Z</published>
    <title>Discourse Marker Augmented Network with Reinforcement Learning for
  Natural Language Inference</title>
    <summary>  Natural Language Inference (NLI), also known as Recognizing Textual
Entailment (RTE), is one of the most important problems in natural language
processing. It requires to infer the logical relationship between two given
sentences. While current approaches mostly focus on the interaction
architectures of the sentences, in this paper, we propose to transfer knowledge
from some important discourse markers to augment the quality of the NLI model.
We observe that people usually use some discourse markers such as "so" or "but"
to represent the logical relationship between two sentences. These words
potentially have deep connections with the meanings of the sentences, thus can
be utilized to help improve the representations of them. Moreover, we use
reinforcement learning to optimize a new objective function with a reward
defined by the property of the NLI datasets to make full use of the labels
information. Experiments show that our method achieves the state-of-the-art
performance on several large-scale datasets.
</summary>
    <author>
      <name>Boyuan Pan</name>
    </author>
    <author>
      <name>Yazheng Yang</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <author>
      <name>Yueting Zhuang</name>
    </author>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Xiaofei He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ACL 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09671v1</id>
    <updated>2019-07-23T03:11:07Z</updated>
    <published>2019-07-23T03:11:07Z</published>
    <title>Pre-Learning Environment Representations for Data-Efficient Neural
  Instruction Following</title>
    <summary>  We consider the problem of learning to map from natural language instructions
to state transitions (actions) in a data-efficient manner. Our method takes
inspiration from the idea that it should be easier to ground language to
concepts that have already been formed through pre-linguistic observation. We
augment a baseline instruction-following learner with an initial
environment-learning phase that uses observations of language-free state
transitions to induce a suitable latent representation of actions before
processing the instruction-following training data. We show that mapping to
pre-learned representations substantially improves performance over systems
whose representations are learned from limited instructional data alone.
</summary>
    <author>
      <name>David Gaddy</name>
    </author>
    <author>
      <name>Dan Klein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09527v1</id>
    <updated>2019-07-22T18:57:14Z</updated>
    <published>2019-07-22T18:57:14Z</published>
    <title>Maximizing Stylistic Control and Semantic Accuracy in NLG: Personality
  Variation and Discourse Contrast</title>
    <summary>  Neural generation methods for task-oriented dialogue typically generate from
a meaning representation that is populated using a database of domain
information, such as a table of data describing a restaurant. While earlier
work focused solely on the semantic fidelity of outputs, recent work has
started to explore methods for controlling the style of the generated text
while simultaneously achieving semantic accuracy. Here we experiment with two
stylistic benchmark tasks, generating language that exhibits variation in
personality, and generating discourse contrast. We report a huge performance
improvement in both stylistic control and semantic accuracy over the state of
the art on both of these benchmarks. We test several different models and show
that putting stylistic conditioning in the decoder and eliminating the semantic
re-ranker used in earlier models results in more than 15 points higher BLEU for
Personality, with a reduction of semantic error to near zero. We also report an
improvement from .75 to .81 in controlling contrast and a reduction in semantic
error from 16% to 2%.
</summary>
    <author>
      <name>Vrindavan Harrison</name>
    </author>
    <author>
      <name>Lena Reed</name>
    </author>
    <author>
      <name>Shereen Oraby</name>
    </author>
    <author>
      <name>Marilyn Walker</name>
    </author>
    <link href="http://arxiv.org/abs/1907.09527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09361v1</id>
    <updated>2019-07-22T14:57:13Z</updated>
    <published>2019-07-22T14:57:13Z</published>
    <title>Introduction to Neural Network based Approaches for Question Answering
  over Knowledge Graphs</title>
    <summary>  Question answering has emerged as an intuitive way of querying structured
data sources, and has attracted significant advancements over the years. In
this article, we provide an overview over these recent advancements, focusing
on neural network based question answering systems over knowledge graphs. We
introduce readers to the challenges in the tasks, current paradigms of
approaches, discuss notable advancements, and outline the emerging trends in
the field. Through this article, we aim to provide newcomers to the field with
a suitable entry point, and ease their process of making informed decisions
while creating their own QA system.
</summary>
    <author>
      <name>Nilesh Chakraborty</name>
    </author>
    <author>
      <name>Denis Lukovnikov</name>
    </author>
    <author>
      <name>Gaurav Maheshwari</name>
    </author>
    <author>
      <name>Priyansh Trivedi</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <author>
      <name>Asja Fischer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint, under review. The first four authors contributed equally to
  this paper, and should be regarded as co-first authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09273v2</id>
    <updated>2019-07-25T21:52:08Z</updated>
    <published>2019-07-22T12:32:15Z</published>
    <title>Why Build an Assistant in Minecraft?</title>
    <summary>  In this document we describe a rationale for a research program aimed at
building an open "assistant" in the game Minecraft, in order to make progress
on the problems of natural language understanding and learning from dialogue.
</summary>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Jonathan Gray</name>
    </author>
    <author>
      <name>Kavya Srinet</name>
    </author>
    <author>
      <name>Yacine Jernite</name>
    </author>
    <author>
      <name>Armand Joulin</name>
    </author>
    <author>
      <name>Gabriel Synnaeve</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Haonan Yu</name>
    </author>
    <author>
      <name>Zhuoyuan Chen</name>
    </author>
    <author>
      <name>Siddharth Goyal</name>
    </author>
    <author>
      <name>Demi Guo</name>
    </author>
    <author>
      <name>Danielle Rothermel</name>
    </author>
    <author>
      <name>C. Lawrence Zitnick</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1907.09273v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09273v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01843v1</id>
    <updated>2019-07-22T08:25:16Z</updated>
    <published>2019-07-22T08:25:16Z</published>
    <title>GEAR: Graph-based Evidence Aggregating and Reasoning for Fact
  Verification</title>
    <summary>  Fact verification (FV) is a challenging task which requires to retrieve
relevant evidence from plain text and use the evidence to verify given claims.
Many claims require to simultaneously integrate and reason over several pieces
of evidence for verification. However, previous work employs simple models to
extract information from evidence without letting evidence communicate with
each other, e.g., merely concatenate the evidence for processing. Therefore,
these methods are unable to grasp sufficient relational and logical information
among the evidence. To alleviate this issue, we propose a graph-based evidence
aggregating and reasoning (GEAR) framework which enables information to
transfer on a fully-connected evidence graph and then utilizes different
aggregators to collect multi-evidence information. We further employ BERT, an
effective pre-trained language representation model, to improve the
performance. Experimental results on a large-scale benchmark dataset FEVER have
demonstrated that GEAR could leverage multi-evidence information for FV and
thus achieves the promising result with a test FEVER score of 67.10%. Our code
is available at https://github.com/thunlp/GEAR.
</summary>
    <author>
      <name>Jie Zhou</name>
    </author>
    <author>
      <name>Xu Han</name>
    </author>
    <author>
      <name>Cheng Yang</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <author>
      <name>Lifeng Wang</name>
    </author>
    <author>
      <name>Changcheng Li</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.01843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.08937v1</id>
    <updated>2019-07-21T09:22:50Z</updated>
    <published>2019-07-21T09:22:50Z</published>
    <title>Quantifying Similarity between Relations with Fact Distribution</title>
    <summary>  We introduce a conceptually simple and effective method to quantify the
similarity between relations in knowledge bases. Specifically, our approach is
based on the divergence between the conditional probability distributions over
entity pairs. In this paper, these distributions are parameterized by a very
simple neural network. Although computing the exact similarity is in-tractable,
we provide a sampling-based method to get a good approximation. We empirically
show the outputs of our approach significantly correlate with human judgments.
By applying our method to various tasks, we also find that (1) our approach
could effectively detect redundant relations extracted by open information
extraction (Open IE) models, that (2) even the most competitive models for
relational classification still make mistakes among very similar relations, and
that (3) our approach could be incorporated into negative sampling and softmax
classification to alleviate these mistakes. The source code and experiment
details of this paper can be obtained from
https://github.com/thunlp/relation-similarity.
</summary>
    <author>
      <name>Weize Chen</name>
    </author>
    <author>
      <name>Hao Zhu</name>
    </author>
    <author>
      <name>Xu Han</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <author>
      <name>Maosong Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.08937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09293v1</id>
    <updated>2019-07-19T01:49:37Z</updated>
    <published>2019-07-19T01:49:37Z</published>
    <title>DREAMT -- Embodied Motivational Conversational Storytelling</title>
    <summary>  Storytelling is fundamental to language, including culture, conversation and
communication in their broadest senses. It thus emerges as an essential
component of intelligent systems, including systems where natural language is
not a primary focus or where we do not usually think of a story being involved.
In this paper we explore the emergence of storytelling as a requirement in
embodied conversational agents, including its role in educational and health
interventions, as well as in a general-purpose computer interface for people
with disabilities or other constraints that prevent the use of traditional
keyboard and speech interfaces. We further present a characterization of
storytelling as an inventive fleshing out of detail according to a particular
personal perspective, and propose the DREAMT model to focus attention on the
different layers that need to be present in a character-driven storytelling
system. Most if not all aspects of the DREAMT model have arisen from or been
explored in some aspect of our implemented research systems, but currently only
at a primitive and relatively unintegrated level. However, this experience
leads us to formalize and elaborate the DREAMT model mnemonically as follows: -
Description/Dialogue/Definition/Denotation - Realization/Representation/Role -
Explanation/Education/Entertainment - Actualization/Activation -
Motivation/Modelling - Topicalization/Transformation
</summary>
    <author>
      <name>David M W Powers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; to be presented as lightning talk plus poster at StoryNLP
  on 1 August 2019 at ACL in Florence - poster pdf and powerpoint available</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.08321v3</id>
    <updated>2019-09-25T18:57:47Z</updated>
    <published>2019-07-18T23:48:21Z</published>
    <title>SentiMATE: Learning to play Chess through Natural Language Processing</title>
    <summary>  We present SentiMATE, a novel end-to-end Deep Learning model for Chess,
employing Natural Language Processing that aims to learn an effective
evaluation function assessing move quality. This function is pre-trained on the
sentiment of commentary associated with the training moves and is used to guide
and optimize the agent's game-playing decision making. The contributions of
this research are three-fold: we build and put forward both a classifier which
extracts commentary describing the quality of Chess moves in vast commentary
datasets, and a Sentiment Analysis model trained on Chess commentary to
accurately predict the quality of said moves, to then use those predictions to
evaluate the optimal next move of a Chess agent. Both classifiers achieve over
90 % classification accuracy. Lastly, we present a Chess engine, SentiMATE,
which evaluates Chess moves based on a pre-trained sentiment evaluation
function. Our results exhibit strong evidence to support our initial hypothesis
- "Can Natural Language Processing be used to train a novel and sample
efficient evaluation function in Chess Engines?" - as we integrate our
evaluation function into modern Chess engines and play against agents with
traditional Chess move evaluation functions, beating both random agents and a
DeepChess implementation at a level-one search depth - representing the number
of moves a traditional Chess agent (employing the alpha-beta search algorithm)
looks ahead in order to evaluate a given chess state.
</summary>
    <author>
      <name>Isaac Kamlish</name>
    </author>
    <author>
      <name>Isaac Bentata Chocron</name>
    </author>
    <author>
      <name>Nicholas McCarthy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for Oral at the AIIDE-19 Workshop on Artificial Intelligence
  for Strategy Games</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.08321v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08321v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.08176v1</id>
    <updated>2019-07-18T17:37:13Z</updated>
    <published>2019-07-18T17:37:13Z</published>
    <title>Querying Knowledge via Multi-Hop English Questions</title>
    <summary>  The inherent difficulty of knowledge specification and the lack of trained
specialists are some of the key obstacles on the way to making intelligent
systems based on the knowledge representation and reasoning (KRR) paradigm
commonplace. Knowledge and query authoring using natural language, especially
controlled natural language (CNL), is one of the promising approaches that
could enable domain experts, who are not trained logicians, to both create
formal knowledge and query it. In previous work, we introduced the KALM system
(Knowledge Authoring Logic Machine) that supports knowledge authoring (and
simple querying) with very high accuracy that at present is unachievable via
machine learning approaches. The present paper expands on the question
answering aspect of KALM and introduces KALM-QA (KALM for Question Answering)
that is capable of answering much more complex English questions. We show that
KALM-QA achieves 100% accuracy on an extensive suite of movie-related
questions, called MetaQA, which contains almost 29,000 test questions and over
260,000 training questions. We contrast this with a published machine learning
approach, which falls far short of this high mark.
</summary>
    <author>
      <name>Tiantian Gao</name>
    </author>
    <author>
      <name>Paul Fodor</name>
    </author>
    <author>
      <name>Michael Kifer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S1471068419000103</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S1471068419000103" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper presented at the 35th International Conference on Logic
  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,
  16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Theory and Practice of Logic Programming 19 (2019) 636-653</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1907.08176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.08015v2</id>
    <updated>2019-08-07T17:44:58Z</updated>
    <published>2019-07-18T12:39:12Z</published>
    <title>ELG: An Event Logic Graph</title>
    <summary>  The evolution and development of events have their own basic principles,
which make events happen sequentially. Therefore, the discovery of such
evolutionary patterns among events are of great value for event prediction,
decision-making and scenario design of dialog systems. However, conventional
knowledge graph mainly focuses on the entities and their relations, which
neglects the real world events. In this paper, we present a novel type of
knowledge base - Event Logic Graph (ELG), which can reveal evolutionary
patterns and development logics of real world events. Specifically, ELG is a
directed cyclic graph, whose nodes are events, and edges stand for the
sequential, causal, conditional or hypernym-hyponym (is-a) relations between
events. We constructed two domain ELG: financial domain ELG, which consists of
more than 1.5 million of event nodes and more than 1.8 million of directed
edges, and travel domain ELG, which consists of about 30 thousand of event
nodes and more than 234 thousand of directed edges. Experimental results show
that ELG is effective for the task of script event prediction.
</summary>
    <author>
      <name>Xiao Ding</name>
    </author>
    <author>
      <name>Zhongyang Li</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Kuo Liao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1805.05081</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.08015v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08015v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.07638v1</id>
    <updated>2019-07-17T16:50:16Z</updated>
    <published>2019-07-17T16:50:16Z</published>
    <title>Learning End-to-End Goal-Oriented Dialog with Maximal User Task Success
  and Minimal Human Agent Use</title>
    <summary>  Neural end-to-end goal-oriented dialog systems showed promise to reduce the
workload of human agents for customer service, as well as reduce wait time for
users. However, their inability to handle new user behavior at deployment has
limited their usage in real world. In this work, we propose an end-to-end
trainable method for neural goal-oriented dialog systems which handles new user
behaviors at deployment by transferring the dialog to a human agent
intelligently. The proposed method has three goals: 1) maximize user's task
success by transferring to human agents, 2) minimize the load on the human
agents by transferring to them only when it is essential and 3) learn online
from the human agent's responses to reduce human agents load further. We
evaluate our proposed method on a modified-bAbI dialog task that simulates the
scenario of new user behaviors occurring at test time. Experimental results
show that our proposed method is effective in achieving the desired goals.
</summary>
    <author>
      <name>Janarthanan Rajendran</name>
    </author>
    <author>
      <name>Jatin Ganhotra</name>
    </author>
    <author>
      <name>Lazaros Polymenakos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/tacl_a_00274</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/tacl_a_00274" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Author final version of article accepted for publication in TACL -
  https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00274 and oral
  presentation at ACL 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Transactions of the Association for Computational Linguistics 2019
  Vol. 7, 375-386</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1907.07638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.07638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.06773v2</id>
    <updated>2019-08-11T13:17:01Z</updated>
    <published>2019-07-15T22:16:00Z</published>
    <title>Logic Conditionals, Supervenience, and Selection Tasks</title>
    <summary>  Principles of cognitive economy would require that concepts about objects,
properties and relations should be introduced only if they simplify the
conceptualisation of a domain. Unexpectedly, classic logic conditionals,
specifying structures holding within elements of a formal conceptualisation, do
not always satisfy this crucial principle. The paper argues that this
requirement is captured by supervenience, hereby further identified as a
property necessary for compression. The resulting theory suggests an
alternative explanation of the empirical experiences observable in Wason's
selection tasks, associating human performance with conditionals on the ability
of dealing with compression, rather than with logic necessity.
</summary>
    <author>
      <name>Giovanni Sileno</name>
    </author>
    <link href="http://arxiv.org/abs/1907.06773v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06773v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.06554v1</id>
    <updated>2019-07-15T15:45:37Z</updated>
    <published>2019-07-15T15:45:37Z</published>
    <title>Asking Clarifying Questions in Open-Domain Information-Seeking
  Conversations</title>
    <summary>  Users often fail to formulate their complex information needs in a single
query. As a consequence, they may need to scan multiple result pages or
reformulate their queries, which may be a frustrating experience.
Alternatively, systems can improve user satisfaction by proactively asking
questions of the users to clarify their information needs. Asking clarifying
questions is especially important in conversational systems since they can only
return a limited number of (often only one) result(s). In this paper, we
formulate the task of asking clarifying questions in open-domain
information-seeking conversational systems. To this end, we propose an offline
evaluation methodology for the task and collect a dataset, called Qulac,
through crowdsourcing. Our dataset is built on top of the TREC Web Track
2009-2012 data and consists of over 10K question-answer pairs for 198 TREC
topics with 762 facets. Our experiments on an oracle model demonstrate that
asking only one good question leads to over 170% retrieval performance
improvement in terms of P@1, which clearly demonstrates the potential impact of
the task. We further propose a retrieval framework consisting of three
components: question retrieval, question selection, and document retrieval. In
particular, our question selection model takes into account the original query
and previous question-answer interactions while selecting the next question.
Our model significantly outperforms competitive baselines. To foster research
in this area, we have made Qulac publicly available.
</summary>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Hamed Zamani</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <author>
      <name>W. Bruce Croft</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3331184.3331265</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3331184.3331265" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in SIGIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.06554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.06226v4</id>
    <updated>2019-08-16T01:48:46Z</updated>
    <published>2019-07-14T14:19:22Z</published>
    <title>A Simple BERT-Based Approach for Lexical Simplification</title>
    <summary>  Lexical simplification (LS) aims to replace complex words in a given sentence
with their simpler alternatives of equivalent meaning. Recently unsupervised
lexical simplification approaches only rely on the complex word itself
regardless of the given sentence to generate candidate substitutions, which
will inevitably produce a large number of spurious candidates. We present a
simple BERT-based LS approach that makes use of the pre-trained unsupervised
deep bidirectional representations BERT. Despite being entirely unsupervised,
experimental results show that our approach obtains obvious improvement than
these baselines leveraging linguistic databases and parallel corpus,
outperforming the state-of-the-art by more than 11 Accuracy points on three
well-known benchmarks.
</summary>
    <author>
      <name>Jipeng Qiang</name>
    </author>
    <author>
      <name>Yun Li</name>
    </author>
    <author>
      <name>Yi Zhu</name>
    </author>
    <author>
      <name>Yunhao Yuan</name>
    </author>
    <author>
      <name>Xindong Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1907.06226v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06226v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05446v2</id>
    <updated>2019-11-28T16:59:52Z</updated>
    <published>2019-07-11T18:42:03Z</published>
    <title>General Evaluation for Instruction Conditioned Navigation using Dynamic
  Time Warping</title>
    <summary>  In instruction conditioned navigation, agents interpret natural language and
their surroundings to navigate through an environment. Datasets for studying
this task typically contain pairs of these instructions and reference
trajectories. Yet, most evaluation metrics used thus far fail to properly
account for the latter, relying instead on insufficient similarity comparisons.
We address fundamental flaws in previously used metrics and show how Dynamic
Time Warping (DTW), a long known method of measuring similarity between two
time series, can be used for evaluation of navigation agents. For such, we
define the normalized Dynamic Time Warping (nDTW) metric, that softly penalizes
deviations from the reference path, is naturally sensitive to the order of the
nodes composing each path, is suited for both continuous and graph-based
evaluations, and can be efficiently calculated. Further, we define SDTW, which
constrains nDTW to only successful paths. We collect human similarity judgments
for simulated paths and find nDTW correlates better with human rankings than
all other metrics. We also demonstrate that using nDTW as a reward signal for
Reinforcement Learning navigation agents improves their performance on both the
Room-to-Room (R2R) and Room-for-Room (R4R) datasets. The R4R results in
particular highlight the superiority of SDTW over previous success-constrained
metrics.
</summary>
    <author>
      <name>Gabriel Ilharco</name>
    </author>
    <author>
      <name>Vihan Jain</name>
    </author>
    <author>
      <name>Alexander Ku</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Thirty-third Conference on Neural Information Processing Systems
  (NeurIPS 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1907.05446v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05446v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05792v1</id>
    <updated>2019-07-11T15:55:24Z</updated>
    <published>2019-07-11T15:55:24Z</published>
    <title>Knowledge-incorporating ESIM models for Response Selection in
  Retrieval-based Dialog Systems</title>
    <summary>  Goal-oriented dialog systems, which can be trained end-to-end without
manually encoding domain-specific features, show tremendous promise in the
customer support use-case e.g. flight booking, hotel reservation, technical
support, student advising etc. These dialog systems must learn to interact with
external domain knowledge to achieve the desired goal e.g. recommending courses
to a student, booking a table at a restaurant etc. This paper presents extended
Enhanced Sequential Inference Model (ESIM) models: a) K-ESIM (Knowledge-ESIM),
which incorporates the external domain knowledge and b) T-ESIM (Targeted-ESIM),
which leverages information from similar conversations to improve the
prediction accuracy. Our proposed models and the baseline ESIM model are
evaluated on the Ubuntu and Advising datasets in the Sentence Selection track
of the latest Dialog System Technology Challenge (DSTC7), where the goal is to
find the correct next utterance, given a partial conversation, from a set of
candidates. Our preliminary results suggest that incorporating external
knowledge sources and leveraging information from similar dialogs leads to
performance improvements for predicting the next utterance.
</summary>
    <author>
      <name>Jatin Ganhotra</name>
    </author>
    <author>
      <name>Siva Sankalp Patel</name>
    </author>
    <author>
      <name>Kshitij Fadnis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Ranked 2nd on Ubuntu and 4th on Advising task in DSTC-7 Track 1.
  Accepted for an oral presentation at the DSTC-7 workshop at AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.05792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.04957v3</id>
    <updated>2019-10-13T02:09:00Z</updated>
    <published>2019-07-10T23:41:46Z</published>
    <title>Vision-and-Dialog Navigation</title>
    <summary>  Robots navigating in human environments should use language to ask for
assistance and be able to understand human responses. To study this challenge,
we introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k
embodied, human-human dialogs situated in simulated, photorealistic home
environments. The Navigator asks questions to their partner, the Oracle, who
has privileged access to the best next steps the Navigator should take
according to a shortest path planner. To train agents that search an
environment for a goal location, we define the Navigation from Dialog History
task. An agent, given a target object and a dialog history between humans
cooperating to find that object, must infer navigation actions towards the goal
in unexplored environments. We establish an initial, multi-modal
sequence-to-sequence model and demonstrate that looking farther back in the
dialog history improves performance. Sourcecode and a live interface demo can
be found at https://cvdn.dev/
</summary>
    <author>
      <name>Jesse Thomason</name>
    </author>
    <author>
      <name>Michael Murray</name>
    </author>
    <author>
      <name>Maya Cakmak</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Robot Learning (CoRL) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.04957v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04957v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05343v2</id>
    <updated>2019-07-24T15:57:19Z</updated>
    <published>2019-07-10T04:51:44Z</published>
    <title>Semantic Parsing with Dual Learning</title>
    <summary>  Semantic parsing converts natural language queries into structured logical
forms. The paucity of annotated training samples is a fundamental challenge in
this field. In this work, we develop a semantic parsing framework with the dual
learning algorithm, which enables a semantic parser to make full use of data
(labeled and even unlabeled) through a dual-learning game. This game between a
primal model (semantic parsing) and a dual model (logical form to query) forces
them to regularize each other, and can achieve feedback signals from some
prior-knowledge. By utilizing the prior-knowledge of logical form structures,
we propose a novel reward signal at the surface and semantic levels which tends
to generate complete and reasonable logical forms. Experimental results show
that our approach achieves new state-of-the-art performance on ATIS dataset and
gets competitive performance on Overnight dataset.
</summary>
    <author>
      <name>Ruisheng Cao</name>
    </author>
    <author>
      <name>Su Zhu</name>
    </author>
    <author>
      <name>Chen Liu</name>
    </author>
    <author>
      <name>Jieyu Li</name>
    </author>
    <author>
      <name>Kai Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019 Long Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.05343v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05343v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.02551v1</id>
    <updated>2019-07-10T02:29:39Z</updated>
    <published>2019-07-10T02:29:39Z</published>
    <title>Tweets Can Tell: Activity Recognition using Hybrid Long Short-Term
  Memory Model</title>
    <summary>  This paper presents techniques to detect the "offline" activity a person is
engaged in when she is tweeting (such as dining, shopping or entertainment), in
order to create a dynamic profile of the user, for uses such as better
targeting of advertisements. To this end, we propose a hybrid LSTM model for
rich contextual learning, along with studies on the effects of applying and
combining multiple LSTM based methods with different contextual features. The
hybrid model is shown to outperform a set of baselines and state-of-the-art
methods. Finally, this paper presents an orthogonal validation with a real-case
application. Our model generates an offline activity analysis for the followers
of several well-known accounts, which is quite representative of the expected
characteristics of these accounts.
</summary>
    <author>
      <name>Renhao Cui</name>
    </author>
    <author>
      <name>Gagan Agrawal</name>
    </author>
    <author>
      <name>Rajiv Ramnath</name>
    </author>
    <link href="http://arxiv.org/abs/1908.02551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05336v1</id>
    <updated>2019-07-09T12:32:40Z</updated>
    <published>2019-07-09T12:32:40Z</published>
    <title>Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a
  Correntropy Objective Function</title>
    <summary>  Translation-based embedding models have gained significant attention in link
prediction tasks for knowledge graphs. TransE is the primary model among
translation-based embeddings and is well-known for its low complexity and high
efficiency. Therefore, most of the earlier works have modified the score
function of the TransE approach in order to improve the performance of link
prediction tasks. Nevertheless, proven theoretically and experimentally, the
performance of TransE strongly depends on the loss function. Margin Ranking
Loss (MRL) has been one of the earlier loss functions which is widely used for
training TransE. However, the scores of positive triples are not necessarily
enforced to be sufficiently small to fulfill the translation from head to tail
by using relation vector (original assumption of TransE). To tackle this
problem, several loss functions have been proposed recently by adding upper
bounds and lower bounds to the scores of positive and negative samples.
Although highly effective, previously developed models suffer from an expansion
in search space for a selection of the hyperparameters (in particular the upper
and lower bounds of scores) on which the performance of the translation-based
models is highly dependent. In this paper, we propose a new loss function
dubbed Adaptive Margin Loss (AML) for training translation-based embedding
models. The formulation of the proposed loss function enables an adaptive and
automated adjustment of the margin during the learning process. Therefore,
instead of obtaining two values (upper bound and lower bound), only the center
of a margin needs to be determined. During learning, the margin is expanded
automatically until it converges. In our experiments on a set of standard
benchmark datasets including Freebase and WordNet, the effectiveness of AML is
confirmed for training TransE on link prediction tasks.
</summary>
    <author>
      <name>Mojtaba Nayyeri</name>
    </author>
    <author>
      <name>Xiaotian Zhou</name>
    </author>
    <author>
      <name>Sahar Vahdati</name>
    </author>
    <author>
      <name>Hamed Shariat Yazdi</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <link href="http://arxiv.org/abs/1907.05336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.04105v1</id>
    <updated>2019-07-09T12:01:35Z</updated>
    <published>2019-07-09T12:01:35Z</published>
    <title>On the Semantic Interpretability of Artificial Intelligence Models</title>
    <summary>  Artificial Intelligence models are becoming increasingly more powerful and
accurate, supporting or even replacing humans' decision making. But with
increased power and accuracy also comes higher complexity, making it hard for
users to understand how the model works and what the reasons behind its
predictions are. Humans must explain and justify their decisions, and so do the
AI models supporting them in this process, making semantic interpretability an
emerging field of study. In this work, we look at interpretability from a
broader point of view, going beyond the machine learning scope and covering
different AI fields such as distributional semantics and fuzzy logic, among
others. We examine and classify the models according to their nature and also
based on how they introduce interpretability features, analyzing how each
approach affects the final users and pointing to gaps that still need to be
addressed to provide more human-centered interpretability solutions.
</summary>
    <author>
      <name>Vivian S. Silva</name>
    </author>
    <author>
      <name>André Freitas</name>
    </author>
    <author>
      <name>Siegfried Handschuh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures. Submitted to AI Magazine on August, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.04105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03950v4</id>
    <updated>2019-11-25T10:02:05Z</updated>
    <published>2019-07-09T03:08:41Z</published>
    <title>Learning by Abstraction: The Neural State Machine</title>
    <summary>  We introduce the Neural State Machine, seeking to bridge the gap between the
neural and symbolic views of AI and integrate their complementary strengths for
the task of visual reasoning. Given an image, we first predict a probabilistic
graph that represents its underlying semantics and serves as a structured world
model. Then, we perform sequential reasoning over the graph, iteratively
traversing its nodes to answer a given question or draw a new inference. In
contrast to most neural architectures that are designed to closely interact
with the raw sensory data, our model operates instead in an abstract latent
space, by transforming both the visual and linguistic modalities into semantic
concept-based representations, thereby achieving enhanced transparency and
modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets
that involve compositionality, multi-step inference and diverse reasoning
skills, achieving state-of-the-art results in both cases. We provide further
experiments that illustrate the model's strong generalization capacity across
multiple dimensions, including novel compositions of concepts, changes in the
answer distribution, and unseen linguistic structures, demonstrating the
qualities and efficacy of our approach.
</summary>
    <author>
      <name>Drew A. Hudson</name>
    </author>
    <author>
      <name>Christopher D. Manning</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at NeurIPS 2019 (spotlight)</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03950v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03950v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03590v1</id>
    <updated>2019-07-08T13:16:07Z</updated>
    <published>2019-07-08T13:16:07Z</published>
    <title>Multiple Generative Models Ensemble for Knowledge-Driven Proactive
  Human-Computer Dialogue Agent</title>
    <summary>  Multiple sequence to sequence models were used to establish an end-to-end
multi-turns proactive dialogue generation agent, with the aid of data
augmentation techniques and variant encoder-decoder structure designs. A
rank-based ensemble approach was developed for boosting performance. Results
indicate that our single model, in average, makes an obvious improvement in the
terms of F1-score and BLEU over the baseline by 18.67% on the DuConv dataset.
In particular, the ensemble methods further significantly outperform the
baseline by 35.85%.
</summary>
    <author>
      <name>Zelin Dai</name>
    </author>
    <author>
      <name>Weitang Liu</name>
    </author>
    <author>
      <name>Hao Zhang</name>
    </author>
    <author>
      <name>Minghao Zhu</name>
    </author>
    <author>
      <name>Long Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures submitted to journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03399v1</id>
    <updated>2019-07-08T04:19:17Z</updated>
    <published>2019-07-08T04:19:17Z</published>
    <title>A Natural Language Corpus of Common Grounding under Continuous and
  Partially-Observable Context</title>
    <summary>  Common grounding is the process of creating, repairing and updating mutual
understandings, which is a critical aspect of sophisticated human
communication. However, traditional dialogue systems have limited capability of
establishing common ground, and we also lack task formulations which introduce
natural difficulty in terms of common grounding while enabling easy evaluation
and analysis of complex models. In this paper, we propose a minimal dialogue
task which requires advanced skills of common grounding under continuous and
partially-observable context. Based on this task formulation, we collected a
largescale dataset of 6,760 dialogues which fulfills essential requirements of
natural language corpora. Our analysis of the dataset revealed important
phenomena related to common grounding that need to be considered. Finally, we
evaluate and analyze baseline neural models on a simple subtask that requires
recognition of the created common ground. We show that simple baseline models
perform decently but leave room for further improvement. Overall, we show that
our proposed task will be a fundamental testbed where we can train, evaluate,
and analyze dialogue system's ability for sophisticated common grounding.
</summary>
    <author>
      <name>Takuma Udagawa</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03020v1</id>
    <updated>2019-07-05T20:43:30Z</updated>
    <published>2019-07-05T20:43:30Z</published>
    <title>Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues</title>
    <summary>  Machine learning approaches for building task-oriented dialogue systems
require large conversational datasets with labels to train on. We are
interested in building task-oriented dialogue systems from human-human
conversations, which may be available in ample amounts in existing customer
care center logs or can be collected from crowd workers. Annotating these
datasets can be prohibitively expensive. Recently multiple annotated
task-oriented human-machine dialogue datasets have been released, however their
annotation schema varies across different collections, even for well-defined
categories such as dialogue acts (DAs). We propose a Universal DA schema for
task-oriented dialogues and align existing annotated datasets with our schema.
Our aim is to train a Universal DA tagger (U-DAT) for task-oriented dialogues
and use it for tagging human-human conversations. We investigate multiple
datasets, propose manual and automated approaches for aligning the different
schema, and present results on a target corpus of human-human dialogues. In
unsupervised learning experiments we achieve an F1 score of 54.1% on system
turns in human-human dialogues. In a semi-supervised setup, the F1 score
increases to 57.7% which would otherwise require at least 1.7K manually
annotated turns. For new domains, we show further improvements when unlabeled
or labeled target domain data is available.
</summary>
    <author>
      <name>Shachi Paul</name>
    </author>
    <author>
      <name>Rahul Goel</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tür</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Interspeech 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.03020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03007v1</id>
    <updated>2019-07-05T19:47:10Z</updated>
    <published>2019-07-05T19:47:10Z</published>
    <title>NeuType: A Simple and Effective Neural Network Approach for Predicting
  Missing Entity Type Information in Knowledge Bases</title>
    <summary>  Knowledge bases store information about the semantic types of entities, which
can be utilized in a range of information access tasks. This information,
however, is often incomplete, due to new entities emerging on a daily basis. We
address the task of automatically assigning types to entities in a knowledge
base from a type taxonomy. Specifically, we present two neural network
architectures, which take short entity descriptions and, optionally,
information about related entities as input. Using the DBpedia knowledge base
for experimental evaluation, we demonstrate that these simple architectures
yield significant improvements over the current state of the art.
</summary>
    <author>
      <name>Jon Arne Bø Hovda</name>
    </author>
    <author>
      <name>Darío Garigliotti</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <link href="http://arxiv.org/abs/1907.03007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.02606v1</id>
    <updated>2019-07-04T21:42:29Z</updated>
    <published>2019-07-04T21:42:29Z</published>
    <title>A Road-map Towards Explainable Question Answering A Solution for
  Information Pollution</title>
    <summary>  The increasing rate of information pollution on the Web requires novel
solutions to tackle that. Question Answering (QA) interfaces are simplified and
user-friendly interfaces to access information on the Web. However, similar to
other AI applications, they are black boxes which do not manifest the details
of the learning or reasoning steps for augmenting an answer. The Explainable
Question Answering (XQA) system can alleviate the pain of information pollution
where it provides transparency to the underlying computational model and
exposes an interface enabling the end-user to access and validate provenance,
validity, context, circulation, interpretation, and feedbacks of information.
This position paper sheds light on the core concepts, expectations, and
challenges in favor of the following questions (i) What is an XQA system?, (ii)
Why do we need XQA?, (iii) When do we need XQA? (iv) How to represent the
explanations? (iv) How to evaluate XQA systems?
</summary>
    <author>
      <name>Saeedeh Shekarpour</name>
    </author>
    <author>
      <name>Faisal Alshargi</name>
    </author>
    <link href="http://arxiv.org/abs/1907.02606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.02606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.02031v1</id>
    <updated>2019-07-03T16:53:28Z</updated>
    <published>2019-07-03T16:53:28Z</published>
    <title>Combining Q&amp;A Pair Quality and Question Relevance Features on
  Community-based Question Retrieval</title>
    <summary>  The Q&amp;A community has become an important way for people to access knowledge
and information from the Internet. However, the existing translation based on
models does not consider the query specific semantics when assigning weights to
query terms in question retrieval. So we improve the term weighting model based
on the traditional topic translation model and further considering the quality
characteristics of question and answer pairs, this paper proposes a
communitybased question retrieval method that combines question and answer on
quality and question relevance (T2LM+). We have also proposed a question
retrieval method based on convolutional neural networks. The results show that
Compared with the relatively advanced methods, the two methods proposed in this
paper increase MAP by 4.91% and 6.31%.
</summary>
    <author>
      <name>Dong Li</name>
    </author>
    <author>
      <name>Lin Li</name>
    </author>
    <link href="http://arxiv.org/abs/1907.02031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.02031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.02022v2</id>
    <updated>2019-11-26T18:52:33Z</updated>
    <published>2019-07-03T16:39:05Z</published>
    <title>Chasing Ghosts: Instruction Following as Bayesian State Tracking</title>
    <summary>  A visually-grounded navigation instruction can be interpreted as a sequence
of expected observations and actions an agent following the correct trajectory
would encounter and perform. Based on this intuition, we formulate the problem
of finding the goal location in Vision-and-Language Navigation (VLN) within the
framework of Bayesian state tracking - learning observation and motion models
conditioned on these expectable events. Together with a mapper that constructs
a semantic spatial map on-the-fly during navigation, we formulate an end-to-end
differentiable Bayes filter and train it to identify the goal by predicting the
most likely trajectory through the map according to the instructions. The
resulting navigation policy constitutes a new approach to instruction following
that explicitly models a probability distribution over states, encoding strong
geometric and algorithmic priors while enabling greater explainability. Our
experiments show that our approach outperforms a strong LingUNet baseline when
predicting the goal location on the map. On the full VLN task, i.e. navigating
to the goal location, our approach achieves promising results with less
reliance on navigation constraints.
</summary>
    <author>
      <name>Peter Anderson</name>
    </author>
    <author>
      <name>Ayush Shrivastava</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <author>
      <name>Stefan Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.02022v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.02022v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01791v1</id>
    <updated>2019-07-03T08:39:14Z</updated>
    <published>2019-07-03T08:39:14Z</published>
    <title>Multi-Task Networks With Universe, Group, and Task Feature Learning</title>
    <summary>  We present methods for multi-task learning that take advantage of natural
groupings of related tasks. Task groups may be defined along known properties
of the tasks, such as task domain or language. Such task groups represent
supervised information at the inter-task level and can be encoded into the
model. We investigate two variants of neural network architectures that
accomplish this, learning different feature spaces at the levels of individual
tasks, task groups, as well as the universe of all tasks: (1) parallel
architectures encode each input simultaneously into feature spaces at different
levels; (2) serial architectures encode each input successively into feature
spaces at different levels in the task hierarchy. We demonstrate the methods on
natural language understanding (NLU) tasks, where a grouping of tasks into
different task domains leads to improved performance on ATIS, Snips, and a
large inhouse dataset.
</summary>
    <author>
      <name>Shiva Pentyala</name>
    </author>
    <author>
      <name>Mengwen Liu</name>
    </author>
    <author>
      <name>Markus Dreyer</name>
    </author>
    <link href="http://arxiv.org/abs/1907.01791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01752v4</id>
    <updated>2020-01-15T07:19:09Z</updated>
    <published>2019-07-03T06:15:14Z</published>
    <title>On the Weaknesses of Reinforcement Learning for Neural Machine
  Translation</title>
    <summary>  Reinforcement learning (RL) is frequently used to increase performance in
text generation tasks, including machine translation (MT), notably through the
use of Minimum Risk Training (MRT) and Generative Adversarial Networks (GAN).
However, little is known about what and how these methods learn in the context
of MT. We prove that one of the most common RL methods for MT does not optimize
the expected reward, as well as show that other methods take an infeasibly long
time to converge. In fact, our results suggest that RL practices in MT are
likely to improve performance only where the pre-trained parameters are already
close to yielding the correct translation. Our findings further suggest that
observed gains may be due to effects unrelated to the training signal, but
rather from changes in the shape of the distribution curve.
</summary>
    <author>
      <name>Leshem Choshen</name>
    </author>
    <author>
      <name>Lior Fox</name>
    </author>
    <author>
      <name>Zohar Aizenbud</name>
    </author>
    <author>
      <name>Omri Abend</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICLR 2020 (matching content, different style)</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01752v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01752v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01669v4</id>
    <updated>2019-12-03T22:41:37Z</updated>
    <published>2019-07-02T22:30:31Z</published>
    <title>MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State
  Corrections and State Tracking Baselines</title>
    <summary>  MultiWOZ 2.0 (Budzianowski et al., 2018) is a recently released multi-domain
dialogue dataset spanning 7 distinct domains and containing over 10,000
dialogues. Though immensely useful and one of the largest resources of its kind
to-date, MultiWOZ 2.0 has a few shortcomings. Firstly, there is substantial
noise in the dialogue state annotations and dialogue utterances which
negatively impact the performance of state-tracking models. Secondly, follow-up
work (Lee et al., 2019) has augmented the original dataset with user dialogue
acts. This leads to multiple co-existent versions of the same dataset with
minor modifications. In this work we tackle the aforementioned issues by
introducing MultiWOZ 2.1. To fix the noisy state annotations, we use
crowdsourced workers to re-annotate state and utterances based on the original
utterances in the dataset. This correction process results in changes to over
32% of state annotations across 40% of the dialogue turns. In addition, we fix
146 dialogue utterances by canonicalizing slot values in the utterances to the
values in the dataset ontology. To address the second problem, we combined the
contributions of the follow-up works into MultiWOZ 2.1. Hence, our dataset also
includes user dialogue acts as well as multiple slot descriptions per dialogue
state slot. We then benchmark a number of state-of-the-art dialogue state
tracking models on the MultiWOZ 2.1 dataset and show the joint state tracking
performance on the corrected state annotations. We are publicly releasing
MultiWOZ 2.1 to the community, hoping that this dataset resource will allow for
more effective models across various dialogue subproblems to be built in the
future.
</summary>
    <author>
      <name>Mihail Eric</name>
    </author>
    <author>
      <name>Rahul Goel</name>
    </author>
    <author>
      <name>Shachi Paul</name>
    </author>
    <author>
      <name>Adarsh Kumar</name>
    </author>
    <author>
      <name>Abhishek Sethi</name>
    </author>
    <author>
      <name>Peter Ku</name>
    </author>
    <author>
      <name>Anuj Kumar Goyal</name>
    </author>
    <author>
      <name>Sanchit Agarwal</name>
    </author>
    <author>
      <name>Shuyang Gao</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Data release writeup</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01669v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01669v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00883v1</id>
    <updated>2019-07-01T15:55:36Z</updated>
    <published>2019-07-01T15:55:36Z</published>
    <title>HyST: A Hybrid Approach for Flexible and Accurate Dialogue State
  Tracking</title>
    <summary>  Recent works on end-to-end trainable neural network based approaches have
demonstrated state-of-the-art results on dialogue state tracking. The best
performing approaches estimate a probability distribution over all possible
slot values. However, these approaches do not scale for large value sets
commonly present in real-life applications and are not ideal for tracking slot
values that were not observed in the training set. To tackle these issues,
candidate-generation-based approaches have been proposed. These approaches
estimate a set of values that are possible at each turn based on the
conversation history and/or language understanding outputs, and hence enable
state tracking over unseen values and large value sets however, they fall short
in terms of performance in comparison to the first group. In this work, we
analyze the performance of these two alternative dialogue state tracking
methods, and present a hybrid approach (HyST) which learns the appropriate
method for each slot type. To demonstrate the effectiveness of HyST on a
rich-set of slot types, we experiment with the recently released MultiWOZ-2.0
multi-domain, task-oriented dialogue-dataset. Our experiments show that HyST
scales to multi-domain applications. Our best performing model results in a
relative improvement of 24% and 10% over the previous SOTA and our best
baseline respectively.
</summary>
    <author>
      <name>Rahul Goel</name>
    </author>
    <author>
      <name>Shachi Paul</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tür</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Interspeech 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00854v2</id>
    <updated>2020-01-31T19:01:40Z</updated>
    <published>2019-07-01T15:20:10Z</published>
    <title>Katecheo: A Portable and Modular System for Multi-Topic Question
  Answering</title>
    <summary>  We introduce a modular system that can be deployed on any Kubernetes cluster
for question answering via REST API. This system, called Katecheo, includes
three configurable modules that collectively enable identification of
questions, classification of those questions into topics, document search, and
reading comprehension. We demonstrate the system using publicly available
knowledge base articles extracted from Stack Exchange sites. However, users can
extend the system to any number of topics, or domains, without the need to
modify any of the model serving code or train their own models. All components
of the system are open source and available under a permissive Apache 2
License.
</summary>
    <author>
      <name>Shirish Hirekodi</name>
    </author>
    <author>
      <name>Seban Sunny</name>
    </author>
    <author>
      <name>Leonard Topno</name>
    </author>
    <author>
      <name>Alwin Daniel</name>
    </author>
    <author>
      <name>Daniel Whitenack</name>
    </author>
    <author>
      <name>Reuben Skewes</name>
    </author>
    <author>
      <name>Stuart Cranney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2020 system demo submission, 7 pages, 3 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00854v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00854v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00852v2</id>
    <updated>2019-10-13T11:13:49Z</updated>
    <published>2019-07-01T15:20:01Z</published>
    <title>EGG: a toolkit for research on Emergence of lanGuage in Games</title>
    <summary>  There is renewed interest in simulating language emergence among deep neural
agents that communicate to jointly solve a task, spurred by the practical aim
to develop language-enabled interactive AIs, as well as by theoretical
questions about the evolution of human language. However, optimizing deep
architectures connected by a discrete communication channel (such as that in
which language emerges) is technically challenging. We introduce EGG, a toolkit
that greatly simplifies the implementation of emergent-language communication
games. EGG's modular design provides a set of building blocks that the user can
combine to create new games, easily navigating the optimization and
architecture space. We hope that the tool will lower the technical barrier, and
encourage researchers from various backgrounds to do original work in this
exciting area.
</summary>
    <author>
      <name>Eugene Kharitonov</name>
    </author>
    <author>
      <name>Rahma Chaabouni</name>
    </author>
    <author>
      <name>Diane Bouchacourt</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 Demo paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00852v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00852v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00607v1</id>
    <updated>2019-07-01T08:44:30Z</updated>
    <published>2019-07-01T08:44:30Z</published>
    <title>Weak Supervision Enhanced Generative Network for Question Generation</title>
    <summary>  Automatic question generation according to an answer within the given passage
is useful for many applications, such as question answering system, dialogue
system, etc. Current neural-based methods mostly take two steps which extract
several important sentences based on the candidate answer through manual rules
or supervised neural networks and then use an encoder-decoder framework to
generate questions about these sentences. These approaches neglect the semantic
relations between the answer and the context of the whole passage which is
sometimes necessary for answering the question. To address this problem, we
propose the Weak Supervision Enhanced Generative Network (WeGen) which
automatically discovers relevant features of the passage given the answer span
in a weakly supervised manner to improve the quality of generated questions.
More specifically, we devise a discriminator, Relation Guider, to capture the
relations between the whole passage and the associated answer and then the
Multi-Interaction mechanism is deployed to transfer the knowledge dynamically
for our question generation system. Experiments show the effectiveness of our
method in both automatic evaluations and human evaluations.
</summary>
    <author>
      <name>Yutong Wang</name>
    </author>
    <author>
      <name>Jiyuan Zheng</name>
    </author>
    <author>
      <name>Qijiong Liu</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <author>
      <name>Jun Xiao</name>
    </author>
    <author>
      <name>Yueting Zhuang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at IJCAI2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00570v2</id>
    <updated>2019-07-08T14:57:07Z</updated>
    <published>2019-07-01T06:46:43Z</published>
    <title>Do Transformer Attention Heads Provide Transparency in Abstractive
  Summarization?</title>
    <summary>  Learning algorithms become more powerful, often at the cost of increased
complexity. In response, the demand for algorithms to be transparent is
growing. In NLP tasks, attention distributions learned by attention-based deep
learning models are used to gain insights in the models' behavior. To which
extent is this perspective valid for all NLP tasks? We investigate whether
distributions calculated by different attention heads in a transformer
architecture can be used to improve transparency in the task of abstractive
summarization. To this end, we present both a qualitative and quantitative
analysis to investigate the behavior of the attention heads. We show that some
attention heads indeed specialize towards syntactically and semantically
distinct input. We propose an approach to evaluate to which extent the
Transformer model relies on specifically learned attention distributions. We
also discuss what this implies for using attention distributions as a means of
transparency.
</summary>
    <author>
      <name>Joris Baan</name>
    </author>
    <author>
      <name>Maartje ter Hoeve</name>
    </author>
    <author>
      <name>Marlies van der Wees</name>
    </author>
    <author>
      <name>Anne Schuth</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at FACTS-IR 2019, SIGIR</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00570v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00570v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00390v1</id>
    <updated>2019-06-30T14:54:01Z</updated>
    <published>2019-06-30T14:54:01Z</published>
    <title>A Novel Bi-directional Interrelated Model for Joint Intent Detection and
  Slot Filling</title>
    <summary>  A spoken language understanding (SLU) system includes two main tasks, slot
filling (SF) and intent detection (ID). The joint model for the two tasks is
becoming a tendency in SLU. But the bi-directional interrelated connections
between the intent and slots are not established in the existing joint models.
In this paper, we propose a novel bi-directional interrelated model for joint
intent detection and slot filling. We introduce an SF-ID network to establish
direct connections for the two tasks to help them promote each other mutually.
Besides, we design an entirely new iteration mechanism inside the SF-ID network
to enhance the bi-directional interrelated connections. The experimental
results show that the relative improvement in the sentence-level semantic frame
accuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,
respectively, compared to the state-of-the-art model.
</summary>
    <author>
      <name>Haihong E</name>
    </author>
    <author>
      <name>Peiqing Niu</name>
    </author>
    <author>
      <name>Zhongfu Chen</name>
    </author>
    <author>
      <name>Meina Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper of ACL 2019 (short paper) with 5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00151v5</id>
    <updated>2019-09-05T02:34:36Z</updated>
    <published>2019-06-29T06:04:48Z</published>
    <title>GPT-based Generation for Classical Chinese Poetry</title>
    <summary>  We present a simple yet effective method for generating high quality
classical Chinese poetry with Generative Pre-trained Language Model (GPT). The
method adopts a simple GPT model, without using any human crafted rules or
features, or designing any additional neural components. While the proposed
model learns to generate various forms of classical Chinese poems, including
Jueju, L\"{u}shi, various Cipai and Couples, the generated poems are of very
high quality. We also propose and implement a method to fine-tune the model to
generate acrostic poetry. To the best of our knowledge, this is the first to
employ GPT in developing a poetry generation system. We have released an online
mini demonstration program on Wechat to show the generation capability of the
proposed method for classical Chinese poetry.
</summary>
    <author>
      <name>Yi Liao</name>
    </author>
    <author>
      <name>Yasheng Wang</name>
    </author>
    <author>
      <name>Qun Liu</name>
    </author>
    <author>
      <name>Xin Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/1907.00151v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00151v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.12035v1</id>
    <updated>2019-06-28T04:08:15Z</updated>
    <published>2019-06-28T04:08:15Z</published>
    <title>Multi-Criteria Chinese Word Segmentation with Transformer</title>
    <summary>  Different linguistic perspectives cause many diverse segmentation criteria
for Chinese word segmentation (CWS). Most existing methods focus on improving
the performance of single-criterion CWS. However, it is interesting to exploit
these heterogeneous segmentation criteria and mine their common underlying
knowledge. In this paper, we propose a concise and effective model for
multi-criteria CWS, which utilizes a shared fully-connected self-attention
model to segment the sentence according to a criterion indicator. Experiments
on eight datasets with heterogeneous segmentation criteria show that the
performance of each corpus obtains a significant improvement, compared to
single-criterion learning.
</summary>
    <author>
      <name>Xipeng Qiu</name>
    </author>
    <author>
      <name>Hengzhi Pei</name>
    </author>
    <author>
      <name>Hang Yan</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.12035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.12035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11315v2</id>
    <updated>2019-09-20T13:44:38Z</updated>
    <published>2019-06-26T19:48:25Z</published>
    <title>Generalization to Novel Objects using Prior Relational Knowledge</title>
    <summary>  To solve tasks in new environments involving objects unseen during training,
agents must reason over prior information about those objects and their
relations. We introduce the Prior Knowledge Graph network, an architecture for
combining prior information, structured as a knowledge graph, with a symbolic
parsing of the visual scene, and demonstrate that this approach is able to
apply learned relations to novel objects whereas the baseline algorithms fail.
Ablation experiments show that the agents ground the knowledge graph relations
to semantically-relevant behaviors. In both a Sokoban game and the more complex
Pacman environment, our network is also more sample efficient than the
baselines, reaching the same performance in 5-10x fewer episodes. Once the
agents are trained with our approach, we can manipulate agent behavior by
modifying the knowledge graph in semantically meaningful ways. These results
suggest that our network provides a framework for agents to reason over
structured knowledge graphs while still leveraging gradient based learning
approaches.
</summary>
    <author>
      <name>Varun Kumar Vijay</name>
    </author>
    <author>
      <name>Abhinav Ganesh</name>
    </author>
    <author>
      <name>Hanlin Tang</name>
    </author>
    <author>
      <name>Arjun Bansal</name>
    </author>
    <link href="http://arxiv.org/abs/1906.11315v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11315v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11313v1</id>
    <updated>2019-06-26T19:45:42Z</updated>
    <published>2019-06-26T19:45:42Z</published>
    <title>Determining Relative Argument Specificity and Stance for Complex
  Argumentative Structures</title>
    <summary>  Systems for automatic argument generation and debate require the ability to
(1) determine the stance of any claims employed in the argument and (2) assess
the specificity of each claim relative to the argument context. Existing work
on understanding claim specificity and stance, however, has been limited to the
study of argumentative structures that are relatively shallow, most often
consisting of a single claim that directly supports or opposes the argument
thesis. In this paper, we tackle these tasks in the context of complex
arguments on a diverse set of topics. In particular, our dataset consists of
manually curated argument trees for 741 controversial topics covering 95,312
unique claims; lines of argument are generally of depth 2 to 6. We find that as
the distance between a pair of claims increases along the argument path,
determining the relative specificity of a pair of claims becomes easier and
determining their relative stance becomes harder.
</summary>
    <author>
      <name>Esin Durmus</name>
    </author>
    <author>
      <name>Faisal Ladhak</name>
    </author>
    <author>
      <name>Claire Cardie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/P19-1456</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/P19-1456" rel="related"/>
    <link href="http://arxiv.org/abs/1906.11313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11310v1</id>
    <updated>2019-06-26T19:38:02Z</updated>
    <published>2019-06-26T19:38:02Z</published>
    <title>A Corpus for Modeling User and Language Effects in Argumentation on
  Online Debating</title>
    <summary>  Existing argumentation datasets have succeeded in allowing researchers to
develop computational methods for analyzing the content, structure and
linguistic features of argumentative text. They have been much less successful
in fostering studies of the effect of "user" traits -- characteristics and
beliefs of the participants -- on the debate/argument outcome as this type of
user information is generally not available. This paper presents a dataset of
78, 376 debates generated over a 10-year period along with surprisingly
comprehensive participant profiles. We also complete an example study using the
dataset to analyze the effect of selected user traits on the debate outcome in
comparison to the linguistic features typically employed in studies of this
kind.
</summary>
    <author>
      <name>Esin Durmus</name>
    </author>
    <author>
      <name>Claire Cardie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/P19-1057</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/P19-1057" rel="related"/>
    <link href="http://arxiv.org/abs/1906.11310v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11310v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11301v1</id>
    <updated>2019-06-26T19:15:41Z</updated>
    <published>2019-06-26T19:15:41Z</published>
    <title>Exploring the Role of Prior Beliefs for Argument Persuasion</title>
    <summary>  Public debate forums provide a common platform for exchanging opinions on a
topic of interest. While recent studies in natural language processing (NLP)
have provided empirical evidence that the language of the debaters and their
patterns of interaction play a key role in changing the mind of a reader,
research in psychology has shown that prior beliefs can affect our
interpretation of an argument and could therefore constitute a competing
alternative explanation for resistance to changing one's stance. To study the
actual effect of language use vs. prior beliefs on persuasion, we provide a new
dataset and propose a controlled setting that takes into consideration two
reader level factors: political and religious ideology. We find that prior
beliefs affected by these reader level factors play a more important role than
language use effects and argue that it is important to account for them in NLP
studies of persuasion.
</summary>
    <author>
      <name>Esin Durmus</name>
    </author>
    <author>
      <name>Claire Cardie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/N18-1094</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/N18-1094" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.11301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11180v1</id>
    <updated>2019-06-26T15:53:59Z</updated>
    <published>2019-06-26T15:53:59Z</published>
    <title>Canonicalizing Knowledge Base Literals</title>
    <summary>  Ontology-based knowledge bases (KBs) like DBpedia are very valuable
resources, but their usefulness and usability is limited by various quality
issues. One such issue is the use of string literals instead of semantically
typed entities. In this paper we study the automated canonicalization of such
literals, i.e., replacing the literal with an existing entity from the KB or
with a new entity that is typed using classes from the KB. We propose a
framework that combines both reasoning and machine learning in order to predict
the relevant entities and types, and we evaluate this framework against
state-of-the-art baselines for both semantic typing and entity matching.
</summary>
    <author>
      <name>Jiaoyan Chen</name>
    </author>
    <author>
      <name>Ernesto Jimenez-Ruiz</name>
    </author>
    <author>
      <name>Ian Horrocks</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Semantic Web Conference (ISWC) 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.11180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00720v1</id>
    <updated>2019-06-26T14:50:39Z</updated>
    <published>2019-06-26T14:50:39Z</published>
    <title>Constructing Information-Lossless Biological Knowledge Graphs from
  Conditional Statements</title>
    <summary>  Conditions are essential in the statements of biological literature. Without
the conditions (e.g., environment, equipment) that were precisely specified,
the facts (e.g., observations) in the statements may no longer be valid. One
biological statement has one or multiple fact(s) and/or condition(s). Their
subject and object can be either a concept or a concept's attribute. Existing
information extraction methods do not consider the role of condition in the
biological statement nor the role of attribute in the subject/object. In this
work, we design a new tag schema and propose a deep sequence tagging framework
to structure conditional statement into fact and condition tuples from
biological text. Experiments demonstrate that our method yields a
information-lossless structure of the literature.
</summary>
    <author>
      <name>Tianwen Jiang</name>
    </author>
    <author>
      <name>Tong Zhao</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Nitesh V. Chawla</name>
    </author>
    <author>
      <name>Meng Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/1907.00720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.12188v1</id>
    <updated>2019-06-26T13:51:59Z</updated>
    <published>2019-06-26T13:51:59Z</published>
    <title>A Deep Decoder Structure Based on WordEmbedding Regression for An
  Encoder-Decoder Based Model for Image Captioning</title>
    <summary>  Generating textual descriptions for images has been an attractive problem for
the computer vision and natural language processing researchers in recent
years. Dozens of models based on deep learning have been proposed to solve this
problem. The existing approaches are based on neural encoder-decoder structures
equipped with the attention mechanism. These methods strive to train decoders
to minimize the log likelihood of the next word in a sentence given the
previous ones, which results in the sparsity of the output space. In this work,
we propose a new approach to train decoders to regress the word embedding of
the next word with respect to the previous ones instead of minimizing the log
likelihood. The proposed method is able to learn and extract long-term
information and can generate longer fine-grained captions without introducing
any external memory cell. Furthermore, decoders trained by the proposed
technique can take the importance of the generated words into consideration
while generating captions. In addition, a novel semantic attention mechanism is
proposed that guides attention points through the image, taking the meaning of
the previously generated word into account. We evaluate the proposed approach
with the MS-COCO dataset. The proposed model outperformed the state of the art
models especially in generating longer captions. It achieved a CIDEr score
equal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of the
state of the art models are 117.1 and 48.0, respectively.
</summary>
    <author>
      <name>Ahmad Asadi</name>
    </author>
    <author>
      <name>Reza Safabakhsh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.12188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.12188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10924v1</id>
    <updated>2019-06-26T09:10:33Z</updated>
    <published>2019-06-26T09:10:33Z</published>
    <title>Interpretable Question Answering on Knowledge Bases and Text</title>
    <summary>  Interpretability of machine learning (ML) models becomes more relevant with
their increasing adoption. In this work, we address the interpretability of ML
based question answering (QA) models on a combination of knowledge bases (KB)
and text documents. We adapt post hoc explanation methods such as LIME and
input perturbation (IP) and compare them with the self-explanatory attention
mechanism of the model. For this purpose, we propose an automatic evaluation
paradigm for explanation methods in the context of QA. We also conduct a study
with human annotators to evaluate whether explanations help them identify
better QA models. Our results suggest that IP provides better explanations than
LIME or attention, according to both automatic and human evaluation. We obtain
the same ranking of methods in both experiments, which supports the validity of
our automatic evaluation paradigm.
</summary>
    <author>
      <name>Alona Sydorova</name>
    </author>
    <author>
      <name>Nina Poerner</name>
    </author>
    <author>
      <name>Benjamin Roth</name>
    </author>
    <link href="http://arxiv.org/abs/1906.10924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10816v4</id>
    <updated>2019-11-05T02:44:38Z</updated>
    <published>2019-06-26T02:28:10Z</published>
    <title>Program Synthesis and Semantic Parsing with Learned Code Idioms</title>
    <summary>  Program synthesis of general-purpose source code from natural language
specifications is challenging due to the need to reason about high-level
patterns in the target program and low-level implementation details at the same
time. In this work, we present PATOIS, a system that allows a neural program
synthesizer to explicitly interleave high-level and low-level reasoning at
every generation step. It accomplishes this by automatically mining common code
idioms from a given corpus, incorporating them into the underlying language for
neural synthesis, and training a tree-based neural synthesizer to use these
idioms during code generation. We evaluate PATOIS on two complex semantic
parsing datasets and show that using learned code idioms improves the
synthesizer's accuracy.
</summary>
    <author>
      <name>Richard Shin</name>
    </author>
    <author>
      <name>Miltiadis Allamanis</name>
    </author>
    <author>
      <name>Marc Brockschmidt</name>
    </author>
    <author>
      <name>Oleksandr Polozov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33rd Conference on Neural Information Processing Systems (NeurIPS)
  2019. 13 pages total, 9 pages of main text</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.10816v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10816v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00710v1</id>
    <updated>2019-06-25T04:39:26Z</updated>
    <published>2019-06-25T04:39:26Z</published>
    <title>Deep Conversational Recommender in Travel</title>
    <summary>  When traveling to a foreign country, we are often in dire need of an
intelligent conversational agent to provide instant and informative responses
to our various queries. However, to build such a travel agent is non-trivial.
First of all, travel naturally involves several sub-tasks such as hotel
reservation, restaurant recommendation and taxi booking etc, which invokes the
need for global topic control. Secondly, the agent should consider various
constraints like price or distance given by the user to recommend an
appropriate venue. In this paper, we present a Deep Conversational Recommender
(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)
models with a neural latent topic component to better guide response generation
and make the training easier. To consider the various constraints for venue
recommendation, we leverage a graph convolutional network (GCN) based approach
to capture the relationships between different venues and the match between
venue and dialog context. For response generation, we combine the topic-based
component with the idea of pointer networks, which allows us to effectively
incorporate recommendation results. We perform extensive evaluation on a
multi-turn task-oriented dialog dataset in travel domain and the results show
that our method achieves superior performance as compared to a wide range of
baselines.
</summary>
    <author>
      <name>Lizi Liao</name>
    </author>
    <author>
      <name>Ryuichi Takanobu</name>
    </author>
    <author>
      <name>Yunshan Ma</name>
    </author>
    <author>
      <name>Xun Yang</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <author>
      <name>Tat-Seng Chua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures, submitted to TKDE. arXiv admin note: text
  overlap with arXiv:1809.07070 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00692v1</id>
    <updated>2019-06-24T16:24:46Z</updated>
    <published>2019-06-24T16:24:46Z</published>
    <title>Event extraction based on open information extraction and ontology</title>
    <summary>  The work presented in this master thesis consists of extracting a set of
events from texts written in natural language. For this purpose, we have based
ourselves on the basic notions of the information extraction as well as the
open information extraction. First, we applied an open information
extraction(OIE) system for the relationship extraction, to highlight the
importance of OIEs in event extraction, and we used the ontology to the event
modeling. We tested the results of our approach with test metrics. As a result,
the two-level event extraction approach has shown good performance results but
requires a lot of expert intervention in the construction of classifiers and
this will take time. In this context we have proposed an approach that reduces
the expert intervention in the relation extraction, the recognition of entities
and the reasoning which are automatic and based on techniques of adaptation and
correspondence. Finally, to prove the relevance of the extracted results, we
conducted a set of experiments using different test metrics as well as a
comparative study.
</summary>
    <author>
      <name>Sihem Sahnoun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1607.02784 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10002v1</id>
    <updated>2019-06-24T14:49:05Z</updated>
    <published>2019-06-24T14:49:05Z</published>
    <title>LIAAD at SemDeep-5 Challenge: Word-in-Context (WiC)</title>
    <summary>  This paper describes the LIAAD system that was ranked second place in the
Word-in-Context challenge (WiC) featured in SemDeep-5. Our solution is based on
a novel system for Word Sense Disambiguation (WSD) using contextual embeddings
and full-inventory sense embeddings. We adapt this WSD system, in a
straightforward manner, for the present task of detecting whether the same
sense occurs in a pair of sentences. Additionally, we show that our solution is
able to achieve competitive performance even without using the provided
training or development sets, mitigating potential concerns related to task
overfitting
</summary>
    <author>
      <name>Daniel Loureiro</name>
    </author>
    <author>
      <name>Alipio Jorge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the SemDeep-5 Workshop in IJCAI 2019. Code and data:
  https://github.com/danlou/LMMS</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.10002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09833v1</id>
    <updated>2019-06-24T10:14:42Z</updated>
    <published>2019-06-24T10:14:42Z</published>
    <title>Translationese in Machine Translation Evaluation</title>
    <summary>  The term translationese has been used to describe the presence of unusual
features of translated text. In this paper, we provide a detailed analysis of
the adverse effects of translationese on machine translation evaluation
results. Our analysis shows evidence to support differences in text originally
written in a given language relative to translated text and this can
potentially negatively impact the accuracy of machine translation evaluations.
For this reason we recommend that reverse-created test data be omitted from
future machine translation test sets. In addition, we provide a re-evaluation
of a past high-profile machine translation evaluation claiming human-parity of
MT, as well as analysis of the since re-evaluations of it. We find potential
ways of improving the reliability of all three past evaluations. One important
issue not previously considered is the statistical power of significance tests
applied in past evaluations that aim to investigate human-parity of MT. Since
the very aim of such evaluations is to reveal legitimate ties between human and
MT systems, power analysis is of particular importance, where low power could
result in claims of human parity that in fact simply correspond to Type II
error. We therefore provide a detailed power analysis of tests used in such
evaluations to provide an indication of a suitable minimum sample size of
translations for such studies. Subsequently, since no past evaluation that
aimed to investigate claims of human parity ticks all boxes in terms of
accuracy and reliability, we rerun the evaluation of the systems claiming human
parity. Finally, we provide a comprehensive check-list for future machine
translation evaluation.
</summary>
    <author>
      <name>Yvette Graham</name>
    </author>
    <author>
      <name>Barry Haddow</name>
    </author>
    <author>
      <name>Philipp Koehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09676v1</id>
    <updated>2019-06-24T00:30:32Z</updated>
    <published>2019-06-24T00:30:32Z</published>
    <title>CORAL8: Concurrent Object Regression for Area Localization in Medical
  Image Panels</title>
    <summary>  This work tackles the problem of generating a medical report for multi-image
panels. We apply our solution to the Renal Direct Immunofluorescence (RDIF)
assay which requires a pathologist to generate a report based on observations
across the eight different WSI in concert with existing clinical features. To
this end, we propose a novel attention-based multi-modal generative recurrent
neural network (RNN) architecture capable of dynamically sampling image data
concurrently across the RDIF panel. The proposed methodology incorporates text
from the clinical notes of the requesting physician to regulate the output of
the network to align with the overall clinical context. In addition, we found
the importance of regularizing the attention weights for word generation
processes. This is because the system can ignore the attention mechanism by
assigning equal weights for all members. Thus, we propose two regularizations
which force the system to utilize the attention mechanism. Experiments on our
novel collection of RDIF WSIs provided by a large clinical laboratory
demonstrate that our framework offers significant improvements over existing
methods.
</summary>
    <author>
      <name>Sam Maksoud</name>
    </author>
    <author>
      <name>Arnold Wiliem</name>
    </author>
    <author>
      <name>Kun Zhao</name>
    </author>
    <author>
      <name>Teng Zhang</name>
    </author>
    <author>
      <name>Lin Wu</name>
    </author>
    <author>
      <name>Brian C. Lovell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for MICCAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09601v1</id>
    <updated>2019-06-23T16:13:45Z</updated>
    <published>2019-06-23T16:13:45Z</published>
    <title>Sequence Generation: From Both Sides to the Middle</title>
    <summary>  The encoder-decoder framework has achieved promising process for many
sequence generation tasks, such as neural machine translation and text
summarization. Such a framework usually generates a sequence token by token
from left to right, hence (1) this autoregressive decoding procedure is
time-consuming when the output sentence becomes longer, and (2) it lacks the
guidance of future context which is crucial to avoid under translation. To
alleviate these issues, we propose a synchronous bidirectional sequence
generation (SBSG) model which predicts its outputs from both sides to the
middle simultaneously. In the SBSG model, we enable the left-to-right (L2R) and
right-to-left (R2L) generation to help and interact with each other by
leveraging interactive bidirectional attention network. Experiments on neural
machine translation (En-De, Ch-En, and En-Ro) and text summarization tasks show
that the proposed model significantly speeds up decoding while improving the
generation quality compared to the autoregressive Transformer.
</summary>
    <author>
      <name>Long Zhou</name>
    </author>
    <author>
      <name>Jiajun Zhang</name>
    </author>
    <author>
      <name>Chengqing Zong</name>
    </author>
    <author>
      <name>Heng Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IJCAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09601v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09601v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09445v1</id>
    <updated>2019-06-22T13:28:32Z</updated>
    <published>2019-06-22T13:28:32Z</published>
    <title>Learning with fuzzy hypergraphs: a topical approach to query-oriented
  text summarization</title>
    <summary>  Existing graph-based methods for extractive document summarization represent
sentences of a corpus as the nodes of a graph or a hypergraph in which edges
depict relationships of lexical similarity between sentences. Such approaches
fail to capture semantic similarities between sentences when they express a
similar information but have few words in common and are thus lexically
dissimilar. To overcome this issue, we propose to extract semantic similarities
based on topical representations of sentences. Inspired by the Hierarchical
Dirichlet Process, we propose a probabilistic topic model in order to infer
topic distributions of sentences. As each topic defines a semantic connection
among a group of sentences with a certain degree of membership for each
sentence, we propose a fuzzy hypergraph model in which nodes are sentences and
fuzzy hyperedges are topics. To produce an informative summary, we extract a
set of sentences from the corpus by simultaneously maximizing their relevance
to a user-defined query, their centrality in the fuzzy hypergraph and their
coverage of topics present in the corpus. We formulate a polynomial time
algorithm building on the theory of submodular functions to solve the
associated optimization problem. A thorough comparative analysis with other
graph-based summarization systems is included in the paper. Our obtained
results show the superiority of our method in terms of content coverage of the
summaries.
</summary>
    <author>
      <name>Hadrien Van Lierde</name>
    </author>
    <author>
      <name>Tommy W. S. Chow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ins.2019.05.020</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ins.2019.05.020" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences, 496 (2019), 212-224</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.09445v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09445v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09444v1</id>
    <updated>2019-06-22T13:20:57Z</updated>
    <published>2019-06-22T13:20:57Z</published>
    <title>Retrieving Sequential Information for Non-Autoregressive Neural Machine
  Translation</title>
    <summary>  Non-Autoregressive Transformer (NAT) aims to accelerate the Transformer model
through discarding the autoregressive mechanism and generating target words
independently, which fails to exploit the target sequential information.
Over-translation and under-translation errors often occur for the above reason,
especially in the long sentence translation scenario. In this paper, we propose
two approaches to retrieve the target sequential information for NAT to enhance
its translation ability while preserving the fast-decoding property. Firstly,
we propose a sequence-level training method based on a novel reinforcement
algorithm for NAT (Reinforce-NAT) to reduce the variance and stabilize the
training procedure. Secondly, we propose an innovative Transformer decoder
named FS-decoder to fuse the target sequential information into the top layer
of the decoder. Experimental results on three translation tasks show that the
Reinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU
without decelerating the decoding speed and the FS-decoder achieves comparable
translation performance to the autoregressive Transformer with considerable
speedup.
</summary>
    <author>
      <name>Chenze Shao</name>
    </author>
    <author>
      <name>Yang Feng</name>
    </author>
    <author>
      <name>Jinchao Zhang</name>
    </author>
    <author>
      <name>Fandong Meng</name>
    </author>
    <author>
      <name>Xilin Chen</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures, ACL 2019 long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09384v1</id>
    <updated>2019-06-22T04:02:26Z</updated>
    <published>2019-06-22T04:02:26Z</published>
    <title>A Bandit Approach to Posterior Dialog Orchestration Under a Budget</title>
    <summary>  Building multi-domain AI agents is a challenging task and an open problem in
the area of AI. Within the domain of dialog, the ability to orchestrate
multiple independently trained dialog agents, or skills, to create a unified
system is of particular significance. In this work, we study the task of online
posterior dialog orchestration, where we define posterior orchestration as the
task of selecting a subset of skills which most appropriately answer a user
input using features extracted from both the user input and the individual
skills. To account for the various costs associated with extracting skill
features, we consider online posterior orchestration under a skill execution
budget. We formalize this setting as Context Attentive Bandit with Observations
(CABO), a variant of context attentive bandits, and evaluate it on simulated
non-conversational and proprietary conversational datasets.
</summary>
    <author>
      <name>Sohini Upadhyay</name>
    </author>
    <author>
      <name>Mayank Agarwal</name>
    </author>
    <author>
      <name>Djallel Bounneffouf</name>
    </author>
    <author>
      <name>Yasaman Khazaeni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd Conversational AI Workshop, NeurIPS 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09317v1</id>
    <updated>2019-06-21T20:55:57Z</updated>
    <published>2019-06-21T20:55:57Z</published>
    <title>Identification of Tasks, Datasets, Evaluation Metrics, and Numeric
  Scores for Scientific Leaderboards Construction</title>
    <summary>  While the fast-paced inception of novel tasks and new datasets helps foster
active research in a community towards interesting directions, keeping track of
the abundance of research activity in different areas on different datasets is
likely to become increasingly difficult. The community could greatly benefit
from an automatic system able to summarize scientific results, e.g., in the
form of a leaderboard. In this paper we build two datasets and develop a
framework (TDMS-IE) aimed at automatically extracting task, dataset, metric and
score from NLP papers, towards the automatic construction of leaderboards.
Experiments show that our model outperforms several baselines by a large
margin. Our model is a first step towards automatic leaderboard construction,
e.g., in the NLP domain.
</summary>
    <author>
      <name>Yufang Hou</name>
    </author>
    <author>
      <name>Charles Jochim</name>
    </author>
    <author>
      <name>Martin Gleize</name>
    </author>
    <author>
      <name>Francesca Bonin</name>
    </author>
    <author>
      <name>Debasis Ganguly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09310v1</id>
    <updated>2019-06-21T20:16:52Z</updated>
    <published>2019-06-21T20:16:52Z</published>
    <title>A Study of State Aliasing in Structured Prediction with RNNs</title>
    <summary>  End-to-end reinforcement learning agents learn a state representation and a
policy at the same time. Recurrent neural networks (RNNs) have been trained
successfully as reinforcement learning agents in settings like dialogue that
require structured prediction. In this paper, we investigate the
representations learned by RNN-based agents when trained with both policy
gradient and value-based methods. We show through extensive experiments and
analysis that, when trained with policy gradient, recurrent neural networks
often fail to learn a state representation that leads to an optimal policy in
settings where the same action should be taken at different states. To explain
this failure, we highlight the problem of state aliasing, which entails
conflating two or more distinct states in the representation space. We
demonstrate that state aliasing occurs when several states share the same
optimal action and the agent is trained via policy gradient. We characterize
this phenomenon through experiments on a simple maze setting and a more complex
text-based game, and make recommendations for training RNNs with reinforcement
learning.
</summary>
    <author>
      <name>Layla El Asri</name>
    </author>
    <author>
      <name>Adam Trischler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Deep Reinforcement Learning Meets Structured Prediction workshop at
  ICLR 2019 and Representation Learning for NLP workshop at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09310v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09310v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09308v2</id>
    <updated>2019-11-04T01:47:34Z</updated>
    <published>2019-06-21T20:08:18Z</published>
    <title>Approximating Interactive Human Evaluation with Self-Play for
  Open-Domain Dialog Systems</title>
    <summary>  Building an open-domain conversational agent is a challenging problem.
Current evaluation methods, mostly post-hoc judgments of static conversation,
do not capture conversation quality in a realistic interactive context. In this
paper, we investigate interactive human evaluation and provide evidence for its
necessity; we then introduce a novel, model-agnostic, and dataset-agnostic
method to approximate it. In particular, we propose a self-play scenario where
the dialog system talks to itself and we calculate a combination of proxies
such as sentiment and semantic coherence on the conversation trajectory. We
show that this metric is capable of capturing the human-rated quality of a
dialog model better than any automated metric known to-date, achieving a
significant Pearson correlation (r&gt;.7, p&lt;.05). To investigate the strengths of
this novel metric and interactive evaluation in comparison to state-of-the-art
metrics and human evaluation of static conversations, we perform extended
experiments with a set of models, including several that make novel
improvements to recent hierarchical dialog generation architectures through
sentiment and semantic knowledge distillation on the utterance level. Finally,
we open-source the interactive evaluation platform we built and the dataset we
collected to allow researchers to efficiently deploy and evaluate dialog
models.
</summary>
    <author>
      <name>Asma Ghandeharioun</name>
    </author>
    <author>
      <name>Judy Hanwen Shen</name>
    </author>
    <author>
      <name>Natasha Jaques</name>
    </author>
    <author>
      <name>Craig Ferguson</name>
    </author>
    <author>
      <name>Noah Jones</name>
    </author>
    <author>
      <name>Agata Lapedriza</name>
    </author>
    <author>
      <name>Rosalind Picard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33rd Conference on Neural Information Processing Systems (NeurIPS
  2019), Vancouver, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09308v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09308v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08939v1</id>
    <updated>2019-06-21T04:14:07Z</updated>
    <published>2019-06-21T04:14:07Z</published>
    <title>Learning Bilingual Word Embeddings Using Lexical Definitions</title>
    <summary>  Bilingual word embeddings, which representlexicons of different languages in
a shared em-bedding space, are essential for supporting se-mantic and knowledge
transfers in a variety ofcross-lingual NLP tasks. Existing approachesto
training bilingual word embeddings requireoften require pre-defined seed
lexicons that areexpensive to obtain, or parallel sentences thatcomprise coarse
and noisy alignment. In con-trast, we propose BilLex that leverages pub-licly
available lexical definitions for bilingualword embedding learning. Without the
needof predefined seed lexicons, BilLex comprisesa novel word pairing strategy
to automati-cally identify and propagate the precise fine-grained word
alignment from lexical defini-tions. We evaluate BilLex in word-level
andsentence-level translation tasks, which seek tofind the cross-lingual
counterparts of wordsand sentences respectively.BilLex signifi-cantly
outperforms previous embedding meth-ods on both tasks.
</summary>
    <author>
      <name>Weijia Shi</name>
    </author>
    <author>
      <name>Muhao Chen</name>
    </author>
    <author>
      <name>Yingtao Tian</name>
    </author>
    <author>
      <name>Kai-Wei Chang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019 RepL4NLP</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.08939v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08939v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08733v1</id>
    <updated>2019-06-20T16:25:47Z</updated>
    <published>2019-06-20T16:25:47Z</published>
    <title>Autonomous Haiku Generation</title>
    <summary>  Artificial Intelligence is an excellent tool to improve efficiency and lower
cost in many quantitative real world applications, but what if the task is not
easily defined? What if the task is generating creativity? Poetry is a creative
endeavor that is highly difficult to both grasp and achieve with any level of
competence. As Rita Dove, a famous American poet and author states, "Poetry is
language at its most distilled and most powerful." Taking Doves quote as an
inspiration, our task was to generate high quality haikus using artificial
intelligence and deep learning.
</summary>
    <author>
      <name>Rui Aguiar</name>
    </author>
    <author>
      <name>Kevin Liao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.08733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97R40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08487v1</id>
    <updated>2019-06-20T08:03:58Z</updated>
    <published>2019-06-20T08:03:58Z</published>
    <title>HappyBot: Generating Empathetic Dialogue Responses by Improving User
  Experience Look-ahead</title>
    <summary>  Recent neural conversation models that attempted to incorporate emotion and
generate empathetic responses either focused on conditioning the output to a
given emotion, or incorporating the current user emotional state. While these
approaches have been successful to some extent in generating more diverse and
seemingly engaging utterances, they do not factor in how the user would feel
towards the generated dialogue response. Hence, in this paper, we advocate such
look-ahead of user emotion as the key to modeling and generating empathetic
dialogue responses. We thus train a Sentiment Predictor to estimate the user
sentiment look-ahead towards the generated system responses, which is then used
as the reward function for generating more empathetic responses. Human
evaluation results show that our model outperforms other baselines in empathy,
relevance, and fluency.
</summary>
    <author>
      <name>Jamin Shin</name>
    </author>
    <author>
      <name>Peng Xu</name>
    </author>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <link href="http://arxiv.org/abs/1906.08487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08382v1</id>
    <updated>2019-06-19T22:23:20Z</updated>
    <published>2019-06-19T22:23:20Z</published>
    <title>An Open-World Extension to Knowledge Graph Completion Models</title>
    <summary>  We present a novel extension to embedding-based knowledge graph completion
models which enables them to perform open-world link prediction, i.e. to
predict facts for entities unseen in training based on their textual
description. Our model combines a regular link prediction model learned from a
knowledge graph with word embeddings learned from a textual corpus. After
training both independently, we learn a transformation to map the embeddings of
an entity's name and description to the graph-based embedding space. In
experiments on several datasets including FB20k, DBPedia50k and our new dataset
FB15k-237-OWE, we demonstrate competitive results. Particularly, our approach
exploits the full knowledge graph structure even when textual descriptions are
scarce, does not require a joint training on graph and text, and can be applied
to any embedding-based link prediction model, such as TransE, ComplEx and
DistMult.
</summary>
    <author>
      <name>Haseeb Shah</name>
    </author>
    <author>
      <name>Johannes Villmow</name>
    </author>
    <author>
      <name>Adrian Ulges</name>
    </author>
    <author>
      <name>Ulrich Schwanecke</name>
    </author>
    <author>
      <name>Faisal Shafait</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1609/aaai.v33i01.33013044</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1609/aaai.v33i01.33013044" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, accepted to AAAI-2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI-19 Vol 33 (2019) 3044-3051</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.08382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07389v1</id>
    <updated>2019-06-18T05:51:13Z</updated>
    <published>2019-06-18T05:51:13Z</published>
    <title>Uncovering Probabilistic Implications in Typological Knowledge Bases</title>
    <summary>  The study of linguistic typology is rooted in the implications we find
between linguistic features, such as the fact that languages with object-verb
word ordering tend to have post-positions. Uncovering such implications
typically amounts to time-consuming manual processing by trained and
experienced linguists, which potentially leaves key linguistic universals
unexplored. In this paper, we present a computational model which successfully
identifies known universals, including Greenberg universals, but also uncovers
new ones, worthy of further linguistic investigation. Our approach outperforms
baselines previously used for this problem, as well as a strong baseline from
knowledge base population.
</summary>
    <author>
      <name>Johannes Bjerva</name>
    </author>
    <author>
      <name>Yova Kementchedjhieva</name>
    </author>
    <author>
      <name>Ryan Cotterell</name>
    </author>
    <author>
      <name>Isabelle Augenstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07343v2</id>
    <updated>2019-11-18T21:51:49Z</updated>
    <published>2019-06-18T02:27:45Z</published>
    <title>Language as an Abstraction for Hierarchical Deep Reinforcement Learning</title>
    <summary>  Solving complex, temporally-extended tasks is a long-standing problem in
reinforcement learning (RL). We hypothesize that one critical element of
solving such problems is the notion of compositionality. With the ability to
learn concepts and sub-skills that can be composed to solve longer tasks, i.e.
hierarchical RL, we can acquire temporally-extended behaviors. However,
acquiring effective yet general abstractions for hierarchical RL is remarkably
challenging. In this paper, we propose to use language as the abstraction, as
it provides unique compositional structure, enabling fast learning and
combinatorial generalization, while retaining tremendous flexibility, making it
suitable for a variety of problems. Our approach learns an
instruction-following low-level policy and a high-level policy that can reuse
abstractions across tasks, in essence, permitting agents to reason using
structured language. To study compositional task learning, we introduce an
open-source object interaction environment built using the MuJoCo physics
engine and the CLEVR engine. We find that, using our approach, agents can learn
to solve to diverse, temporally-extended tasks such as object sorting and
multi-object rearrangement, including from raw pixel observations. Our analysis
reveals that the compositional nature of language is critical for learning
diverse sub-skills and systematically generalizing to new sub-skills in
comparison to non-compositional abstractions that use the same supervision.
</summary>
    <author>
      <name>Yiding Jiang</name>
    </author>
    <author>
      <name>Shixiang Gu</name>
    </author>
    <author>
      <name>Kevin Murphy</name>
    </author>
    <author>
      <name>Chelsea Finn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Neural Information Processing Systems (NeurIPS) 2019;
  Supplementary materials: https://sites.google.com/view/hal-demo</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07343v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07343v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07220v1</id>
    <updated>2019-06-17T18:54:51Z</updated>
    <published>2019-06-17T18:54:51Z</published>
    <title>Constrained Decoding for Neural NLG from Compositional Representations
  in Task-Oriented Dialogue</title>
    <summary>  Generating fluent natural language responses from structured semantic
representations is a critical step in task-oriented conversational systems.
Avenues like the E2E NLG Challenge have encouraged the development of neural
approaches, particularly sequence-to-sequence (Seq2Seq) models for this
problem. The semantic representations used, however, are often underspecified,
which places a higher burden on the generation model for sentence planning, and
also limits the extent to which generated responses can be controlled in a live
system. In this paper, we (1) propose using tree-structured semantic
representations, like those used in traditional rule-based NLG systems, for
better discourse-level structuring and sentence-level planning; (2) introduce a
challenging dataset using this representation for the weather domain; (3)
introduce a constrained decoding approach for Seq2Seq models that leverages
this representation to improve semantic correctness; and (4) demonstrate
promising results on our dataset and the E2E dataset.
</summary>
    <author>
      <name>Anusha Balakrishnan</name>
    </author>
    <author>
      <name>Jinfeng Rao</name>
    </author>
    <author>
      <name>Kartikeya Upasani</name>
    </author>
    <author>
      <name>Michael White</name>
    </author>
    <author>
      <name>Rajen Subba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the Proceedings of the 57th Annual Meeting of the
  Association for Computational Linguistics (2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07132v1</id>
    <updated>2019-06-17T17:03:57Z</updated>
    <published>2019-06-17T17:03:57Z</published>
    <title>Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and
  Model Development for Multi-Hop QA</title>
    <summary>  Multi-hop question answering requires a model to connect multiple pieces of
evidence scattered in a long context to answer the question. In this paper, we
show that in the multi-hop HotpotQA (Yang et al., 2018) dataset, the examples
often contain reasoning shortcuts through which models can directly locate the
answer by word-matching the question with a sentence in the context. We
demonstrate this issue by constructing adversarial documents that create
contradicting answers to the shortcut but do not affect the validity of the
original answer. The performance of strong baseline models drops significantly
on our adversarial evaluation, indicating that they are indeed exploiting the
shortcuts rather than performing multi-hop reasoning. After adversarial
training, the baseline's performance improves but is still limited on the
adversarial evaluation. Hence, we use a control unit that dynamically attends
to the question at different reasoning hops to guide the model's multi-hop
reasoning. We show that this 2-hop model trained on the regular data is more
robust to the adversaries than the baseline model. After adversarial training,
this 2-hop model not only achieves improvements over its counterpart trained on
regular data, but also outperforms the adversarially-trained 1-hop baseline. We
hope that these insights and initial improvements will motivate the development
of new models that combine explicit compositional reasoning with adversarial
training.
</summary>
    <author>
      <name>Yichen Jiang</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019 (11 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06788v4</id>
    <updated>2019-09-16T09:29:48Z</updated>
    <published>2019-06-16T22:36:33Z</published>
    <title>SEntNet: Source-aware Recurrent Entity Network for Dialogue Response
  Selection</title>
    <summary>  Dialogue response selection is an important part of Task-oriented Dialogue
Systems (TDSs); it aims to predict an appropriate response given a dialogue
context. Obtaining key information from a complex, long dialogue context is
challenging, especially when different sources of information are available,
e.g., the user's utterances, the system's responses, and results retrieved from
a knowledge base (KB). Previous work ignores the type of information source and
merges sources for response selection. However, accounting for the source type
may lead to remarkable differences in the quality of response selection. We
propose the Source-aware Recurrent Entity Network (SEntNet), which is aware of
different information sources for the response selection process. SEntNet
achieves this by employing source-specific memories to exploit differences in
the usage of words and syntactic structure from different information sources
(user, system, and KB). Experimental results show that SEntNet obtains 91.0%
accuracy on the Dialog bAbI dataset, outperforming prior work by 4.7%. On the
DSTC2 dataset, SEntNet obtains an accuracy of 41.2%, beating source unaware
recurrent entity networks by 2.4%.
</summary>
    <author>
      <name>Jiahuan Pei</name>
    </author>
    <author>
      <name>Arent Stienstra</name>
    </author>
    <author>
      <name>Julia Kiseleva</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2019 IJCAI Workshop SCAI: The 4th International
  Workshop on Search-Oriented Conversational AI</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06788v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06788v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06725v2</id>
    <updated>2020-01-13T04:17:44Z</updated>
    <published>2019-06-16T16:43:02Z</published>
    <title>Persuasion for Good: Towards a Personalized Persuasive Dialogue System
  for Social Good</title>
    <summary>  Developing intelligent persuasive conversational agents to change people's
opinions and actions for social good is the frontier in advancing the ethical
development of automated dialogue systems. To do so, the first step is to
understand the intricate organization of strategic disclosures and appeals
employed in human persuasion conversations. We designed an online persuasion
task where one participant was asked to persuade the other to donate to a
specific charity. We collected a large dataset with 1,017 dialogues and
annotated emerging persuasion strategies from a subset. Based on the
annotation, we built a baseline classifier with context information and
sentence-level features to predict the 10 persuasion strategies used in the
corpus. Furthermore, to develop an understanding of personalized persuasion
processes, we analyzed the relationships between individuals' demographic and
psychological backgrounds including personality, morality, value systems, and
their willingness for donation. Then, we analyzed which types of persuasion
strategies led to a greater amount of donation depending on the individuals'
personal backgrounds. This work lays the ground for developing a personalized
persuasive dialogue system.
</summary>
    <author>
      <name>Xuewei Wang</name>
    </author>
    <author>
      <name>Weiyan Shi</name>
    </author>
    <author>
      <name>Richard Kim</name>
    </author>
    <author>
      <name>Yoojung Oh</name>
    </author>
    <author>
      <name>Sijia Yang</name>
    </author>
    <author>
      <name>Jingwen Zhang</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019 as a long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06725v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06725v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06685v1</id>
    <updated>2019-06-16T13:33:55Z</updated>
    <published>2019-06-16T13:33:55Z</published>
    <title>Improving Background Based Conversation with Context-aware Knowledge
  Pre-selection</title>
    <summary>  Background Based Conversations (BBCs) have been developed to make dialogue
systems generate more informative and natural responses by leveraging
background knowledge. Existing methods for BBCs can be grouped into two
categories: extraction-based methods and generation-based methods. The former
extract spans frombackground material as responses that are not necessarily
natural. The latter generate responses thatare natural but not necessarily
effective in leveraging background knowledge. In this paper, we focus on
generation-based methods and propose a model, namely Context-aware Knowledge
Pre-selection (CaKe), which introduces a pre-selection process that uses
dynamic bi-directional attention to improve knowledge selection by using the
utterance history context as prior information to select the most relevant
background material. Experimental results show that our model is superior to
current state-of-the-art baselines, indicating that it benefits from the
pre-selection process, thus improving in-formativeness and fluency.
</summary>
    <author>
      <name>Yangjun Zhang</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SCAI 2019 workshop paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06582v2</id>
    <updated>2019-07-19T09:49:19Z</updated>
    <published>2019-06-15T15:57:57Z</published>
    <title>A Computational-Hermeneutic Approach for Conceptual Explicitation</title>
    <summary>  We present a computer-supported approach for the logical analysis and
conceptual explicitation of argumentative discourse. Computational hermeneutics
harnesses recent progresses in automated reasoning for higher-order logics and
aims at formalizing natural-language argumentative discourse using flexible
combinations of expressive non-classical logics. In doing so, it allows us to
render explicit the tacit conceptualizations implicit in argumentative
discursive practices. Our approach operates on networks of structured arguments
and is iterative and two-layered. At one layer we search for logically correct
formalizations for each of the individual arguments. At the next layer we
select among those correct formalizations the ones which honor the argument's
dialectic role, i.e. attacking or supporting other arguments as intended. We
operate at these two layers in parallel and continuously rate sentences'
formalizations by using, primarily, inferential adequacy criteria. An
interpretive, logical theory will thus gradually evolve. This theory is
composed of meaning postulates serving as explications for concepts playing a
role in the analyzed arguments. Such a recursive, iterative approach to
interpretation does justice to the inherent circularity of understanding: the
whole is understood compositionally on the basis of its parts, while each part
is understood only in the context of the whole (hermeneutic circle). We
summarily discuss previous work on exemplary applications of human-in-the-loop
computational hermeneutics in metaphysical discourse. We also discuss some of
the main challenges involved in fully-automating our approach. By sketching
some design ideas and reviewing relevant technologies, we argue for the
technological feasibility of a highly-automated computational hermeneutics.
</summary>
    <author>
      <name>David Fuenmayor</name>
    </author>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 9 figures, to appear in A. Nepomuceno, L. Magnani, F.
  Salguero, C. Bar\'es, M. Fontaine (eds.), Model-Based Reasoning in Science
  and Technology. Inferential Models for Logic, Language, Cognition and
  Computation, Series "Sapere", Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06582v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06582v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03B60, 03B15, 68T27, 68T30, 68T15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.3; I.2.4; I.2.0; F.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09324v1</id>
    <updated>2019-06-15T09:20:41Z</updated>
    <published>2019-06-15T09:20:41Z</published>
    <title>Automatic Conditional Generation of Personalized Social Media Short
  Texts</title>
    <summary>  Automatic text generation has received much attention owing to rapid
development of deep neural networks. In general, text generation systems based
on statistical language model will not consider anthropomorphic
characteristics, which results in machine-like generated texts. To fill the
gap, we propose a conditional language generation model with Big Five
Personality (BFP) feature vectors as input context, which writes human-like
short texts. The short text generator consists of a layer of long short memory
network (LSTM), where a BFP feature vector is concatenated as one part of input
for each cell. To enable supervised training generation model, a text
classification model based convolution neural network (CNN) has been used to
prepare BFP-tagged Chinese micro-blog corpora. Validated by a BFP linguistic
computational model, our generated Chinese short texts exhibit discriminative
personality styles, which are also syntactically correct and semantically
smooth with appropriate emoticons. With combination of natural language
generation with psychological linguistics, our proposed BFP-dependent text
generation model can be widely used for individualization in machine
translation, image caption, dialogue generation and so on.
</summary>
    <author>
      <name>Ziwen Wang</name>
    </author>
    <author>
      <name>Jie Wang</name>
    </author>
    <author>
      <name>Haiqian Gu</name>
    </author>
    <author>
      <name>Fei Su</name>
    </author>
    <author>
      <name>Bojin Zhuang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-97310-4_7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-97310-4_7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in PRICAI 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Geng X., Kang BH. (eds) PRICAI 2018: Trends in Artificial
  Intelligence</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.09324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09322v1</id>
    <updated>2019-06-15T09:09:12Z</updated>
    <published>2019-06-15T09:09:12Z</published>
    <title>A Syllable-Structured, Contextually-Based Conditionally Generation of
  Chinese Lyrics</title>
    <summary>  This paper presents a novel, syllable-structured Chinese lyrics generation
model given a piece of original melody. Most previously reported lyrics
generation models fail to include the relationship between lyrics and melody.
In this work, we propose to interpret lyrics-melody alignments as syllable
structural information and use a multi-channel sequence-to-sequence model with
considering both phrasal structures and semantics. Two different RNN encoders
are applied, one of which is for encoding syllable structures while the other
for semantic encoding with contextual sentences or input keywords. Moreover, a
large Chinese lyrics corpus for model training is leveraged. With automatic and
human evaluations, results demonstrate the effectiveness of our proposed lyrics
generation model. To the best of our knowledge, there is few previous reports
on lyrics generation considering both music and linguistic perspectives.
</summary>
    <author>
      <name>Xu Lu</name>
    </author>
    <author>
      <name>Jie Wang</name>
    </author>
    <author>
      <name>Bojin Zhuang</name>
    </author>
    <author>
      <name>Shaojun Wang</name>
    </author>
    <author>
      <name>Jing Xiao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by The 16th Pacific Rim International Conference on AI</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06425v1</id>
    <updated>2019-06-14T22:52:21Z</updated>
    <published>2019-06-14T22:52:21Z</published>
    <title>Principled Frameworks for Evaluating Ethics in NLP Systems</title>
    <summary>  We critique recent work on ethics in natural language processing. Those
discussions have focused on data collection, experimental design, and
interventions in modeling. But we argue that we ought to first understand the
frameworks of ethics that are being used to evaluate the fairness and justice
of algorithmic systems. Here, we begin that discussion by outlining
deontological ethics, and envision a research agenda prioritized by it.
</summary>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <author>
      <name>Elijah Mayfield</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Widening NLP Workshop at ACL 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.06425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07004v1</id>
    <updated>2019-06-14T06:45:08Z</updated>
    <published>2019-06-14T06:45:08Z</published>
    <title>Improving Multi-turn Dialogue Modelling with Utterance ReWriter</title>
    <summary>  Recent research has made impressive progress in single-turn dialogue
modelling. In the multi-turn setting, however, current models are still far
from satisfactory. One major challenge is the frequently occurred coreference
and information omission in our daily conversation, making it hard for machines
to understand the real intention. In this paper, we propose rewriting the human
utterance as a pre-process to help multi-turn dialgoue modelling. Each
utterance is first rewritten to recover all coreferred and omitted information.
The next processing steps are then performed based on the rewritten utterance.
To properly train the utterance rewriter, we collect a new dataset with human
annotations and introduce a Transformer-based utterance rewriting architecture
using the pointer network. We show the proposed architecture achieves
remarkably good performance on the utterance rewriting task. The trained
utterance rewriter can be easily integrated into online chatbots and brings
general improvement over different domains.
</summary>
    <author>
      <name>Hui Su</name>
    </author>
    <author>
      <name>Xiaoyu Shen</name>
    </author>
    <author>
      <name>Rongzhi Zhang</name>
    </author>
    <author>
      <name>Fei Sun</name>
    </author>
    <author>
      <name>Pengwei Hu</name>
    </author>
    <author>
      <name>Cheng Niu</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06332v1</id>
    <updated>2019-06-14T06:38:33Z</updated>
    <published>2019-06-14T06:38:33Z</published>
    <title>IITP at MEDIQA 2019: Systems Report for Natural Language Inference,
  Question Entailment and Question Answering</title>
    <summary>  This paper presents the experiments accomplished as a part of our
participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We
participated in all the three tasks defined in this particular shared task. The
tasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question
Entailment(RQE) and their application in medical Question Answering (QA). We
submitted runs using multiple deep learning based systems (runs) for each of
these three tasks. We submitted five system results in each of the NLI and RQE
tasks, and four system results for the QA task. The systems yield encouraging
results in all three tasks. The highest performance obtained in NLI, RQE and QA
tasks are 81.8%, 53.2%, and 71.7%, respectively.
</summary>
    <author>
      <name>Dibyanayan Bandyopadhyay</name>
    </author>
    <author>
      <name>Baban Gain</name>
    </author>
    <author>
      <name>Tanik Saikh</name>
    </author>
    <author>
      <name>Asif Ekbal</name>
    </author>
    <link href="http://arxiv.org/abs/1906.06332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05939v2</id>
    <updated>2019-06-20T08:15:57Z</updated>
    <published>2019-06-13T21:40:15Z</published>
    <title>Embedding Biomedical Ontologies by Jointly Encoding Network Structure
  and Textual Node Descriptors</title>
    <summary>  Network Embedding (NE) methods, which map network nodes to low-dimensional
feature vectors, have wide applications in network analysis and bioinformatics.
Many existing NE methods rely only on network structure, overlooking other
information associated with the nodes, e.g., text describing the nodes. Recent
attempts to combine the two sources of information only consider local network
structure. We extend NODE2VEC, a well-known NE method that considers broader
network structure, to also consider textual node descriptors using recurrent
neural encoders. Our method is evaluated on link prediction in two networks
derived from UMLS. Experimental results demonstrate the effectiveness of the
proposed approach compared to previous work.
</summary>
    <author>
      <name>Sotiris Kotitsas</name>
    </author>
    <author>
      <name>Dimitris Pappas</name>
    </author>
    <author>
      <name>Ion Androutsopoulos</name>
    </author>
    <author>
      <name>Ryan McDonald</name>
    </author>
    <author>
      <name>Marianna Apidianaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 18th Workshop on Biomedical Natural Language
  Processing (BioNLP 2019) of the 57th Annual Meeting of the Association for
  Computational Linguistics (ACL 2019), Florence, Italy, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05939v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05939v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05691v1</id>
    <updated>2019-06-13T13:53:10Z</updated>
    <published>2019-06-13T13:53:10Z</published>
    <title>Unsupervised Neural Single-Document Summarization of Reviews via
  Learning Latent Discourse Structure and its Ranking</title>
    <summary>  This paper focuses on the end-to-end abstractive summarization of a single
product review without supervision. We assume that a review can be described as
a discourse tree, in which the summary is the root, and the child sentences
explain their parent in detail. By recursively estimating a parent from its
children, our model learns the latent discourse tree without an external parser
and generates a concise summary. We also introduce an architecture that ranks
the importance of each sentence on the tree to support summary generation
focusing on the main review point. The experimental results demonstrate that
our model is competitive with or outperforms other unsupervised approaches. In
particular, for relatively long reviews, it achieves a competitive or better
performance than supervised models. The induced tree shows that the child
sentences provide additional information about their parent, and the generated
summary abstracts the entire review.
</summary>
    <author>
      <name>Masaru Isonuma</name>
    </author>
    <author>
      <name>Junichiro Mori</name>
    </author>
    <author>
      <name>Ichiro Sakata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, ACL 2019 (long paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05670v1</id>
    <updated>2019-06-13T13:33:22Z</updated>
    <published>2019-06-13T13:33:22Z</published>
    <title>KCAT: A Knowledge-Constraint Typing Annotation Tool</title>
    <summary>  Fine-grained Entity Typing is a tough task which suffers from noise samples
extracted from distant supervision. Thousands of manually annotated samples can
achieve greater performance than millions of samples generated by the previous
distant supervision method. Whereas, it's hard for human beings to
differentiate and memorize thousands of types, thus making large-scale human
labeling hardly possible. In this paper, we introduce a Knowledge-Constraint
Typing Annotation Tool (KCAT), which is efficient for fine-grained entity
typing annotation. KCAT reduces the size of candidate types to an acceptable
range for human beings through entity linking and provides a Multi-step Typing
scheme to revise the entity linking result. Moreover, KCAT provides an
efficient Annotator Client to accelerate the annotation process and a
comprehensive Manager Module to analyse crowdsourcing annotations. Experiment
shows that KCAT can significantly improve annotation efficiency, the time
consumption increases slowly as the size of type set expands.
</summary>
    <author>
      <name>Sheng Lin</name>
    </author>
    <author>
      <name>Luye Zheng</name>
    </author>
    <author>
      <name>Bo Chen</name>
    </author>
    <author>
      <name>Siliang Tang</name>
    </author>
    <author>
      <name>Yueting Zhuang</name>
    </author>
    <author>
      <name>Fei Wu</name>
    </author>
    <author>
      <name>Zhigang Chen</name>
    </author>
    <author>
      <name>Guoping Hu</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, acl2019 demo paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05381v2</id>
    <updated>2019-10-08T22:03:19Z</updated>
    <published>2019-06-12T21:25:09Z</published>
    <title>Compositional generalization through meta sequence-to-sequence learning</title>
    <summary>  People can learn a new concept and use it compositionally, understanding how
to "blicket twice" after learning how to "blicket." In contrast, powerful
sequence-to-sequence (seq2seq) neural networks fail such tests of
compositionality, especially when composing new concepts together with existing
concepts. In this paper, I show how memory-augmented neural networks can be
trained to generalize compositionally through meta seq2seq learning. In this
approach, models train on a series of seq2seq problems to acquire the
compositional skills needed to solve new seq2seq problems. Meta se2seq learning
solves several of the SCAN tests for compositional learning and can learn to
apply implicit rules to variables.
</summary>
    <author>
      <name>Brenden M. Lake</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper appears in the 33rd Conference on Neural Information
  Processing Systems (NeurIPS 2019), Vancouver, Canada</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Neural Information Processing Systems 33 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.05381v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05381v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05373v2</id>
    <updated>2020-02-13T06:20:11Z</updated>
    <published>2019-06-12T20:49:48Z</published>
    <title>E3: Entailment-driven Extracting and Editing for Conversational Machine
  Reading</title>
    <summary>  Conversational machine reading systems help users answer high-level questions
(e.g. determine if they qualify for particular government benefits) when they
do not know the exact rules by which the determination is made(e.g. whether
they need certain income levels or veteran status). The key challenge is that
these rules are only provided in the form of a procedural text (e.g. guidelines
from government website) which the system must read to figure out what to ask
the user. We present a new conversational machine reading model that jointly
extracts a set of decision rules from the procedural text while reasoning about
which are entailed by the conversational history and which still need to be
edited to create questions for the user. On the recently introduced ShARC
conversational machine reading dataset, our Entailment-driven Extract and Edit
network (E3) achieves a new state-of-the-art, outperforming existing systems as
well as a new BERT-based baseline. In addition, by explicitly highlighting
which information still needs to be gathered, E3 provides a more explainable
alternative to prior work. We release source code for our models and
experiments at https://github.com/vzhong/e3.
</summary>
    <author>
      <name>Victor Zhong</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at the Annual Meeting of the Association for Computational
  Linguistics (ACL) 2019. Source code: https://github.com/vzhong/e3. 10 pages,
  5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05373v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05373v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05317v2</id>
    <updated>2019-06-14T20:13:16Z</updated>
    <published>2019-06-12T18:11:20Z</published>
    <title>COMET: Commonsense Transformers for Automatic Knowledge Graph
  Construction</title>
    <summary>  We present the first comprehensive study on automatic knowledge base
construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et
al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional
KBs that store knowledge with canonical templates, commonsense KBs only store
loosely structured open-text descriptions of knowledge. We posit that an
important step toward automatic commonsense completion is the development of
generative models of commonsense knowledge, and propose COMmonsEnse
Transformers (COMET) that learn to generate rich and diverse commonsense
descriptions in natural language. Despite the challenges of commonsense
modeling, our investigation reveals promising results when implicit knowledge
from deep pre-trained language models is transferred to generate explicit
knowledge in commonsense knowledge graphs. Empirical results demonstrate that
COMET is able to generate novel knowledge that humans rate as high quality,
with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which
approaches human performance for these resources. Our findings suggest that
using generative commonsense models for automatic commonsense KB completion
could soon be a plausible alternative to extractive methods.
</summary>
    <author>
      <name>Antoine Bosselut</name>
    </author>
    <author>
      <name>Hannah Rashkin</name>
    </author>
    <author>
      <name>Maarten Sap</name>
    </author>
    <author>
      <name>Chaitanya Malaviya</name>
    </author>
    <author>
      <name>Asli Celikyilmaz</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05317v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05317v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05651v1</id>
    <updated>2019-06-12T17:29:22Z</updated>
    <published>2019-06-12T17:29:22Z</published>
    <title>Representation Learning for Words and Entities</title>
    <summary>  This thesis presents new methods for unsupervised learning of distributed
representations of words and entities from text and knowledge bases. The first
algorithm presented in the thesis is a multi-view algorithm for learning
representations of words called Multiview Latent Semantic Analysis (MVLSA). By
incorporating up to 46 different types of co-occurrence statistics for the same
vocabulary of english words, I show that MVLSA outperforms other
state-of-the-art word embedding models. Next, I focus on learning entity
representations for search and recommendation and present the second method of
this thesis, Neural Variational Set Expansion (NVSE). NVSE is also an
unsupervised learning method, but it is based on the Variational Autoencoder
framework. Evaluations with human annotators show that NVSE can facilitate
better search and recommendation of information gathered from noisy, automatic
annotation of unstructured natural language corpora. Finally, I move from
unstructured data and focus on structured knowledge graphs. I present novel
approaches for learning embeddings of vertices and edges in a knowledge graph
that obey logical constraints.
</summary>
    <author>
      <name>Pushpendre Rastogi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">phd thesis, Machine Learning, Natural Language Processing,
  Representation Learning, Knowledge Graphs, Entities, Word Embeddings, Entity
  Embeddings</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05210v1</id>
    <updated>2019-06-12T15:26:59Z</updated>
    <published>2019-06-12T15:26:59Z</published>
    <title>Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop
  Reading Comprehension</title>
    <summary>  Multi-hop reading comprehension requires the model to explore and connect
relevant information from multiple sentences/documents in order to answer the
question about the context. To achieve this, we propose an interpretable
3-module system called Explore-Propose-Assemble reader (EPAr). First, the
Document Explorer iteratively selects relevant documents and represents
divergent reasoning chains in a tree structure so as to allow assimilating
information from all chains. The Answer Proposer then proposes an answer from
every root-to-leaf path in the reasoning tree. Finally, the Evidence Assembler
extracts a key sentence containing the proposed answer from every path and
combines them to predict the final answer. Intuitively, EPAr approximates the
coarse-to-fine-grained comprehension behavior of human readers when facing
multiple long documents. We jointly optimize our 3 modules by minimizing the
sum of losses from each stage conditioned on the previous stage's output. On
two multi-hop reading comprehension datasets WikiHop and MedHop, our EPAr model
achieves significant improvements over the baseline and competitive results
compared to the state-of-the-art model. We also present multiple
reasoning-chain-recovery tests and ablation studies to demonstrate our system's
ability to perform interpretable and accurate reasoning.
</summary>
    <author>
      <name>Yichen Jiang</name>
    </author>
    <author>
      <name>Nitish Joshi</name>
    </author>
    <author>
      <name>Yen-Chun Chen</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019 (12 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05210v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05210v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04980v2</id>
    <updated>2019-06-27T09:43:46Z</updated>
    <published>2019-06-12T07:30:32Z</published>
    <title>Unsupervised Question Answering by Cloze Translation</title>
    <summary>  Obtaining training data for Question Answering (QA) is time-consuming and
resource-intensive, and existing QA datasets are only available for limited
domains and languages. In this work, we explore to what extent high quality
training data is actually required for Extractive QA, and investigate the
possibility of unsupervised Extractive QA. We approach this problem by first
learning to generate context, question and answer triples in an unsupervised
manner, which we then use to synthesize Extractive QA training data
automatically. To generate such triples, we first sample random context
paragraphs from a large corpus of documents and then random noun phrases or
named entity mentions from these paragraphs as answers. Next we convert answers
in context to "fill-in-the-blank" cloze questions and finally translate them
into natural questions. We propose and compare various unsupervised ways to
perform cloze-to-natural question translation, including training an
unsupervised NMT model using non-aligned corpora of natural questions and cloze
questions as well as a rule-based approach. We find that modern QA models can
learn to answer human questions surprisingly well using only synthetic training
data. We demonstrate that, without using the SQuAD training data at all, our
approach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named
entity mention), outperforming early supervised models.
</summary>
    <author>
      <name>Patrick Lewis</name>
    </author>
    <author>
      <name>Ludovic Denoyer</name>
    </author>
    <author>
      <name>Sebastian Riedel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04980v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04980v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04941v1</id>
    <updated>2019-06-12T04:58:51Z</updated>
    <published>2019-06-12T04:58:51Z</published>
    <title>Joint Reasoning for Temporal and Causal Relations</title>
    <summary>  Understanding temporal and causal relations between events is a fundamental
natural language understanding task. Because a cause must be before its effect
in time, temporal and causal relations are closely related and one relation
even dictates the other one in many cases. However, limited attention has been
paid to studying these two relations jointly. This paper presents a joint
inference framework for them using constrained conditional models (CCMs).
Specifically, we formulate the joint problem as an integer linear programming
(ILP) problem, enforcing constraints inherently in the nature of time and
causality. We show that the joint inference framework results in statistically
significant improvement in the extraction of both temporal and causal relations
from text.
</summary>
    <author>
      <name>Qiang Ning</name>
    </author>
    <author>
      <name>Zhili Feng</name>
    </author>
    <author>
      <name>Hao Wu</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long paper appeared in ACL'18. 11 pages and 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04706v1</id>
    <updated>2019-06-11T17:15:32Z</updated>
    <published>2019-06-11T17:15:32Z</published>
    <title>Using Structured Representation and Data: A Hybrid Model for Negation
  and Sentiment in Customer Service Conversations</title>
    <summary>  Twitter customer service interactions have recently emerged as an effective
platform to respond and engage with customers. In this work, we explore the
role of negation in customer service interactions, particularly applied to
sentiment analysis. We define rules to identify true negation cues and scope
more suited to conversational data than existing general review data. Using
semantic knowledge and syntactic structure from constituency parse trees, we
propose an algorithm for scope detection that performs comparable to state of
the art BiLSTM. We further investigate the results of negation scope detection
for the sentiment prediction task on customer service conversation data using
both a traditional SVM and a Neural Network. We propose an antonym dictionary
based method for negation applied to a CNN-LSTM combination model for sentiment
analysis. Experimental results show that the antonym-based method outperforms
the previous lexicon-based and neural network methods.
</summary>
    <author>
      <name>Amita Misra</name>
    </author>
    <author>
      <name>Mansurul Bhuiyan</name>
    </author>
    <author>
      <name>Jalal Mahmud</name>
    </author>
    <author>
      <name>Saurabh Tripathy</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 10th Workshop on Computational Approaches to
  Subjectivity, Sentiment and Social Media Analysis, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.04706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04447v1</id>
    <updated>2019-06-11T08:54:23Z</updated>
    <published>2019-06-11T08:54:23Z</published>
    <title>Reinforcement Learning of Minimalist Numeral Grammars</title>
    <summary>  Speech-controlled user interfaces facilitate the operation of devices and
household functions to laymen. State-of-the-art language technology scans the
acoustically analyzed speech signal for relevant keywords that are subsequently
inserted into semantic slots to interpret the user's intent. In order to
develop proper cognitive information and communication technologies, simple
slot-filling should be replaced by utterance meaning transducers (UMT) that are
based on semantic parsers and a \emph{mental lexicon}, comprising syntactic,
phonetic and semantic features of the language under consideration. This
lexicon must be acquired by a cognitive agent during interaction with its
users. We outline a reinforcement learning algorithm for the acquisition of the
syntactic morphology and arithmetic semantics of English numerals, based on
minimalist grammar (MG), a recent computational implementation of generative
linguistics. Number words are presented to the agent by a teacher in form of
utterance meaning pairs (UMP) where the meanings are encoded as arithmetic
terms from a suitable term algebra. Since MG encodes universal linguistic
competence through inference rules, thereby separating innate linguistic
knowledge from the contingently acquired lexicon, our approach unifies
generative grammar and reinforcement learning, hence potentially resolving the
still pending Chomsky-Skinner controversy.
</summary>
    <author>
      <name>Peter beim Graben</name>
    </author>
    <author>
      <name>Ronald Römer</name>
    </author>
    <author>
      <name>Werner Meyer</name>
    </author>
    <author>
      <name>Markus Huber</name>
    </author>
    <author>
      <name>Matthias Wolff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04102v1</id>
    <updated>2019-06-10T16:23:07Z</updated>
    <published>2019-06-10T16:23:07Z</published>
    <title>Detecting Everyday Scenarios in Narrative Texts</title>
    <summary>  Script knowledge consists of detailed information on everyday activities.
Such information is often taken for granted in text and needs to be inferred by
readers. Therefore, script knowledge is a central component to language
comprehension. Previous work on representing scripts is mostly based on
extensive manual work or limited to scenarios that can be found with sufficient
redundancy in large corpora. We introduce the task of scenario detection, in
which we identify references to scripts. In this task, we address a wide range
of different scripts (200 scenarios) and we attempt to identify all references
to them in a collection of narrative texts. We present a first benchmark data
set and a baseline model that tackles scenario detection using techniques from
topic segmentation and text classification.
</summary>
    <author>
      <name>Lilian D. A. Wanzare</name>
    </author>
    <author>
      <name>Michael Roth</name>
    </author>
    <author>
      <name>Manfred Pinkal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Storytelling workshop 2019@ACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04043v1</id>
    <updated>2019-06-10T14:52:41Z</updated>
    <published>2019-06-10T14:52:41Z</published>
    <title>GLTR: Statistical Detection and Visualization of Generated Text</title>
    <summary>  The rapid improvement of language models has raised the specter of abuse of
text generation systems. This progress motivates the development of simple
methods for detecting generated text that can be used by and explained to
non-experts. We develop GLTR, a tool to support humans in detecting whether a
text was generated by a model. GLTR applies a suite of baseline statistical
methods that can detect generation artifacts across common sampling schemes. In
a human-subjects study, we show that the annotation scheme provided by GLTR
improves the human detection-rate of fake text from 54% to 72% without any
prior training. GLTR is open-source and publicly deployed, and has already been
widely used to detect generated outputs
</summary>
    <author>
      <name>Sebastian Gehrmann</name>
    </author>
    <author>
      <name>Hendrik Strobelt</name>
    </author>
    <author>
      <name>Alexander M. Rush</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019 Demo Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.04043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03926v1</id>
    <updated>2019-06-10T12:17:45Z</updated>
    <published>2019-06-10T12:17:45Z</published>
    <title>A Survey of Reinforcement Learning Informed by Natural Language</title>
    <summary>  To be successful in real-world tasks, Reinforcement Learning (RL) needs to
exploit the compositional, relational, and hierarchical structure of the world,
and learn to transfer it to the task at hand. Recent advances in representation
learning for language make it possible to build models that acquire world
knowledge from text corpora and integrate this knowledge into downstream
decision making problems. We thus argue that the time is right to investigate a
tight integration of natural language understanding into RL in particular. We
survey the state of the field, including work on instruction following, text
games, and learning from textual domain knowledge. Finally, we call for the
development of new environments as well as further investigation into the
potential uses of recent Natural Language Processing (NLP) techniques for such
tasks.
</summary>
    <author>
      <name>Jelena Luketina</name>
    </author>
    <author>
      <name>Nantas Nardelli</name>
    </author>
    <author>
      <name>Gregory Farquhar</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Jacob Andreas</name>
    </author>
    <author>
      <name>Edward Grefenstette</name>
    </author>
    <author>
      <name>Shimon Whiteson</name>
    </author>
    <author>
      <name>Tim Rocktäschel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at IJCAI'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03897v1</id>
    <updated>2019-06-10T10:57:47Z</updated>
    <published>2019-06-10T10:57:47Z</published>
    <title>Learning to combine Grammatical Error Corrections</title>
    <summary>  The field of Grammatical Error Correction (GEC) has produced various systems
to deal with focused phenomena or general text editing. We propose an automatic
way to combine black-box systems. Our method automatically detects the strength
of a system or the combination of several systems per error type, improving
precision and recall while optimizing $F$ score directly. We show consistent
improvement over the best standalone system in all the configurations tested.
This approach also outperforms average ensembling of different RNN models with
random initializations.
  In addition, we analyze the use of BERT for GEC - reporting promising results
on this end. We also present a spellchecker created for this task which
outperforms standard spellcheckers tested on the task of spellchecking.
  This paper describes a system submission to Building Educational Applications
2019 Shared Task: Grammatical Error Correction.
  Combining the output of top BEA 2019 shared task systems using our approach,
currently holds the highest reported score in the open phase of the BEA 2019
shared task, improving F0.5 by 3.7 points over the best result reported.
</summary>
    <author>
      <name>Yoav Kantor</name>
    </author>
    <author>
      <name>Yoav Katz</name>
    </author>
    <author>
      <name>Leshem Choshen</name>
    </author>
    <author>
      <name>Edo Cohen-Karlik</name>
    </author>
    <author>
      <name>Naftali Liberman</name>
    </author>
    <author>
      <name>Assaf Toledo</name>
    </author>
    <author>
      <name>Amir Menczel</name>
    </author>
    <author>
      <name>Noam Slonim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">BEA 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03672v1</id>
    <updated>2019-06-09T16:56:31Z</updated>
    <published>2019-06-09T16:56:31Z</published>
    <title>Question Answering as Global Reasoning over Semantic Abstractions</title>
    <summary>  We propose a novel method for exploiting the semantic structure of text to
answer multiple-choice questions. The approach is especially suitable for
domains that require reasoning over a diverse set of linguistic constructs but
have limited training data. To address these challenges, we present the first
system, to the best of our knowledge, that reasons over a wide range of
semantic abstractions of the text, which are derived using off-the-shelf,
general-purpose, pre-trained natural language modules such as semantic role
labelers, coreference resolvers, and dependency parsers. Representing multiple
abstractions as a family of graphs, we translate question answering (QA) into a
search for an optimal subgraph that satisfies certain global and local
properties. This formulation generalizes several prior structured QA systems.
Our system, SEMANTICILP, demonstrates strong performance on two domains
simultaneously. In particular, on a collection of challenging science QA
datasets, it outperforms various state-of-the-art approaches, including neural
models, broad coverage information retrieval, and specialized techniques using
structured knowledge bases, by 2%-6%.
</summary>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <author>
      <name>Tushar Khot</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appeared in AAAI'18</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05833v2</id>
    <updated>2019-11-28T20:26:52Z</updated>
    <published>2019-06-09T12:42:23Z</published>
    <title>There is no Artificial General Intelligence</title>
    <summary>  The goal of creating Artificial General Intelligence (AGI) -- or in other
words of creating Turing machines (modern computers) that can behave in a way
that mimics human intelligence -- has occupied AI researchers ever since the
idea of AI was first proposed. One common theme in these discussions is the
thesis that the ability of a machine to conduct convincing dialogues with human
beings can serve as at least a sufficient criterion of AGI. We argue that this
very ability should be accepted also as a necessary condition of AGI, and we
provide a description of the nature of human dialogue in particular and of
human language in general against this background. We then argue that it is for
mathematical reasons impossible to program a machine in such a way that it
could master human dialogue behaviour in its full generality. This is (1)
because there are no traditional explicitly designed mathematical models that
could be used as a starting point for creating such programs; and (2) because
even the sorts of automated models generated by using machine learning, which
have been used successfully in areas such as machine translation, cannot be
extended to cope with human dialogue. If this is so, then we can conclude that
a Turing machine also cannot possess AGI, because it fails to fulfil a
necessary condition thereof. At the same time, however, we acknowledge the
potential of Turing machines to master dialogue behaviour in highly restricted
contexts, where what is called ``narrow'' AI can still be of considerable
utility.
</summary>
    <author>
      <name>J. Landgrebe</name>
    </author>
    <author>
      <name>B. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1906.05833v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05833v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03506v1</id>
    <updated>2019-06-08T19:18:18Z</updated>
    <published>2019-06-08T19:18:18Z</published>
    <title>Forward and Backward Knowledge Transfer for Sentiment Classification</title>
    <summary>  This paper studies the problem of learning a sequence of sentiment
classification tasks. The learned knowledge from each task is retained and used
to help future or subsequent task learning. This learning paradigm is called
Lifelong Learning (LL). However, existing LL methods either only transfer
knowledge forward to help future learning and do not go back to improve the
model of a previous task or require the training data of the previous task to
retrain its model to exploit backward/reverse knowledge transfer. This paper
studies reverse knowledge transfer of LL in the context of naive Bayesian (NB)
classification. It aims to improve the model of a previous task by leveraging
future knowledge without retraining using its training data. This is done by
exploiting a key characteristic of the generative model of NB. That is, it is
possible to improve the NB classifier for a task by improving its model
parameters directly by using the retained knowledge from other tasks.
Experimental results show that the proposed method markedly outperforms
existing LL baselines.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Bing Liu</name>
    </author>
    <author>
      <name>Shuai Wang</name>
    </author>
    <author>
      <name>Nianzu Ma</name>
    </author>
    <author>
      <name>Yan Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1906.03506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03348v1</id>
    <updated>2019-06-07T22:26:29Z</updated>
    <published>2019-06-07T22:26:29Z</published>
    <title>Classifying the reported ability in clinical mobility descriptions</title>
    <summary>  Assessing how individuals perform different activities is key information for
modeling health states of individuals and populations. Descriptions of activity
performance in clinical free text are complex, including syntactic negation and
similarities to textual entailment tasks. We explore a variety of methods for
the novel task of classifying four types of assertions about activity
performance: Able, Unable, Unclear, and None (no information). We find that
ensembling an SVM trained with lexical features and a CNN achieves 77.9% macro
F1 score on our task, and yields nearly 80% recall on the rare Unclear and
Unable samples. Finally, we highlight several challenges in classifying
performance assertions, including capturing information about sources of
assistance, incorporating syntactic structure and negation scope, and handling
new modalities at test time. Our findings establish a strong baseline for this
novel task, and identify intriguing areas for further research.
</summary>
    <author>
      <name>Denis Newman-Griffis</name>
    </author>
    <author>
      <name>Ayah Zirikly</name>
    </author>
    <author>
      <name>Guy Divita</name>
    </author>
    <author>
      <name>Bart Desmet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appearing in BioNLP 2019. 10 pages; 6 tables, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03158v1</id>
    <updated>2019-06-07T15:26:50Z</updated>
    <published>2019-06-07T15:26:50Z</published>
    <title>Matching the Blanks: Distributional Similarity for Relation Learning</title>
    <summary>  General purpose relation extractors, which can model arbitrary relations, are
a core aspiration in information extraction. Efforts have been made to build
general purpose extractors that represent relations with their surface forms,
or which jointly embed surface forms with relations from an existing knowledge
graph. However, both of these approaches are limited in their ability to
generalize. In this paper, we build on extensions of Harris' distributional
hypothesis to relations, as well as recent advances in learning text
representations (specifically, BERT), to build task agnostic relation
representations solely from entity-linked text. We show that these
representations significantly outperform previous work on exemplar based
relation extraction (FewRel) even without using any of that task's training
data. We also show that models initialized with our task agnostic
representations, and then tuned on supervised relation extraction datasets,
significantly outperform the previous methods on SemEval 2010 Task 8, KBP37,
and TACRED.
</summary>
    <author>
      <name>Livio Baldini Soares</name>
    </author>
    <author>
      <name>Nicholas FitzGerald</name>
    </author>
    <author>
      <name>Jeffrey Ling</name>
    </author>
    <author>
      <name>Tom Kwiatkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03129v1</id>
    <updated>2019-06-07T14:32:17Z</updated>
    <published>2019-06-07T14:32:17Z</published>
    <title>Word-based Domain Adaptation for Neural Machine Translation</title>
    <summary>  In this paper, we empirically investigate applying word-level weights to
adapt neural machine translation to e-commerce domains, where small e-commerce
datasets and large out-of-domain datasets are available. In order to mine
in-domain like words in the out-of-domain datasets, we compute word weights by
using a domain-specific and a non-domain-specific language model followed by
smoothing and binary quantization. The baseline model is trained on mixed
in-domain and out-of-domain datasets. Experimental results on English to
Chinese e-commerce domain translation show that compared to continuing training
without word weights, it improves MT quality by up to 2.11% BLEU absolute and
1.59% TER. We have also trained models using fine-tuning on the in-domain data.
Pre-training a model with word weights improves fine-tuning up to 1.24% BLEU
absolute and 1.64% TER, respectively.
</summary>
    <author>
      <name>Shen Yan</name>
    </author>
    <author>
      <name>Leonard Dahlmann</name>
    </author>
    <author>
      <name>Pavel Petrushkov</name>
    </author>
    <author>
      <name>Sanjika Hewavitharana</name>
    </author>
    <author>
      <name>Shahram Khadivi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published on the proceedings of the International Workshop on Spoken
  Language Translation (IWSLT), 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 15th International Workshop on Spoken Language
  Translation, Bruges, Belgium, October 29-30, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.03129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.03100v1</id>
    <updated>2019-06-07T13:48:46Z</updated>
    <published>2019-06-07T13:48:46Z</published>
    <title>Shared-Private Bilingual Word Embeddings for Neural Machine Translation</title>
    <summary>  Word embedding is central to neural machine translation (NMT), which has
attracted intensive research interest in recent years. In NMT, the source
embedding plays the role of the entrance while the target embedding acts as the
terminal. These layers occupy most of the model parameters for representation
learning. Furthermore, they indirectly interface via a soft-attention
mechanism, which makes them comparatively isolated. In this paper, we propose
shared-private bilingual word embeddings, which give a closer relationship
between the source and target embeddings, and which also reduce the number of
model parameters. For similar source and target words, their embeddings tend to
share a part of the features and they cooperatively learn these common
representation units. Experiments on 5 language pairs belonging to 6 different
language families and written in 5 different alphabets demonstrate that the
proposed model provides a significant performance boost over the strong
baselines with dramatically fewer model parameters.
</summary>
    <author>
      <name>Xuebo Liu</name>
    </author>
    <author>
      <name>Derek F. Wong</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Lidia S. Chao</name>
    </author>
    <author>
      <name>Tong Xiao</name>
    </author>
    <author>
      <name>Jingbo Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.03100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02916v2</id>
    <updated>2019-06-30T22:30:19Z</updated>
    <published>2019-06-07T06:22:17Z</published>
    <title>Multi-hop Reading Comprehension through Question Decomposition and
  Rescoring</title>
    <summary>  Multi-hop Reading Comprehension (RC) requires reasoning and aggregation
across several paragraphs. We propose a system for multi-hop RC that decomposes
a compositional question into simpler sub-questions that can be answered by
off-the-shelf single-hop RC models. Since annotations for such decomposition
are expensive, we recast sub-question generation as a span prediction problem
and show that our method, trained using only 400 labeled examples, generates
sub-questions that are as effective as human-authored sub-questions. We also
introduce a new global rescoring approach that considers each decomposition
(i.e. the sub-questions and their answers) to select the best final answer,
greatly improving overall performance. Our experiments on HotpotQA show that
this approach achieves the state-of-the-art results, while providing
explainable evidence for its decision making in the form of sub-questions.
</summary>
    <author>
      <name>Sewon Min</name>
    </author>
    <author>
      <name>Victor Zhong</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at ACL 2019 (long). Code available at
  https://github.com/shmsw25/DecompRC</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02916v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02916v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02900v1</id>
    <updated>2019-06-07T05:10:15Z</updated>
    <published>2019-06-07T05:10:15Z</published>
    <title>Compositional Questions Do Not Necessitate Multi-hop Reasoning</title>
    <summary>  Multi-hop reading comprehension (RC) questions are challenging because they
require reading and reasoning over multiple paragraphs. We argue that it can be
difficult to construct large multi-hop RC datasets. For example, even highly
compositional questions can be answered with a single hop if they target
specific entity types, or the facts needed to answer them are redundant. Our
analysis is centered on HotpotQA, where we show that single-hop reasoning can
solve much more of the dataset than previously thought. We introduce a
single-hop BERT-based RC model that achieves 67 F1---comparable to
state-of-the-art multi-hop models. We also design an evaluation setting where
humans are not shown all of the necessary paragraphs for the intended multi-hop
reasoning but can still answer over 80% of questions. Together with detailed
error analysis, these results suggest there should be an increasing focus on
the role of evidence in multi-hop reasoning and possibly even a shift towards
information retrieval style evaluations with large and diverse evidence
collections.
</summary>
    <author>
      <name>Sewon Min</name>
    </author>
    <author>
      <name>Eric Wallace</name>
    </author>
    <author>
      <name>Sameer Singh</name>
    </author>
    <author>
      <name>Matt Gardner</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at ACL 2019 (short). Code available
  at https://github.com/shmsw25/single-hop-rc</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02738v2</id>
    <updated>2019-06-07T03:10:20Z</updated>
    <published>2019-06-06T17:55:37Z</published>
    <title>Conversing by Reading: Contentful Neural Conversation with On-demand
  Machine Reading</title>
    <summary>  Although neural conversation models are effective in learning how to produce
fluent responses, their primary challenge lies in knowing what to say to make
the conversation contentful and non-vacuous. We present a new end-to-end
approach to contentful neural conversation that jointly models response
generation and on-demand machine reading. The key idea is to provide the
conversation model with relevant long-form text on the fly as a source of
external knowledge. The model performs QA-style reading comprehension on this
text in response to each conversational turn, thereby allowing for more focused
integration of external knowledge than has been possible in prior approaches.
To support further research on knowledge-grounded conversation, we introduce a
new large-scale conversation dataset grounded in external web pages (2.8M
turns, 7.4M sentences of grounding). Both human evaluation and automated
metrics show that our approach results in more contentful responses compared to
a variety of previous methods, improving both the informativeness and diversity
of generated output.
</summary>
    <author>
      <name>Lianhui Qin</name>
    </author>
    <author>
      <name>Michel Galley</name>
    </author>
    <author>
      <name>Chris Brockett</name>
    </author>
    <author>
      <name>Xiaodong Liu</name>
    </author>
    <author>
      <name>Xiang Gao</name>
    </author>
    <author>
      <name>Bill Dolan</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019 long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02738v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02738v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02564v1</id>
    <updated>2019-06-06T13:13:46Z</updated>
    <published>2019-06-06T13:13:46Z</published>
    <title>Analysis of Automatic Annotation Suggestions for Hard Discourse-Level
  Tasks in Expert Domains</title>
    <summary>  Many complex discourse-level tasks can aid domain experts in their work but
require costly expert annotations for data creation. To speed up and ease
annotations, we investigate the viability of automatically generated annotation
suggestions for such tasks. As an example, we choose a task that is
particularly hard for both humans and machines: the segmentation and
classification of epistemic activities in diagnostic reasoning texts. We create
and publish a new dataset covering two domains and carefully analyse the
suggested annotations. We find that suggestions have positive effects on
annotation speed and performance, while not introducing noteworthy biases.
Envisioning suggestion models that improve with newly annotated texts, we
contrast methods for continuous model adjustment and suggest the most effective
setup for suggestions in future expert tasks.
</summary>
    <author>
      <name>Claudia Schulz</name>
    </author>
    <author>
      <name>Christian M. Meyer</name>
    </author>
    <author>
      <name>Jan Kiesewetter</name>
    </author>
    <author>
      <name>Michael Sailer</name>
    </author>
    <author>
      <name>Elisabeth Bauer</name>
    </author>
    <author>
      <name>Martin R. Fischer</name>
    </author>
    <author>
      <name>Frank Fischer</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of the 57th Annual Meeting of the
  Association for Computational Linguistics (ACL 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02461v3</id>
    <updated>2019-06-25T02:58:06Z</updated>
    <published>2019-06-06T07:48:36Z</published>
    <title>Unsupervised Pivot Translation for Distant Languages</title>
    <summary>  Unsupervised neural machine translation (NMT) has attracted a lot of
attention recently. While state-of-the-art methods for unsupervised translation
usually perform well between similar languages (e.g., English-German
translation), they perform poorly between distant languages, because
unsupervised alignment does not work well for distant languages. In this work,
we introduce unsupervised pivot translation for distant languages, which
translates a language to a distant language through multiple hops, and the
unsupervised translation on each hop is relatively easier than the original
direct translation. We propose a learning to route (LTR) method to choose the
translation path between the source and target languages. LTR is trained on
language pairs whose best translation path is available and is applied on the
unseen language pairs for path selection. Experiments on 20 languages and 294
distant language pairs demonstrate the advantages of the unsupervised pivot
translation for distant languages, as well as the effectiveness of the proposed
LTR for path selection. Specifically, in the best case, LTR achieves an
improvement of 5.58 BLEU points over the conventional direct unsupervised
method.
</summary>
    <author>
      <name>Yichong Leng</name>
    </author>
    <author>
      <name>Xu Tan</name>
    </author>
    <author>
      <name>Tao Qin</name>
    </author>
    <author>
      <name>Xiang-Yang Li</name>
    </author>
    <author>
      <name>Tie-Yan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL-2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02461v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02461v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02403v2</id>
    <updated>2019-10-28T22:51:26Z</updated>
    <published>2019-06-06T03:59:37Z</published>
    <title>Ease-of-Teaching and Language Structure from Emergent Communication</title>
    <summary>  Artificial agents have been shown to learn to communicate when needed to
complete a cooperative task. Some level of language structure (e.g.,
compositionality) has been found in the learned communication protocols. This
observed structure is often the result of specific environmental pressures
during training. By introducing new agents periodically to replace old ones,
sequentially and within a population, we explore such a new pressure -- ease of
teaching -- and show its impact on the structure of the resulting language.
</summary>
    <author>
      <name>Fushan Li</name>
    </author>
    <author>
      <name>Michael Bowling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Neural Information Processing Systems (NeurIPS) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02403v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02403v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02390v1</id>
    <updated>2019-06-06T02:52:12Z</updated>
    <published>2019-06-06T02:52:12Z</published>
    <title>Multi-view Knowledge Graph Embedding for Entity Alignment</title>
    <summary>  We study the problem of embedding-based entity alignment between knowledge
graphs (KGs). Previous works mainly focus on the relational structure of
entities. Some further incorporate another type of features, such as
attributes, for refinement. However, a vast of entity features are still
unexplored or not equally treated together, which impairs the accuracy and
robustness of embedding-based entity alignment. In this paper, we propose a
novel framework that unifies multiple views of entities to learn embeddings for
entity alignment. Specifically, we embed entities based on the views of entity
names, relations and attributes, with several combination strategies.
Furthermore, we design some cross-KG inference methods to enhance the alignment
between two KGs. Our experiments on real-world datasets show that the proposed
framework significantly outperforms the state-of-the-art embedding-based entity
alignment methods. The selected views, cross-KG inference and combination
strategies all contribute to the performance improvement.
</summary>
    <author>
      <name>Qingheng Zhang</name>
    </author>
    <author>
      <name>Zequn Sun</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <author>
      <name>Muhao Chen</name>
    </author>
    <author>
      <name>Lingbing Guo</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 28th International Joint Conference on Artificial
  Intelligence (IJCAI 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02285v1</id>
    <updated>2019-06-05T20:05:18Z</updated>
    <published>2019-06-05T20:05:18Z</published>
    <title>SParC: Cross-Domain Semantic Parsing in Context</title>
    <summary>  We present SParC, a dataset for cross-domainSemanticParsing inContext that
consists of 4,298 coherent question sequences (12k+ individual questions
annotated with SQL queries). It is obtained from controlled user interactions
with 200 complex databases over 138 domains. We provide an in-depth analysis of
SParC and show that it introduces new challenges compared to existing datasets.
SParC demonstrates complex contextual dependencies, (2) has greater semantic
diversity, and (3) requires generalization to unseen domains due to its
cross-domain nature and the unseen databases at test time. We experiment with
two state-of-the-art text-to-SQL models adapted to the context-dependent,
cross-domain setup. The best model obtains an exact match accuracy of 20.2%
over all questions and less than10% over all interaction sequences, indicating
that the cross-domain setting and the con-textual phenomena of the dataset
present significant challenges for future research. The dataset, baselines, and
leaderboard are released at https://yale-lily.github.io/sparc.
</summary>
    <author>
      <name>Tao Yu</name>
    </author>
    <author>
      <name>Rui Zhang</name>
    </author>
    <author>
      <name>Michihiro Yasunaga</name>
    </author>
    <author>
      <name>Yi Chern Tan</name>
    </author>
    <author>
      <name>Xi Victoria Lin</name>
    </author>
    <author>
      <name>Suyi Li</name>
    </author>
    <author>
      <name>Heyang Er</name>
    </author>
    <author>
      <name>Irene Li</name>
    </author>
    <author>
      <name>Bo Pang</name>
    </author>
    <author>
      <name>Tao Chen</name>
    </author>
    <author>
      <name>Emily Ji</name>
    </author>
    <author>
      <name>Shreya Dixit</name>
    </author>
    <author>
      <name>David Proctor</name>
    </author>
    <author>
      <name>Sungrok Shim</name>
    </author>
    <author>
      <name>Jonathan Kraft</name>
    </author>
    <author>
      <name>Vincent Zhang</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Dragomir Radev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019, long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01946v1</id>
    <updated>2019-06-05T11:23:14Z</updated>
    <published>2019-06-05T11:23:14Z</published>
    <title>Automated Speech Generation from UN General Assembly Statements: Mapping
  Risks in AI Generated Texts</title>
    <summary>  Automated text generation has been applied broadly in many domains such as
marketing and robotics, and used to create chatbots, product reviews and write
poetry. The ability to synthesize text, however, presents many potential risks,
while access to the technology required to build generative models is becoming
increasingly easy. This work is aligned with the efforts of the United Nations
and other civil society organisations to highlight potential political and
societal risks arising through the malicious use of text generation software,
and their potential impact on human rights. As a case study, we present the
findings of an experiment to generate remarks in the style of political leaders
by fine-tuning a pretrained AWD- LSTM model on a dataset of speeches made at
the UN General Assembly. This work highlights the ease with which this can be
accomplished, as well as the threats of combining these techniques with other
technologies.
</summary>
    <author>
      <name>Joseph Bullock</name>
    </author>
    <author>
      <name>Miguel Luengo-Oroz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning AI for Social Good
  Workshop, Long Beach, United States, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.01946v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01946v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01873v3</id>
    <updated>2019-08-16T14:24:58Z</updated>
    <published>2019-06-05T08:11:12Z</published>
    <title>Towards conceptual generalization in the embedding space</title>
    <summary>  Humans are able to conceive physical reality by jointly learning different
facets thereof. To every pair of notions related to a perceived reality may
correspond a mutual relation, which is a notion on its own, but one-level
higher. Thus, we may have a description of perceived reality on at least two
levels and the translation map between them is in general, due to their
different content corpus, one-to-many. Following success of the unsupervised
neural machine translation models, which are essentially one-to-one mappings
trained separately on monolingual corpora, we examine further capabilities of
the unsupervised deep learning methods used there and apply some of these
methods to sets of notions of different level and measure. Using the graph and
word embedding-like techniques, we build one-to-many map without parallel data
in order to establish a unified vector representation of the outer world by
combining notions of different kind into a unique conceptual framework. Due to
their latent similarity, by aligning the two embedding spaces in purely
unsupervised way, one obtains a geometric relation between objects of cognition
on the two levels, making it possible to express a natural knowledge using one
description in the context of the other.
</summary>
    <author>
      <name>Luka Nenadović</name>
    </author>
    <author>
      <name>Vladimir Prelovac</name>
    </author>
    <link href="http://arxiv.org/abs/1906.01873v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01873v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01833v1</id>
    <updated>2019-06-05T05:27:31Z</updated>
    <published>2019-06-05T05:27:31Z</published>
    <title>A Hierarchical Reinforced Sequence Operation Method for Unsupervised
  Text Style Transfer</title>
    <summary>  Unsupervised text style transfer aims to alter text styles while preserving
the content, without aligned data for supervision. Existing seq2seq methods
face three challenges: 1) the transfer is weakly interpretable, 2) generated
outputs struggle in content preservation, and 3) the trade-off between content
and style is intractable. To address these challenges, we propose a
hierarchical reinforced sequence operation method, named Point-Then-Operate
(PTO), which consists of a high-level agent that proposes operation positions
and a low-level agent that alters the sentence. We provide comprehensive
training objectives to control the fluency, style, and content of the outputs
and a mask-based inference algorithm that allows for multi-step revision based
on the single-step trained agents. Experimental results on two text style
transfer datasets show that our method significantly outperforms recent methods
and effectively addresses the aforementioned challenges.
</summary>
    <author>
      <name>Chen Wu</name>
    </author>
    <author>
      <name>Xuancheng Ren</name>
    </author>
    <author>
      <name>Fuli Luo</name>
    </author>
    <author>
      <name>Xu Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01764v1</id>
    <updated>2019-06-05T00:33:47Z</updated>
    <published>2019-06-05T00:33:47Z</published>
    <title>Visual Story Post-Editing</title>
    <summary>  We introduce the first dataset for human edits of machine-generated visual
stories and explore how these collected edits may be used for the visual story
post-editing task. The dataset, VIST-Edit, includes 14,905 human edited
versions of 2,981 machine-generated visual stories. The stories were generated
by two state-of-the-art visual storytelling models, each aligned to 5
human-edited versions. We establish baselines for the task, showing how a
relatively small set of human edits can be leveraged to boost the performance
of large visual storytelling models. We also discuss the weak correlation
between automatic evaluation scores and human ratings, motivating the need for
new automatic metrics.
</summary>
    <author>
      <name>Ting-Yao Hsu</name>
    </author>
    <author>
      <name>Chieh-Yang Huang</name>
    </author>
    <author>
      <name>Yen-Chia Hsu</name>
    </author>
    <author>
      <name>Ting-Hao 'Kenneth' Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01622v3</id>
    <updated>2019-11-11T07:36:47Z</updated>
    <published>2019-06-04T17:56:22Z</published>
    <title>Are Girls Neko or Shōjo? Cross-Lingual Alignment of Non-Isomorphic
  Embeddings with Iterative Normalization</title>
    <summary>  Cross-lingual word embeddings (CLWE) underlie many multilingual natural
language processing systems, often through orthogonal transformations of
pre-trained monolingual embeddings. However, orthogonal mapping only works on
language pairs whose embeddings are naturally isomorphic. For non-isomorphic
pairs, our method (Iterative Normalization) transforms monolingual embeddings
to make orthogonal alignment easier by simultaneously enforcing that (1)
individual word vectors are unit length, and (2) each language's average vector
is zero. Iterative Normalization consistently improves word translation
accuracy of three CLWE methods, with the largest improvement observed on
English-Japanese (from 2% to 44% test accuracy).
</summary>
    <author>
      <name>Mozhi Zhang</name>
    </author>
    <author>
      <name>Keyulu Xu</name>
    </author>
    <author>
      <name>Ken-ichi Kawarabayashi</name>
    </author>
    <author>
      <name>Stefanie Jegelka</name>
    </author>
    <author>
      <name>Jordan Boyd-Graber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01622v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01622v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01605v1</id>
    <updated>2019-06-04T17:39:52Z</updated>
    <published>2019-06-04T17:39:52Z</published>
    <title>Transferable Neural Projection Representations</title>
    <summary>  Neural word representations are at the core of many state-of-the-art natural
language processing models. A widely used approach is to pre-train, store and
look up word or character embedding matrices. While useful, such
representations occupy huge memory making it hard to deploy on-device and often
do not generalize to unknown words due to vocabulary pruning.
  In this paper, we propose a skip-gram based architecture coupled with
Locality-Sensitive Hashing (LSH) projections to learn efficient dynamically
computable representations. Our model does not need to store lookup tables as
representations are computed on-the-fly and require low memory footprint. The
representations can be trained in an unsupervised fashion and can be easily
transferred to other NLP tasks. For qualitative evaluation, we analyze the
nearest neighbors of the word representations and discover semantically similar
words even with misspellings. For quantitative evaluation, we plug our
transferable projections into a simple LSTM and run it on multiple NLP tasks
and show how our transferable projections achieve better performance compared
to prior work.
</summary>
    <author>
      <name>Chinnadhurai Sankar</name>
    </author>
    <author>
      <name>Sujith Ravi</name>
    </author>
    <author>
      <name>Zornitsa Kozareva</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. of NAACL 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.01605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01603v2</id>
    <updated>2019-07-25T20:27:46Z</updated>
    <published>2019-06-04T17:32:35Z</published>
    <title>Do Neural Dialog Systems Use the Conversation History Effectively? An
  Empirical Study</title>
    <summary>  Neural generative models have been become increasingly popular when building
conversational agents. They offer flexibility, can be easily adapted to new
domains, and require minimal domain engineering. A common criticism of these
systems is that they seldom understand or use the available dialog history
effectively. In this paper, we take an empirical approach to understanding how
these models use the available dialog history by studying the sensitivity of
the models to artificially introduced unnatural changes or perturbations to
their context at test time. We experiment with 10 different types of
perturbations on 4 multi-turn dialog datasets and find that commonly used
neural dialog architectures like recurrent and transformer-based seq2seq models
are rarely sensitive to most perturbations such as missing or reordering
utterances, shuffling words, etc. Also, by open-sourcing our code, we believe
that it will serve as a useful diagnostic tool for evaluating dialog systems in
the future.
</summary>
    <author>
      <name>Chinnadhurai Sankar</name>
    </author>
    <author>
      <name>Sandeep Subramanian</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <author>
      <name>Sarath Chandar</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at ACL 2019(oral; nominated for best paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01603v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01603v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01539v2</id>
    <updated>2019-06-05T09:58:34Z</updated>
    <published>2019-06-04T15:52:46Z</published>
    <title>Blackbox meets blackbox: Representational Similarity and Stability
  Analysis of Neural Language Models and Brains</title>
    <summary>  In this paper, we define and apply representational stability analysis
(ReStA), an intuitive way of analyzing neural language models. ReStA is a
variant of the popular representational similarity analysis (RSA) in cognitive
neuroscience. While RSA can be used to compare representations in models, model
components, and human brains, ReStA compares instances of the same model, while
systematically varying single model parameter. Using ReStA, we study four
recent and successful neural language models, and evaluate how sensitive their
internal representations are to the amount of prior context. Using RSA, we
perform a systematic study of how similar the representational spaces in the
first and second (or higher) layers of these models are to each other and to
patterns of activation in the human brain. Our results reveal surprisingly
strong differences between language models, and give insights into where the
deep linguistic processing, that integrates information over multiple
sentences, is happening in these models. The combination of ReStA and RSA on
models and brains allows us to start addressing the important question of what
kind of linguistic processes we can hope to observe in fMRI brain imaging data.
In particular, our results suggest that the data on story reading from Wehbe et
al. (2014) contains a signal of shallow linguistic processing, but show no
evidence on the more interesting deep linguistic processing.
</summary>
    <author>
      <name>Samira Abnar</name>
    </author>
    <author>
      <name>Lisa Beinborn</name>
    </author>
    <author>
      <name>Rochelle Choenni</name>
    </author>
    <author>
      <name>Willem Zuidema</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2nd BlackBoxNLP workshop @ACL2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.01539v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01539v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01530v2</id>
    <updated>2019-06-26T17:36:47Z</updated>
    <published>2019-06-04T15:41:32Z</published>
    <title>The PhotoBook Dataset: Building Common Ground through Visually-Grounded
  Dialogue</title>
    <summary>  This paper introduces the PhotoBook dataset, a large-scale collection of
visually-grounded, task-oriented dialogues in English designed to investigate
shared dialogue history accumulating during conversation. Taking inspiration
from seminal work on dialogue analysis, we propose a data-collection task
formulated as a collaborative game prompting two online participants to refer
to images utilising both their visual context as well as previously established
referring expressions. We provide a detailed description of the task setup and
a thorough analysis of the 2,500 dialogues collected. To further illustrate the
novel features of the dataset, we propose a baseline model for reference
resolution which uses a simple method to take into account shared information
accumulated in a reference chain. Our results show that this information is
particularly important to resolve later descriptions and underline the need to
develop more sophisticated models of common ground in dialogue interaction.
</summary>
    <author>
      <name>Janosch Haber</name>
    </author>
    <author>
      <name>Tim Baumgärtner</name>
    </author>
    <author>
      <name>Ece Takmaz</name>
    </author>
    <author>
      <name>Lieke Gelderloos</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <author>
      <name>Raquel Fernández</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Updates 26-06-2019: Changed caption sizes to comply with the ACL
  style guidelines and corrected some references</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01530v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01530v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01502v1</id>
    <updated>2019-06-04T15:12:47Z</updated>
    <published>2019-06-04T15:12:47Z</published>
    <title>How multilingual is Multilingual BERT?</title>
    <summary>  In this paper, we show that Multilingual BERT (M-BERT), released by Devlin et
al. (2018) as a single language model pre-trained from monolingual corpora in
104 languages, is surprisingly good at zero-shot cross-lingual model transfer,
in which task-specific annotations in one language are used to fine-tune the
model for evaluation in another language. To understand why, we present a large
number of probing experiments, showing that transfer is possible even to
languages in different scripts, that transfer works best between typologically
similar languages, that monolingual corpora can train models for
code-switching, and that the model can find translation pairs. From these
results, we can conclude that M-BERT does create multilingual representations,
but that these representations exhibit systematic deficiencies affecting
certain language pairs.
</summary>
    <author>
      <name>Telmo Pires</name>
    </author>
    <author>
      <name>Eva Schlinger</name>
    </author>
    <author>
      <name>Dan Garrette</name>
    </author>
    <link href="http://arxiv.org/abs/1906.01502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01440v1</id>
    <updated>2019-06-04T13:54:47Z</updated>
    <published>2019-06-04T13:54:47Z</published>
    <title>Tracing Antisemitic Language Through Diachronic Embedding Projections:
  France 1789-1914</title>
    <summary>  We investigate some aspects of the history of antisemitism in France, one of
the cradles of modern antisemitism, using diachronic word embeddings. We
constructed a large corpus of French books and periodicals issues that contain
a keyword related to Jews and performed a diachronic word embedding over the
1789-1914 period. We studied the changes over time in the semantic spaces of 4
target words and performed embedding projections over 6 streams of antisemitic
discourse. This allowed us to track the evolution of antisemitic bias in the
religious, economic, socio-politic, racial, ethic and conspiratorial domains.
Projections show a trend of growing antisemitism, especially in the years
starting in the mid-80s and culminating in the Dreyfus affair. Our analysis
also allows us to highlight the peculiar adverse bias towards Judaism in the
broader context of other religions.
</summary>
    <author>
      <name>Rocco Tripodi</name>
    </author>
    <author>
      <name>Massimo Warglien</name>
    </author>
    <author>
      <name>Simon Levis Sullam</name>
    </author>
    <author>
      <name>Deborah Paci</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 1st International Workshop on Computational
  Approaches to Historical Language Change 2019 (ACL 2019). 11 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01393v1</id>
    <updated>2019-06-04T13:07:35Z</updated>
    <published>2019-06-04T13:07:35Z</published>
    <title>SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for
  Evaluating Natural Language Inference</title>
    <summary>  We present SherLIiC, a testbed for lexical inference in context (LIiC),
consisting of 3985 manually annotated inference rule candidates (InfCands),
accompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual
relations between Freebase entities extracted from the large entity-linked
corpus ClueWeb09. Each InfCand consists of one of these relations, expressed as
a lemmatized dependency path, and two argument placeholders, each linked to one
or more Freebase types. Due to our candidate selection process based on strong
distributional evidence, SherLIiC is much harder than existing testbeds because
distributional evidence is of little utility in the classification of InfCands.
We also show that, due to its construction, many of SherLIiC's correct InfCands
are novel and missing from existing rule bases. We evaluate a number of strong
baselines on SherLIiC, ranging from semantic vector space models to state of
the art neural models of natural language inference (NLI). We show that
SherLIiC poses a tough challenge to existing NLI systems.
</summary>
    <author>
      <name>Martin Schmitt</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a long paper to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01250v1</id>
    <updated>2019-06-04T07:49:46Z</updated>
    <published>2019-06-04T07:49:46Z</published>
    <title>Boosting Entity Linking Performance by Leveraging Unlabeled Documents</title>
    <summary>  Modern entity linking systems rely on large collections of documents
specifically annotated for the task (e.g., AIDA CoNLL). In contrast, we propose
an approach which exploits only naturally occurring information: unlabeled
documents and Wikipedia. Our approach consists of two stages. First, we
construct a high recall list of candidate entities for each mention in an
unlabeled document. Second, we use the candidate lists as weak supervision to
constrain our document-level entity linking model. The model treats entities as
latent variables and, when estimated on a collection of unlabelled texts,
learns to choose entities relying both on local context of each mention and on
coherence with other entities in the document. The resulting approach rivals
fully-supervised state-of-the-art systems on standard test sets. It also
approaches their performance in the very challenging setting: when tested on a
test set sampled from the data used to estimate the supervised systems. By
comparing to Wikipedia-only training of our model, we demonstrate that modeling
unlabeled documents is beneficial.
</summary>
    <author>
      <name>Phong Le</name>
    </author>
    <author>
      <name>Ivan Titov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01634v2</id>
    <updated>2019-06-06T08:42:25Z</updated>
    <published>2019-06-04T07:30:48Z</published>
    <title>On the Realization of Compositionality in Neural Networks</title>
    <summary>  We present a detailed comparison of two types of sequence to sequence models
trained to conduct a compositional task. The models are architecturally
identical at inference time, but differ in the way that they are trained: our
baseline model is trained with a task-success signal only, while the other
model receives additional supervision on its attention mechanism (Attentive
Guidance), which has shown to be an effective method for encouraging more
compositional solutions (Hupkes et al.,2019). We first confirm that the models
with attentive guidance indeed infer more compositional solutions than the
baseline, by training them on the lookup table task presented by Li\v{s}ka et
al. (2019). We then do an in-depth analysis of the structural differences
between the two model types, focusing in particular on the organisation of the
parameter space and the hidden layer activations and find noticeable
differences in both these aspects. Guided networks focus more on the components
of the input rather than the sequence as a whole and develop small functional
groups of neurons with specific purposes that use their gates more selectively.
Results from parameter heat maps, component swapping and graph analysis also
indicate that guided networks exhibit a more modular structure with a small
number of specialized, strongly connected neurons.
</summary>
    <author>
      <name>Joris Baan</name>
    </author>
    <author>
      <name>Jana Leible</name>
    </author>
    <author>
      <name>Mitja Nikolaus</name>
    </author>
    <author>
      <name>David Rau</name>
    </author>
    <author>
      <name>Dennis Ulmer</name>
    </author>
    <author>
      <name>Tim Baumgärtner</name>
    </author>
    <author>
      <name>Dieuwke Hupkes</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at BlackboxNLP 2019, ACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01634v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01634v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01234v2</id>
    <updated>2019-06-06T08:34:09Z</updated>
    <published>2019-06-04T07:07:56Z</published>
    <title>Transcoding compositionally: using attention to find more generalizable
  solutions</title>
    <summary>  While sequence-to-sequence models have shown remarkable generalization power
across several natural language tasks, their construct of solutions are argued
to be less compositional than human-like generalization. In this paper, we
present seq2attn, a new architecture that is specifically designed to exploit
attention to find compositional patterns in the input. In seq2attn, the two
standard components of an encoder-decoder model are connected via a transcoder,
that modulates the information flow between them. We show that seq2attn can
successfully generalize, without requiring any additional supervision, on two
tasks which are specifically constructed to challenge the compositional skills
of neural networks. The solutions found by the model are highly interpretable,
allowing easy analysis of both the types of solutions that are found and
potential causes for mistakes. We exploit this opportunity to introduce a new
paradigm to test compositionality that studies the extent to which a model
overgeneralizes when confronted with exceptions. We show that seq2attn exhibits
such overgeneralization to a larger degree than a standard sequence-to-sequence
model.
</summary>
    <author>
      <name>Kris Korrel</name>
    </author>
    <author>
      <name>Dieuwke Hupkes</name>
    </author>
    <author>
      <name>Verna Dankers</name>
    </author>
    <author>
      <name>Elia Bruni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at BlackboxNLP 2019, ACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01234v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01234v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01231v1</id>
    <updated>2019-06-04T07:03:04Z</updated>
    <published>2019-06-04T07:03:04Z</published>
    <title>Coherent Comment Generation for Chinese Articles with a
  Graph-to-Sequence Model</title>
    <summary>  Automatic article commenting is helpful in encouraging user engagement and
interaction on online news platforms. However, the news documents are usually
too long for traditional encoder-decoder based models, which often results in
general and irrelevant comments. In this paper, we propose to generate comments
with a graph-to-sequence model that models the input news as a topic
interaction graph. By organizing the article into graph structure, our model
can better understand the internal structure of the article and the connection
between topics, which makes it better able to understand the story. We collect
and release a large scale news-comment corpus from a popular Chinese online
news platform Tencent Kuaibao. Extensive experiment results show that our model
can generate much more coherent and informative comments compared with several
strong baseline models.
</summary>
    <author>
      <name>Wei Li</name>
    </author>
    <author>
      <name>Jingjing Xu</name>
    </author>
    <author>
      <name>Yancheng He</name>
    </author>
    <author>
      <name>Shengli Yan</name>
    </author>
    <author>
      <name>Yunfang Wu</name>
    </author>
    <author>
      <name>Xu sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01105v2</id>
    <updated>2019-06-24T19:41:06Z</updated>
    <published>2019-06-03T22:33:22Z</published>
    <title>Training Neural Machine Translation To Apply Terminology Constraints</title>
    <summary>  This paper proposes a novel method to inject custom terminology into neural
machine translation at run time. Previous works have mainly proposed
modifications to the decoding algorithm in order to constrain the output to
include run-time-provided target terms. While being effective, these
constrained decoding methods add, however, significant computational overhead
to the inference step, and, as we show in this paper, can be brittle when
tested in realistic conditions. In this paper we approach the problem by
training a neural MT system to learn how to use custom terminology when
provided with the input. Comparative experiments show that our method is not
only more effective than a state-of-the-art implementation of constrained
decoding, but is also as fast as constraint-free decoding.
</summary>
    <author>
      <name>Georgiana Dinu</name>
    </author>
    <author>
      <name>Prashant Mathur</name>
    </author>
    <author>
      <name>Marcello Federico</name>
    </author>
    <author>
      <name>Yaser Al-Onaizan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a short paper at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01105v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01105v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01983v1</id>
    <updated>2019-06-03T17:26:36Z</updated>
    <published>2019-06-03T17:26:36Z</published>
    <title>The Computational Structure of Unintentional Meaning</title>
    <summary>  Speech-acts can have literal meaning as well as pragmatic meaning, but these
both involve consequences typically intended by a speaker. Speech-acts can also
have unintentional meaning, in which what is conveyed goes above and beyond
what was intended. Here, we present a Bayesian analysis of how, to a listener,
the meaning of an utterance can significantly differ from a speaker's intended
meaning. Our model emphasizes how comprehending the intentional and
unintentional meaning of speech-acts requires listeners to engage in
sophisticated model-based perspective-taking and reasoning about the history of
the state of the world, each other's actions, and each other's observations. To
test our model, we have human participants make judgments about vignettes where
speakers make utterances that could be interpreted as intentional insults or
unintentional faux pas. In elucidating the mechanics of speech-acts with
unintentional meanings, our account provides insight into how communication
both functions and malfunctions.
</summary>
    <author>
      <name>Mark K. Ho</name>
    </author>
    <author>
      <name>Joanna Korman</name>
    </author>
    <author>
      <name>Thomas L. Griffiths</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01983v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01983v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00908v1</id>
    <updated>2019-06-03T16:20:04Z</updated>
    <published>2019-06-03T16:20:04Z</published>
    <title>Phase-based Minimalist Parsing and complexity in non-local dependencies</title>
    <summary>  A cognitively plausible parsing algorithm should perform like the human
parser in critical contexts. Here I propose an adaptation of Earley's parsing
algorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that
is able to predict complexity effects in performance. Focusing on self-paced
reading experiments of object clefts sentences (Warren &amp; Gibson 2005) I will
associate to parsing a complexity metric based on cued features to be retrieved
at the verb segment (Feature Retrieval &amp; Encoding Cost, FREC). FREC is
crucially based on the usage of memory predicted by the discussed parsing
algorithm and it correctly fits with the reading time revealed.
</summary>
    <author>
      <name>Cristiano Chesi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of CLiC-it 2017. CEUR WORKSHOP PROCEEDINGS, ROMA:CEUR
  Workshop Proceedings, ISBN: 9788899982768, ISSN: 1613-0073, Rome, 11-13
  December 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.00908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00872v1</id>
    <updated>2019-06-03T15:28:48Z</updated>
    <published>2019-06-03T15:28:48Z</published>
    <title>From Words to Sentences: A Progressive Learning Approach for
  Zero-resource Machine Translation with Visual Pivots</title>
    <summary>  The neural machine translation model has suffered from the lack of
large-scale parallel corpora. In contrast, we humans can learn multi-lingual
translations even without parallel texts by referring our languages to the
external world. To mimic such human learning behavior, we employ images as
pivots to enable zero-resource translation learning. However, a picture tells a
thousand words, which makes multi-lingual sentences pivoted by the same image
noisy as mutual translations and thus hinders the translation model learning.
In this work, we propose a progressive learning approach for image-pivoted
zero-resource machine translation. Since words are less diverse when grounded
in the image, we first learn word-level translation with image pivots, and then
progress to learn the sentence-level translation by utilizing the learned word
translation to suppress noises in image-pivoted multi-lingual sentences.
Experimental results on two widely used image-pivot translation datasets,
IAPR-TC12 and Multi30k, show that the proposed approach significantly
outperforms other state-of-the-art methods.
</summary>
    <author>
      <name>Shizhe Chen</name>
    </author>
    <author>
      <name>Qin Jin</name>
    </author>
    <author>
      <name>Jianlong Fu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IJCAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00744v5</id>
    <updated>2019-10-02T16:10:21Z</updated>
    <published>2019-06-03T12:28:50Z</published>
    <title>Hierarchical Decision Making by Generating and Following Natural
  Language Instructions</title>
    <summary>  We explore using latent natural language instructions as an expressive and
compositional representation of complex actions for hierarchical decision
making. Rather than directly selecting micro-actions, our agent first generates
a latent plan in natural language, which is then executed by a separate model.
We introduce a challenging real-time strategy game environment in which the
actions of a large number of units must be coordinated across long time scales.
We gather a dataset of 76 thousand pairs of instructions and executions from
human play, and train instructor and executor models. Experiments show that
models using natural language as a latent variable significantly outperform
models that directly imitate human actions. The compositional structure of
language proves crucial to its effectiveness for action representation. We also
release our code, models and data.
</summary>
    <author>
      <name>Hengyuan Hu</name>
    </author>
    <author>
      <name>Denis Yarats</name>
    </author>
    <author>
      <name>Qucheng Gong</name>
    </author>
    <author>
      <name>Yuandong Tian</name>
    </author>
    <author>
      <name>Mike Lewis</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00744v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00744v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00687v1</id>
    <updated>2019-06-03T10:13:32Z</updated>
    <published>2019-06-03T10:13:32Z</published>
    <title>Relation Embedding with Dihedral Group in Knowledge Graph</title>
    <summary>  Link prediction is critical for the application of incomplete knowledge graph
(KG) in the downstream tasks. As a family of effective approaches for link
predictions, embedding methods try to learn low-rank representations for both
entities and relations such that the bilinear form defined therein is a
well-behaved scoring function. Despite of their successful performances,
existing bilinear forms overlook the modeling of relation compositions,
resulting in lacks of interpretability for reasoning on KG. To fulfill this
gap, we propose a new model called DihEdral, named after dihedral symmetry
group. This new model learns knowledge graph embeddings that can capture
relation compositions by nature. Furthermore, our approach models the relation
embeddings parametrized by discrete values, thereby decrease the solution space
drastically. Our experiments show that DihEdral is able to capture all desired
properties such as (skew-) symmetry, inversion and (non-) Abelian composition,
and outperforms existing bilinear form based approach and is comparable to or
better than deep learning models such as ConvE.
</summary>
    <author>
      <name>Canran Xu</name>
    </author>
    <author>
      <name>Ruijiang Li</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/P19-1026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/P19-1026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00592v1</id>
    <updated>2019-06-03T06:32:29Z</updated>
    <published>2019-06-03T06:32:29Z</published>
    <title>Assessing the Ability of Self-Attention Networks to Learn Word Order</title>
    <summary>  Self-attention networks (SAN) have attracted a lot of interests due to their
high parallelization and strong performance on a variety of NLP tasks, e.g.
machine translation. Due to the lack of recurrence structure such as recurrent
neural networks (RNN), SAN is ascribed to be weak at learning positional
information of words for sequence modeling. However, neither this speculation
has been empirically confirmed, nor explanations for their strong performances
on machine translation tasks when "lacking positional information" have been
explored. To this end, we propose a novel word reordering detection task to
quantify how well the word order information learned by SAN and RNN.
Specifically, we randomly move one word to another position, and examine
whether a trained model can detect both the original and inserted positions.
Experimental results reveal that: 1) SAN trained on word reordering detection
indeed has difficulty learning the positional information even with the
position embedding; and 2) SAN trained on machine translation learns better
positional information than its RNN counterpart, in which position embedding
plays a critical role. Although recurrence structure make the model more
universally-effective on learning word order, learning objectives matter more
in the downstream tasks such as machine translation.
</summary>
    <author>
      <name>Baosong Yang</name>
    </author>
    <author>
      <name>Longyue Wang</name>
    </author>
    <author>
      <name>Derek F. Wong</name>
    </author>
    <author>
      <name>Lidia S. Chao</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00580v1</id>
    <updated>2019-06-03T05:27:05Z</updated>
    <published>2019-06-03T05:27:05Z</published>
    <title>Massive Styles Transfer with Limited Labeled Data</title>
    <summary>  Language style transfer has attracted more and more attention in the past few
years. Recent researches focus on improving neural models targeting at
transferring from one style to the other with labeled data. However,
transferring across multiple styles is often very useful in real-life
applications. Previous researches of language style transfer have two main
deficiencies: dependency on massive labeled data and neglect of mutual
influence among different style transfer tasks. In this paper, we propose a
multi-agent style transfer system (MAST) for addressing multiple style transfer
tasks with limited labeled data, by leveraging abundant unlabeled data and the
mutual benefit among the multiple styles. A style transfer agent in our system
not only learns from unlabeled data by using techniques like denoising
auto-encoder and back-translation, but also learns to cooperate with other
style transfer agents in a self-organization manner. We conduct our experiments
by simulating a set of real-world style transfer tasks with multiple versions
of the Bible. Our model significantly outperforms the other competitive
methods. Extensive results and analysis further verify the efficacy of our
proposed system.
</summary>
    <author>
      <name>Hongyu Zang</name>
    </author>
    <author>
      <name>Xiaojun Wan</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00499v1</id>
    <updated>2019-06-02T22:53:33Z</updated>
    <published>2019-06-02T22:53:33Z</published>
    <title>Budgeted Policy Learning for Task-Oriented Dialogue Systems</title>
    <summary>  This paper presents a new approach that extends Deep Dyna-Q (DDQ) by
incorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed,
small amount of user interactions (budget) for learning task-oriented dialogue
agents. BCS consists of (1) a Poisson-based global scheduler to allocate budget
over different stages of training; (2) a controller to decide at each training
step whether the agent is trained using real or simulated experiences; (3) a
user goal sampling module to generate the experiences that are most effective
for policy learning. Experiments on a movie-ticket booking task with simulated
and real users show that our approach leads to significant improvements in
success rate over the state-of-the-art baselines given the fixed budget.
</summary>
    <author>
      <name>Zhirui Zhang</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Enhong Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures, ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00414v2</id>
    <updated>2019-06-04T02:09:30Z</updated>
    <published>2019-06-02T14:57:25Z</published>
    <title>Pretraining Methods for Dialog Context Representation Learning</title>
    <summary>  This paper examines various unsupervised pretraining objectives for learning
dialog context representations. Two novel methods of pretraining dialog context
encoders are proposed, and a total of four methods are examined. Each
pretraining objective is fine-tuned and evaluated on a set of downstream dialog
tasks using the MultiWoz dataset and strong performance improvement is
observed. Further evaluation shows that our pretraining objectives result in
not only better performance, but also better convergence, models that are less
data hungry and have better domain generalizability.
</summary>
    <author>
      <name>Shikib Mehri</name>
    </author>
    <author>
      <name>Evgeniia Razumovskaia</name>
    </author>
    <author>
      <name>Tiancheng Zhao</name>
    </author>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00414v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00414v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00363v1</id>
    <updated>2019-06-02T08:03:21Z</updated>
    <published>2019-06-02T08:03:21Z</published>
    <title>Does It Make Sense? And Why? A Pilot Study for Sense Making and
  Explanation</title>
    <summary>  Introducing common sense to natural language understanding systems has
received increasing research attention. It remains a fundamental question on
how to evaluate whether a system has a sense making capability. Existing
benchmarks measures commonsense knowledge indirectly and without explanation.
In this paper, we release a benchmark to directly test whether a system can
differentiate natural language statements that make sense from those that do
not make sense. In addition, a system is asked to identify the most crucial
reason why a statement does not make sense. We evaluate models trained over
large-scale language modeling tasks as well as human performance, showing that
there are different challenges for system sense making.
</summary>
    <author>
      <name>Cunxiang Wang</name>
    </author>
    <author>
      <name>Shuailong Liang</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Xiaonan Li</name>
    </author>
    <author>
      <name>Tian Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted by ACL2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00346v2</id>
    <updated>2019-11-27T02:36:05Z</updated>
    <published>2019-06-02T05:11:38Z</published>
    <title>Pre-training of Graph Augmented Transformers for Medication
  Recommendation</title>
    <summary>  Medication recommendation is an important healthcare application. It is
commonly formulated as a temporal prediction task. Hence, most existing works
only utilize longitudinal electronic health records (EHRs) from a small number
of patients with multiple visits ignoring a large number of patients with a
single visit (selection bias). Moreover, important hierarchical knowledge such
as diagnosis hierarchy is not leveraged in the representation learning process.
To address these challenges, we propose G-BERT, a new model to combine the
power of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder
Representations from Transformers) for medical code representation and
medication recommendation. We use GNNs to represent the internal hierarchical
structures of medical codes. Then we integrate the GNN representation into a
transformer-based visit encoder and pre-train it on EHR data from patients only
with a single visit. The pre-trained visit encoder and representation are then
fine-tuned for downstream predictive tasks on longitudinal EHRs from patients
with multiple visits. G-BERT is the first to bring the language model
pre-training schema into the healthcare domain and it achieved state-of-the-art
performance on the medication recommendation task.
</summary>
    <author>
      <name>Junyuan Shang</name>
    </author>
    <author>
      <name>Tengfei Ma</name>
    </author>
    <author>
      <name>Cao Xiao</name>
    </author>
    <author>
      <name>Jimeng Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCAI2019; fix some undefined problems; provide more intuitive
  figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00346v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00346v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00180v1</id>
    <updated>2019-06-01T08:17:42Z</updated>
    <published>2019-06-01T08:17:42Z</published>
    <title>Siamese recurrent networks learn first-order logic reasoning and exhibit
  zero-shot compositional generalization</title>
    <summary>  Can neural nets learn logic? We approach this classic question with current
methods, and demonstrate that recurrent neural networks can learn to recognize
first order logical entailment relations between expressions. We define an
artificial language in first-order predicate logic, generate a large dataset of
sample 'sentences', and use an automatic theorem prover to infer the relation
between random pairs of such sentences. We describe a Siamese neural
architecture trained to predict the logical relation, and experiment with
recurrent and recursive networks. Siamese Recurrent Networks are surprisingly
successful at the entailment recognition task, reaching near perfect
performance on novel sentences (consisting of known words), and even
outperforming recursive networks. We report a series of experiments to test the
ability of the models to perform compositional generalization. In particular,
we study how they deal with sentences of unseen length, and sentences
containing unseen words. We show that set-ups using LSTMs and GRUs obtain high
scores on these tests, demonstrating a form of compositionality.
</summary>
    <author>
      <name>Mathijs Mul</name>
    </author>
    <author>
      <name>Willem Zuidema</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13618v1</id>
    <updated>2019-05-31T13:54:54Z</updated>
    <published>2019-05-31T13:54:54Z</published>
    <title>Crowdsourcing and Validating Event-focused Emotion Corpora for German
  and English</title>
    <summary>  Sentiment analysis has a range of corpora available across multiple
languages. For emotion analysis, the situation is more limited, which hinders
potential research on cross-lingual modeling and the development of predictive
models for other languages. In this paper, we fill this gap for German by
constructing deISEAR, a corpus designed in analogy to the well-established
English ISEAR emotion dataset. Motivated by Scherer's appraisal theory, we
implement a crowdsourcing experiment which consists of two steps. In step 1,
participants create descriptions of emotional events for a given emotion. In
step 2, five annotators assess the emotion expressed by the texts. We show that
transferring an emotion classification model from the original English ISEAR to
the German crowdsourced deISEAR via machine translation does not, on average,
cause a performance drop.
</summary>
    <author>
      <name>Enrica Troiano</name>
    </author>
    <author>
      <name>Sebastian Padó</name>
    </author>
    <author>
      <name>Roman Klinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure, accepted for publication at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13601v1</id>
    <updated>2019-05-31T13:13:51Z</updated>
    <published>2019-05-31T13:13:51Z</published>
    <title>Using Natural Language Processing to Develop an Automated Orthodontic
  Diagnostic System</title>
    <summary>  We work on the task of automatically designing a treatment plan from the
findings included in the medical certificate written by the dentist. To develop
an artificial intelligence system that deals with free-form certificates
written by dentists, we annotate the findings and utilized the natural language
processing approach. As a result of the experiment using 990 certificates,
0.585 F1-score was achieved for the task of extracting orthodontic problems
from findings, and 0.584 correlation coefficient with the human ranking was
achieved for the treatment prioritization task.
</summary>
    <author>
      <name>Tomoyuki Kajiwara</name>
    </author>
    <author>
      <name>Chihiro Tanikawa</name>
    </author>
    <author>
      <name>Yuujin Shimizu</name>
    </author>
    <author>
      <name>Chenhui Chu</name>
    </author>
    <author>
      <name>Takashi Yamashiro</name>
    </author>
    <author>
      <name>Hajime Nagahara</name>
    </author>
    <link href="http://arxiv.org/abs/1905.13601v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13601v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13497v1</id>
    <updated>2019-05-31T10:27:58Z</updated>
    <published>2019-05-31T10:27:58Z</published>
    <title>Attention Is (not) All You Need for Commonsense Reasoning</title>
    <summary>  The recently introduced BERT model exhibits strong performance on several
language understanding benchmarks. In this paper, we describe a simple
re-implementation of BERT for commonsense reasoning. We show that the
attentions produced by BERT can be directly utilized for tasks such as the
Pronoun Disambiguation Problem and Winograd Schema Challenge. Our proposed
attention-guided commonsense reasoning method is conceptually simple yet
empirically powerful. Experimental analysis on multiple datasets demonstrates
that our proposed system performs remarkably well on all cases while
outperforming the previously reported state of the art by a margin. While
results suggest that BERT seems to implicitly learn to establish complex
relationships between entities, solving commonsense reasoning tasks might
require more than unsupervised models learned from huge text corpora.
</summary>
    <author>
      <name>Tassilo Klein</name>
    </author>
    <author>
      <name>Moin Nabi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13453v1</id>
    <updated>2019-05-31T08:05:31Z</updated>
    <published>2019-05-31T08:05:31Z</published>
    <title>MultiQA: An Empirical Investigation of Generalization and Transfer in
  Reading Comprehension</title>
    <summary>  A large number of reading comprehension (RC) datasets has been created
recently, but little analysis has been done on whether they generalize to one
another, and the extent to which existing datasets can be leveraged for
improving performance on new ones. In this paper, we conduct such an
investigation over ten RC datasets, training on one or more source RC datasets,
and evaluating generalization, as well as transfer to a target RC dataset. We
analyze the factors that contribute to generalization, and show that training
on a source RC dataset and transferring to a target dataset substantially
improves performance, even in the presence of powerful contextual
representations from BERT (Devlin et al., 2019). We also find that training on
multiple source RC datasets leads to robust generalization and transfer, and
can reduce the cost of example collection for a new RC dataset. Following our
analysis, we propose MultiQA, a BERT-based model, trained on multiple RC
datasets, which leads to state-of-the-art performance on five RC datasets. We
share our infrastructure for the benefit of the research community.
</summary>
    <author>
      <name>Alon Talmor</name>
    </author>
    <author>
      <name>Jonathan Berant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted as a long paper at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13438v2</id>
    <updated>2019-06-26T17:23:45Z</updated>
    <published>2019-05-31T06:36:19Z</published>
    <title>Content Word-based Sentence Decoding and Evaluating for Open-domain
  Neural Response Generation</title>
    <summary>  Various encoder-decoder models have been applied to response generation in
open-domain dialogs, but a majority of conventional models directly learn a
mapping from lexical input to lexical output without explicitly modeling
intermediate representations. Utilizing language hierarchy and modeling
intermediate information have been shown to benefit many language understanding
and generation tasks. Motivated by Broca's aphasia, we propose to use a content
word sequence as an intermediate representation for open-domain response
generation. Experimental results show that the proposed method improves content
relatedness of produced responses, and our models can often choose correct
grammar for generated content words. Meanwhile, instead of evaluating complete
sentences, we propose to compute conventional metrics on content word
sequences, which is a better indicator of content relevance.
</summary>
    <author>
      <name>Tianyu Zhao</name>
    </author>
    <author>
      <name>Shinsuke Mori</name>
    </author>
    <author>
      <name>Tatsuya Kawahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2 figures, 8 tables (rejected by ACL 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13438v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13438v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13164v1</id>
    <updated>2019-05-30T16:49:11Z</updated>
    <published>2019-05-30T16:49:11Z</published>
    <title>Hierarchical Transformers for Multi-Document Summarization</title>
    <summary>  In this paper, we develop a neural summarization model which can effectively
process multiple input documents and distill Transformer architecture with the
ability to encode documents in a hierarchical manner. We represent
cross-document relationships via an attention mechanism which allows to share
information as opposed to simply concatenating text spans and processing them
as a flat sequence. Our model learns latent dependencies among textual units,
but can also take advantage of explicit graph representations focusing on
similarity or discourse relations. Empirical results on the WikiSum dataset
demonstrate that the proposed architecture brings substantial improvements over
several strong baselines.
</summary>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Mirella Lapata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.13164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12897v2</id>
    <updated>2019-08-23T08:12:51Z</updated>
    <published>2019-05-30T07:44:34Z</published>
    <title>A Compare-Aggregate Model with Latent Clustering for Answer Selection</title>
    <summary>  In this paper, we propose a novel method for a sentence-level
answer-selection task that is a fundamental problem in natural language
processing. First, we explore the effect of additional information by adopting
a pretrained language model to compute the vector representation of the input
text and by applying transfer learning from a large-scale corpus. Second, we
enhance the compare-aggregate model by proposing a novel latent clustering
method to compute additional information within the target corpus and by
changing the objective function from listwise to pointwise. To evaluate the
performance of the proposed approaches, experiments are performed with the
WikiQA and TREC-QA datasets. The empirical results demonstrate the superiority
of our proposed approach, which achieve state-of-the-art performance for both
datasets.
</summary>
    <author>
      <name>Seunghyun Yoon</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Doo Soon Kim</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Kyomin Jung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Accepted as a conference paper at CIKM 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12897v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12897v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12866v3</id>
    <updated>2019-06-09T18:11:47Z</updated>
    <published>2019-05-30T05:57:27Z</published>
    <title>Semantically Conditioned Dialog Response Generation via Hierarchical
  Disentangled Self-Attention</title>
    <summary>  Semantically controlled neural response generation on limited-domain has
achieved great performance. However, moving towards multi-domain large-scale
scenarios are shown to be difficult because the possible combinations of
semantic inputs grow exponentially with the number of domains. To alleviate
such scalability issue, we exploit the structure of dialog acts to build a
multi-layer hierarchical graph, where each act is represented as a root-to-leaf
route on the graph. Then, we incorporate such graph structure prior as an
inductive bias to build a hierarchical disentangled self-attention network,
where we disentangle attention heads to model designated nodes on the dialog
act graph. By activating different (disentangled) heads at each layer,
combinatorially many dialog act semantics can be modeled to control the neural
response generation. On the large-scale Multi-Domain-WOZ dataset, our model can
yield a significant improvement over the baselines on various automatic and
human evaluation metrics.
</summary>
    <author>
      <name>Wenhu Chen</name>
    </author>
    <author>
      <name>Jianshu Chen</name>
    </author>
    <author>
      <name>Pengda Qin</name>
    </author>
    <author>
      <name>Xifeng Yan</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019, 9 pages long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12866v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12866v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12786v1</id>
    <updated>2019-05-29T23:40:54Z</updated>
    <published>2019-05-29T23:40:54Z</published>
    <title>Large Scale Question Paraphrase Retrieval with Smoothed Deep Metric
  Learning</title>
    <summary>  The goal of a Question Paraphrase Retrieval (QPR) system is to retrieve
equivalent questions that result in the same answer as the original question.
Such a system can be used to understand and answer rare and noisy
reformulations of common questions by mapping them to a set of canonical forms.
This has large-scale applications for community Question Answering (cQA) and
open-domain spoken language question answering systems. In this paper we
describe a new QPR system implemented as a Neural Information Retrieval (NIR)
system consisting of a neural network sentence encoder and an approximate
k-Nearest Neighbour index for efficient vector retrieval. We also describe our
mechanism to generate an annotated dataset for question paraphrase retrieval
experiments automatically from question-answer logs via distant supervision. We
show that the standard loss function in NIR, triplet loss, does not perform
well with noisy labels. We propose smoothed deep metric loss (SDML) and with
our experiments on two QPR datasets we show that it significantly outperforms
triplet loss in the noisy label setting.
</summary>
    <author>
      <name>Daniele Bonadiman</name>
    </author>
    <author>
      <name>Anjishnu Kumar</name>
    </author>
    <author>
      <name>Arpit Mittal</name>
    </author>
    <link href="http://arxiv.org/abs/1905.12786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12561v4</id>
    <updated>2019-10-15T11:56:14Z</updated>
    <published>2019-05-29T16:14:24Z</published>
    <title>Anti-efficient encoding in emergent communication</title>
    <summary>  Despite renewed interest in emergent language simulations with neural
networks, little is known about the basic properties of the induced code, and
how they compare to human language. One fundamental characteristic of the
latter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words
are efficiently associated to shorter strings. We study whether the same
pattern emerges when two neural networks, a "speaker" and a "listener", are
trained to play a signaling game. Surprisingly, we find that networks develop
an \emph{anti-efficient} encoding scheme, in which the most frequent inputs are
associated to the longest messages, and messages in general are skewed towards
the maximum length threshold. This anti-efficient code appears easier to
discriminate for the listener, and, unlike in human communication, the speaker
does not impose a contrasting least-effort pressure towards brevity. Indeed,
when the cost function includes a penalty for longer messages, the resulting
message distribution starts respecting ZLA. Our analysis stresses the
importance of studying the basic features of emergent communication in a highly
controlled setup, to ensure the latter will not strand too far from human
language. Moreover, we present a concrete illustration of how different
functional pressures can lead to successful communication codes that lack basic
properties of human language, thus highlighting the role such pressures play in
the latter.
</summary>
    <author>
      <name>Rahma Chaabouni</name>
    </author>
    <author>
      <name>Eugene Kharitonov</name>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <link href="http://arxiv.org/abs/1905.12561v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12561v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12330v3</id>
    <updated>2019-06-14T08:08:45Z</updated>
    <published>2019-05-29T11:17:59Z</published>
    <title>Word-order biases in deep-agent emergent communication</title>
    <summary>  Sequence-processing neural networks led to remarkable progress on many NLP
tasks. As a consequence, there has been increasing interest in understanding to
what extent they process language as humans do. We aim here to uncover which
biases such models display with respect to "natural" word-order constraints. We
train models to communicate about paths in a simple gridworld, using miniature
languages that reflect or violate various natural language trends, such as the
tendency to avoid redundancy or to minimize long-distance dependencies. We
study how the controlled characteristics of our miniature languages affect
individual learning and their stability across multiple network generations.
The results draw a mixed picture. On the one hand, neural networks show a
strong tendency to avoid long-distance dependencies. On the other hand, there
is no clear preference for the efficient, non-redundant encoding of information
that is widely attested in natural language. We thus suggest inoculating a
notion of "effort" into neural networks, as a possible way to make their
linguistic behavior more human-like.
</summary>
    <author>
      <name>Rahma Chaabouni</name>
    </author>
    <author>
      <name>Eugene Kharitonov</name>
    </author>
    <author>
      <name>Alessandro Lazaric</name>
    </author>
    <author>
      <name>Emmanuel Dupoux</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference: Association for Computational Linguistics (ACL)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12330v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12330v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12260v1</id>
    <updated>2019-05-29T07:55:17Z</updated>
    <published>2019-05-29T07:55:17Z</published>
    <title>Learning Multilingual Word Embeddings Using Image-Text Data</title>
    <summary>  There has been significant interest recently in learning multilingual word
embeddings -- in which semantically similar words across languages have similar
embeddings. State-of-the-art approaches have relied on expensive labeled data,
which is unavailable for low-resource languages, or have involved post-hoc
unification of monolingual embeddings. In the present paper, we investigate the
efficacy of multilingual embeddings learned from weakly-supervised image-text
data. In particular, we propose methods for learning multilingual embeddings
using image-text data, by enforcing similarity between the representations of
the image and that of the text. Our experiments reveal that even without using
any expensive labeled data, a bag-of-words-based embedding model trained on
image-text data achieves performance comparable to the state-of-the-art on
crosslingual semantic similarity tasks.
</summary>
    <author>
      <name>Karan Singhal</name>
    </author>
    <author>
      <name>Karthik Raman</name>
    </author>
    <author>
      <name>Balder ten Cate</name>
    </author>
    <link href="http://arxiv.org/abs/1905.12260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12255v3</id>
    <updated>2019-06-21T16:55:06Z</updated>
    <published>2019-05-29T07:40:38Z</published>
    <title>Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation</title>
    <summary>  Advances in learning and representations have reinvigorated work that
connects language to other modalities. A particularly exciting direction is
Vision-and-Language Navigation(VLN), in which agents interpret natural language
instructions and visual scenes to move through environments and reach goals.
Despite recent progress, current research leaves unclear how much of a role
language understanding plays in this task, especially because dominant
evaluation metrics have focused on goal completion rather than the sequence of
actions corresponding to the instructions. Here, we highlight shortcomings of
current metrics for the Room-to-Room dataset (Anderson et al.,2018b) and
propose a new metric, Coverage weighted by Length Score (CLS). We also show
that the existing paths in the dataset are not ideal for evaluating instruction
following because they are direct-to-goal shortest paths. We join existing
short paths to form more challenging extended paths to create a new data set,
Room-for-Room (R4R). Using R4R and CLS, we show that agents that receive
rewards for instruction fidelity outperform agents that focus on goal
completion.
</summary>
    <author>
      <name>Vihan Jain</name>
    </author>
    <author>
      <name>Gabriel Magalhaes</name>
    </author>
    <author>
      <name>Alexander Ku</name>
    </author>
    <author>
      <name>Ashish Vaswani</name>
    </author>
    <author>
      <name>Eugene Ie</name>
    </author>
    <author>
      <name>Jason Baldridge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ACL 2019 as long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12255v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12255v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12188v1</id>
    <updated>2019-05-29T02:50:50Z</updated>
    <published>2019-05-29T02:50:50Z</published>
    <title>Exploiting Persona Information for Diverse Generation of Conversational
  Responses</title>
    <summary>  In human conversations, due to their personalities in mind, people can easily
carry out and maintain the conversations. Giving conversational context with
persona information to a chatbot, how to exploit the information to generate
diverse and sustainable conversations is still a non-trivial task. Previous
work on persona-based conversational models successfully make use of predefined
persona information and have shown great promise in delivering more realistic
responses. And they all learn with the assumption that given a source input,
there is only one target response. However, in human conversations, there are
massive appropriate responses to a given input message. In this paper, we
propose a memory-augmented architecture to exploit persona information from
context and incorporate a conditional variational autoencoder model together to
generate diverse and sustainable conversations. We evaluate the proposed model
on a benchmark persona-chat dataset. Both automatic and human evaluations show
that our model can deliver more diverse and more engaging persona-based
responses than baseline approaches.
</summary>
    <author>
      <name>Haoyu Song</name>
    </author>
    <author>
      <name>Wei-Nan Zhang</name>
    </author>
    <author>
      <name>Yiming Cui</name>
    </author>
    <author>
      <name>Dong Wang</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published as a conference paper at IJCAI 2019 (to appear). 7 pages, 1
  figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.12008v1</id>
    <updated>2019-05-28T18:15:52Z</updated>
    <published>2019-05-28T18:15:52Z</published>
    <title>Leveraging Medical Visual Question Answering with Supporting Facts</title>
    <summary>  In this working notes paper, we describe IBM Research AI (Almaden) team's
participation in the ImageCLEF 2019 VQA-Med competition. The challenge consists
of four question-answering tasks based on radiology images. The diversity of
imaging modalities, organs and disease types combined with a small imbalanced
training set made this a highly complex problem. To overcome these
difficulties, we implemented a modular pipeline architecture that utilized
transfer learning and multi-task learning. Our findings led to the development
of a novel model called Supporting Facts Network (SFN). The main idea behind
SFN is to cross-utilize information from upstream tasks to improve the accuracy
on harder downstream ones. This approach significantly improved the scores
achieved in the validation set (18 point improvement in F-1 score). Finally, we
submitted four runs to the competition and were ranked seventh.
</summary>
    <author>
      <name>Tomasz Kornuta</name>
    </author>
    <author>
      <name>Deepta Rajan</name>
    </author>
    <author>
      <name>Chaitanya Shivade</name>
    </author>
    <author>
      <name>Alexis Asseman</name>
    </author>
    <author>
      <name>Ahmet S. Ozcan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working notes from the ImageCLEF 2019 VQA-Med competition</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11833v4</id>
    <updated>2019-11-13T16:25:28Z</updated>
    <published>2019-05-28T14:13:09Z</published>
    <title>Interpreting and improving natural-language processing (in machines)
  with natural language-processing (in the brain)</title>
    <summary>  Neural networks models for NLP are typically implemented without the explicit
encoding of language rules and yet they are able to break one performance
record after another. This has generated a lot of research interest in
interpreting the representations learned by these networks. We propose here a
novel interpretation approach that relies on the only processing system we have
that does understand language: the human brain. We use brain imaging recordings
of subjects reading complex natural text to interpret word and sequence
embeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We
study how their representations differ across layer depth, context length, and
attention type. Our results reveal differences in the context-related
representations across these models. Further, in the transformer models, we
find an interaction between layer depth and context length, and between layer
depth and attention type. We finally hypothesize that altering BERT to better
align with brain recordings would enable it to also better understand language.
Probing the altered BERT using syntactic NLP tasks reveals that the model with
increased brain-alignment outperforms the original model. Cognitive
neuroscientists have already begun using NLP networks to study the brain, and
this work closes the loop to allow the interaction between NLP and cognitive
neuroscience to be a true cross-pollination.
</summary>
    <author>
      <name>Mariya Toneva</name>
    </author>
    <author>
      <name>Leila Wehbe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.11833v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11833v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11553v2</id>
    <updated>2019-05-29T01:36:13Z</updated>
    <published>2019-05-28T00:55:25Z</published>
    <title>Target-Guided Open-Domain Conversation</title>
    <summary>  Many real-world open-domain conversation applications have specific goals to
achieve during open-ended chats, such as recommendation, psychotherapy,
education, etc. We study the problem of imposing conversational goals on
open-domain chat agents. In particular, we want a conversational system to chat
naturally with human and proactively guide the conversation to a designated
target subject. The problem is challenging as no public data is available for
learning such a target-guided strategy. We propose a structured approach that
introduces coarse-grained keywords to control the intended content of system
responses. We then attain smooth conversation transition through turn-level
supervised learning, and drive the conversation towards the target with
discourse-level constraints. We further derive a keyword-augmented conversation
dataset for the study. Quantitative and human evaluations show our system can
produce meaningful and effective conversations, significantly improving over
other approaches.
</summary>
    <author>
      <name>Jianheng Tang</name>
    </author>
    <author>
      <name>Tiancheng Zhao</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Xiaodan Liang</name>
    </author>
    <author>
      <name>Eric P. Xing</name>
    </author>
    <author>
      <name>Zhiting Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019. Data and code available at
  https://github.com/squareRoot3/Target-Guided-Conversation. fixed typos</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.11553v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11553v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11471v1</id>
    <updated>2019-05-27T19:44:33Z</updated>
    <published>2019-05-27T19:44:33Z</published>
    <title>XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and
  Question Answering</title>
    <summary>  While natural language processing systems often focus on a single language,
multilingual transfer learning has the potential to improve performance,
especially for low-resource languages. We introduce XLDA, cross-lingual data
augmentation, a method that replaces a segment of the input text with its
translation in another language. XLDA enhances performance of all 14 tested
languages of the cross-lingual natural language inference (XNLI) benchmark.
With improvements of up to $4.8\%$, training with XLDA achieves
state-of-the-art performance for Greek, Turkish, and Urdu. XLDA is in contrast
to, and performs markedly better than, a more naive approach that aggregates
examples in various languages in a way that each example is solely in one
language. On the SQuAD question answering task, we see that XLDA provides a
$1.0\%$ performance increase on the English evaluation set. Comprehensive
experiments suggest that most languages are effective as cross-lingual
augmentors, that XLDA is robust to a wide range of translation quality, and
that XLDA is even more effective for randomly initialized models than for
pretrained models.
</summary>
    <author>
      <name>Jasdeep Singh</name>
    </author>
    <author>
      <name>Bryan McCann</name>
    </author>
    <author>
      <name>Nitish Shirish Keskar</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <link href="http://arxiv.org/abs/1905.11471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11259v1</id>
    <updated>2019-05-27T14:27:13Z</updated>
    <published>2019-05-27T14:27:13Z</published>
    <title>AgentGraph: Towards Universal Dialogue Management with Structured Deep
  Reinforcement Learning</title>
    <summary>  Dialogue policy plays an important role in task-oriented spoken dialogue
systems. It determines how to respond to users. The recently proposed deep
reinforcement learning (DRL) approaches have been used for policy optimization.
However, these deep models are still challenging for two reasons: 1) Many
DRL-based policies are not sample-efficient. 2) Most models don't have the
capability of policy transfer between different domains. In this paper, we
propose a universal framework, AgentGraph, to tackle these two problems. The
proposed AgentGraph is the combination of GNN-based architecture and DRL-based
algorithm. It can be regarded as one of the multi-agent reinforcement learning
approaches. Each agent corresponds to a node in a graph, which is defined
according to the dialogue domain ontology. When making a decision, each agent
can communicate with its neighbors on the graph. Under AgentGraph framework, we
further propose Dual GNN-based dialogue policy, which implicitly decomposes the
decision in each turn into a high-level global decision and a low-level local
decision. Experiments show that AgentGraph models significantly outperform
traditional reinforcement learning approaches on most of the 18 tasks of the
PyDial benchmark. Moreover, when transferred from the source task to a target
task, these models not only have acceptable initial performance but also
converge much faster on the target task.
</summary>
    <author>
      <name>Lu Chen</name>
    </author>
    <author>
      <name>Zhi Chen</name>
    </author>
    <author>
      <name>Bowen Tan</name>
    </author>
    <author>
      <name>Sishan Long</name>
    </author>
    <author>
      <name>Milica Gasic</name>
    </author>
    <author>
      <name>Kai Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 8 figures; Accepted by IEEE/ACM TRANSACTIONS ON AUDIO,
  SPEECH, AND LANGUAGE PROCESSING</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.11259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11393v1</id>
    <updated>2019-05-27T10:22:20Z</updated>
    <published>2019-05-27T10:22:20Z</published>
    <title>A Self-Attention Joint Model for Spoken Language Understanding in
  Situational Dialog Applications</title>
    <summary>  Spoken language understanding (SLU) acts as a critical component in
goal-oriented dialog systems. It typically involves identifying the speakers
intent and extracting semantic slots from user utterances, which are known as
intent detection (ID) and slot filling (SF). SLU problem has been intensively
investigated in recent years. However, these methods just constrain SF results
grammatically, solve ID and SF independently, or do not fully utilize the
mutual impact of the two tasks. This paper proposes a multi-head self-attention
joint model with a conditional random field (CRF) layer and a prior mask. The
experiments show the effectiveness of our model, as compared with
state-of-the-art models. Meanwhile, online education in China has made great
progress in the last few years. But there are few intelligent educational
dialog applications for students to learn foreign languages. Hence, we design
an intelligent dialog robot equipped with different scenario settings to help
students learn communication skills.
</summary>
    <author>
      <name>Mengyang Chen</name>
    </author>
    <author>
      <name>Jin Zeng</name>
    </author>
    <author>
      <name>Jie Lou</name>
    </author>
    <link href="http://arxiv.org/abs/1905.11393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10989v3</id>
    <updated>2019-09-02T08:52:21Z</updated>
    <published>2019-05-27T06:12:56Z</published>
    <title>Commonsense Properties from Query Logs and Question Answering Forums</title>
    <summary>  Commonsense knowledge about object properties, human behavior and general
concepts is crucial for robust AI applications. However, automatic acquisition
of this knowledge is challenging because of sparseness and bias in online
sources. This paper presents Quasimodo, a methodology and tool suite for
distilling commonsense properties from non-standard web sources. We devise
novel ways of tapping into search-engine query logs and QA forums, and
combining the resulting candidate assertions with statistical cues from
encyclopedias, books and image tags in a corroboration step. Unlike prior work
on commonsense knowledge bases, Quasimodo focuses on salient properties that
are typically associated with certain objects or concepts. Extensive
evaluations, including extrinsic use-case studies, show that Quasimodo provides
better coverage than state-of-the-art baselines with comparable quality.
</summary>
    <author>
      <name>Julien Romero</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Koninika Pal</name>
    </author>
    <author>
      <name>Jeff Z. Pan</name>
    </author>
    <author>
      <name>Archit Sakhadeo</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CIKM 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.10989v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10989v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10957v3</id>
    <updated>2019-12-01T03:08:59Z</updated>
    <published>2019-05-27T03:35:30Z</published>
    <title>Enhancing Item Response Theory for Cognitive Diagnosis</title>
    <summary>  Cognitive diagnosis is a fundamental and crucial task in many educational
applications, e.g., computer adaptive test and cognitive assignments. Item
Response Theory (IRT) is a classical cognitive diagnosis method which can
provide interpretable parameters (i.e., student latent trait, question
discrimination, and difficulty) for analyzing student performance. However,
traditional IRT ignores the rich information in question texts, cannot diagnose
knowledge concept proficiency, and it is inaccurate to diagnose the parameters
for the questions which only appear several times. To this end, in this paper,
we propose a general Deep Item Response Theory (DIRT) framework to enhance
traditional IRT for cognitive diagnosis by exploiting semantic representation
from question texts with deep learning. In DIRT, we first use a proficiency
vector to represent students' proficiency in knowledge concepts and embed
question texts and knowledge concepts to dense vectors by Word2Vec. Then, we
design a deep diagnosis module to diagnose parameters in traditional IRT by
deep learning techniques. Finally, with the diagnosed parameters, we input them
into the logistic-like formula of IRT to predict student performance. Extensive
experimental results on real-world data clearly demonstrate the effectiveness
and interpretation power of DIRT framework.
</summary>
    <author>
      <name>Song Cheng</name>
    </author>
    <author>
      <name>Qi Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3357384.3358070</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3357384.3358070" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by CIKM'2019. https://github.com/chsong513/DIRT</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10957v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10957v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10847v1</id>
    <updated>2019-05-26T17:56:11Z</updated>
    <published>2019-05-26T17:56:11Z</published>
    <title>Simple and Effective Curriculum Pointer-Generator Networks for Reading
  Comprehension over Long Narratives</title>
    <summary>  This paper tackles the problem of reading comprehension over long narratives
where documents easily span over thousands of tokens. We propose a curriculum
learning (CL) based Pointer-Generator framework for reading/sampling over large
documents, enabling diverse training of the neural model based on the notion of
alternating contextual difficulty. This can be interpreted as a form of domain
randomization and/or generative pretraining during training. To this end, the
usage of the Pointer-Generator softens the requirement of having the answer
within the context, enabling us to construct diverse training samples for
learning. Additionally, we propose a new Introspective Alignment Layer (IAL),
which reasons over decomposed alignments using block-based self-attention. We
evaluate our proposed method on the NarrativeQA reading comprehension
benchmark, achieving state-of-the-art performance, improving existing baselines
by $51\%$ relative improvement on BLEU-4 and $17\%$ relative improvement on
Rouge-L. Extensive ablations confirm the effectiveness of our proposed IAL and
CL components.
</summary>
    <author>
      <name>Yi Tay</name>
    </author>
    <author>
      <name>Shuohang Wang</name>
    </author>
    <author>
      <name>Luu Anh Tuan</name>
    </author>
    <author>
      <name>Jie Fu</name>
    </author>
    <author>
      <name>Minh C. Phan</name>
    </author>
    <author>
      <name>Xingdi Yuan</name>
    </author>
    <author>
      <name>Jinfeng Rao</name>
    </author>
    <author>
      <name>Siu Cheung Hui</name>
    </author>
    <author>
      <name>Aston Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10799v3</id>
    <updated>2019-11-26T17:34:15Z</updated>
    <published>2019-05-26T12:57:47Z</published>
    <title>Path Ranking with Attention to Type Hierarchies</title>
    <summary>  The objective of the knowledge base completion problem is to infer missing
information from existing facts in a knowledge base. Prior work has
demonstrated the effectiveness of path-ranking based methods, which solve the
problem by discovering observable patterns in knowledge graphs, consisting of
nodes representing entities and edges representing relations. However, these
patterns either lack accuracy because they rely solely on relations or cannot
easily generalize due to the direct use of specific entity information. We
introduce Attentive Path Ranking, a novel path pattern representation that
leverages type hierarchies of entities to both avoid ambiguity and maintain
generalization. Then, we present an end-to-end trained attention-based RNN
model to discover the new path patterns from data. Experiments conducted on
benchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate
that the proposed model outperforms existing methods on the fact prediction
task by statistically significant margins of 26% and 10%, respectively.
Furthermore, quantitative and qualitative analyses show that the path patterns
balance between generalization and discrimination.
</summary>
    <author>
      <name>Weiyu Liu</name>
    </author>
    <author>
      <name>Angel Daruna</name>
    </author>
    <author>
      <name>Zsolt Kira</name>
    </author>
    <author>
      <name>Sonia Chernova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10799v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10799v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10702v8</id>
    <updated>2020-02-21T13:09:08Z</updated>
    <published>2019-05-25T23:48:00Z</published>
    <title>MDE: Multiple Distance Embeddings for Link Prediction in Knowledge
  Graphs</title>
    <summary>  Over the past decade, knowledge graphs became popular for capturing
structured domain knowledge. Relational learning models enable the prediction
of missing links inside knowledge graphs. More specifically, latent distance
approaches model the relationships among entities via a distance between latent
representations. Translating embedding models (e.g., TransE) are among the most
popular latent distance approaches which use one distance function to learn
multiple relation patterns. However, they are mostly inefficient in capturing
symmetric relations since the representation vector norm for all the symmetric
relations becomes equal to zero. They also lose information when learning
relations with reflexive patterns since they become symmetric and transitive.
We propose the Multiple Distance Embedding model (MDE) that addresses these
limitations and a framework to collaboratively combine variant latent
distance-based terms. Our solution is based on two principles: 1) we use a
limit-based loss instead of a margin ranking loss and, 2) by learning
independent embedding vectors for each of the terms we can collectively train
and predict using contradicting distance terms. We further demonstrate that MDE
allows modeling relations with (anti)symmetry, inversion, and composition
patterns. We propose MDE as a neural network model that allows us to map
non-linear relations between the embedding vectors and the expected output of
the score function. Our empirical results show that MDE performs competitively
to state-of-the-art embedding models on several benchmark datasets.
</summary>
    <author>
      <name>Afshin Sadeghi</name>
    </author>
    <author>
      <name>Damien Graux</name>
    </author>
    <author>
      <name>Hamed Shariat Yazdi</name>
    </author>
    <author>
      <name>Jens Lehmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper in ECAI 2020</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">24th European Conference on Artificial Intelligence (ECAI), 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.10702v8" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10702v8" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10625v2</id>
    <updated>2019-07-14T00:50:53Z</updated>
    <published>2019-05-25T16:06:42Z</published>
    <title>ESA: Entity Summarization with Attention</title>
    <summary>  Entity summarization aims at creating brief but informative descriptions of
entities from knowledge graphs. While previous work mostly focused on
traditional techniques such as clustering algorithms and graph models, we ask
how to apply deep learning methods into this task. In this paper we propose
ESA, a neural network with supervised attention mechanisms for entity
summarization. Specifically, we calculate attention weights for facts in each
entity, and rank facts to generate reliable summaries. We explore techniques to
solve difficult learning problems presented by the ESA, and demonstrate the
effectiveness of our model in comparison with the state-of-the-art methods.
Experimental results show that our model improves the quality of the entity
summaries in both F-measure and MAP.
</summary>
    <author>
      <name>Dongjun Wei</name>
    </author>
    <author>
      <name>Yaxin Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10625v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10625v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01965v1</id>
    <updated>2019-05-25T03:05:15Z</updated>
    <published>2019-05-25T03:05:15Z</published>
    <title>Triple-to-Text: Converting RDF Triples into High-Quality Natural
  Languages via Optimizing an Inverse KL Divergence</title>
    <summary>  Knowledge base is one of the main forms to represent information in a
structured way. A knowledge base typically consists of Resource Description
Frameworks (RDF) triples which describe the entities and their relations.
Generating natural language description of the knowledge base is an important
task in NLP, which has been formulated as a conditional language generation
task and tackled using the sequence-to-sequence framework. Current works mostly
train the language models by maximum likelihood estimation, which tends to
generate lousy sentences. In this paper, we argue that such a problem of
maximum likelihood estimation is intrinsic, which is generally irrevocable via
changing network structures. Accordingly, we propose a novel Triple-to-Text
(T2T) framework, which approximately optimizes the inverse Kullback-Leibler
(KL) divergence between the distributions of the real and generated sentences.
Due to the nature that inverse KL imposes large penalty on fake-looking
samples, the proposed method can significantly reduce the probability of
generating low-quality sentences. Our experiments on three real-world datasets
demonstrate that T2T can generate higher-quality sentences and outperform
baseline models in several evaluation metrics.
</summary>
    <author>
      <name>Yaoming Zhu</name>
    </author>
    <author>
      <name>Juncheng Wan</name>
    </author>
    <author>
      <name>Zhiming Zhou</name>
    </author>
    <author>
      <name>Liheng Chen</name>
    </author>
    <author>
      <name>Lin Qiu</name>
    </author>
    <author>
      <name>Weinan Zhang</name>
    </author>
    <author>
      <name>Xin Jiang</name>
    </author>
    <author>
      <name>Yong Yu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3331184.3331232</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3331184.3331232" rel="related"/>
    <link href="http://arxiv.org/abs/1906.01965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10425v3</id>
    <updated>2019-06-01T20:35:31Z</updated>
    <published>2019-05-24T19:55:34Z</published>
    <title>Human vs. Muppet: A Conservative Estimate of Human Performance on the
  GLUE Benchmark</title>
    <summary>  The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding
tasks which has seen dramatic progress in the past year, with average
performance moving from 70.0 at launch to 83.9, state of the art at the time of
writing (May 24, 2019). Here, we measure human performance on the benchmark, in
order to learn whether significant headroom remains for further progress. We
provide a conservative estimate of human performance on the benchmark through
crowdsourcing: Our annotators are non-experts who must learn each task from a
brief set of instructions and 20 examples. In spite of limited training, these
annotators robustly outperform the state of the art on six of the nine GLUE
tasks and achieve an average score of 87.1. Given the fast pace of progress
however, the headroom we observe is quite limited. To reproduce the data-poor
setting that our annotators must learn in, we also train the BERT model (Devlin
et al., 2019) in limited-data regimes, and conclude that low-resource sentence
classification remains a challenge for modern neural network approaches to text
understanding.
</summary>
    <author>
      <name>Nikita Nangia</name>
    </author>
    <author>
      <name>Samuel R. Bowman</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.10425v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10425v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10417v1</id>
    <updated>2019-05-24T19:20:03Z</updated>
    <published>2019-05-24T19:20:03Z</published>
    <title>Differentiable Representations For Multihop Inference Rules</title>
    <summary>  We present efficient differentiable implementations of second-order multi-hop
reasoning using a large symbolic knowledge base (KB). We introduce a new
operation which can be used to compositionally construct second-order multi-hop
templates in a neural model, and evaluate a number of alternative
implementations, with different time and memory trade offs. These techniques
scale to KBs with millions of entities and tens of millions of triples, and
lead to simple models with competitive performance on several learning tasks
requiring multi-hop reasoning.
</summary>
    <author>
      <name>William W. Cohen</name>
    </author>
    <author>
      <name>Haitian Sun</name>
    </author>
    <author>
      <name>R. Alex Hofer</name>
    </author>
    <author>
      <name>Matthew Siegler</name>
    </author>
    <link href="http://arxiv.org/abs/1905.10417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10412v1</id>
    <updated>2019-05-24T19:10:18Z</updated>
    <published>2019-05-24T19:10:18Z</published>
    <title>Using Deep Networks and Transfer Learning to Address Disinformation</title>
    <summary>  We apply an ensemble pipeline composed of a character-level convolutional
neural network (CNN) and a long short-term memory (LSTM) as a general tool for
addressing a range of disinformation problems. We also demonstrate the ability
to use this architecture to transfer knowledge from labeled data in one domain
to related (supervised and unsupervised) tasks. Character-level neural networks
and transfer learning are particularly valuable tools in the disinformation
space because of the messy nature of social media, lack of labeled data, and
the multi-channel tactics of influence campaigns. We demonstrate their
effectiveness in several tasks relevant for detecting disinformation: spam
emails, review bombing, political sentiment, and conversation clustering.
</summary>
    <author>
      <name>Numa Dhamani</name>
    </author>
    <author>
      <name>Paul Azunre</name>
    </author>
    <author>
      <name>Jeffrey L. Gleason</name>
    </author>
    <author>
      <name>Craig Corcoran</name>
    </author>
    <author>
      <name>Garrett Honke</name>
    </author>
    <author>
      <name>Steve Kramer</name>
    </author>
    <author>
      <name>Jonathon Morgan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AI for Social Good Workshop at the International Conference on
  Machine Learning, Long Beach, United States (2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10033v1</id>
    <updated>2019-05-24T05:01:14Z</updated>
    <published>2019-05-24T05:01:14Z</published>
    <title>Personalizing Dialogue Agents via Meta-Learning</title>
    <summary>  Existing personalized dialogue models use human designed persona descriptions
to improve dialogue consistency. Collecting such descriptions from existing
dialogues is expensive and requires hand-crafted feature designs. In this
paper, we propose to extend Model-Agnostic Meta-Learning (MAML)(Finn et al.,
2017) to personalized dialogue learning without using any persona descriptions.
Our model learns to quickly adapt to new personas by leveraging only a few
dialogue samples collected from the same user, which is fundamentally different
from conditioning the response on the persona descriptions. Empirical results
on Persona-chat dataset (Zhang et al., 2018) indicate that our solution
outperforms non-meta-learning baselines using automatic evaluation metrics, and
in terms of human-evaluated fluency and consistency.
</summary>
    <author>
      <name>Zhaojiang Lin</name>
    </author>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ACL 2019. Zhaojiang Lin* and Andrea Madotto* contributed
  equally to this work</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.09557v1</id>
    <updated>2019-05-23T09:44:50Z</updated>
    <published>2019-05-23T09:44:50Z</published>
    <title>Knowledge Graph Embedding Bi-Vector Models for Symmetric Relation</title>
    <summary>  Knowledge graph embedding (KGE) models have been proposed to improve the
performance of knowledge graph reasoning. However, there is a general
phenomenon in most of KGEs, as the training progresses, the symmetric relations
tend to zero vector, if the symmetric triples ratio is high enough in the
dataset. This phenomenon causes subsequent tasks, e.g. link prediction etc., of
symmetric relations to fail. The root cause of the problem is that KGEs do not
utilize the semantic information of symmetric relations. We propose KGE
bi-vector models, which represent the symmetric relations as vector pair,
significantly increasing the processing capability of the symmetry relations.
We generate the benchmark datasets based on FB15k and WN18 by completing the
symmetric relation triples to verify models. The experiment results of our
models clearly affirm the effectiveness and superiority of our models against
baseline.
</summary>
    <author>
      <name>Jinkui Yao</name>
    </author>
    <author>
      <name>Lianghua Xu</name>
    </author>
    <link href="http://arxiv.org/abs/1905.09557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.09438v1</id>
    <updated>2019-05-23T02:32:34Z</updated>
    <published>2019-05-23T02:32:34Z</published>
    <title>Multi-hop Reading Comprehension via Deep Reinforcement Learning based
  Document Traversal</title>
    <summary>  Reading Comprehension has received significant attention in recent years as
high quality Question Answering (QA) datasets have become available. Despite
state-of-the-art methods achieving strong overall accuracy, Multi-Hop (MH)
reasoning remains particularly challenging. To address MH-QA specifically, we
propose a Deep Reinforcement Learning based method capable of learning
sequential reasoning across large collections of documents so as to pass a
query-aware, fixed-size context subset to existing models for answer
extraction. Our method is comprised of two stages: a linker, which decomposes
the provided support documents into a graph of sentences, and an extractor,
which learns where to look based on the current question and already-visited
sentences. The result of the linker is a novel graph structure at the sentence
level that preserves logical flow while still allowing rapid movement between
documents. Importantly, we demonstrate that the sparsity of the resultant graph
is invariant to context size. This translates to fewer decisions required from
the Deep-RL trained extractor, allowing the system to scale effectively to
large collections of documents.
  The importance of sequential decision making in the document traversal step
is demonstrated by comparison to standard IE methods, and we additionally
introduce a BM25-based IR baseline that retrieves documents relevant to the
query only. We examine the integration of our method with existing models on
the recently proposed QAngaroo benchmark and achieve consistent increases in
accuracy across the board, as well as a 2-3x reduction in training time.
</summary>
    <author>
      <name>Alex Long</name>
    </author>
    <author>
      <name>Joel Mason</name>
    </author>
    <author>
      <name>Alan Blair</name>
    </author>
    <author>
      <name>Wei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1905.09438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.09153v1</id>
    <updated>2019-05-22T14:11:30Z</updated>
    <published>2019-05-22T14:11:30Z</published>
    <title>Simplified Neural Unsupervised Domain Adaptation</title>
    <summary>  Unsupervised domain adaptation (UDA) is the task of modifying a statistical
model trained on labeled data from a source domain to achieve better
performance on data from a target domain, with access to only unlabeled data in
the target domain. Existing state-of-the-art UDA approaches use neural networks
to learn representations that can predict the values of subset of important
features called "pivot features." In this work, we show that it is possible to
improve on these methods by jointly training the representation learner with
the task learner, and examine the importance of existing pivot selection
methods.
</summary>
    <author>
      <name>Timothy A Miller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented at NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.09153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08941v1</id>
    <updated>2019-05-22T03:55:54Z</updated>
    <published>2019-05-22T03:55:54Z</published>
    <title>Augmenting Data with Mixup for Sentence Classification: An Empirical
  Study</title>
    <summary>  Mixup, a recent proposed data augmentation method through linearly
interpolating inputs and modeling targets of random samples, has demonstrated
its capability of significantly improving the predictive accuracy of the
state-of-the-art networks for image classification. However, how this technique
can be applied to and what is its effectiveness on natural language processing
(NLP) tasks have not been investigated. In this paper, we propose two
strategies for the adaption of Mixup on sentence classification: one performs
interpolation on word embeddings and another on sentence embeddings. We conduct
experiments to evaluate our methods using several benchmark datasets. Our
studies show that such interpolation strategies serve as an effective, domain
independent data augmentation approach for sentence classification, and can
result in significant accuracy improvement for both CNN and LSTM models.
</summary>
    <author>
      <name>Hongyu Guo</name>
    </author>
    <author>
      <name>Yongyi Mao</name>
    </author>
    <author>
      <name>Richong Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08937v2</id>
    <updated>2019-05-30T06:22:53Z</updated>
    <published>2019-05-22T03:34:59Z</published>
    <title>Can a Humanoid Robot be part of the Organizational Workforce? A User
  Study Leveraging Sentiment Analysis</title>
    <summary>  Hiring robots for the workplaces is a challenging task as robots have to
cater to customer demands, follow organizational protocols and behave with
social etiquette. In this study, we propose to have a humanoid social robot,
Nadine, as a customer service agent in an open social work environment. The
objective of this study is to analyze the effects of humanoid robots on
customers at work environment, and see if it can handle social scenarios. We
propose to evaluate these objectives through two modes, namely, survey
questionnaire and customer feedback. We also propose a novel approach to
analyze customer feedback data (text) using sentic computing methods.
Specifically, we employ aspect extraction and sentiment analysis to analyze the
data. From our framework, we detect sentiment associated to the aspects that
mainly concerned the customers during their interaction. This allows us to
understand customers expectations and current limitations of robots as
employees.
</summary>
    <author>
      <name>Nidhi Mishra</name>
    </author>
    <author>
      <name>Manoj Ramanathan</name>
    </author>
    <author>
      <name>Ranjan Satapathy</name>
    </author>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Nadia Magnenat-Thalmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE RO-MAN2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08937v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08937v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08743v2</id>
    <updated>2019-05-26T14:36:57Z</updated>
    <published>2019-05-21T16:43:54Z</published>
    <title>Transferable Multi-Domain State Generator for Task-Oriented Dialogue
  Systems</title>
    <summary>  Over-dependence on domain ontology and lack of knowledge sharing across
domains are two practical and yet less studied problems of dialogue state
tracking. Existing approaches generally fall short in tracking unknown slot
values during inference and often have difficulties in adapting to new domains.
In this paper, we propose a Transferable Dialogue State Generator (TRADE) that
generates dialogue states from utterances using a copy mechanism, facilitating
knowledge transfer when predicting (domain, slot, value) triplets not
encountered during training. Our model is composed of an utterance encoder, a
slot gate, and a state generator, which are shared across domains. Empirical
results demonstrate that TRADE achieves state-of-the-art joint goal accuracy of
48.62% for the five domains of MultiWOZ, a human-human dialogue dataset. In
addition, we show its transferring ability by simulating zero-shot and few-shot
dialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal
accuracy in one of the zero-shot domains, and is able to adapt to few-shot
cases without forgetting already trained domains.
</summary>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Andrea Madotto</name>
    </author>
    <author>
      <name>Ehsan Hosseini-Asl</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Pascale Fung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 57th Annual Meeting of the Association for Computational
  Linguistics (ACL 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08743v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08743v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08527v1</id>
    <updated>2019-05-21T10:14:12Z</updated>
    <published>2019-05-21T10:14:12Z</published>
    <title>CNNs found to jump around more skillfully than RNNs: Compositional
  generalization in seq2seq convolutional networks</title>
    <summary>  Lake and Baroni (2018) introduced the SCAN dataset probing the ability of
seq2seq models to capture compositional generalizations, such as inferring the
meaning of "jump around" 0-shot from the component words. Recurrent networks
(RNNs) were found to completely fail the most challenging generalization cases.
We test here a convolutional network (CNN) on these tasks, reporting hugely
improved performance with respect to RNNs. Despite the big improvement, the CNN
has however not induced systematic rules, suggesting that the difference
between compositional and non-compositional behaviour is not clear-cut.
</summary>
    <author>
      <name>Roberto Dessì</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted as a short paper at ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07870v4</id>
    <updated>2019-05-31T06:51:13Z</updated>
    <published>2019-05-20T04:41:10Z</published>
    <title>PaperRobot: Incremental Draft Generation of Scientific Ideas</title>
    <summary>  We present a PaperRobot who performs as an automatic research assistant by
(1) conducting deep understanding of a large collection of human-written papers
in a target domain and constructing comprehensive background knowledge graphs
(KGs); (2) creating new ideas by predicting links from the background KGs, by
combining graph attention and contextual text attention; (3) incrementally
writing some key elements of a new paper based on memory-attention networks:
from the input title along with predicted related entities to generate a paper
abstract, from the abstract to generate conclusion and future work, and finally
from future work to generate a title for a follow-on paper. Turing Tests, where
a biomedical domain expert is asked to compare a system output and a
human-authored string, show PaperRobot generated abstracts, conclusion and
future work sections, and new titles are chosen over human-written ones up to
30%, 24% and 12% of the time, respectively.
</summary>
    <author>
      <name>Qingyun Wang</name>
    </author>
    <author>
      <name>Lifu Huang</name>
    </author>
    <author>
      <name>Zhiying Jiang</name>
    </author>
    <author>
      <name>Kevin Knight</name>
    </author>
    <author>
      <name>Heng Ji</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <author>
      <name>Yi Luan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. Accepted by ACL 2019 Code and resource is available at
  https://github.com/EagleW/PaperRobot</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07870v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07870v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07687v1</id>
    <updated>2019-05-19T04:00:08Z</updated>
    <published>2019-05-19T04:00:08Z</published>
    <title>Learning to Memorize in Neural Task-Oriented Dialogue Systems</title>
    <summary>  In this thesis, we leverage the neural copy mechanism and memory-augmented
neural networks (MANNs) to address existing challenge of neural task-oriented
dialogue learning. We show the effectiveness of our strategy by achieving good
performance in multi-domain dialogue state tracking, retrieval-based dialogue
systems, and generation-based dialogue systems. We first propose a transferable
dialogue state generator (TRADE) that leverages its copy mechanism to get rid
of dialogue ontology and share knowledge between domains. We also evaluate
unseen domain dialogue state tracking and show that TRADE enables zero-shot
dialogue state tracking and can adapt to new few-shot domains without
forgetting the previous domains. Second, we utilize MANNs to improve
retrieval-based dialogue learning. They are able to capture dialogue sequential
dependencies and memorize long-term information. We also propose a recorded
delexicalization copy strategy to replace real entity values with ordered
entity types. Our models are shown to surpass other retrieval baselines,
especially when the conversation has a large number of turns. Lastly, we tackle
generation-based dialogue learning with two proposed models, the
memory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP).
Mem2Seq is the first model to combine multi-hop memory attention with the idea
of the copy mechanism. GLMP further introduces the concept of response
sketching and double pointers copying. We show that GLMP achieves the
state-of-the-art performance on human evaluation.
</summary>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">HKUST MPhil Thesis. 93 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07562v2</id>
    <updated>2019-06-01T07:46:23Z</updated>
    <published>2019-05-18T09:23:00Z</published>
    <title>Human-like machine thinking: Language guided imagination</title>
    <summary>  Human thinking requires the brain to understand the meaning of language
expression and to properly organize the thoughts flow using the language.
However, current natural language processing models are primarily limited in
the word probability estimation. Here, we proposed a Language guided
imagination (LGI) network to incrementally learn the meaning and usage of
numerous words and syntaxes, aiming to form a human-like machine thinking
process. LGI contains three subsystems: (1) vision system that contains an
encoder to disentangle the input or imagined scenarios into abstract population
representations, and an imagination decoder to reconstruct imagined scenario
from higher level representations; (2) Language system, that contains a
binarizer to transfer symbol texts into binary vectors, an IPS (mimicking the
human IntraParietal Sulcus, implemented by an LSTM) to extract the quantity
information from the input texts, and a textizer to convert binary vectors into
text symbols; (3) a PFC (mimicking the human PreFrontal Cortex, implemented by
an LSTM) to combine inputs of both language and vision representations, and
predict text symbols and manipulated images accordingly. LGI has incrementally
learned eight different syntaxes (or tasks), with which a machine thinking loop
has been formed and validated by the proper interaction between language and
vision system. The paper provides a new architecture to let the machine learn,
understand and use language in a human-like way that could ultimately enable a
machine to construct fictitious 'mental' scenario and possess intelligence.
</summary>
    <author>
      <name>Feng Qi</name>
    </author>
    <author>
      <name>Wenchuan Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1905.07562v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07562v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07356v1</id>
    <updated>2019-05-17T16:26:05Z</updated>
    <published>2019-05-17T16:26:05Z</published>
    <title>Don't Blame Distributional Semantics if it can't do Entailment</title>
    <summary>  Distributional semantics has had enormous empirical success in Computational
Linguistics and Cognitive Science in modeling various semantic phenomena, such
as semantic similarity, and distributional models are widely used in
state-of-the-art Natural Language Processing systems. However, the theoretical
status of distributional semantics within a broader theory of language and
cognition is still unclear: What does distributional semantics model? Can it
be, on its own, a fully adequate model of the meanings of linguistic
expressions? The standard answer is that distributional semantics is not fully
adequate in this regard, because it falls short on some of the central aspects
of formal semantic approaches: truth conditions, entailment, reference, and
certain aspects of compositionality. We argue that this standard answer rests
on a misconception: These aspects do not belong in a theory of expression
meaning, they are instead aspects of speaker meaning, i.e., communicative
intentions in a particular context. In a slogan: words do not refer, speakers
do. Clearing this up enables us to argue that distributional semantics on its
own is an adequate model of expression meaning. Our proposal sheds light on the
role of distributional semantics in a broader theory of language and cognition,
its relationship to formal semantics, and its place in computational models.
</summary>
    <author>
      <name>Matthijs Westera</name>
    </author>
    <author>
      <name>Gemma Boleda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of the 13th International Conference on
  Computational Semantics (IWCS 2019), Gothenburg, Sweden</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07189v2</id>
    <updated>2019-06-04T07:43:50Z</updated>
    <published>2019-05-17T10:49:47Z</published>
    <title>Distant Learning for Entity Linking with Automatic Noise Detection</title>
    <summary>  Accurate entity linkers have been produced for domains and languages where
annotated data (i.e., texts linked to a knowledge base) is available. However,
little progress has been made for the settings where no or very limited amounts
of labeled data are present (e.g., legal or most scientific domains). In this
work, we show how we can learn to link mentions without having any labeled
examples, only a knowledge base and a collection of unannotated texts from the
corresponding domain. In order to achieve this, we frame the task as a
multi-instance learning problem and rely on surface matching to create initial
noisy labels. As the learning signal is weak and our surrogate labels are
noisy, we introduce a noise detection component in our model: it lets the model
detect and disregard examples which are likely to be noisy. Our method, jointly
learning to detect noise and link entities, greatly outperforms the surface
matching baseline. For a subset of entity categories, it even approaches the
performance of supervised learning.
</summary>
    <author>
      <name>Phong Le</name>
    </author>
    <author>
      <name>Ivan Titov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07189v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07189v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07185v1</id>
    <updated>2019-05-17T10:14:21Z</updated>
    <published>2019-05-17T10:14:21Z</published>
    <title>Plotting Markson's 'Mistress'</title>
    <summary>  The post-modern novel 'Wittgenstein's Mistress' by David Markson (1988)
presents the reader with a very challenging non linear narrative, that itself
appears to one of the novel's themes. We present a distant reading of this work
designed to complement a close reading of it by David Foster Wallace (1990).
Using a combination of text analysis, entity recognition and networks, we plot
repetitive structures in the novel's narrative relating them to its critical
analysis.
</summary>
    <author>
      <name>Kelleher Conor</name>
    </author>
    <author>
      <name>Mark T. Keane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.08063v1</id>
    <updated>2019-05-17T10:14:07Z</updated>
    <published>2019-05-17T10:14:07Z</published>
    <title>The Unexpected Unexpected and the Expected Unexpected: How People's
  Conception of the Unexpected is Not That Unexpected</title>
    <summary>  The answers people give when asked to 'think of the unexpected' for everyday
event scenarios appear to be more expected than unexpected. There are expected
unexpected outcomes that closely adhere to the given information in a scenario,
based on familiar disruptions and common plan-failures. There are also
unexpected unexpected outcomes that are more inventive, that depart from given
information, adding new concepts/actions. However, people seem to tend to
conceive of the unexpected as the former more than the latter. Study 1 tests
these proposals by analysing the object-concepts people mention in their
reports of the unexpected and the agreement between their answers. Study 2
shows that object-choices are weakly influenced by recency, the order of
sentences in the scenario. The implications of these results for ideas in
philosophy, psychology and computing is discussed
</summary>
    <author>
      <name>Molly S Quinn</name>
    </author>
    <author>
      <name>Kathleen Campbell</name>
    </author>
    <author>
      <name>Mark T Keane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.07098v2</id>
    <updated>2019-05-31T04:35:36Z</updated>
    <published>2019-05-17T03:00:46Z</published>
    <title>Improving Question Answering over Incomplete KBs with Knowledge-Aware
  Reader</title>
    <summary>  We propose a new end-to-end question answering model, which learns to
aggregate answer evidence from an incomplete knowledge base (KB) and a set of
retrieved text snippets. Under the assumptions that the structured KB is easier
to query and the acquired knowledge can help the understanding of unstructured
text, our model first accumulates knowledge of entities from a question-related
KB subgraph; then reformulates the question in the latent space and reads the
texts with the accumulated entity knowledge at hand. The evidence from KB and
texts are finally aggregated to predict answers. On the widely-used KBQA
benchmark WebQSP, our model achieves consistent improvements across settings
with different extents of KB incompleteness.
</summary>
    <author>
      <name>Wenhan Xiong</name>
    </author>
    <author>
      <name>Mo Yu</name>
    </author>
    <author>
      <name>Shiyu Chang</name>
    </author>
    <author>
      <name>Xiaoxiao Guo</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07098v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07098v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06883v1</id>
    <updated>2019-05-16T16:15:01Z</updated>
    <published>2019-05-16T16:15:01Z</published>
    <title>TraceWalk: Semantic-based Process Graph Embedding for Consistency
  Checking</title>
    <summary>  Process consistency checking (PCC), an interdiscipline of natural language
processing (NLP) and business process management (BPM), aims to quantify the
degree of (in)consistencies between graphical and textual descriptions of a
process. However, previous studies heavily depend on a great deal of complex
expert-defined knowledge such as alignment rules and assessment metrics, thus
suffer from the problems of low accuracy and poor adaptability when applied in
open-domain scenarios. To address the above issues, this paper makes the first
attempt that uses deep learning to perform PCC. Specifically, we proposed
TraceWalk, using semantic information of process graphs to learn latent node
representations, and integrates it into a convolutional neural network (CNN)
based model called TraceNet to predict consistencies. The theoretical proof
formally provides the PCC's lower limit and experimental results demonstrate
that our approach performs more accurately than state-of-the-art baselines.
</summary>
    <author>
      <name>Chen Qian</name>
    </author>
    <author>
      <name>Lijie Wen</name>
    </author>
    <author>
      <name>Akhil Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1905.06883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02127v2</id>
    <updated>2019-08-20T13:06:30Z</updated>
    <published>2019-05-16T16:04:49Z</published>
    <title>Extracting Process Graphs from Texts via Multi-Granularity Text
  Classification</title>
    <summary>  Process graph extraction (PGE) is a recently emerged interdiscipline between
natural language processing and business process management, which aims to
extract process graphs expressed in texts. Previous process extractors heavily
depend on manual features and ignore the potential relations between clues of
different text granularities. In this paper, we formalize the PGE task into the
multi-granularity text classification problem, and propose a hierarchical model
to effectively model and extract multi-granularity information without manually
defined procedural knowledge. Under this framework, we accordingly propose the
coarse-to-fine learning mechanism, training multi-granularity tasks in
coarse-to-fine order to share the high-level knowledge for the low-level tasks.
To evaluate our approach, we construct two finer-grained datasets from two
sentence-level corpora and conduct extensive experiments from different
dimensions. The experimental results demonstrate that our approach outperforms
the state-of-the-art methods with statistical significance, and the ablation
studies demonstrate its effectiveness.
</summary>
    <author>
      <name>Chen Qian</name>
    </author>
    <author>
      <name>Lijie Wen</name>
    </author>
    <author>
      <name>MingSheng Long</name>
    </author>
    <author>
      <name>Yanwei Li</name>
    </author>
    <author>
      <name>Akhil Kumar</name>
    </author>
    <author>
      <name>Jianmin Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1806.02557 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02127v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02127v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06221v4</id>
    <updated>2019-06-10T03:12:43Z</updated>
    <published>2019-05-15T14:51:33Z</published>
    <title>Selection Bias Explorations and Debias Methods for Natural Language
  Sentence Matching Datasets</title>
    <summary>  Natural Language Sentence Matching (NLSM) has gained substantial attention
from both academics and the industry, and rich public datasets contribute a lot
to this process. However, biased datasets can also hurt the generalization
performance of trained models and give untrustworthy evaluation results. For
many NLSM datasets, the providers select some pairs of sentences into the
datasets, and this sampling procedure can easily bring unintended pattern,
i.e., selection bias. One example is the QuoraQP dataset, where some
content-independent naive features are unreasonably predictive. Such features
are the reflection of the selection bias and termed as the leakage features. In
this paper, we investigate the problem of selection bias on six NLSM datasets
and find that four out of them are significantly biased. We further propose a
training and evaluation framework to alleviate the bias. Experimental results
on QuoraQP suggest that the proposed framework can improve the generalization
ability of trained models, and give more trustworthy evaluation results for
real-world adoptions.
</summary>
    <author>
      <name>Guanhua Zhang</name>
    </author>
    <author>
      <name>Bing Bai</name>
    </author>
    <author>
      <name>Jian Liang</name>
    </author>
    <author>
      <name>Kun Bai</name>
    </author>
    <author>
      <name>Shiyu Chang</name>
    </author>
    <author>
      <name>Mo Yu</name>
    </author>
    <author>
      <name>Conghui Zhu</name>
    </author>
    <author>
      <name>Tiejun Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.06221v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06221v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06175v1</id>
    <updated>2019-05-15T13:37:58Z</updated>
    <published>2019-05-15T13:37:58Z</published>
    <title>TSXplain: Demystification of DNN Decisions for Time-Series using Natural
  Language and Statistical Features</title>
    <summary>  Neural networks (NN) are considered as black-boxes due to the lack of
explainability and transparency of their decisions. This significantly hampers
their deployment in environments where explainability is essential along with
the accuracy of the system. Recently, significant efforts have been made for
the interpretability of these deep networks with the aim to open up the
black-box. However, most of these approaches are specifically developed for
visual modalities. In addition, the interpretations provided by these systems
require expert knowledge and understanding for intelligibility. This indicates
a vital gap between the explainability provided by the systems and the novice
user. To bridge this gap, we present a novel framework i.e. Time-Series
eXplanation (TSXplain) system which produces a natural language based
explanation of the decision taken by a NN. It uses the extracted statistical
features to describe the decision of a NN, merging the deep learning world with
that of statistics. The two-level explanation provides ample description of the
decision made by the network to aid an expert as well as a novice user alike.
Our survey and reliability assessment test confirm that the generated
explanations are meaningful and correct. We believe that generating natural
language based descriptions of the network's decisions is a big step towards
opening up the black-box.
</summary>
    <author>
      <name>Mohsin Munir</name>
    </author>
    <author>
      <name>Shoaib Ahmed Siddiqui</name>
    </author>
    <author>
      <name>Ferdinand Küsters</name>
    </author>
    <author>
      <name>Dominique Mercier</name>
    </author>
    <author>
      <name>Andreas Dengel</name>
    </author>
    <author>
      <name>Sheraz Ahmed</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-30493-5_43</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-30493-5_43" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pre-print</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.06175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02126v1</id>
    <updated>2019-05-15T12:42:42Z</updated>
    <published>2019-05-15T12:42:42Z</published>
    <title>Extractive Summarization via Weighted Dissimilarity and Importance
  Aligned Key Iterative Algorithm</title>
    <summary>  We present importance aligned key iterative algorithm for extractive
summarization that is faster than conventional algorithms keeping its accuracy.
The computational complexity of our algorithm is O($SNlogN$) to summarize
original $N$ sentences into final $S$ sentences. Our algorithm maximizes the
weighted dissimilarity defined by the product of importance and cosine
dissimilarity so that the summary represents the document and at the same time
the sentences of the summary are not similar to each other. The weighted
dissimilarity is heuristically maximized by iterative greedy search and binary
search to the sentences ordered by importance. We finally show a benchmark
score based on summarization of customer reviews of products, which highlights
the quality of our algorithm comparable to human and existing algorithms. We
provide the source code of our algorithm on github
https://github.com/qhapaq-49/imakita .
</summary>
    <author>
      <name>Ryohto Sawada</name>
    </author>
    <link href="http://arxiv.org/abs/1906.02126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05888v1</id>
    <updated>2019-05-14T23:53:57Z</updated>
    <published>2019-05-14T23:53:57Z</published>
    <title>Generative Design in Minecraft: Chronicle Challenge</title>
    <summary>  We introduce the Chronicle Challenge as an optional addition to the
Settlement Generation Challenge in Minecraft. One of the foci of the overall
competition is adaptive procedural content generation (PCG), an arguably
under-explored problem in computational creativity. In the base challenge,
participants must generate new settlements that respond to and ideally interact
with existing content in the world, such as the landscape or climate. The goal
is to understand the underlying creative process, and to design better PCG
systems. The Chronicle Challenge in particular focuses on the generation of a
narrative based on the history of a generated settlement, expressed in natural
language. We discuss the unique features of the Chronicle Challenge in
comparison to other competitions, clarify the characteristics of a chronicle
eligible for submission and describe the evaluation criteria. We furthermore
draw on simulation-based approaches in computational storytelling as examples
to how this challenge could be approached.
</summary>
    <author>
      <name>Christoph Salge</name>
    </author>
    <author>
      <name>Christian Guckelsberger</name>
    </author>
    <author>
      <name>Michael Cerny Green</name>
    </author>
    <author>
      <name>Rodrigo Canaan</name>
    </author>
    <author>
      <name>Julian Togelius</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 Figure, accepted as late-breaking paper at ICCC 2019, 10th
  International Conference on Computational Creativity</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05778v3</id>
    <updated>2019-06-18T17:07:09Z</updated>
    <published>2019-05-14T18:01:41Z</published>
    <title>Misleading Failures of Partial-input Baselines</title>
    <summary>  Recent work establishes dataset difficulty and removes annotation artifacts
via partial-input baselines (e.g., hypothesis-only models for SNLI or
question-only models for VQA). When a partial-input baseline gets high
accuracy, a dataset is cheatable. However, the converse is not necessarily
true: the failure of a partial-input baseline does not mean a dataset is free
of artifacts. To illustrate this, we first design artificial datasets which
contain trivial patterns in the full input that are undetectable by any
partial-input model. Next, we identify such artifacts in the SNLI dataset - a
hypothesis-only model augmented with trivial patterns in the premise can solve
15% of the examples that are previously considered "hard". Our work provides a
caveat for the use of partial-input baselines for dataset verification and
creation.
</summary>
    <author>
      <name>Shi Feng</name>
    </author>
    <author>
      <name>Eric Wallace</name>
    </author>
    <author>
      <name>Jordan Boyd-Graber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05778v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05778v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05682v2</id>
    <updated>2019-06-12T05:05:06Z</updated>
    <published>2019-05-14T15:54:57Z</published>
    <title>A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</title>
    <summary>  We propose an efficient neural framework for sentence-level discourse
analysis in accordance with Rhetorical Structure Theory (RST). Our framework
comprises a discourse segmenter to identify the elementary discourse units
(EDU) in a text, and a discourse parser that constructs a discourse tree in a
top-down fashion. Both the segmenter and the parser are based on Pointer
Networks and operate in linear time. Our segmenter yields an $F_1$ score of
95.4, and our parser achieves an $F_1$ score of 81.7 on the aggregated labeled
(relation) metric, surpassing previous approaches by a good margin and
approaching human agreement on both tasks (98.3 and 83.0 $F_1$).
</summary>
    <author>
      <name>Xiang Lin</name>
    </author>
    <author>
      <name>Shafiq Joty</name>
    </author>
    <author>
      <name>Prathyusha Jwalapuram</name>
    </author>
    <author>
      <name>M Saiful Bari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05682v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05682v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02125v2</id>
    <updated>2020-02-28T07:01:32Z</updated>
    <published>2019-05-14T13:44:37Z</published>
    <title>Strong and Simple Baselines for Multimodal Utterance Embeddings</title>
    <summary>  Human language is a rich multimodal signal consisting of spoken words, facial
expressions, body gestures, and vocal intonations. Learning representations for
these spoken utterances is a complex research problem due to the presence of
multiple heterogeneous sources of information. Recent advances in multimodal
learning have followed the general trend of building more complex models that
utilize various attention, memory and recurrent components. In this paper, we
propose two simple but strong baselines to learn embeddings of multimodal
utterances. The first baseline assumes a conditional factorization of the
utterance into unimodal factors. Each unimodal factor is modeled using the
simple form of a likelihood function obtained via a linear transformation of
the embedding. We show that the optimal embedding can be derived in closed form
by taking a weighted average of the unimodal features. In order to capture
richer representations, our second baseline extends the first by factorizing
into unimodal, bimodal, and trimodal factors, while retaining simplicity and
efficiency during learning and inference. From a set of experiments across two
tasks, we show strong performance on both supervised and semi-supervised
multimodal prediction, as well as significant (10 times) speedups over neural
models during inference. Overall, we believe that our strong baseline models
offer new benchmarking options for future research in multimodal learning.
</summary>
    <author>
      <name>Paul Pu Liang</name>
    </author>
    <author>
      <name>Yao Chong Lim</name>
    </author>
    <author>
      <name>Yao-Hung Hubert Tsai</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Louis-Philippe Morency</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019 oral presentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02125v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02125v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05526v2</id>
    <updated>2019-10-06T07:54:54Z</updated>
    <published>2019-05-14T11:39:43Z</published>
    <title>Is Word Segmentation Necessary for Deep Learning of Chinese
  Representations?</title>
    <summary>  Segmenting a chunk of text into words is usually the first step of processing
Chinese text, but its necessity has rarely been explored. In this paper, we ask
the fundamental question of whether Chinese word segmentation (CWS) is
necessary for deep learning-based Chinese Natural Language Processing. We
benchmark neural word-based models which rely on word segmentation against
neural char-based models which do not involve word segmentation in four
end-to-end NLP benchmark tasks: language modeling, machine translation,
sentence matching/paraphrase and text classification. Through direct
comparisons between these two types of models, we find that char-based models
consistently outperform word-based models. Based on these observations, we
conduct comprehensive experiments to study why word-based models underperform
char-based models in these deep learning-based NLP tasks. We show that it is
because word-based models are more vulnerable to data sparsity and the presence
of out-of-vocabulary (OOV) words, and thus more prone to overfitting. We hope
this paper could encourage researchers in the community to rethink the
necessity of word segmentation in deep learning-based Chinese Natural Language
Processing. \footnote{Yuxian Meng and Xiaoya Li contributed equally to this
paper.}
</summary>
    <author>
      <name>Xiaoya Li</name>
    </author>
    <author>
      <name>Yuxian Meng</name>
    </author>
    <author>
      <name>Xiaofei Sun</name>
    </author>
    <author>
      <name>Qinghong Han</name>
    </author>
    <author>
      <name>Arianna Yuan</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at ACL2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05526v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05526v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05471v3</id>
    <updated>2019-08-02T17:54:01Z</updated>
    <published>2019-05-14T09:07:30Z</published>
    <title>Improving Neural Conversational Models with Entropy-Based Data Filtering</title>
    <summary>  Current neural network-based conversational models lack diversity and
generate boring responses to open-ended utterances. Priors such as persona,
emotion, or topic provide additional information to dialog models to aid
response generation, but annotating a dataset with priors is expensive and such
annotations are rarely available. While previous methods for improving the
quality of open-domain response generation focused on either the underlying
model or the training objective, we present a method of filtering dialog
datasets by removing generic utterances from training data using a simple
entropy-based approach that does not require human supervision. We conduct
extensive experiments with different variations of our method, and compare
dialog models across 17 evaluation metrics to show that training on datasets
filtered this way results in better conversational quality as chatbots learn to
output more diverse responses.
</summary>
    <author>
      <name>Richard Csaky</name>
    </author>
    <author>
      <name>Patrik Purgai</name>
    </author>
    <author>
      <name>Gabor Recski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages. same as ACL version:
  https://www.aclweb.org/anthology/P19-1567</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 57th Conference of the ACL (2019) 5650-5669</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.05471v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05471v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02123v1</id>
    <updated>2019-05-14T08:32:39Z</updated>
    <published>2019-05-14T08:32:39Z</published>
    <title>SP-10K: A Large-scale Evaluation Set for Selectional Preference
  Acquisition</title>
    <summary>  Selectional Preference (SP) is a commonly observed language phenomenon and
proved to be useful in many natural language processing tasks. To provide a
better evaluation method for SP models, we introduce SP-10K, a large-scale
evaluation set that provides human ratings for the plausibility of 10,000 SP
pairs over five SP relations, covering 2,500 most frequent verbs, nouns, and
adjectives in American English. Three representative SP acquisition methods
based on pseudo-disambiguation are evaluated with SP-10K. To demonstrate the
importance of our dataset, we investigate the relationship between SP-10K and
the commonsense knowledge in ConceptNet5 and show the potential of using SP to
represent the commonsense knowledge. We also use the Winograd Schema Challenge
to prove that the proposed new SP relations are essential for the hard pronoun
coreference resolution problem.
</summary>
    <author>
      <name>Hongming Zhang</name>
    </author>
    <author>
      <name>Hantian Ding</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02121v1</id>
    <updated>2019-05-13T19:43:54Z</updated>
    <published>2019-05-13T19:43:54Z</published>
    <title>Classifying Norm Conflicts using Learned Semantic Representations</title>
    <summary>  While most social norms are informal, they are often formalized by companies
in contracts to regulate trades of goods and services. When poorly written,
contracts may contain normative conflicts resulting from opposing deontic
meanings or contradict specifications. As contracts tend to be long and contain
many norms, manually identifying such conflicts requires human-effort, which is
time-consuming and error-prone. Automating such task benefits contract makers
increasing productivity and making conflict identification more reliable. To
address this problem, we introduce an approach to detect and classify norm
conflicts in contracts by converting them into latent representations that
preserve both syntactic and semantic information and training a model to
classify norm conflicts in four conflict types. Our results reach the new state
of the art when compared to a previous approach.
</summary>
    <author>
      <name>João Paulo Aires</name>
    </author>
    <author>
      <name>Roger Granada</name>
    </author>
    <author>
      <name>Juarez Monteiro</name>
    </author>
    <author>
      <name>Rodrigo C. Barros</name>
    </author>
    <author>
      <name>Felipe Meneguzzi</name>
    </author>
    <link href="http://arxiv.org/abs/1906.02121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.04914v1</id>
    <updated>2019-05-13T08:53:31Z</updated>
    <published>2019-05-13T08:53:31Z</published>
    <title>Learning to Exploit Long-term Relational Dependencies in Knowledge
  Graphs</title>
    <summary>  We study the problem of knowledge graph (KG) embedding. A widely-established
assumption to this problem is that similar entities are likely to have similar
relational roles. However, existing related methods derive KG embeddings mainly
based on triple-level learning, which lack the capability of capturing
long-term relational dependencies of entities. Moreover, triple-level learning
is insufficient for the propagation of semantic information among entities,
especially for the case of cross-KG embedding. In this paper, we propose
recurrent skipping networks (RSNs), which employ a skipping mechanism to bridge
the gaps between entities. RSNs integrate recurrent neural networks (RNNs) with
residual learning to efficiently capture the long-term relational dependencies
within and between KGs. We design an end-to-end framework to support RSNs on
different tasks. Our experimental results showed that RSNs outperformed
state-of-the-art embedding-based methods for entity alignment and achieved
competitive performance for KG completion.
</summary>
    <author>
      <name>Lingbing Guo</name>
    </author>
    <author>
      <name>Zequn Sun</name>
    </author>
    <author>
      <name>Wei Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 36th International Conference on Machine Learning
  (ICML 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.04914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.04914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.04847v1</id>
    <updated>2019-05-13T03:34:14Z</updated>
    <published>2019-05-13T03:34:14Z</published>
    <title>Synchronous Bidirectional Neural Machine Translation</title>
    <summary>  Existing approaches to neural machine translation (NMT) generate the target
language sequence token by token from left to right. However, this kind of
unidirectional decoding framework cannot make full use of the target-side
future contexts which can be produced in a right-to-left decoding direction,
and thus suffers from the issue of unbalanced outputs. In this paper, we
introduce a synchronous bidirectional neural machine translation (SB-NMT) that
predicts its outputs using left-to-right and right-to-left decoding
simultaneously and interactively, in order to leverage both of the history and
future information at the same time. Specifically, we first propose a new
algorithm that enables synchronous bidirectional decoding in a single model.
Then, we present an interactive decoding model in which left-to-right
(right-to-left) generation does not only depend on its previously generated
outputs, but also relies on future contexts predicted by right-to-left
(left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on
large-scale NIST Chinese-English, WMT14 English-German, and WMT18
Russian-English translation tasks. Experimental results demonstrate that our
model achieves significant improvements over the strong Transformer model by
3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art
performance on Chinese-English and English-German translation tasks.
</summary>
    <author>
      <name>Long Zhou</name>
    </author>
    <author>
      <name>Jiajun Zhang</name>
    </author>
    <author>
      <name>Chengqing Zong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published by TACL 2019, 15 pages, 9 figures, 9 tabels</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.04847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.04847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05709v3</id>
    <updated>2020-02-28T09:16:35Z</updated>
    <published>2019-05-13T02:46:28Z</published>
    <title>Challenges in Building Intelligent Open-domain Dialog Systems</title>
    <summary>  There is a resurgent interest in developing intelligent open-domain dialog
systems due to the availability of large amounts of conversational data and the
recent progress on neural approaches to conversational AI. Unlike traditional
task-oriented bots, an open-domain dialog system aims to establish long-term
connections with users by satisfying the human need for communication,
affection, and social belonging. This paper reviews the recent works on neural
approaches that are devoted to addressing three challenges in developing such
systems: semantics, consistency, and interactiveness. Semantics requires a
dialog system to not only understand the content of the dialog but also
identify user's social needs during the conversation. Consistency requires the
system to demonstrate a consistent personality to win users trust and gain
their long-term confidence. Interactiveness refers to the system's ability to
generate interpersonal responses to achieve particular social goals such as
entertainment, conforming, and task completion. The works we select to present
here is based on our unique views and are by no means complete. Nevertheless,
we hope that the discussion will inspire new research in developing more
intelligent dialog systems.
</summary>
    <author>
      <name>Minlie Huang</name>
    </author>
    <author>
      <name>Xiaoyan Zhu</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1905.05709v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05709v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05708v1</id>
    <updated>2019-05-12T11:19:25Z</updated>
    <published>2019-05-12T11:19:25Z</published>
    <title>The relational processing limits of classic and contemporary neural
  network models of language processing</title>
    <summary>  The ability of neural networks to capture relational knowledge is a matter of
long-standing controversy. Recently, some researchers in the PDP side of the
debate have argued that (1) classic PDP models can handle relational structure
(Rogers &amp; McClelland, 2008, 2014) and (2) the success of deep learning
approaches to text processing suggests that structured representations are
unnecessary to capture the gist of human language (Rabovsky et al., 2018). In
the present study we tested the Story Gestalt model (St. John, 1992), a classic
PDP model of text comprehension, and a Sequence-to-Sequence with Attention
model (Bahdanau et al., 2015), a contemporary deep learning architecture for
text processing. Both models were trained to answer questions about stories
based on the thematic roles that several concepts played on the stories. In
three critical test we varied the statistical structure of new stories while
keeping their relational structure constant with respect to the training data.
Each model was susceptible to each statistical structure manipulation to a
different degree, with their performance failing below chance at least under
one manipulation. We argue that the failures of both models are due to the fact
that they cannotperform dynamic binding of independent roles and fillers.
Ultimately, these results cast doubts onthe suitability of traditional neural
networks models for explaining phenomena based on relational reasoning,
including language processing.
</summary>
    <author>
      <name>Guillermo Puebla</name>
    </author>
    <author>
      <name>Andrea E. Martin</name>
    </author>
    <author>
      <name>Leonidas A. A. Doumas</name>
    </author>
    <link href="http://arxiv.org/abs/1905.05708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.04655v1</id>
    <updated>2019-05-12T06:11:30Z</updated>
    <published>2019-05-12T06:11:30Z</published>
    <title>Improving Natural Language Interaction with Robots Using Advice</title>
    <summary>  Over the last few years, there has been growing interest in learning models
for physically grounded language understanding tasks, such as the popular
blocks world domain. These works typically view this problem as a single-step
process, in which a human operator gives an instruction and an automated agent
is evaluated on its ability to execute it. In this paper we take the first step
towards increasing the bandwidth of this interaction, and suggest a protocol
for including advice, high-level observations about the task, which can help
constrain the agent's prediction. We evaluate our approach on the blocks world
task, and show that even simple advice can help lead to significant performance
improvements. To help reduce the effort involved in supplying the advice, we
also explore model self-generated advice which can still improve results.
</summary>
    <author>
      <name>Nikhil Mehta</name>
    </author>
    <author>
      <name>Dan Goldwasser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a short paper at NAACL 2019 (8 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.04655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.04655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.04422v1</id>
    <updated>2019-05-11T02:02:55Z</updated>
    <published>2019-05-11T02:02:55Z</published>
    <title>Controlled Natural Languages and Default Reasoning</title>
    <summary>  Controlled natural languages (CNLs) are effective languages for knowledge
representation and reasoning. They are designed based on certain natural
languages with restricted lexicon and grammar. CNLs are unambiguous and simple
as opposed to their base languages. They preserve the expressiveness and
coherence of natural languages. In this report, we focus on a class of CNLs,
called machine-oriented CNLs, which have well-defined semantics that can be
deterministically translated into formal languages, such as Prolog, to do
logical reasoning. Over the past 20 years, a number of machine-oriented CNLs
emerged and have been used in many application domains for problem solving and
question answering. However, few of them support non-monotonic inference. In
our work, we propose non-monotonic extensions of CNL to support defeasible
reasoning.
  In the first part of this report, we survey CNLs and compare three
influential systems: Attempto Controlled English (ACE), Processable English
(PENG), and Computer-processable English (CPL). We compare their language
design, semantic interpretations, and reasoning services. In the second part of
this report, we first identify typical non-monotonicity in natural languages,
such as defaults, exceptions and conversational implicatures. Then, we propose
their representation in CNL and the corresponding formalizations in a form of
defeasible reasoning known as Logic Programming with Defaults and Argumentation
Theory (LPDA).
</summary>
    <author>
      <name>Tiantian Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1905.04422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.04422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05704v5</id>
    <updated>2019-10-24T00:15:50Z</updated>
    <published>2019-05-10T19:39:55Z</published>
    <title>A logical-based corpus for cross-lingual evaluation</title>
    <summary>  At present, different deep learning models are presenting high accuracy on
popular inference datasets such as SNLI, MNLI, and SciTail. However, there are
different indicators that those datasets can be exploited by using some simple
linguistic patterns. This fact poses difficulties to our understanding of the
actual capacity of machine learning models to solve the complex task of textual
inference. We propose a new set of syntactic tasks focused on contradiction
detection that require specific capacities over linguistic logical forms such
as: Boolean coordination, quantifiers, definite description, and counting
operators. We evaluate two kinds of deep learning models that implicitly
exploit language structure: recurrent models and the Transformer network BERT.
We show that although BERT is clearly more efficient to generalize over most
logical forms, there is space for improvement when dealing with counting
operators. Since the syntactic tasks can be implemented in different languages,
we show a successful case of cross-lingual transfer learning between English
and Portuguese.
</summary>
    <author>
      <name>Felipe Salvatore</name>
    </author>
    <author>
      <name>Marcelo Finger</name>
    </author>
    <author>
      <name>Roberto Hirata Jr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the proceedings of the Deep Learning for low-resource
  NLP (DeepLo) workshop at EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.05704v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05704v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.04071v1</id>
    <updated>2019-05-10T11:14:12Z</updated>
    <published>2019-05-10T11:14:12Z</published>
    <title>Survey on Evaluation Methods for Dialogue Systems</title>
    <summary>  In this paper we survey the methods and concepts developed for the evaluation
of dialogue systems. Evaluation is a crucial part during the development
process. Often, dialogue systems are evaluated by means of human evaluations
and questionnaires. However, this tends to be very cost and time intensive.
Thus, much work has been put into finding methods, which allow to reduce the
involvement of human labour. In this survey, we present the main concepts and
methods. For this, we differentiate between the various classes of dialogue
systems (task-oriented dialogue systems, conversational dialogue systems, and
question-answering dialogue systems). We cover each class by introducing the
main technologies developed for the dialogue systems and then by presenting the
evaluation methods regarding this class.
</summary>
    <author>
      <name>Jan Deriu</name>
    </author>
    <author>
      <name>Alvaro Rodrigo</name>
    </author>
    <author>
      <name>Arantxa Otegi</name>
    </author>
    <author>
      <name>Guillermo Echegoyen</name>
    </author>
    <author>
      <name>Sophie Rosset</name>
    </author>
    <author>
      <name>Eneko Agirre</name>
    </author>
    <author>
      <name>Mark Cieliebak</name>
    </author>
    <link href="http://arxiv.org/abs/1905.04071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.04071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05701v2</id>
    <updated>2019-07-14T15:03:53Z</updated>
    <published>2019-05-09T20:57:14Z</published>
    <title>Modeling user context for valence prediction from narratives</title>
    <summary>  Automated prediction of valence, one key feature of a person's emotional
state, from individuals' personal narratives may provide crucial information
for mental healthcare (e.g. early diagnosis of mental diseases, supervision of
disease course, etc.). In the Interspeech 2018 ComParE Self-Assessed Affect
challenge, the task of valence prediction was framed as a three-class
classification problem using 8 seconds fragments from individuals' narratives.
As such, the task did not allow for exploring contextual information of the
narratives. In this work, we investigate the intrinsic information from
multiple narratives recounted by the same individual in order to predict their
current state-of-mind. Furthermore, with generalizability in mind, we decided
to focus our experiments exclusively on textual information as the public
availability of audio narratives is limited compared to text. Our hypothesis
is, that context modeling might provide insights about emotion triggering
concepts (e.g. events, people, places) mentioned in the narratives that are
linked to an individual's state of mind. We explore multiple machine learning
techniques to model narratives. We find that the models are able to capture
inter-individual differences, leading to more accurate predictions of an
individual's emotional state, as compared to single narratives.
</summary>
    <author>
      <name>Aniruddha Tammewar</name>
    </author>
    <author>
      <name>Alessandra Cervone</name>
    </author>
    <author>
      <name>Eva-Maria Messner</name>
    </author>
    <author>
      <name>Giuseppe Riccardi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21437/Interspeech.2019-2489</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21437/Interspeech.2019-2489" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in Interspeech 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interspeech 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.05701v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05701v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.03640v1</id>
    <updated>2019-05-09T14:04:44Z</updated>
    <published>2019-05-09T14:04:44Z</published>
    <title>Transparency in Maintenance of Recruitment Chatbots</title>
    <summary>  We report on experiences with implementing conversational agents in the
recruitment domain based on a machine learning (ML) system. Recruitment
chatbots mediate communication between job-seekers and recruiters by exposing
ML data to recruiter teams. Errors are difficult to understand, communicate,
and resolve because they may span and combine UX, ML, and software issues. In
an effort to improve organizational and technical transparency, we came to rely
on a key contact role. Though effective for design and development, the
centralization of this role poses challenges for transparency in sustained
maintenance of this kind of ML-based mediating system.
</summary>
    <author>
      <name>Kit Kuksenok</name>
    </author>
    <author>
      <name>Nina Praß</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, prepared for CHI2019 (Glasgow) workshop: Where is
  the Human? Bridging the Gap Between AI and HCI</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.03640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.03640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.03638v2</id>
    <updated>2019-06-21T11:22:59Z</updated>
    <published>2019-05-09T13:51:46Z</published>
    <title>Mappa Mundi: An Interactive Artistic Mind Map Generator with Artificial
  Imagination</title>
    <summary>  We present a novel real-time, collaborative, and interactive AI painting
system, Mappa Mundi, for artistic Mind Map creation. The system consists of a
voice-based input interface, an automatic topic expansion module, and an image
projection module. The key innovation is to inject Artificial Imagination into
painting creation by considering lexical and phonological similarities of
language, learning and inheriting artist's original painting style, and
applying the principles of Dadaism and impossibility of improvisation. Our
system indicates that AI and artist can collaborate seamlessly to create
imaginative artistic painting and Mappa Mundi has been applied in art
exhibition in UCCA, Beijing
</summary>
    <author>
      <name>Ruixue Liu</name>
    </author>
    <author>
      <name>Baoyang Chen</name>
    </author>
    <author>
      <name>Meng Chen</name>
    </author>
    <author>
      <name>Youzheng Wu</name>
    </author>
    <author>
      <name>Zhijie Qiu</name>
    </author>
    <author>
      <name>Xiaodong He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted by IJCAI 2019 Demo track</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.03638v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.03638v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02947v1</id>
    <updated>2019-05-08T07:46:30Z</updated>
    <published>2019-05-08T07:46:30Z</published>
    <title>Emotion Recognition in Conversation: Research Challenges, Datasets, and
  Recent Advances</title>
    <summary>  Emotion is intrinsic to humans and consequently emotion understanding is a
key part of human-like artificial intelligence (AI). Emotion recognition in
conversation (ERC) is becoming increasingly popular as a new research frontier
in natural language processing (NLP) due to its ability to mine opinions from
the plethora of publicly available conversational data in platforms such as
Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential
applications in health-care systems (as a tool for psychological analysis),
education (understanding student frustration) and more. Additionally, ERC is
also extremely important for generating emotion-aware dialogues that require an
understanding of the user's emotions. Catering to these needs calls for
effective and scalable conversational emotion-recognition algorithms. However,
it is a strenuous problem to solve because of several research challenges. In
this paper, we discuss these challenges and shed light on the recent research
in this field. We also describe the drawbacks of these approaches and discuss
the reasons why they fail to successfully overcome the research challenges in
ERC.
</summary>
    <author>
      <name>Soujanya Poria</name>
    </author>
    <author>
      <name>Navonil Majumder</name>
    </author>
    <author>
      <name>Rada Mihalcea</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <link href="http://arxiv.org/abs/1905.02947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.05700v1</id>
    <updated>2019-05-07T21:14:03Z</updated>
    <published>2019-05-07T21:14:03Z</published>
    <title>Learning meters of Arabic and English poems with Recurrent Neural
  Networks: a step forward for language understanding and synthesis</title>
    <summary>  Recognizing a piece of writing as a poem or prose is usually easy for the
majority of people; however, only specialists can determine which meter a poem
belongs to. In this paper, we build Recurrent Neural Network (RNN) models that
can classify poems according to their meters from plain text. The input text is
encoded at the character level and directly fed to the models without feature
handcrafting. This is a step forward for machine understanding and synthesis of
languages in general, and Arabic language in particular. Among the 16 poem
meters of Arabic and the 4 meters of English the networks were able to
correctly classify poem with an overall accuracy of 96.38\% and 82.31\%
respectively. The poem datasets used to conduct this research were massive,
over 1.5 million of verses, and were crawled from different nontechnical
sources, almost Arabic and English literature sites, and in different
heterogeneous and unstructured formats. These datasets are now made publicly
available in clean, structured, and documented format for other future
research. To the best of the authors' knowledge, this research is the first to
address classifying poem meters in a machine learning approach, in general, and
in RNN featureless based approach, in particular. In addition, the dataset is
the first publicly available dataset ready for the purpose of future
computational research.
</summary>
    <author>
      <name>Waleed A. Yousef</name>
    </author>
    <author>
      <name>Omar M. Ibrahime</name>
    </author>
    <author>
      <name>Taha M. Madbouly</name>
    </author>
    <author>
      <name>Moustafa A. Mahmoud</name>
    </author>
    <link href="http://arxiv.org/abs/1905.05700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.05700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02497v2</id>
    <updated>2019-05-16T13:49:36Z</updated>
    <published>2019-05-07T12:30:55Z</published>
    <title>RelExt: Relation Extraction using Deep Learning approaches for
  Cybersecurity Knowledge Graph Improvement</title>
    <summary>  Security Analysts that work in a `Security Operations Center' (SoC) play a
major role in ensuring the security of the organization. The amount of
background knowledge they have about the evolving and new attacks makes a
significant difference in their ability to detect attacks. Open source threat
intelligence sources, like text descriptions about cyber-attacks, can be stored
in a structured fashion in a cybersecurity knowledge graph. A cybersecurity
knowledge graph can be paramount in aiding a security analyst to detect cyber
threats because it stores a vast range of cyber threat information in the form
of semantic triples which can be queried. A semantic triple contains two
cybersecurity entities with a relationship between them. In this work, we
propose a system to create semantic triples over cybersecurity text, using deep
learning approaches to extract possible relationships. We use the set of
semantic triples generated through our system to assert in a cybersecurity
knowledge graph. Security Analysts can retrieve this data from the knowledge
graph, and use this information to form a decision about a cyber-attack.
</summary>
    <author>
      <name>Aditya Pingle</name>
    </author>
    <author>
      <name>Aritran Piplai</name>
    </author>
    <author>
      <name>Sudip Mittal</name>
    </author>
    <author>
      <name>Anupam Joshi</name>
    </author>
    <author>
      <name>James Holt</name>
    </author>
    <author>
      <name>Richard Zak</name>
    </author>
    <link href="http://arxiv.org/abs/1905.02497v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02497v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02895v1</id>
    <updated>2019-05-07T12:15:32Z</updated>
    <published>2019-05-07T12:15:32Z</published>
    <title>Cyber-All-Intel: An AI for Security related Threat Intelligence</title>
    <summary>  Keeping up with threat intelligence is a must for a security analyst today.
There is a volume of information present in `the wild' that affects an
organization. We need to develop an artificial intelligence system that scours
the intelligence sources, to keep the analyst updated about various threats
that pose a risk to her organization. A security analyst who is better `tapped
in' can be more effective.
  In this paper we present, Cyber-All-Intel an artificial intelligence system
to aid a security analyst. It is a system for knowledge extraction,
representation and analytics in an end-to-end pipeline grounded in the
cybersecurity informatics domain. It uses multiple knowledge representations
like, vector spaces and knowledge graphs in a 'VKG structure' to store incoming
intelligence. The system also uses neural network models to pro-actively
improve its knowledge. We have also created a query engine and an alert system
that can be used by an analyst to find actionable cybersecurity insights.
</summary>
    <author>
      <name>Sudip Mittal</name>
    </author>
    <author>
      <name>Anupam Joshi</name>
    </author>
    <author>
      <name>Tim Finin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1708.03310</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.02895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02450v5</id>
    <updated>2019-06-21T04:36:52Z</updated>
    <published>2019-05-07T10:13:04Z</published>
    <title>MASS: Masked Sequence to Sequence Pre-training for Language Generation</title>
    <summary>  Pre-training and fine-tuning, e.g., BERT, have achieved great success in
language understanding by transferring knowledge from rich-resource
pre-training task to the low/zero-resource downstream tasks. Inspired by the
success of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for
the encoder-decoder based language generation tasks. MASS adopts the
encoder-decoder framework to reconstruct a sentence fragment given the
remaining part of the sentence: its encoder takes a sentence with randomly
masked fragment (several consecutive tokens) as input, and its decoder tries to
predict this masked fragment. In this way, MASS can jointly train the encoder
and decoder to develop the capability of representation extraction and language
modeling. By further fine-tuning on a variety of zero/low-resource language
generation tasks, including neural machine translation, text summarization and
conversational response generation (3 tasks and totally 8 datasets), MASS
achieves significant improvements over the baselines without pre-training or
with other pre-training methods. Specially, we achieve the state-of-the-art
accuracy (37.5 in terms of BLEU score) on the unsupervised English-French
translation, even beating the early attention-based supervised model.
</summary>
    <author>
      <name>Kaitao Song</name>
    </author>
    <author>
      <name>Xu Tan</name>
    </author>
    <author>
      <name>Tao Qin</name>
    </author>
    <author>
      <name>Jianfeng Lu</name>
    </author>
    <author>
      <name>Tie-Yan Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ICML 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.02450v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02450v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01780v2</id>
    <updated>2019-06-11T14:46:27Z</updated>
    <published>2019-05-06T01:16:33Z</published>
    <title>Anonymized BERT: An Augmentation Approach to the Gendered Pronoun
  Resolution Challenge</title>
    <summary>  We present our 7th place solution to the Gendered Pronoun Resolution
challenge, which uses BERT without fine-tuning and a novel augmentation
strategy designed for contextual embedding token-level tasks. Our method
anonymizes the referent by replacing candidate names with a set of common
placeholder names. Besides the usual benefits of effectively increasing
training data size, this approach diversifies idiosyncratic information
embedded in names. Using same set of common first names can also help the model
recognize names better, shorten token length, and remove gender and regional
biases associated with names. The system scored 0.1947 log loss in stage 2,
where the augmentation contributed to an improvements of 0.04. Post-competition
analysis shows that, when using different embedding layers, the system scores
0.1799 which would be third place.
</summary>
    <author>
      <name>Bo Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages; accepted by 1st ACL Workshop on Gender Bias for NLP at ACL
  2019; code is at https://github.com/boliu61/gendered-pronoun-resolution</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01780v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01780v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01647v1</id>
    <updated>2019-05-05T10:30:03Z</updated>
    <published>2019-05-05T10:30:03Z</published>
    <title>A Typedriven Vector Semantics for Ellipsis with Anaphora using Lambek
  Calculus with Limited Contraction</title>
    <summary>  We develop a vector space semantics for verb phrase ellipsis with anaphora
using type-driven compositional distributional semantics based on the Lambek
calculus with limited contraction (LCC) of J\"ager (2006). Distributional
semantics has a lot to say about the statistical collocation-based meanings of
content words, but provides little guidance on how to treat function words.
Formal semantics on the other hand, has powerful mechanisms for dealing with
relative pronouns, coordinators, and the like. Type-driven compositional
distributional semantics brings these two models together. We review previous
compositional distributional models of relative pronouns, coordination and a
restricted account of ellipsis in the DisCoCat framework of Coecke et al.
(2010, 2013). We show how DisCoCat cannot deal with general forms of ellipsis,
which rely on copying of information, and develop a novel way of connecting
typelogical grammar to distributional semantics by assigning vector
interpretable lambda terms to derivations of LCC in the style of Muskens &amp;
Sadrzadeh (2016). What follows is an account of (verb phrase) ellipsis in which
word meanings can be copied: the meaning of a sentence is now a program with
non-linear access to individual word embeddings. We present the theoretical
setting, work out examples, and demonstrate our results on a toy distributional
model motivated by data.
</summary>
    <author>
      <name>Gijs Wijnholds</name>
    </author>
    <author>
      <name>Mehrnoosh Sadrzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Forthcoming in: Journal of Logic, Language and Information</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01566v1</id>
    <updated>2019-05-04T23:22:51Z</updated>
    <published>2019-05-04T23:22:51Z</published>
    <title>Learning to Denoise Distantly-Labeled Data for Entity Typing</title>
    <summary>  Distantly-labeled data can be used to scale up training of statistical
models, but it is typically noisy and that noise can vary with the distant
labeling technique. In this work, we propose a two-stage procedure for handling
this type of data: denoise it with a learned model, then train our final model
on clean and denoised distant data with standard supervised training. Our
denoising approach consists of two parts. First, a filtering function discards
examples from the distantly labeled data that are wholly unusable. Second, a
relabeling function repairs noisy labels for the retained examples. Each of
these components is a model trained on synthetically-noised examples generated
from a small manually-labeled set. We investigate this approach on the
ultra-fine entity typing task of Choi et al. (2018). Our baseline model is an
extension of their model with pre-trained ELMo representations, which already
achieves state-of-the-art performance. Adding distant data that has been
denoised with our learned models gives further performance gains over this base
model, outperforming models trained on raw distant data or
heuristically-denoised distant data.
</summary>
    <author>
      <name>Yasumasa Onoe</name>
    </author>
    <author>
      <name>Greg Durrett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01566v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01566v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01386v1</id>
    <updated>2019-05-03T23:28:18Z</updated>
    <published>2019-05-03T23:28:18Z</published>
    <title>Personalized Query Auto-Completion Through a Lightweight Representation
  of the User Context</title>
    <summary>  Query Auto-Completion (QAC) is a widely used feature in many domains,
including web and eCommerce search, suggesting full queries based on a prefix
typed by the user. QAC has been extensively studied in the literature in the
recent years, and it has been consistently shown that adding personalization
features can significantly improve the performance of QAC. In this work we
propose a novel method for personalized QAC that uses lightweight embeddings
learnt through fastText. We construct an embedding for the user context
queries, which are the last few queries issued by the user. We also use the
same model to get the embedding for the candidate queries to be ranked. We
introduce ranking features that compute the distance between the candidate
queries and the context queries in the embedding space. These features are then
combined with other commonly used QAC ranking features to learn a ranking
model. We apply our method to a large eCommerce search engine (eBay) and show
that the ranker with our proposed feature significantly outperforms the
baselines on all of the offline metrics measured, which includes Mean
Reciprocal Rank (MRR), Success Rate (SR), Mean Average Precision (MAP), and
Normalized Discounted Cumulative Gain (NDCG). Our baselines include the Most
Popular Completion (MPC) model as well as a ranking model without our proposed
features. The ranking model with the proposed features results in a $20-30\%$
improvement over the MPC model on all metrics. We obtain up to a $5\%$
improvement over the baseline ranking model for all the sessions, which goes up
to about $10\%$ when we restrict to sessions that contain the user context.
Moreover, our proposed features also significantly outperform text based
personalization features studied in the literature before, and adding text
based features on top of our proposed embedding based features results only in
minor improvements.
</summary>
    <author>
      <name>Manojkumar Rangasamy Kannadasan</name>
    </author>
    <author>
      <name>Grigor Aslanyan</name>
    </author>
    <link href="http://arxiv.org/abs/1905.01386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01966v2</id>
    <updated>2019-05-07T15:35:32Z</updated>
    <published>2019-05-03T01:45:50Z</published>
    <title>Question Relatedness on Stack Overflow: The Task, Dataset, and
  Corpus-inspired Models</title>
    <summary>  Domain-specific community question answering is becoming an integral part of
professions. Finding related questions and answers in these communities can
significantly improve the effectiveness and efficiency of information seeking.
Stack Overflow is one of the most popular communities that is being used by
millions of programmers. In this paper, we analyze the problem of predicting
knowledge unit (question thread) relatedness in Stack Overflow. In particular,
we formulate the question relatedness task as a multi-class classification
problem with four degrees of relatedness. We present a large-scale dataset with
more than 300K pairs. To the best of our knowledge, this dataset is the largest
domain-specific dataset for Question-Question relatedness. We present the steps
that we took to collect, clean, process, and assure the quality of the dataset.
The proposed dataset Stack Overflow is a useful resource to develop novel
solutions, specifically data-hungry neural network models, for the prediction
of relatedness in technical community question-answering forums. We adopt a
neural network architecture and a traditional model for this task that
effectively utilize information from different parts of knowledge units to
compute the relatedness between them. These models can be used to benchmark
novel models, as they perform well in our task and in a closely similar task.
</summary>
    <author>
      <name>Amirreza Shirani</name>
    </author>
    <author>
      <name>Bowen Xu</name>
    </author>
    <author>
      <name>David Lo</name>
    </author>
    <author>
      <name>Thamar Solorio</name>
    </author>
    <author>
      <name>Amin Alipour</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019 Reasoning for Complex Question Answering Workshop</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.01966v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01966v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00840v3</id>
    <updated>2019-09-18T07:13:08Z</updated>
    <published>2019-05-02T16:39:55Z</published>
    <title>Knowledge Authoring and Question Answering with KALM</title>
    <summary>  Knowledge representation and reasoning (KRR) is one of the key areas in
artificial intelligence (AI) field. It is intended to represent the world
knowledge in formal languages (e.g., Prolog, SPARQL) and then enhance the
expert systems to perform querying and inference tasks. Currently, constructing
large scale knowledge bases (KBs) with high quality is prohibited by the fact
that the construction process requires many qualified knowledge engineers who
not only understand the domain-specific knowledge but also have sufficient
skills in knowledge representation. Unfortunately, qualified knowledge
engineers are in short supply. Therefore, it would be very useful to build a
tool that allows the user to construct and query the KB simply via text.
Although there is a number of systems developed for knowledge extraction and
question answering, they mainly fail in that these system don't achieve high
enough accuracy whereas KRR is highly sensitive to erroneous data. In this
thesis proposal, I will present Knowledge Authoring Logic Machine (KALM), a
rule-based system which allows the user to author knowledge and query the KB in
text. The experimental results show that KALM achieved superior accuracy in
knowledge authoring and question answering as compared to the state-of-the-art
systems.
</summary>
    <author>
      <name>Tiantian Gao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Stony Brook University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.306.52</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.306.52" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ICLP 2019, arXiv:1909.07646</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 306, 2019, pp. 389-395</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.00840v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00840v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.02019v1</id>
    <updated>2019-05-02T01:07:20Z</updated>
    <published>2019-05-02T01:07:20Z</published>
    <title>Conditioning LSTM Decoder and Bi-directional Attention Based Question
  Answering System</title>
    <summary>  Applying neural-networks on Question Answering has gained increasing
popularity in recent years. In this paper, I implemented a model with
Bi-directional attention flow layer, connected with a Multi-layer LSTM encoder,
connected with one start-index decoder and one conditioning end-index decoder.
I introduce a new end-index decoder layer, conditioning on start-index output.
The Experiment shows this has increased model performance by 15.16%. For
prediction, I proposed a new smart-span equation, rewarding both short answer
length and high probability in start-index and end-index, which further
improved the prediction accuracy. The best single model achieves an F1 score of
73.97% and EM score of 64.95% on test set.
</summary>
    <author>
      <name>Heguang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.02019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.02019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00537v3</id>
    <updated>2020-02-13T00:28:00Z</updated>
    <published>2019-05-02T00:41:50Z</published>
    <title>SuperGLUE: A Stickier Benchmark for General-Purpose Language
  Understanding Systems</title>
    <summary>  In the last year, new models and methods for pretraining and transfer
learning have driven striking performance improvements across a range of
language understanding tasks. The GLUE benchmark, introduced a little over one
year ago, offers a single-number metric that summarizes progress on a diverse
set of such tasks, but performance on the benchmark has recently surpassed the
level of non-expert humans, suggesting limited headroom for further research.
In this paper we present SuperGLUE, a new benchmark styled after GLUE with a
new set of more difficult language understanding tasks, a software toolkit, and
a public leaderboard. SuperGLUE is available at super.gluebenchmark.com.
</summary>
    <author>
      <name>Alex Wang</name>
    </author>
    <author>
      <name>Yada Pruksachatkun</name>
    </author>
    <author>
      <name>Nikita Nangia</name>
    </author>
    <author>
      <name>Amanpreet Singh</name>
    </author>
    <author>
      <name>Julian Michael</name>
    </author>
    <author>
      <name>Felix Hill</name>
    </author>
    <author>
      <name>Omer Levy</name>
    </author>
    <author>
      <name>Samuel R. Bowman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019, super.gluebenchmark.com updating acknowledegments</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.00537v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00537v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01984v1</id>
    <updated>2019-05-01T23:26:38Z</updated>
    <published>2019-05-01T23:26:38Z</published>
    <title>AI-Powered Text Generation for Harmonious Human-Machine Interaction:
  Current State and Future Directions</title>
    <summary>  In the last two decades, the landscape of text generation has undergone
tremendous changes and is being reshaped by the success of deep learning. New
technologies for text generation ranging from template-based methods to neural
network-based methods emerged. Meanwhile, the research objectives have also
changed from generating smooth and coherent sentences to infusing personalized
traits to enrich the diversification of newly generated content. With the rapid
development of text generation solutions, one comprehensive survey is urgent to
summarize the achievements and track the state of the arts. In this survey
paper, we present the general systematical framework, illustrate the widely
utilized models and summarize the classic applications of text generation.
</summary>
    <author>
      <name>Qiuyun Zhang</name>
    </author>
    <author>
      <name>Bin Guo</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Yunji Liang</name>
    </author>
    <author>
      <name>Shaoyang Hao</name>
    </author>
    <author>
      <name>Zhiwen Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by IEEE UIC 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00787v4</id>
    <updated>2019-08-11T12:47:34Z</updated>
    <published>2019-05-01T16:51:32Z</published>
    <title>Computer Science and Metaphysics: A Cross-Fertilization</title>
    <summary>  Computational philosophy is the use of mechanized computational techniques to
unearth philosophical insights that are either difficult or impossible to find
using traditional philosophical methods. Computational metaphysics is
computational philosophy with a focus on metaphysics. In this paper, we (a)
develop results in modal metaphysics whose discovery was computer assisted, and
(b) conclude that these results work not only to the obvious benefit of
philosophy but also, less obviously, to the benefit of computer science, since
the new computational techniques that led to these results may be more broadly
applicable within computer science. The paper includes a description of our
background methodology and how it evolved, and a discussion of our new results.
</summary>
    <author>
      <name>Daniel Kirchner</name>
    </author>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <author>
      <name>Edward N. Zalta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1515/opphil-2019-0015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1515/opphil-2019-0015" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Open Philosophy, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.00787v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00787v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00270v3</id>
    <updated>2020-01-25T10:29:21Z</updated>
    <published>2019-05-01T11:32:13Z</published>
    <title>ASER: A Large-scale Eventuality Knowledge Graph</title>
    <summary>  Understanding human's language requires complex world knowledge. However,
existing large-scale knowledge graphs mainly focus on knowledge about entities
while ignoring knowledge about activities, states, or events, which are used to
describe how entities or things act in the real world. To fill this gap, we
develop ASER (activities, states, events, and their relations), a large-scale
eventuality knowledge graph extracted from more than 11-billion-token
unstructured textual data. ASER contains 15 relation types belonging to five
categories, 194-million unique eventualities, and 64-million unique edges among
them. Both intrinsic and extrinsic evaluations demonstrate the quality and
effectiveness of ASER.
</summary>
    <author>
      <name>Hongming Zhang</name>
    </author>
    <author>
      <name>Xin Liu</name>
    </author>
    <author>
      <name>Haojie Pan</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <author>
      <name>Cane Wing-Ki Leung</name>
    </author>
    <link href="http://arxiv.org/abs/1905.00270v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00270v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00198v1</id>
    <updated>2019-05-01T06:29:02Z</updated>
    <published>2019-05-01T06:29:02Z</published>
    <title>Declarative Question Answering over Knowledge Bases containing Natural
  Language Text with Answer Set Programming</title>
    <summary>  While in recent years machine learning (ML) based approaches have been the
popular approach in developing end-to-end question answering systems, such
systems often struggle when additional knowledge is needed to correctly answer
the questions. Proposed alternatives involve translating the question and the
natural language text to a logical representation and then use logical
reasoning. However, this alternative falters when the size of the text gets
bigger. To address this we propose an approach that does logical reasoning over
premises written in natural language text. The proposed method uses recent
features of Answer Set Programming (ASP) to call external NLP modules (which
may be based on ML) which perform simple textual entailment. To test our
approach we develop a corpus based on the life cycle questions and showed that
Our system achieves up to $18\%$ performance gain when compared to standard MCQ
solvers.
</summary>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <author>
      <name>Peter Clark</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Chitta Baral</name>
    </author>
    <link href="http://arxiv.org/abs/1905.00198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01988v2</id>
    <updated>2019-05-30T21:54:10Z</updated>
    <published>2019-04-30T23:56:54Z</published>
    <title>Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less
  Manual Data Annotation and More Self-Studying</title>
    <summary>  Lifelong machine learning is a novel machine learning paradigm which can
continually accumulate knowledge during learning. The knowledge extracting and
reusing abilities enable the lifelong machine learning to solve the related
problems. The traditional approaches like Na\"ive Bayes and some neural network
based approaches only aim to achieve the best performance upon a single task.
Unlike them, the lifelong machine learning in this paper focuses on how to
accumulate knowledge during learning and leverage them for further tasks.
Meanwhile, the demand for labelled data for training also is significantly
decreased with the knowledge reusing. This paper suggests that the aim of the
lifelong learning is to use less labelled data and computational cost to
achieve the performance as well as or even better than the supervised learning.
</summary>
    <author>
      <name>Xianbin Hong</name>
    </author>
    <author>
      <name>Gautam Pal</name>
    </author>
    <author>
      <name>Sheng-Uei Guan</name>
    </author>
    <author>
      <name>Prudence Wong</name>
    </author>
    <author>
      <name>Dawei Liu</name>
    </author>
    <author>
      <name>Ka Lok Man</name>
    </author>
    <author>
      <name>Xin Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1905.01988v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01988v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.13015v4</id>
    <updated>2019-11-22T03:06:41Z</updated>
    <published>2019-04-30T02:03:05Z</published>
    <title>Towards Coherent and Engaging Spoken Dialog Response Generation Using
  Automatic Conversation Evaluators</title>
    <summary>  Encoder-decoder based neural architectures serve as the basis of
state-of-the-art approaches in end-to-end open domain dialog systems. Since
most of such systems are trained with a maximum likelihood~(MLE) objective they
suffer from issues such as lack of generalizability and the generic response
problem, i.e., a system response that can be an answer to a large number of
user utterances, e.g., "Maybe, I don't know." Having explicit feedback on the
relevance and interestingness of a system response at each turn can be a useful
signal for mitigating such issues and improving system quality by selecting
responses from different approaches. Towards this goal, we present a system
that evaluates chatbot responses at each dialog turn for coherence and
engagement. Our system provides explicit turn-level dialog quality feedback,
which we show to be highly correlated with human evaluation. To show that
incorporating this feedback in the neural response generation models improves
dialog quality, we present two different and complementary mechanisms to
incorporate explicit feedback into a neural response generation model:
reranking and direct modification of the loss function during training. Our
studies show that a response generation model that incorporates these combined
feedback mechanisms produce more engaging and coherent responses in an
open-domain spoken dialog setting, significantly improving the response quality
using both automatic and human evaluation.
</summary>
    <author>
      <name>Sanghyun Yi</name>
    </author>
    <author>
      <name>Rahul Goel</name>
    </author>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Alessandra Cervone</name>
    </author>
    <author>
      <name>Tagyoung Chung</name>
    </author>
    <author>
      <name>Behnam Hedayatnia</name>
    </author>
    <author>
      <name>Anu Venkatesh</name>
    </author>
    <author>
      <name>Raefer Gabriel</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <link href="http://arxiv.org/abs/1904.13015v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.13015v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12907v1</id>
    <updated>2019-04-29T18:59:59Z</updated>
    <published>2019-04-29T18:59:59Z</published>
    <title>Enabling Robots to Understand Incomplete Natural Language Instructions
  Using Commonsense Reasoning</title>
    <summary>  Enabling robots to understand instructions provided via spoken natural
language would facilitate interaction between robots and people in a variety of
settings in homes and workplaces. However, natural language instructions are
often missing information that would be obvious to a human based on
environmental context and common sense, and hence does not need to be
explicitly stated. In this paper, we introduce Language-Model-based Commonsense
Reasoning (LMCR), a new method which enables a robot to listen to a natural
language instruction from a human, observe the environment around it, and
automatically fill in information missing from the instruction using
environmental context and a new commonsense reasoning approach. Our approach
first converts an instruction provided as unconstrained natural language into a
form that a robot can understand by parsing it into verb frames. Our approach
then fills in missing information in the instruction by observing objects in
its vicinity and leveraging commonsense reasoning. To learn commonsense
reasoning automatically, our approach distills knowledge from large
unstructured textual corpora by training a language model. Our results show the
feasibility of a robot learning commonsense knowledge automatically from
web-based textual corpora, and the power of learned commonsense reasoning
models in enabling a robot to autonomously perform tasks based on incomplete
natural language instructions.
</summary>
    <author>
      <name>Haonan Chen</name>
    </author>
    <author>
      <name>Hao Tan</name>
    </author>
    <author>
      <name>Alan Kuntz</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <author>
      <name>Ron Alterovitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12848v4</id>
    <updated>2019-09-30T15:40:40Z</updated>
    <published>2019-04-29T17:56:59Z</published>
    <title>Unsupervised Data Augmentation for Consistency Training</title>
    <summary>  Semi-supervised learning lately has shown much promise in improving deep
learning models when labeled data is scarce. Common among recent approaches is
the use of consistency training on a large amount of unlabeled data to
constrain model predictions to be invariant to input noise. In this work, we
present a new perspective on how to effectively noise unlabeled examples and
argue that the quality of noising, specifically those produced by advanced data
augmentation methods, plays a crucial role in semi-supervised learning. By
substituting simple noising operations with advanced data augmentation methods,
our method brings substantial improvements across six language and three vision
tasks under the same consistency training framework. On the IMDb text
classification dataset, with only 20 labeled examples, our method achieves an
error rate of 4.20, outperforming the state-of-the-art model trained on 25,000
labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10,
our method outperforms all previous approaches and achieves an error rate of
2.7% with only 4,000 examples, nearly matching the performance of models
trained on 50,000 labeled examples. Our method also combines well with transfer
learning, e.g., when finetuning from BERT, and yields improvements in high-data
regime, such as ImageNet, whether when there is only 10% labeled data or when a
full labeled set with 1.3M extra unlabeled examples is used. Code is available
at https://github.com/google-research/uda.
</summary>
    <author>
      <name>Qizhe Xie</name>
    </author>
    <author>
      <name>Zihang Dai</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <author>
      <name>Minh-Thang Luong</name>
    </author>
    <author>
      <name>Quoc V. Le</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12848v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12848v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12535v1</id>
    <updated>2019-04-29T09:37:31Z</updated>
    <published>2019-04-29T09:37:31Z</published>
    <title>Logician: A Unified End-to-End Neural Approach for Open-Domain
  Information Extraction</title>
    <summary>  In this paper, we consider the problem of open information extraction (OIE)
for extracting entity and relation level intermediate structures from sentences
in open-domain. We focus on four types of valuable intermediate structures
(Relation, Attribute, Description, and Concept), and propose a unified
knowledge expression form, SAOKE, to express them. We publicly release a data
set which contains more than forty thousand sentences and the corresponding
facts in the SAOKE format labeled by crowd-sourcing. To our knowledge, this is
the largest publicly available human labeled data set for open information
extraction tasks. Using this labeled SAOKE data set, we train an end-to-end
neural model using the sequenceto-sequence paradigm, called Logician, to
transform sentences into facts. For each sentence, different to existing
algorithms which generally focus on extracting each single fact without
concerning other possible facts, Logician performs a global optimization over
all possible involved facts, in which facts not only compete with each other to
attract the attention of words, but also cooperate to share words. An
experimental study on various types of open domain relation extraction tasks
reveals the consistent superiority of Logician to other states-of-the-art
algorithms. The experiments verify the reasonableness of SAOKE format, the
valuableness of SAOKE data set, the effectiveness of the proposed Logician
model, and the feasibility of the methodology to apply end-to-end learning
paradigm on supervised data sets for the challenging tasks of open information
extraction.
</summary>
    <author>
      <name>Mingming Sun</name>
    </author>
    <author>
      <name>Xu Li</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Miao Fan</name>
    </author>
    <author>
      <name>Yue Feng</name>
    </author>
    <author>
      <name>Ping Li</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01995v1</id>
    <updated>2019-04-27T12:57:24Z</updated>
    <published>2019-04-27T12:57:24Z</published>
    <title>Using Context Information to Enhance Simple Question Answering</title>
    <summary>  With the rapid development of knowledge bases(KBs),question
answering(QA)based on KBs has become a hot research issue. In this paper,we
propose two frameworks(i.e.,pipeline framework,an end-to-end framework)to focus
answering single-relation factoid question. In both of two frameworks,we study
the effect of context information on the quality of QA,such as the entity's
notable type,out-degree. In the end-to-end framework,we combine char-level
encoding and self-attention mechanisms,using weight sharing and multi-task
strategies to enhance the accuracy of QA. Experimental results show that
context information can get better results of simple QA whether it is the
pipeline framework or the end-to-end framework. In addition,we find that the
end-to-end framework achieves results competitive with state-of-the-art
approaches in terms of accuracy and take much shorter time than them.
</summary>
    <author>
      <name>Lin Li</name>
    </author>
    <author>
      <name>Mengjing Zhang</name>
    </author>
    <author>
      <name>Zhaohui Chao</name>
    </author>
    <author>
      <name>Jianwen Xiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">under review World Wide Web Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12106v1</id>
    <updated>2019-04-27T04:36:57Z</updated>
    <published>2019-04-27T04:36:57Z</published>
    <title>Understanding Dataset Design Choices for Multi-hop Reasoning</title>
    <summary>  Learning multi-hop reasoning has been a key challenge for reading
comprehension models, leading to the design of datasets that explicitly focus
on it. Ideally, a model should not be able to perform well on a multi-hop
question answering task without doing multi-hop reasoning. In this paper, we
investigate two recently proposed datasets, WikiHop and HotpotQA. First, we
explore sentence-factored models for these tasks; by design, these models
cannot do multi-hop reasoning, but they are still able to solve a large number
of examples in both datasets. Furthermore, we find spurious correlations in the
unmasked version of WikiHop, which make it easy to achieve high performance
considering only the questions and answers. Finally, we investigate one key
difference between these datasets, namely span-based vs. multiple-choice
formulations of the QA task. Multiple-choice versions of both datasets can be
easily gamed, and two models we examine only marginally exceed a baseline in
this setting. Overall, while these datasets are useful testbeds,
high-performing models may not be learning as much multi-hop reasoning as
previously thought.
</summary>
    <author>
      <name>Jifan Chen</name>
    </author>
    <author>
      <name>Greg Durrett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01994v1</id>
    <updated>2019-04-27T01:57:28Z</updated>
    <published>2019-04-27T01:57:28Z</published>
    <title>Review-Driven Answer Generation for Product-Related Questions in
  E-Commerce</title>
    <summary>  The users often have many product-related questions before they make a
purchase decision in E-commerce. However, it is often time-consuming to examine
each user review to identify the desired information. In this paper, we propose
a novel review-driven framework for answer generation for product-related
questions in E-commerce, named RAGE. We develope RAGE on the basis of the
multi-layer convolutional architecture to facilitate speed-up of answer
generation with the parallel computation. For each question, RAGE first
extracts the relevant review snippets from the reviews of the corresponding
product. Then, we devise a mechanism to identify the relevant information from
the noise-prone review snippets and incorporate this information to guide the
answer generation. The experiments on two real-world E-Commerce datasets show
that the proposed RAGE significantly outperforms the existing alternatives in
producing more accurate and informative answers in natural language. Moreover,
RAGE takes much less time for both model training and answer generation than
the existing RNN based generation models.
</summary>
    <author>
      <name>Shiqian Chen</name>
    </author>
    <author>
      <name>Chenliang Li</name>
    </author>
    <author>
      <name>Feng Ji</name>
    </author>
    <author>
      <name>Wei Zhou</name>
    </author>
    <author>
      <name>Haiqing Chen</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WSDM 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.01994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.11961v1</id>
    <updated>2019-04-26T17:44:04Z</updated>
    <published>2019-04-26T17:44:04Z</published>
    <title>CoachAI: A Conversational Agent Assisted Health Coaching Platform</title>
    <summary>  Poor lifestyle represents a health risk factor and is the leading cause of
morbidity and chronic conditions. The impact of poor lifestyle can be
significantly altered by individual behavior change. Although the current shift
in healthcare towards a long lasting modifiable behavior, however, with
increasing caregiver workload and individuals' continuous needs of care, there
is a need to ease caregiver's work while ensuring continuous interaction with
users. This paper describes the design and validation of CoachAI, a
conversational agent assisted health coaching system to support health
intervention delivery to individuals and groups. CoachAI instantiates a text
based healthcare chatbot system that bridges the remote human coach and the
users. This research provides three main contributions to the preventive
healthcare and healthy lifestyle promotion: (1) it presents the conversational
agent to aid the caregiver; (2) it aims to decrease caregiver's workload and
enhance care given to users, by handling (automating) repetitive caregiver
tasks; and (3) it presents a domain independent mobile health conversational
agent for health intervention delivery. We will discuss our approach and
analyze the results of a one month validation study on physical activity,
healthy diet and stress management.
</summary>
    <author>
      <name>Ahmed Fadhil</name>
    </author>
    <author>
      <name>Gianluca Schiavo</name>
    </author>
    <author>
      <name>Yunlong Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1904.11961v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.11961v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12584v1</id>
    <updated>2019-04-26T06:50:54Z</updated>
    <published>2019-04-26T06:50:54Z</published>
    <title>The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and
  Sentences From Natural Supervision</title>
    <summary>  We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns
visual concepts, words, and semantic parsing of sentences without explicit
supervision on any of them; instead, our model learns by simply looking at
images and reading paired questions and answers. Our model builds an
object-based scene representation and translates sentences into executable,
symbolic programs. To bridge the learning of two modules, we use a
neuro-symbolic reasoning module that executes these programs on the latent
scene representation. Analogical to human concept learning, the perception
module learns visual concepts based on the language description of the object
being referred to. Meanwhile, the learned visual concepts facilitate learning
new words and parsing new sentences. We use curriculum learning to guide the
searching over the large compositional space of images and language. Extensive
experiments demonstrate the accuracy and efficiency of our model on learning
visual concepts, word representations, and semantic parsing of sentences.
Further, our method allows easy generalization to new object attributes,
compositions, language concepts, scenes and questions, and even new program
domains. It also empowers applications including visual question answering and
bidirectional image-text retrieval.
</summary>
    <author>
      <name>Jiayuan Mao</name>
    </author>
    <author>
      <name>Chuang Gan</name>
    </author>
    <author>
      <name>Pushmeet Kohli</name>
    </author>
    <author>
      <name>Joshua B. Tenenbaum</name>
    </author>
    <author>
      <name>Jiajun Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2019 (Oral). Project page: http://nscl.csail.mit.edu/</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.11610v1</id>
    <updated>2019-04-25T22:12:43Z</updated>
    <published>2019-04-25T22:12:43Z</published>
    <title>Look Who's Talking: Inferring Speaker Attributes from Personal
  Longitudinal Dialog</title>
    <summary>  We examine a large dialog corpus obtained from the conversation history of a
single individual with 104 conversation partners. The corpus consists of half a
million instant messages, across several messaging platforms. We focus our
analyses on seven speaker attributes, each of which partitions the set of
speakers, namely: gender; relative age; family member; romantic partner;
classmate; co-worker; and native to the same country. In addition to the
content of the messages, we examine conversational aspects such as the time
messages are sent, messaging frequency, psycholinguistic word categories,
linguistic mirroring, and graph-based features reflecting how people in the
corpus mention each other. We present two sets of experiments predicting each
attribute using (1) short context windows; and (2) a larger set of messages. We
find that using all features leads to gains of 9-14% over using message text
only.
</summary>
    <author>
      <name>Charles Welch</name>
    </author>
    <author>
      <name>Verónica Pérez-Rosas</name>
    </author>
    <author>
      <name>Jonathan K. Kummerfeld</name>
    </author>
    <author>
      <name>Rada Mihalcea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages accepted to CICLing 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 20th International Conference on Computational
  Linguistics and Intelligent Text Processing (CICLing 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1904.11610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.11610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.11574v1</id>
    <updated>2019-04-25T20:37:26Z</updated>
    <published>2019-04-25T20:37:26Z</published>
    <title>TVQA+: Spatio-Temporal Grounding for Video Question Answering</title>
    <summary>  We present the task of Spatio-Temporal Video Question Answering, which
requires intelligent systems to simultaneously retrieve relevant moments and
detect referenced visual concepts (people and objects) to answer natural
language questions about videos. We first augment the TVQA dataset with 310.8k
bounding boxes, linking depicted objects to visual concepts in questions and
answers. We name this augmented version as TVQA+. We then propose
Spatio-Temporal Answerer with Grounded Evidence (STAGE), a unified framework
that grounds evidence in both the spatial and temporal domains to answer
questions about videos. Comprehensive experiments and analyses demonstrate the
effectiveness of our framework and how the rich annotations in our TVQA+
dataset can contribute to the question answering task. As a side product, by
performing this joint task, our model is able to produce more insightful
intermediate results. Dataset and code are publicly available.
</summary>
    <author>
      <name>Jie Lei</name>
    </author>
    <author>
      <name>Licheng Yu</name>
    </author>
    <author>
      <name>Tamara L. Berg</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.11574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.11574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.11475v1</id>
    <updated>2019-04-25T17:39:01Z</updated>
    <published>2019-04-25T17:39:01Z</published>
    <title>Importance of Copying Mechanism for News Headline Generation</title>
    <summary>  News headline generation is an essential problem of text summarization
because it is constrained, well-defined, and is still hard to solve. Models
with a limited vocabulary can not solve it well, as new named entities can
appear regularly in the news and these entities often should be in the
headline. News articles in morphologically rich languages such as Russian
require model modifications due to a large number of possible word forms. This
study aims to validate that models with a possibility of copying words from the
original article performs better than models without such an option. The
proposed model achieves a mean ROUGE score of 23 on the provided test dataset,
which is 8 points greater than the result of a similar model without a copying
mechanism. Moreover, the resulting model performs better than any known model
on the new dataset of Russian news.
</summary>
    <author>
      <name>Ilya Gusev</name>
    </author>
    <link href="http://arxiv.org/abs/1904.11475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.11475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10876v1</id>
    <updated>2019-04-24T15:40:14Z</updated>
    <published>2019-04-24T15:40:14Z</published>
    <title>Integrating Social Media into a Pan-European Flood Awareness System: A
  Multilingual Approach</title>
    <summary>  This paper describes a prototype system that integrates social media analysis
into the European Flood Awareness System (EFAS). This integration allows the
collection of social media data to be automatically triggered by flood risk
warnings determined by a hydro-meteorological model. Then, we adopt a
multi-lingual approach to find flood-related messages by employing two
state-of-the-art methodologies: language-agnostic word embeddings and
language-aligned word embeddings. Both approaches can be used to bootstrap a
classifier of social media messages for a new language with little or no
labeled data. Finally, we describe a method for selecting relevant and
representative messages and displaying them back in the interface of EFAS.
</summary>
    <author>
      <name>V. Lorini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">European Commission, Joint Research Centre</arxiv:affiliation>
    </author>
    <author>
      <name>C. Castillo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Pompeu Fabra, Barcelona, Spain</arxiv:affiliation>
    </author>
    <author>
      <name>F. Dottori</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">European Commission, Joint Research Centre</arxiv:affiliation>
    </author>
    <author>
      <name>M. Kalas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">KAJO, Bytca, Slovakia</arxiv:affiliation>
    </author>
    <author>
      <name>D. Nappo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">European Commission, Joint Research Centre</arxiv:affiliation>
    </author>
    <author>
      <name>P. Salamon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">European Commission, Joint Research Centre</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted at ISCRAM2019 Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10820v3</id>
    <updated>2019-08-13T13:31:59Z</updated>
    <published>2019-04-24T13:55:42Z</published>
    <title>Semantic Drift in Multilingual Representations</title>
    <summary>  Multilingual representations have mostly been evaluated based on their
performance on specific tasks. In this article, we look beyond engineering
goals and analyze the relations between languages in computational
representations. We introduce a methodology for comparing languages based on
their organization of semantic concepts. We propose to conduct an adapted
version of representational similarity analysis of a selected set of concepts
in computational multilingual representations. Using this analysis method, we
can reconstruct a phylogenetic tree that closely resembles those assumed by
linguistic experts. These results indicate that multilingual distributional
representations which are only trained on monolingual text and bilingual
dictionaries preserve relations between languages without the need for any
etymological information. In addition, we propose a measure to identify
semantic drift between language families. We perform experiments on word-based
and sentence-based multilingual models and provide both quantitative results
and qualitative examples. Analyses of semantic drift in multilingual
representations can serve two purposes: they can indicate unwanted
characteristics of the computational models and they provide a quantitative
means to study linguistic phenomena across languages. The code is available at
https://github.com/beinborn/SemanticDrift.
</summary>
    <author>
      <name>Lisa Beinborn</name>
    </author>
    <author>
      <name>Rochelle Choenni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Substantially revised version after feedback. Now includes additional
  quantitative experiments</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10820v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10820v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10610v1</id>
    <updated>2019-04-24T02:26:48Z</updated>
    <published>2019-04-24T02:26:48Z</published>
    <title>Condition-Transforming Variational AutoEncoder for Conversation Response
  Generation</title>
    <summary>  This paper proposes a new model, called condition-transforming variational
autoencoder (CTVAE), to improve the performance of conversation response
generation using conditional variational autoencoders (CVAEs). In conventional
CVAEs , the prior distribution of latent variable z follows a multivariate
Gaussian distribution with mean and variance modulated by the input conditions.
Previous work found that this distribution tends to become condition
independent in practical application. In our proposed CTVAE model, the latent
variable z is sampled by performing a non-lineartransformation on the
combination of the input conditions and the samples from a
condition-independent prior distribution N (0; I). In our objective
evaluations, the CTVAE model outperforms the CVAE model on fluency metrics and
surpasses a sequence-to-sequence (Seq2Seq) model on diversity metrics. In
subjective preference tests, our proposed CTVAE model performs significantly
better than CVAE and Seq2Seq models on generating fluency, informative and
topic relevant responses.
</summary>
    <author>
      <name>Yu-Ping Ruan</name>
    </author>
    <author>
      <name>Zhen-Hua Ling</name>
    </author>
    <author>
      <name>Quan Liu</name>
    </author>
    <author>
      <name>Zhigang Chen</name>
    </author>
    <author>
      <name>Nitin Indurkhya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2019, oral</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10503v1</id>
    <updated>2019-04-23T19:18:26Z</updated>
    <published>2019-04-23T19:18:26Z</published>
    <title>Fine-Grained Named Entity Recognition using ELMo and Wikidata</title>
    <summary>  Fine-grained Named Entity Recognition is a task whereby we detect and
classify entity mentions to a large set of types. These types can span diverse
domains such as finance, healthcare, and politics. We observe that when the
type set spans several domains the accuracy of the entity detection becomes a
limitation for supervised learning models. The primary reason being the lack of
datasets where entity boundaries are properly annotated, whilst covering a
large spectrum of entity types. Furthermore, many named entity systems suffer
when considering the categorization of fine grained entity types. Our work
attempts to address these issues, in part, by combining state-of-the-art deep
learning models (ELMo) with an expansive knowledge base (Wikidata). Using our
framework, we cross-validate our model on the 112 fine-grained entity types
based on the hierarchy given from the Wiki(gold) dataset.
</summary>
    <author>
      <name>Cihan Dogan</name>
    </author>
    <author>
      <name>Aimore Dutra</name>
    </author>
    <author>
      <name>Adam Gara</name>
    </author>
    <author>
      <name>Alfredo Gemma</name>
    </author>
    <author>
      <name>Lei Shi</name>
    </author>
    <author>
      <name>Michael Sigamani</name>
    </author>
    <author>
      <name>Ella Walters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10788v2</id>
    <updated>2019-05-09T13:34:00Z</updated>
    <published>2019-04-23T13:09:21Z</published>
    <title>Speech Emotion Recognition Using Multi-hop Attention Mechanism</title>
    <summary>  In this paper, we are interested in exploiting textual and acoustic data of
an utterance for the speech emotion classification task. The baseline approach
models the information from audio and text independently using two deep neural
networks (DNNs). The outputs from both the DNNs are then fused for
classification. As opposed to using knowledge from both the modalities
separately, we propose a framework to exploit acoustic information in tandem
with lexical data. The proposed framework uses two bi-directional long
short-term memory (BLSTM) for obtaining hidden representations of the
utterance. Furthermore, we propose an attention mechanism, referred to as the
multi-hop, which is trained to automatically infer the correlation between the
modalities. The multi-hop attention first computes the relevant segments of the
textual data corresponding to the audio signal. The relevant textual data is
then applied to attend parts of the audio signal. To evaluate the performance
of the proposed system, experiments are performed in the IEMOCAP dataset.
Experimental results show that the proposed technique outperforms the
state-of-the-art system by 6.5% relative improvement in terms of weighted
accuracy.
</summary>
    <author>
      <name>Seunghyun Yoon</name>
    </author>
    <author>
      <name>Seokhyun Byun</name>
    </author>
    <author>
      <name>Subhadeep Dey</name>
    </author>
    <author>
      <name>Kyomin Jung</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICASSP.2019.8683483</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICASSP.2019.8683483" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Accepted as a conference paper at ICASSP 2019 (oral
  presentation)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10788v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10788v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09705v1</id>
    <updated>2019-04-22T03:00:40Z</updated>
    <published>2019-04-22T03:00:40Z</published>
    <title>Exploring Unsupervised Pretraining and Sentence Structure Modelling for
  Winograd Schema Challenge</title>
    <summary>  Winograd Schema Challenge (WSC) was proposed as an AI-hard problem in testing
computers' intelligence on common sense representation and reasoning. This
paper presents the new state-of-theart on WSC, achieving an accuracy of 71.1%.
We demonstrate that the leading performance benefits from jointly modelling
sentence structures, utilizing knowledge learned from cutting-edge pretraining
models, and performing fine-tuning. We conduct detailed analyses, showing that
fine-tuning is critical for achieving the performance, but it helps more on the
simpler associative problems. Modelling sentence dependency structures,
however, consistently helps on the harder non-associative subset of WSC.
Analysis also shows that larger fine-tuning datasets yield better performances,
suggesting the potential benefit of future work on annotating more Winograd
schema sentences.
</summary>
    <author>
      <name>Yu-Ping Ruan</name>
    </author>
    <author>
      <name>Xiaodan Zhu</name>
    </author>
    <author>
      <name>Zhen-Hua Ling</name>
    </author>
    <author>
      <name>Zhan Shi</name>
    </author>
    <author>
      <name>Quan Liu</name>
    </author>
    <author>
      <name>Si Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.09705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01969v3</id>
    <updated>2020-02-12T20:07:00Z</updated>
    <published>2019-04-22T02:18:00Z</published>
    <title>Poly-encoders: Transformer Architectures and Pre-training Strategies for
  Fast and Accurate Multi-sentence Scoring</title>
    <summary>  The use of deep pre-trained bidirectional transformers has led to remarkable
progress in a number of applications (Devlin et al., 2018). For tasks that make
pairwise comparisons between sequences, matching a given input with a
corresponding label, two approaches are common: Cross-encoders performing full
self-attention over the pair and Bi-encoders encoding the pair separately. The
former often performs better, but is too slow for practical use. In this work,
we develop a new transformer architecture, the Poly-encoder, that learns global
rather than token level self-attention features. We perform a detailed
comparison of all three approaches, including what pre-training and fine-tuning
strategies work best. We show our models achieve state-of-the-art results on
three existing tasks; that Poly-encoders are faster than Cross-encoders and
more accurate than Bi-encoders; and that the best results are obtained by
pre-training on large datasets similar to the downstream tasks.
</summary>
    <author>
      <name>Samuel Humeau</name>
    </author>
    <author>
      <name>Kurt Shuster</name>
    </author>
    <author>
      <name>Marie-Anne Lachaux</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01969v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01969v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09585v1</id>
    <updated>2019-04-21T12:09:39Z</updated>
    <published>2019-04-21T12:09:39Z</published>
    <title>Obfuscation for Privacy-preserving Syntactic Parsing</title>
    <summary>  The goal of homomorphic encryption is to encrypt data such that another party
can operate on it without being explicitly exposed to the content of the
original data. We introduce an idea for a privacy-preserving transformation on
natural language data, inspired by homomorphic encryption. Our primary tool is
{\em obfuscation}, relying on the properties of natural language. Specifically,
a given text is obfuscated using a neural model that aims to preserve the
syntactic relationships of the original sentence so that the obfuscated
sentence can be parsed instead of the original one. The model works at the word
level, and learns to obfuscate each word separately by changing it into a new
word that has a similar syntactic role. The text encrypted by our model leads
to better performance on three syntactic parsers (two dependency and one
constituency parsers) in comparison to a strong random baseline. The
substituted words have similar syntactic properties, but different semantic
content, compared to the original words.
</summary>
    <author>
      <name>Zhifeng Hu</name>
    </author>
    <author>
      <name>Serhii Havrylov</name>
    </author>
    <author>
      <name>Ivan Titov</name>
    </author>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <link href="http://arxiv.org/abs/1904.09585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09447v2</id>
    <updated>2019-10-30T14:01:24Z</updated>
    <published>2019-04-20T13:46:36Z</published>
    <title>Unsupervised Text Generation from Structured Data</title>
    <summary>  This work presents a joint solution to two challenging tasks: text generation
from data and open information extraction. We propose to model both tasks as
sequence-to-sequence translation problems and thus construct a joint neural
model for both. Our experiments on knowledge graphs from Visual Genome, i.e.,
structured image analyses, shows promising results compared to strong
baselines. Building on recent work on unsupervised machine translation, we
report the first results - to the best of our knowledge - on fully unsupervised
text generation from structured data.
</summary>
    <author>
      <name>Martin Schmitt</name>
    </author>
    <author>
      <name>Sahand Sharifzadeh</name>
    </author>
    <author>
      <name>Volker Tresp</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <link href="http://arxiv.org/abs/1904.09447v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09447v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09408v2</id>
    <updated>2019-10-17T04:25:15Z</updated>
    <published>2019-04-20T06:43:14Z</published>
    <title>Language Models with Transformers</title>
    <summary>  The Transformer architecture is superior to RNN-based models in computational
efficiency. Recently, GPT and BERT demonstrate the efficacy of Transformer
models on various NLP tasks using pre-trained language models on large-scale
corpora. Surprisingly, these Transformer architectures are suboptimal for
language model itself. Neither self-attention nor the positional encoding in
the Transformer is able to efficiently incorporate the word-level sequential
context crucial to language modeling.
  In this paper, we explore effective Transformer architectures for language
model, including adding additional LSTM layers to better capture the sequential
context while still keeping the computation efficient. We propose Coordinate
Architecture Search (CAS) to find an effective architecture through iterative
refinement of the model. Experimental results on the PTB, WikiText-2, and
WikiText-103 show that CAS achieves perplexities between 20.42 and 34.11 on all
problems, i.e. on average an improvement of 12.0 perplexity units compared to
state-of-the-art LSTMs. The source code is publicly available.
</summary>
    <author>
      <name>Chenguang Wang</name>
    </author>
    <author>
      <name>Mu Li</name>
    </author>
    <author>
      <name>Alexander J. Smola</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 tables, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.09408v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09408v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09380v1</id>
    <updated>2019-04-20T00:30:26Z</updated>
    <published>2019-04-20T00:30:26Z</published>
    <title>Repurposing Entailment for Multi-Hop Question Answering Tasks</title>
    <summary>  Question Answering (QA) naturally reduces to an entailment problem, namely,
verifying whether some text entails the answer to a question. However, for
multi-hop QA tasks, which require reasoning with multiple sentences, it remains
unclear how best to utilize entailment models pre-trained on large scale
datasets such as SNLI, which are based on sentence pairs. We introduce Multee,
a general architecture that can effectively use entailment models for multi-hop
QA tasks. Multee uses (i) a local module that helps locate important sentences,
thereby avoiding distracting information, and (ii) a global module that
aggregates information by effectively incorporating importance weights.
Importantly, we show that both modules can use entailment functions pre-trained
on a large scale NLI datasets. We evaluate performance on MultiRC and
OpenBookQA, two multihop QA datasets. When using an entailment function
pre-trained on NLI datasets, Multee outperforms QA models trained only on the
target QA datasets and the OpenAI transformer models. The code is available at
https://github.com/StonyBrookNLP/multee.
</summary>
    <author>
      <name>Harsh Trivedi</name>
    </author>
    <author>
      <name>Heeyoung Kwon</name>
    </author>
    <author>
      <name>Tushar Khot</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Niranjan Balasubramanian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NAACL'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.09380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09324v2</id>
    <updated>2019-09-04T16:31:39Z</updated>
    <published>2019-04-19T19:53:01Z</published>
    <title>Mask-Predict: Parallel Decoding of Conditional Masked Language Models</title>
    <summary>  Most machine translation systems generate text autoregressively from left to
right. We, instead, use a masked language modeling objective to train a model
to predict any subset of the target words, conditioned on both the input text
and a partially masked target translation. This approach allows for efficient
iterative decoding, where we first predict all of the target words
non-autoregressively, and then repeatedly mask out and regenerate the subset of
words that the model is least confident about. By applying this strategy for a
constant number of iterations, our model improves state-of-the-art performance
levels for non-autoregressive and parallel decoding translation models by over
4 BLEU on average. It is also able to reach within about 1 BLEU point of a
typical left-to-right transformer model, while decoding significantly faster.
</summary>
    <author>
      <name>Marjan Ghazvininejad</name>
    </author>
    <author>
      <name>Omer Levy</name>
    </author>
    <author>
      <name>Yinhan Liu</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.09324v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09324v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.09067v1</id>
    <updated>2019-04-19T04:09:12Z</updated>
    <published>2019-04-19T04:09:12Z</published>
    <title>Emergence of Compositional Language with Deep Generational Transmission</title>
    <summary>  Consider a collaborative task that requires communication. Two agents are
placed in an environment and must create a language from scratch in order to
coordinate. Recent work has been interested in what kinds of languages emerge
when deep reinforcement learning agents are put in such a situation, and in
particular in the factors that cause language to be compositional-i.e. meaning
is expressed by combining words which themselves have meaning. Evolutionary
linguists have also studied the emergence of compositional language for
decades, and they find that in addition to structural priors like those already
studied in deep learning, the dynamics of transmitting language from generation
to generation contribute significantly to the emergence of compositionality. In
this paper, we introduce these cultural evolutionary dynamics into language
emergence by periodically replacing agents in a population to create a
knowledge gap, implicitly inducing cultural transmission of language. We show
that this implicit cultural transmission encourages the resulting languages to
exhibit better compositional generalization and suggest how elements of
cultural dynamics can be further integrated into populations of deep agents.
</summary>
    <author>
      <name>Michael Cogswell</name>
    </author>
    <author>
      <name>Jiasen Lu</name>
    </author>
    <author>
      <name>Stefan Lee</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <link href="http://arxiv.org/abs/1904.09067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.09067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01959v1</id>
    <updated>2019-04-19T02:30:59Z</updated>
    <published>2019-04-19T02:30:59Z</published>
    <title>Relation Discovery with Out-of-Relation Knowledge Base as Supervision</title>
    <summary>  Unsupervised relation discovery aims to discover new relations from a given
text corpus without annotated data. However, it does not consider existing
human annotated knowledge bases even when they are relevant to the relations to
be discovered. In this paper, we study the problem of how to use
out-of-relation knowledge bases to supervise the discovery of unseen relations,
where out-of-relation means that relations to discover from the text corpus and
those in knowledge bases are not overlapped. We construct a set of constraints
between entity pairs based on the knowledge base embedding and then incorporate
constraints into the relation discovery by a variational auto-encoder based
algorithm. Experiments show that our new approach can improve the
state-of-the-art relation discovery performance by a large margin.
</summary>
    <author>
      <name>Yan Liang</name>
    </author>
    <author>
      <name>Xin Liu</name>
    </author>
    <author>
      <name>Jianwen Zhang</name>
    </author>
    <author>
      <name>Yangqiu Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Aceepted by NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.01959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08950v1</id>
    <updated>2019-04-18T18:00:30Z</updated>
    <published>2019-04-18T18:00:30Z</published>
    <title>No Permanent Friends or Enemies: Tracking Relationships between Nations
  from News</title>
    <summary>  Understanding the dynamics of international politics is important yet
challenging for civilians. In this work, we explore unsupervised neural models
to infer relations between nations from news articles. We extend existing
models by incorporating shallow linguistics information and propose a new
automatic evaluation metric that aligns relationship dynamics with manually
annotated key events. As understanding international relations requires
carefully analyzing complex relationships, we conduct in-person human
evaluations with three groups of participants. Overall, humans prefer the
outputs of our model and give insightful feedback that suggests future
directions for human-centered models. Furthermore, our model reveals
interesting regional differences in news coverage. For instance, with respect
to US-China relations, Singaporean media focus more on "strengthening" and
"purchasing", while US media focus more on "criticizing" and "denouncing".
</summary>
    <author>
      <name>Xiaochuang Han</name>
    </author>
    <author>
      <name>Eunsol Choi</name>
    </author>
    <author>
      <name>Chenhao Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019; code available at https://github.com/BoulderDS/LARN</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.08950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08637v1</id>
    <updated>2019-04-18T08:35:49Z</updated>
    <published>2019-04-18T08:35:49Z</published>
    <title>ConvLab: Multi-Domain End-to-End Dialog System Platform</title>
    <summary>  We present ConvLab, an open-source multi-domain end-to-end dialog system
platform, that enables researchers to quickly set up experiments with reusable
components and compare a large set of different approaches, ranging from
conventional pipeline systems to end-to-end neural models, in common
environments. ConvLab offers a set of fully annotated datasets and associated
pre-trained reference models. As a showcase, we extend the MultiWOZ dataset
with user dialog act annotations to train all component models and demonstrate
how ConvLab makes it easy and effortless to conduct complicated experiments in
multi-domain end-to-end dialog settings.
</summary>
    <author>
      <name>Sungjin Lee</name>
    </author>
    <author>
      <name>Qi Zhu</name>
    </author>
    <author>
      <name>Ryuichi Takanobu</name>
    </author>
    <author>
      <name>Xiang Li</name>
    </author>
    <author>
      <name>Yaoqin Zhang</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Jinchao Li</name>
    </author>
    <author>
      <name>Baolin Peng</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1904.08637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01978v1</id>
    <updated>2019-04-17T19:55:20Z</updated>
    <published>2019-04-17T19:55:20Z</published>
    <title>CraftAssist Instruction Parsing: Semantic Parsing for a Minecraft
  Assistant</title>
    <summary>  We propose a large scale semantic parsing dataset focused on
instruction-driven communication with an agent in Minecraft. We describe the
data collection process which yields additional 35K human generated
instructions with their semantic annotations. We report the performance of
three baseline models and find that while a dataset of this size helps us train
a usable instruction parser, it still poses interesting generalization
challenges which we hope will help develop better and more robust models.
</summary>
    <author>
      <name>Yacine Jernite</name>
    </author>
    <author>
      <name>Kavya Srinet</name>
    </author>
    <author>
      <name>Jonathan Gray</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <link href="http://arxiv.org/abs/1905.01978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08311v2</id>
    <updated>2019-07-02T13:14:30Z</updated>
    <published>2019-04-17T15:18:23Z</published>
    <title>Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and
  Knowledge Distillation</title>
    <summary>  Conventional automatic speech recognition (ASR) systems trained from
frame-level alignments can easily leverage posterior fusion to improve ASR
accuracy and build a better single model with knowledge distillation.
End-to-end ASR systems trained using the Connectionist Temporal Classification
(CTC) loss do not require frame-level alignment and hence simplify model
training. However, sparse and arbitrary posterior spike timings from CTC models
pose a new set of challenges in posterior fusion from multiple models and
knowledge distillation between CTC models. We propose a method to train a CTC
model so that its spike timings are guided to align with those of a pre-trained
guiding CTC model. As a result, all models that share the same guiding model
have aligned spike timings. We show the advantage of our method in various
scenarios including posterior fusion of CTC models and knowledge distillation
between CTC models with different architectures. With the 300-hour Switchboard
training data, the single word CTC model distilled from multiple models
improved the word error rates to 13.7%/23.1% from 14.9%/24.1% on the Hub5 2000
Switchboard/CallHome test sets without using any data augmentation, language
model, or complex decoder.
</summary>
    <author>
      <name>Gakuto Kurata</name>
    </author>
    <author>
      <name>Kartik Audhkhasi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Interspeech 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.08311v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08311v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08109v1</id>
    <updated>2019-04-17T07:16:10Z</updated>
    <published>2019-04-17T07:16:10Z</published>
    <title>Contextual Aware Joint Probability Model Towards Question Answering
  System</title>
    <summary>  In this paper, we address the question answering challenge with the SQuAD 2.0
dataset. We design a model architecture which leverages BERT's capability of
context-aware word embeddings and BiDAF's context interactive exploration
mechanism. By integrating these two state-of-the-art architectures, our system
tries to extract the contextual word representation at word and character
levels, for better comprehension of both question and context and their
correlations. We also propose our original joint posterior probability
predictor module and its associated loss functions. Our best model so far
obtains F1 score of 75.842% and EM score of 72.24% on the test PCE leaderboad.
</summary>
    <author>
      <name>Liu Yang</name>
    </author>
    <author>
      <name>Lijing Song</name>
    </author>
    <link href="http://arxiv.org/abs/1904.08109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08067v4</id>
    <updated>2019-06-25T22:51:18Z</updated>
    <published>2019-04-17T03:29:05Z</published>
    <title>Text Classification Algorithms: A Survey</title>
    <summary>  In recent years, there has been an exponential growth in the number of
complex documents and texts that require a deeper understanding of machine
learning methods to be able to accurately classify texts in many applications.
Many machine learning approaches have achieved surpassing results in natural
language processing. The success of these learning algorithms relies on their
capacity to understand complex models and non-linear relationships within data.
However, finding suitable structures, architectures, and techniques for text
classification is a challenge for researchers. In this paper, a brief overview
of text classification algorithms is discussed. This overview covers different
text feature extractions, dimensionality reduction methods, existing algorithms
and techniques, and evaluations methods. Finally, the limitations of each
technique and their application in the real-world problem are discussed.
</summary>
    <author>
      <name>Kamran Kowsari</name>
    </author>
    <author>
      <name>Kiana Jafari Meimandi</name>
    </author>
    <author>
      <name>Mojtaba Heidarysafa</name>
    </author>
    <author>
      <name>Sanjana Mendu</name>
    </author>
    <author>
      <name>Laura E. Barnes</name>
    </author>
    <author>
      <name>Donald E. Brown</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3390/info10040150</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3390/info10040150" rel="related"/>
    <link href="http://arxiv.org/abs/1904.08067v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08067v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.06730v1</id>
    <updated>2019-04-14T17:32:44Z</updated>
    <published>2019-04-14T17:32:44Z</published>
    <title>Text segmentation on multilabel documents: A distant-supervised approach</title>
    <summary>  Segmenting text into semantically coherent segments is an important task with
applications in information retrieval and text summarization. Developing
accurate topical segmentation requires the availability of training data with
ground truth information at the segment level. However, generating such labeled
datasets, especially for applications in which the meaning of the labels is
user-defined, is expensive and time-consuming. In this paper, we develop an
approach that instead of using segment-level ground truth information, it
instead uses the set of labels that are associated with a document and are
easier to obtain as the training data essentially corresponds to a multilabel
dataset. Our method, which can be thought of as an instance of distant
supervision, improves upon the previous approaches by exploiting the fact that
consecutive sentences in a document tend to talk about the same topic, and
hence, probably belong to the same class. Experiments on the text segmentation
task on a variety of datasets show that the segmentation produced by our method
beats the competing approaches on four out of five datasets and performs at par
on the fifth dataset. On the multilabel text classification task, our method
performs at par with the competing approaches, while requiring significantly
less time to estimate than the competing approaches.
</summary>
    <author>
      <name>Saurav Manchanda</name>
    </author>
    <author>
      <name>George Karypis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICDM.2018.00154</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICDM.2018.00154" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in 2018 IEEE International Conference on Data Mining (ICDM)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2018 IEEE International Conference on Data Mining (ICDM),
  1170-1175</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1904.06730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.06730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.06725v1</id>
    <updated>2019-04-14T17:01:26Z</updated>
    <published>2019-04-14T17:01:26Z</published>
    <title>Distributed representation of multi-sense words: A loss-driven approach</title>
    <summary>  Word2Vec's Skip Gram model is the current state-of-the-art approach for
estimating the distributed representation of words. However, it assumes a
single vector per word, which is not well-suited for representing words that
have multiple senses. This work presents LDMI, a new model for estimating
distributional representations of words. LDMI relies on the idea that, if a
word carries multiple senses, then having a different representation for each
of its senses should lead to a lower loss associated with predicting its
co-occurring words, as opposed to the case when a single vector representation
is used for all the senses. After identifying the multi-sense words, LDMI
clusters the occurrences of these words to assign a sense to each occurrence.
Experiments on the contextual word similarity task show that LDMI leads to
better performance than competing approaches.
</summary>
    <author>
      <name>Saurav Manchanda</name>
    </author>
    <author>
      <name>George Karypis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-93037-4_27</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-93037-4_27" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PAKDD 2018 Best paper award runner-up</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Knowledge Discovery and Data Mining. PAKDD 2018.
  Lecture Notes in Computer Science, vol 10938. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1904.06725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.06725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.06475v1</id>
    <updated>2019-04-13T03:52:56Z</updated>
    <published>2019-04-13T03:52:56Z</published>
    <title>Improving Distantly-supervised Entity Typing with Compact Latent Space
  Clustering</title>
    <summary>  Recently, distant supervision has gained great success on Fine-grained Entity
Typing (FET). Despite its efficiency in reducing manual labeling efforts, it
also brings the challenge of dealing with false entity type labels, as distant
supervision assigns labels in a context agnostic manner. Existing works
alleviated this issue with partial-label loss, but usually suffer from
confirmation bias, which means the classifier fit a pseudo data distribution
given by itself. In this work, we propose to regularize distantly supervised
models with Compact Latent Space Clustering (CLSC) to bypass this problem and
effectively utilize noisy data yet. Our proposed method first dynamically
constructs a similarity graph of different entity mentions; infer the labels of
noisy instances via label propagation. Based on the inferred labels, mention
embeddings are updated accordingly to encourage entity mentions with close
semantics to form a compact cluster in the embedding space,thus leading to
better classification performance. Extensive experiments on standard benchmarks
show that our CLSC model consistently outperforms state-of-the-art distantly
supervised entity typing systems by a significant margin.
</summary>
    <author>
      <name>Bo Chen</name>
    </author>
    <author>
      <name>Xiaotao Gu</name>
    </author>
    <author>
      <name>Yufeng Hu</name>
    </author>
    <author>
      <name>Siliang Tang</name>
    </author>
    <author>
      <name>Guoping Hu</name>
    </author>
    <author>
      <name>Yueting Zhuang</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.06475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.06475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.06100v1</id>
    <updated>2019-04-12T08:45:43Z</updated>
    <published>2019-04-12T08:45:43Z</published>
    <title>Adapting Sequence to Sequence models for Text Normalization in Social
  Media</title>
    <summary>  Social media offer an abundant source of valuable raw data, however informal
writing can quickly become a bottleneck for many natural language processing
(NLP) tasks. Off-the-shelf tools are usually trained on formal text and cannot
explicitly handle noise found in short online posts. Moreover, the variety of
frequently occurring linguistic variations presents several challenges, even
for humans who might not be able to comprehend the meaning of such posts,
especially when they contain slang and abbreviations. Text Normalization aims
to transform online user-generated text to a canonical form. Current text
normalization systems rely on string or phonetic similarity and classification
models that work on a local fashion. We argue that processing contextual
information is crucial for this task and introduce a social media text
normalization hybrid word-character attention-based encoder-decoder model that
can serve as a pre-processing step for NLP applications to adapt to noisy text
in social media. Our character-based component is trained on synthetic
adversarial examples that are designed to capture errors commonly found in
online user-generated text. Experiments show that our model surpasses neural
architectures designed for text normalization and achieves comparable
performance with state-of-the-art related work.
</summary>
    <author>
      <name>Ismini Lourentzou</name>
    </author>
    <author>
      <name>Kabir Manghnani</name>
    </author>
    <author>
      <name>ChengXiang Zhai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 13th International AAAI Conference on Web and Social
  Media (ICWSM 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.06100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.06100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05880v3</id>
    <updated>2020-03-07T23:35:13Z</updated>
    <published>2019-04-11T17:59:58Z</published>
    <title>Factor Graph Attention</title>
    <summary>  Dialog is an effective way to exchange information, but subtle details and
nuances are extremely important. While significant progress has paved a path to
address visual dialog with algorithms, details and nuances remain a challenge.
Attention mechanisms have demonstrated compelling results to extract details in
visual question answering and also provide a convincing framework for visual
dialog due to their interpretability and effectiveness. However, the many data
utilities that accompany visual dialog challenge existing attention techniques.
We address this issue and develop a general attention mechanism for visual
dialog which operates on any number of data utilities. To this end, we design a
factor graph based attention mechanism which combines any number of utility
representations. We illustrate the applicability of the proposed approach on
the challenging and recently introduced VisDial datasets, outperforming recent
state-of-the-art methods by 1.1% for VisDial0.9 and by 2% for VisDial1.0 on
MRR. Our ensemble model improved the MRR score on VisDial1.0 by more than 6%.
</summary>
    <author>
      <name>Idan Schwartz</name>
    </author>
    <author>
      <name>Seunghak Yu</name>
    </author>
    <author>
      <name>Tamir Hazan</name>
    </author>
    <author>
      <name>Alexander Schwing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to CVPR 2019; revised version includes bottom-up features</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05880v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05880v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05876v1</id>
    <updated>2019-04-11T17:59:51Z</updated>
    <published>2019-04-11T17:59:51Z</published>
    <title>A Simple Baseline for Audio-Visual Scene-Aware Dialog</title>
    <summary>  The recently proposed audio-visual scene-aware dialog task paves the way to a
more data-driven way of learning virtual assistants, smart speakers and car
navigation systems. However, very little is known to date about how to
effectively extract meaningful information from a plethora of sensors that
pound the computational engine of those devices. Therefore, in this paper, we
provide and carefully analyze a simple baseline for audio-visual scene-aware
dialog which is trained end-to-end. Our method differentiates in a data-driven
manner useful signals from distracting ones using an attention mechanism. We
evaluate the proposed approach on the recently introduced and challenging
audio-visual scene-aware dataset, and demonstrate the key features that permit
to outperform the current state-of-the-art by more than 20\% on CIDEr.
</summary>
    <author>
      <name>Idan Schwartz</name>
    </author>
    <author>
      <name>Alexander Schwing</name>
    </author>
    <author>
      <name>Tamir Hazan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to CVPR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05606v1</id>
    <updated>2019-04-11T09:55:41Z</updated>
    <published>2019-04-11T09:55:41Z</published>
    <title>Multi-lingual Dialogue Act Recognition with Deep Learning Methods</title>
    <summary>  This paper deals with multi-lingual dialogue act (DA) recognition. The
proposed approaches are based on deep neural networks and use word2vec
embeddings for word representation. Two multi-lingual models are proposed for
this task. The first approach uses one general model trained on the embeddings
from all available languages. The second method trains the model on a single
pivot language and a linear transformation method is used to project other
languages onto the pivot language. The popular convolutional neural network and
LSTM architectures with different set-ups are used as classifiers. To the best
of our knowledge this is the first attempt at multi-lingual DA recognition
using neural networks. The multi-lingual models are validated experimentally on
two languages from the Verbmobil corpus.
</summary>
    <author>
      <name>Jiří Martínek</name>
    </author>
    <author>
      <name>Pavel Král</name>
    </author>
    <author>
      <name>Ladislav Lenc</name>
    </author>
    <author>
      <name>Christophe Cerisara</name>
    </author>
    <link href="http://arxiv.org/abs/1904.05606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05548v2</id>
    <updated>2019-05-28T23:40:33Z</updated>
    <published>2019-04-11T06:46:15Z</published>
    <title>Reasoning Visual Dialogs with Structural and Partial Observations</title>
    <summary>  We propose a novel model to address the task of Visual Dialog which exhibits
complex dialog structures. To obtain a reasonable answer based on the current
question and the dialog history, the underlying semantic dependencies between
dialog entities are essential. In this paper, we explicitly formalize this task
as inference in a graphical model with partially observed nodes and unknown
graph structures (relations in dialog). The given dialog entities are viewed as
the observed nodes. The answer to a given question is represented by a node
with missing value. We first introduce an Expectation Maximization algorithm to
infer both the underlying dialog structures and the missing node values
(desired answers). Based on this, we proceed to propose a differentiable graph
neural network (GNN) solution that approximates this process. Experiment
results on the VisDial and VisDial-Q datasets show that our model outperforms
comparative methods. It is also observed that our method can infer the
underlying dialog structure for better dialog reasoning.
</summary>
    <author>
      <name>Zilong Zheng</name>
    </author>
    <author>
      <name>Wenguan Wang</name>
    </author>
    <author>
      <name>Siyuan Qi</name>
    </author>
    <author>
      <name>Song-Chun Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CVPR 2019 Oral paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05548v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05548v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05530v3</id>
    <updated>2019-10-08T03:32:40Z</updated>
    <published>2019-04-11T04:45:42Z</published>
    <title>Recurrent Event Network: Global Structure Inference over Temporal
  Knowledge Graph</title>
    <summary>  Modeling dynamically-evolving, multi-relational graph data has received a
surge of interests with the rapid growth of heterogeneous event data. However,
predicting future events on such data requires global structure inference over
time and the ability to integrate temporal and structural information, which
are not yet well understood. We present Recurrent Event Network (RE-Net), a
novel autoregressive architecture for modeling temporal sequences of
multi-relational graphs (e.g., temporal knowledge graph), which can perform
sequential, global structure inference over future time stamps to predict new
events. RE-Net employs a recurrent event encoder to model the temporally
conditioned joint probability distribution for the event sequences, and equips
the event encoder with a neighborhood aggregator for modeling the concurrent
events within a time window associated with each entity. We apply teacher
forcing for model training over historical data, and infer graph sequences over
future time stamps by sampling from the learned joint distribution in a
sequential manner. We evaluate the proposed method via temporal link prediction
on five public datasets. Extensive experiments demonstrate the strength of
RE-Net, especially on multi-step inference over future time stamps. Code and
data can be found at https://github.com/INK-USC/RE-Net .
</summary>
    <author>
      <name>Woojeong Jin</name>
    </author>
    <author>
      <name>He Jiang</name>
    </author>
    <author>
      <name>Meng Qu</name>
    </author>
    <author>
      <name>Tong Chen</name>
    </author>
    <author>
      <name>Changlin Zhang</name>
    </author>
    <author>
      <name>Pedro Szekely</name>
    </author>
    <author>
      <name>Xiang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, short version is accepted at ICLR 2019 RLGM
  Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05530v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05530v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05440v1</id>
    <updated>2019-04-10T21:04:54Z</updated>
    <published>2019-04-10T21:04:54Z</published>
    <title>Generating Animations from Screenplays</title>
    <summary>  Automatically generating animation from natural language text finds
application in a number of areas e.g. movie script writing, instructional
videos, and public safety. However, translating natural language text into
animation is a challenging task. Existing text-to-animation systems can handle
only very simple sentences, which limits their applications. In this paper, we
develop a text-to-animation system which is capable of handling complex
sentences. We achieve this by introducing a text simplification step into the
process. Building on an existing animation generation system for screenwriting,
we create a robust NLP pipeline to extract information from screenplays and map
them to the system's knowledge base. We develop a set of linguistic
transformation rules that simplify complex sentences. Information extracted
from the simplified sentences is used to generate a rough storyboard and video
depicting the text. Our sentence simplification module outperforms existing
systems in terms of BLEU and SARI metrics.We further evaluated our system via a
user study: 68 % participants believe that our system generates reasonable
animation from input screenplays.
</summary>
    <author>
      <name>Yeyao Zhang</name>
    </author>
    <author>
      <name>Eleftheria Tsipidi</name>
    </author>
    <author>
      <name>Sasha Schriber</name>
    </author>
    <author>
      <name>Mubbasir Kapadia</name>
    </author>
    <author>
      <name>Markus Gross</name>
    </author>
    <author>
      <name>Ashutosh Modi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9+1+6 Pages, Accepted at StarSEM 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05426v1</id>
    <updated>2019-04-10T20:22:31Z</updated>
    <published>2019-04-10T20:22:31Z</published>
    <title>A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource
  Languages</title>
    <summary>  Unsupervised part of speech (POS) tagging is often framed as a clustering
problem, but practical taggers need to \textit{ground} their clusters as well.
Grounding generally requires reference labeled data, a luxury a low-resource
language might not have. In this work, we describe an approach for low-resource
unsupervised POS tagging that yields fully grounded output and requires no
labeled training data. We find the classic method of Brown et al. (1992)
clusters well in our use case and employ a decipherment-based approach to
grounding. This approach presumes a sequence of cluster IDs is a `ciphertext'
and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We
show intrinsically that, despite the difficulty of the task, we obtain
reasonable performance across a variety of languages. We also show
extrinsically that incorporating our POS tagger into a name tagger leads to
state-of-the-art tagging performance in Sinhalese and Kinyarwanda, two
languages with nearly no labeled POS data available. We further demonstrate our
tagger's utility by incorporating it into a true `zero-resource' variant of the
Malopa (Ammar et al., 2016) dependency parser model that removes the current
reliance on multilingual resources and gold POS tags for new languages.
Experiments show that including our tagger makes up much of the accuracy lost
when gold POS tags are unavailable.
</summary>
    <author>
      <name>Ronald Cardenas</name>
    </author>
    <author>
      <name>Ying Lin</name>
    </author>
    <author>
      <name>Heng Ji</name>
    </author>
    <author>
      <name>Jonathan May</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL-HLT 2019, 12 pages, code available at
  https://github.com/isi-nlp/universal-cipher-pos-tagging</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05426v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05426v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05276v1</id>
    <updated>2019-04-10T16:26:51Z</updated>
    <published>2019-04-10T16:26:51Z</published>
    <title>Advances in Natural Language Question Answering: A Review</title>
    <summary>  Question Answering has recently received high attention from artificial
intelligence communities due to the advancements in learning technologies.
Early question answering models used rule-based approaches and moved to the
statistical approach to address the vastly available information. However,
statistical approaches are shown to underperform in handling the dynamic nature
and the variation of language. Therefore, learning models have shown the
capability of handling the dynamic nature and variations in language. Many deep
learning methods have been introduced to question answering. Most of the deep
learning approaches have shown to achieve higher results compared to machine
learning and statistical methods. The dynamic nature of language has profited
from the nonlinear learning in deep learning. This has created prominent
success and a spike in work on question answering. This paper discusses the
successes and challenges in question answering question answering systems and
techniques that are used in these challenges.
</summary>
    <author>
      <name>K. S. D. Ishwari</name>
    </author>
    <author>
      <name>A. K. R. R. Aneeze</name>
    </author>
    <author>
      <name>S. Sudheesan</name>
    </author>
    <author>
      <name>H. J. D. A. Karunaratne</name>
    </author>
    <author>
      <name>A. Nugaliyadde</name>
    </author>
    <author>
      <name>Y. Mallawarrachchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1609.04667 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05033v1</id>
    <updated>2019-04-10T07:44:06Z</updated>
    <published>2019-04-10T07:44:06Z</published>
    <title>Better Word Embeddings by Disentangling Contextual n-Gram Information</title>
    <summary>  Pre-trained word vectors are ubiquitous in Natural Language Processing
applications. In this paper, we show how training word embeddings jointly with
bigram and even trigram embeddings, results in improved unigram embeddings. We
claim that training word embeddings along with higher n-gram embeddings helps
in the removal of the contextual information from the unigrams, resulting in
better stand-alone word embeddings. We empirically show the validity of our
hypothesis by outperforming other competing word representation models by a
significant margin on a wide variety of tasks. We make our models publicly
available.
</summary>
    <author>
      <name>Prakhar Gupta</name>
    </author>
    <author>
      <name>Matteo Pagliardini</name>
    </author>
    <author>
      <name>Martin Jaggi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04969v1</id>
    <updated>2019-04-10T01:40:08Z</updated>
    <published>2019-04-10T01:40:08Z</published>
    <title>BAG: Bi-directional Attention Entity Graph Convolutional Network for
  Multi-hop Reasoning Question Answering</title>
    <summary>  Multi-hop reasoning question answering requires deep comprehension of
relationships between various documents and queries. We propose a
Bi-directional Attention Entity Graph Convolutional Network (BAG), leveraging
relationships between nodes in an entity graph and attention information
between a query and the entity graph, to solve this task. Graph convolutional
networks are used to obtain a relation-aware representation of nodes for entity
graphs built from documents with multi-level features. Bidirectional attention
is then applied on graphs and queries to generate a query-aware nodes
representation, which will be used for the final prediction. Experimental
evaluation shows BAG achieves state-of-the-art accuracy performance on the
QAngaroo WIKIHOP dataset.
</summary>
    <author>
      <name>Yu Cao</name>
    </author>
    <author>
      <name>Meng Fang</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, accepted short paper on NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.04969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04764v1</id>
    <updated>2019-04-09T16:20:52Z</updated>
    <published>2019-04-09T16:20:52Z</published>
    <title>Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS</title>
    <summary>  The end-to-end TTS, which can predict speech directly from a given sequence
of graphemes or phonemes, has shown improved performance over the conventional
TTS. However, its predicting capability is still limited by the
acoustic/phonetic coverage of the training data, usually constrained by the
training set size. To further improve the TTS quality in pronunciation, prosody
and perceived naturalness, we propose to exploit the information embedded in a
syntactically parsed tree where the inter-phrase/word information of a sentence
is organized in a multilevel tree structure. Specifically, two key features:
phrase structure and relations between adjacent words are investigated.
Experimental results in subjective listening, measured on three test sets, show
that the proposed approach is effective to improve the pronunciation clarity,
prosody and naturalness of the synthesized speech of the baseline system.
</summary>
    <author>
      <name>Haohan Guo</name>
    </author>
    <author>
      <name>Frank K. Soong</name>
    </author>
    <author>
      <name>Lei He</name>
    </author>
    <author>
      <name>Lei Xie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Interspeech 2019, Graz, Austria</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.04764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04697v2</id>
    <updated>2019-12-18T10:07:33Z</updated>
    <published>2019-04-09T14:25:17Z</published>
    <title>A Graph-based Model for Joint Chinese Word Segmentation and Dependency
  Parsing</title>
    <summary>  Chinese word segmentation and dependency parsing are two fundamental tasks
for Chinese natural language processing. The dependency parsing is defined on
word-level. Therefore word segmentation is the precondition of dependency
parsing, which makes dependency parsing suffer from error propagation and
unable to directly make use of the character-level pre-trained language model
(such as BERT). In this paper, we propose a graph-based model to integrate
Chinese word segmentation and dependency parsing. Different from previous
transition-based joint models, our proposed model is more concise, which
results in fewer efforts of feature engineering. Our graph-based joint model
achieves better performance than previous joint models and state-of-the-art
results in both Chinese word segmentation and dependency parsing. Besides, when
BERT is combined, our model can substantially reduce the performance gap of
dependency parsing between joint models and gold-segmented word-based models.
Our code is publicly available at https://github.com/fastnlp/JointCwsParser.
</summary>
    <author>
      <name>Hang Yan</name>
    </author>
    <author>
      <name>Xipeng Qiu</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Transactions of the Association for Computational
  Linguistics (TACL)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.04697v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04697v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04458v2</id>
    <updated>2019-06-24T07:48:21Z</updated>
    <published>2019-04-09T04:09:45Z</published>
    <title>Knowledge-Augmented Language Model and its Application to Unsupervised
  Named-Entity Recognition</title>
    <summary>  Traditional language models are unable to efficiently model entity names
observed in text. All but the most popular named entities appear infrequently
in text providing insufficient context. Recent efforts have recognized that
context can be generalized between entity names that share the same type (e.g.,
\emph{person} or \emph{location}) and have equipped language models with access
to an external knowledge base (KB). Our Knowledge-Augmented Language Model
(KALM) continues this line of work by augmenting a traditional model with a KB.
Unlike previous methods, however, we train with an end-to-end predictive
objective optimizing the perplexity of text. We do not require any additional
information such as named entity tags. In addition to improving language
modeling performance, KALM learns to recognize named entities in an entirely
unsupervised way by using entity type information latent in the model. On a
Named Entity Recognition (NER) task, KALM achieves performance comparable with
state-of-the-art supervised models. Our work demonstrates that named entities
(and possibly other types of world knowledge) can be modeled successfully using
predictive learning and training on large corpora of text without any
additional information.
</summary>
    <author>
      <name>Angli Liu</name>
    </author>
    <author>
      <name>Jingfei Du</name>
    </author>
    <author>
      <name>Veselin Stoyanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019; updated to cite Zhou et al. (2018) EMNLP as a piece of
  related work</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.04458v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04458v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04388v1</id>
    <updated>2019-04-08T22:47:37Z</updated>
    <published>2019-04-08T22:47:37Z</published>
    <title>Giving Attention to the Unexpected: Using Prosody Innovations in
  Disfluency Detection</title>
    <summary>  Disfluencies in spontaneous speech are known to be associated with prosodic
disruptions. However, most algorithms for disfluency detection use only word
transcripts. Integrating prosodic cues has proved difficult because of the many
sources of variability affecting the acoustic correlates. This paper introduces
a new approach to extracting acoustic-prosodic cues using text-based
distributional prediction of acoustic cues to derive vector z-score features
(innovations). We explore both early and late fusion techniques for integrating
text and prosody, showing gains over a high-accuracy text-only model.
</summary>
    <author>
      <name>Vicky Zayats</name>
    </author>
    <author>
      <name>Mari Ostendorf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.04388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03898v1</id>
    <updated>2019-04-08T09:07:30Z</updated>
    <published>2019-04-08T09:07:30Z</published>
    <title>Semi-Supervised Few-Shot Learning for Dual Question-Answer Extraction</title>
    <summary>  This paper addresses the problem of key phrase extraction from sentences.
Existing state-of-the-art supervised methods require large amounts of annotated
data to achieve good performance and generalization. Collecting labeled data
is, however, often expensive. In this paper, we redefine the problem as
question-answer extraction, and present SAMIE: Self-Asking Model for
Information Ixtraction, a semi-supervised model which dually learns to ask and
to answer questions by itself. Briefly, given a sentence $s$ and an answer $a$,
the model needs to choose the most appropriate question $\hat q$; meanwhile,
for the given sentence $s$ and same question $\hat q$ selected in the previous
step, the model will predict an answer $\hat a$. The model can support few-shot
learning with very limited supervision. It can also be used to perform
clustering analysis when no supervision is provided. Experimental results show
that the proposed method outperforms typical supervised methods especially when
given little labeled data.
</summary>
    <author>
      <name>Jue Wang</name>
    </author>
    <author>
      <name>Ke Chen</name>
    </author>
    <author>
      <name>Lidan Shou</name>
    </author>
    <author>
      <name>Sai Wu</name>
    </author>
    <author>
      <name>Sharad Mehrotra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures, submission to IJCAI19</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03736v2</id>
    <updated>2019-06-25T01:54:46Z</updated>
    <published>2019-04-07T20:28:47Z</published>
    <title>Unsupervised Dialog Structure Learning</title>
    <summary>  Learning a shared dialog structure from a set of task-oriented dialogs is an
important challenge in computational linguistics. The learned dialog structure
can shed light on how to analyze human dialogs, and more importantly contribute
to the design and evaluation of dialog systems. We propose to extract dialog
structures using a modified VRNN model with discrete latent vectors. Different
from existing HMM-based models, our model is based on variational-autoencoder
(VAE). Such model is able to capture more dynamics in dialogs beyond the
surface forms of the language. We find that qualitatively, our method extracts
meaningful dialog structure, and quantitatively, outperforms previous models on
the ability to predict unseen data. We further evaluate the model's
effectiveness in a downstream task, the dialog system building task.
Experiments show that, by integrating the learned dialog structure into the
reward function design, the model converges faster and to a better outcome in a
reinforcement learning setting.
</summary>
    <author>
      <name>Weiyan Shi</name>
    </author>
    <author>
      <name>Tiancheng Zhao</name>
    </author>
    <author>
      <name>Zhou Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long paper accepted by NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03736v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03736v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03461v1</id>
    <updated>2019-04-06T14:50:11Z</updated>
    <published>2019-04-06T14:50:11Z</published>
    <title>Embodied Question Answering in Photorealistic Environments with Point
  Cloud Perception</title>
    <summary>  To help bridge the gap between internet vision-style problems and the goal of
vision for embodied perception we instantiate a large-scale navigation task --
Embodied Question Answering [1] in photo-realistic environments (Matterport
3D). We thoroughly study navigation policies that utilize 3D point clouds, RGB
images, or their combination. Our analysis of these models reveals several key
findings. We find that two seemingly naive navigation baselines, forward-only
and random, are strong navigators and challenging to outperform, due to the
specific choice of the evaluation setting presented by [1]. We find a novel
loss-weighting scheme we call Inflection Weighting to be important when
training recurrent models for navigation with behavior cloning and are able to
out perform the baselines with this technique. We find that point clouds
provide a richer signal than RGB images for learning obstacle avoidance,
motivating the use (and continued study) of 3D deep learning models for
embodied navigation.
</summary>
    <author>
      <name>Erik Wijmans</name>
    </author>
    <author>
      <name>Samyak Datta</name>
    </author>
    <author>
      <name>Oleksandr Maksymets</name>
    </author>
    <author>
      <name>Abhishek Das</name>
    </author>
    <author>
      <name>Georgia Gkioxari</name>
    </author>
    <author>
      <name>Stefan Lee</name>
    </author>
    <author>
      <name>Irfan Essa</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <link href="http://arxiv.org/abs/1904.03461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03396v2</id>
    <updated>2019-05-01T20:58:28Z</updated>
    <published>2019-04-06T09:25:32Z</published>
    <title>Step-by-Step: Separating Planning from Realization in Neural
  Data-to-Text Generation</title>
    <summary>  Data-to-text generation can be conceptually divided into two parts: ordering
and structuring the information (planning), and generating fluent language
describing the information (realization). Modern neural generation systems
conflate these two steps into a single end-to-end differentiable system. We
propose to split the generation process into a symbolic text-planning stage
that is faithful to the input, followed by a neural generation stage that
focuses only on realization. For training a plan-to-text generator, we present
a method for matching reference texts to their corresponding text plans. For
inference time, we describe a method for selecting high-quality text plans for
new inputs. We implement and evaluate our approach on the WebNLG benchmark. Our
results demonstrate that decoupling text planning from neural realization
indeed improves the system's reliability and adequacy while maintaining fluent
output. We observe improvements both in BLEU scores and in manual evaluations.
Another benefit of our approach is the ability to output diverse realizations
of the same input, paving the way to explicit control over the generated text
structure.
</summary>
    <author>
      <name>Amit Moryossef</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <author>
      <name>Ido Dagan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 main pages, 10 appendix pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03396v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03396v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03266v1</id>
    <updated>2019-04-05T20:27:26Z</updated>
    <published>2019-04-05T20:27:26Z</published>
    <title>Domain Authoring Assistant for Intelligent Virtual Agents</title>
    <summary>  Developing intelligent virtual characters has attracted a lot of attention in
the recent years. The process of creating such characters often involves a team
of creative authors who describe different aspects of the characters in natural
language, and planning experts that translate this description into a planning
domain. This can be quite challenging as the team of creative authors should
diligently define every aspect of the character especially if it contains
complex human-like behavior. Also a team of engineers has to manually translate
the natural language description of a character's personality into the planning
domain knowledge. This can be extremely time and resource demanding and can be
an obstacle to author's creativity. The goal of this paper is to introduce an
authoring assistant tool to automate the process of domain generation from
natural language description of virtual characters, thus bridging between the
creative authoring team and the planning domain experts. Moreover, the proposed
tool also identifies possible missing information in the domain description and
iteratively makes suggestions to the author.
</summary>
    <author>
      <name>Sepehr Janghorbani</name>
    </author>
    <author>
      <name>Ashutosh Modi</name>
    </author>
    <author>
      <name>Jakob Buhmann</name>
    </author>
    <author>
      <name>Mubbasir Kapadia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8+1 pages, Accepted at 18th International Conference on Autonomous
  Agents and Multiagent Systems (AAMAS 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03244v1</id>
    <updated>2019-04-05T19:22:47Z</updated>
    <published>2019-04-05T19:22:47Z</published>
    <title>An Analysis of Attention over Clinical Notes for Predictive Tasks</title>
    <summary>  The shift to electronic medical records (EMRs) has engendered research into
machine learning and natural language technologies to analyze patient records,
and to predict from these clinical outcomes of interest. Two observations
motivate our aims here. First, unstructured notes contained within EMR often
contain key information, and hence should be exploited by models. Second, while
strong predictive performance is important, interpretability of models is
perhaps equally so for applications in this domain. Together, these points
suggest that neural models for EMR may benefit from incorporation of attention
over notes, which one may hope will both yield performance gains and afford
transparency in predictions. In this work we perform experiments to explore
this question using two EMR corpora and four different predictive tasks, that:
(i) inclusion of attention mechanisms is critical for neural encoder modules
that operate over notes fields in order to yield competitive performance, but,
(ii) unfortunately, while these boost predictive performance, it is decidedly
less clear whether they provide meaningful support for predictions.
</summary>
    <author>
      <name>Sarthak Jain</name>
    </author>
    <author>
      <name>Ramin Mohammadi</name>
    </author>
    <author>
      <name>Byron C. Wallace</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at The 2nd Clinical Natural Language Processing Workshop (At
  NAACL 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03107v1</id>
    <updated>2019-04-05T15:02:26Z</updated>
    <published>2019-04-05T15:02:26Z</published>
    <title>Convolutional Self-Attention Networks</title>
    <summary>  Self-attention networks (SANs) have drawn increasing interest due to their
high parallelization in computation and flexibility in modeling dependencies.
SANs can be further enhanced with multi-head attention by allowing the model to
attend to information from different representation subspaces. In this work, we
propose novel convolutional self-attention networks, which offer SANs the
abilities to 1) strengthen dependencies among neighboring elements, and 2)
model the interaction between features extracted by multiple attention heads.
Experimental results of machine translation on different language pairs and
model settings show that our approach outperforms both the strong Transformer
baseline and other existing models on enhancing the locality of SANs. Comparing
with prior studies, the proposed model is parameter free in terms of
introducing no more parameters.
</summary>
    <author>
      <name>Baosong Yang</name>
    </author>
    <author>
      <name>Longyue Wang</name>
    </author>
    <author>
      <name>Derek Wong</name>
    </author>
    <author>
      <name>Lidia S. Chao</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03100v1</id>
    <updated>2019-04-05T14:52:28Z</updated>
    <published>2019-04-05T14:52:28Z</published>
    <title>Information Aggregation for Multi-Head Attention with
  Routing-by-Agreement</title>
    <summary>  Multi-head attention is appealing for its ability to jointly extract
different types of information from multiple representation subspaces.
Concerning the information aggregation, a common practice is to use a
concatenation followed by a linear transformation, which may not fully exploit
the expressiveness of multi-head attention. In this work, we propose to improve
the information aggregation for multi-head attention with a more powerful
routing-by-agreement algorithm. Specifically, the routing algorithm iteratively
updates the proportion of how much a part (i.e. the distinct information
learned from a specific subspace) should be assigned to a whole (i.e. the final
output representation), based on the agreement between parts and wholes.
Experimental results on linguistic probing tasks and machine translation tasks
prove the superiority of the advanced information aggregation over the standard
linear transformation.
</summary>
    <author>
      <name>Jian Li</name>
    </author>
    <author>
      <name>Baosong Yang</name>
    </author>
    <author>
      <name>Zi-Yi Dou</name>
    </author>
    <author>
      <name>Xing Wang</name>
    </author>
    <author>
      <name>Michael R. Lyu</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03092v1</id>
    <updated>2019-04-05T14:40:22Z</updated>
    <published>2019-04-05T14:40:22Z</published>
    <title>Modeling Recurrence for Transformer</title>
    <summary>  Recently, the Transformer model that is based solely on attention mechanisms,
has advanced the state-of-the-art on various machine translation tasks.
However, recent studies reveal that the lack of recurrence hinders its further
improvement of translation capacity. In response to this problem, we propose to
directly model recurrence for Transformer with an additional recurrence
encoder. In addition to the standard recurrent neural network, we introduce a
novel attentive recurrent network to leverage the strengths of both attention
and recurrent networks. Experimental results on the widely-used WMT14
English-German and WMT17 Chinese-English translation tasks demonstrate the
effectiveness of the proposed approach. Our studies also reveal that the
proposed model benefits from a short-cut that bridges the source and target
sequences with a single recurrent layer, which outperforms its deep
counterpart.
</summary>
    <author>
      <name>Jie Hao</name>
    </author>
    <author>
      <name>Xing Wang</name>
    </author>
    <author>
      <name>Baosong Yang</name>
    </author>
    <author>
      <name>Longyue Wang</name>
    </author>
    <author>
      <name>Jinfeng Zhang</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03084v1</id>
    <updated>2019-04-05T14:25:25Z</updated>
    <published>2019-04-05T14:25:25Z</published>
    <title>CLEARumor at SemEval-2019 Task 7: ConvoLving ELMo Against Rumors</title>
    <summary>  This paper describes our submission to SemEval-2019 Task 7: RumourEval:
Determining Rumor Veracity and Support for Rumors. We participated in both
subtasks. The goal of subtask A is to classify the type of interaction between
a rumorous social media post and a reply post as support, query, deny, or
comment. The goal of subtask B is to predict the veracity of a given rumor. For
subtask A, we implement a CNN-based neural architecture using ELMo embeddings
of post text combined with auxiliary features and achieve a F1-score of 44.6%.
For subtask B, we employ a MLP neural network leveraging our estimates for
subtask A and achieve a F1-score of 30.1% (second place in the competition). We
provide results and analysis of our system performance and present ablation
experiments.
</summary>
    <author>
      <name>Ipek Baris</name>
    </author>
    <author>
      <name>Lukas Schmelzeisen</name>
    </author>
    <author>
      <name>Steffen Staab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, 3 tables. Accepted for publication at
  SemEval@NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.03084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02856v1</id>
    <updated>2019-04-05T03:17:00Z</updated>
    <published>2019-04-05T03:17:00Z</published>
    <title>Graph Pattern Entity Ranking Model for Knowledge Graph Completion</title>
    <summary>  Knowledge graphs have evolved rapidly in recent years and their usefulness
has been demonstrated in many artificial intelligence tasks. However, knowledge
graphs often have lots of missing facts. To solve this problem, many knowledge
graph embedding models have been developed to populate knowledge graphs and
these have shown outstanding performance. However, knowledge graph embedding
models are so-called black boxes, and the user does not know how the
information in a knowledge graph is processed and the models can be difficult
to interpret. In this paper, we utilize graph patterns in a knowledge graph to
overcome such problems. Our proposed model, the {\it graph pattern entity
ranking model} (GRank), constructs an entity ranking system for each graph
pattern and evaluates them using a ranking measure. By doing so, we can find
graph patterns which are useful for predicting facts. Then, we perform link
prediction tasks on standard datasets to evaluate our GRank method. We show
that our approach outperforms other state-of-the-art approaches such as ComplEx
and TorusE for standard metrics such as HITS@{\it n} and MRR. Moreover, our
model is easily interpretable because the output facts are described by graph
patterns.
</summary>
    <author>
      <name>Takuma Ebisu</name>
    </author>
    <author>
      <name>Ryutaro Ichise</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02815v1</id>
    <updated>2019-04-04T22:54:57Z</updated>
    <published>2019-04-04T22:54:57Z</published>
    <title>Topic Spotting using Hierarchical Networks with Self Attention</title>
    <summary>  Success of deep learning techniques have renewed the interest in development
of dialogue systems. However, current systems struggle to have consistent long
term conversations with the users and fail to build rapport. Topic spotting,
the task of automatically inferring the topic of a conversation, has been shown
to be helpful in making a dialog system more engaging and efficient. We propose
a hierarchical model with self attention for topic spotting. Experiments on the
Switchboard corpus show the superior performance of our model over previously
proposed techniques for topic spotting and deep models for text classification.
Additionally, in contrast to offline processing of dialog, we also analyze the
performance of our model in a more realistic setting i.e. in an online setting
where the topic is identified in real time as the dialog progresses. Results
show that our model is able to generalize even with limited information in the
online setting.
</summary>
    <author>
      <name>Pooja Chitkara</name>
    </author>
    <author>
      <name>Ashutosh Modi</name>
    </author>
    <author>
      <name>Pravalika Avvaru</name>
    </author>
    <author>
      <name>Sepehr Janghorbani</name>
    </author>
    <author>
      <name>Mubbasir Kapadia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5+2 Pages, Accepted at NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02793v1</id>
    <updated>2019-04-04T21:05:13Z</updated>
    <published>2019-04-04T21:05:13Z</published>
    <title>Affect-Driven Dialog Generation</title>
    <summary>  The majority of current systems for end-to-end dialog generation focus on
response quality without an explicit control over the affective content of the
responses. In this paper, we present an affect-driven dialog system, which
generates emotional responses in a controlled manner using a continuous
representation of emotions. The system achieves this by modeling emotions at a
word and sequence level using: (1) a vector representation of the desired
emotion, (2) an affect regularizer, which penalizes neutral words, and (3) an
affect sampling method, which forces the neural network to generate diverse
words that are emotionally relevant. During inference, we use a reranking
procedure that aims to extract the most emotionally relevant responses using a
human-in-the-loop optimization process. We study the performance of our system
in terms of both quantitative (BLEU score and response diversity), and
qualitative (emotional appropriateness) measures.
</summary>
    <author>
      <name>Pierre Colombo</name>
    </author>
    <author>
      <name>Wojciech Witon</name>
    </author>
    <author>
      <name>Ashutosh Modi</name>
    </author>
    <author>
      <name>James Kennedy</name>
    </author>
    <author>
      <name>Mubbasir Kapadia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8+2 Pages, Accepted at NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02792v1</id>
    <updated>2019-04-04T21:03:34Z</updated>
    <published>2019-04-04T21:03:34Z</published>
    <title>Unifying Human and Statistical Evaluation for Natural Language
  Generation</title>
    <summary>  How can we measure whether a natural language generation system produces both
high quality and diverse outputs? Human evaluation captures quality but not
diversity, as it does not catch models that simply plagiarize from the training
set. On the other hand, statistical evaluation (i.e., perplexity) captures
diversity but not quality, as models that occasionally emit low quality samples
would be insufficiently penalized. In this paper, we propose a unified
framework which evaluates both diversity and quality, based on the optimal
error rate of predicting whether a sentence is human- or machine-generated. We
demonstrate that this error rate can be efficiently estimated by combining
human and statistical evaluation, using an evaluation metric which we call
HUSE. On summarization and chit-chat dialogue, we show that (i) HUSE detects
diversity defects which fool pure human evaluation and that (ii) techniques
such as annealing for improving quality actually decrease HUSE due to decreased
diversity.
</summary>
    <author>
      <name>Tatsunori B. Hashimoto</name>
    </author>
    <author>
      <name>Hugh Zhang</name>
    </author>
    <author>
      <name>Percy Liang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL Camera Ready Submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.02792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02547v1</id>
    <updated>2019-04-04T13:34:18Z</updated>
    <published>2019-04-04T13:34:18Z</published>
    <title>Robust Evaluation of Language-Brain Encoding Experiments</title>
    <summary>  Language-brain encoding experiments evaluate the ability of language models
to predict brain responses elicited by language stimuli. The evaluation
scenarios for this task have not yet been standardized which makes it difficult
to compare and interpret results. We perform a series of evaluation experiments
with a consistent encoding setup and compute the results for multiple fMRI
datasets. In addition, we test the sensitivity of the evaluation measures to
randomized data and analyze the effect of voxel selection methods. Our
experimental framework is publicly available to make modelling decisions more
transparent and support reproducibility for future comparisons.
</summary>
    <author>
      <name>Lisa Beinborn</name>
    </author>
    <author>
      <name>Samira Abnar</name>
    </author>
    <author>
      <name>Rochelle Choenni</name>
    </author>
    <link href="http://arxiv.org/abs/1904.02547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02418v1</id>
    <updated>2019-04-04T09:11:24Z</updated>
    <published>2019-04-04T09:11:24Z</published>
    <title>Learning to Decipher Hate Symbols</title>
    <summary>  Existing computational models to understand hate speech typically frame the
problem as a simple classification task, bypassing the understanding of hate
symbols (e.g., 14 words, kigy) and their secret connotations. In this paper, we
propose a novel task of deciphering hate symbols. To do this, we leverage the
Urban Dictionary and collected a new, symbol-rich Twitter corpus of hate
speech. We investigate neural network latent context models for deciphering
hate symbols. More specifically, we study Sequence-to-Sequence models and show
how they are able to crack the ciphers based on context. Furthermore, we
propose a novel Variational Decipher and show how it can generalize better to
unseen hate symbols in a more challenging testing setting.
</summary>
    <author>
      <name>Jing Qian</name>
    </author>
    <author>
      <name>Mai ElSherief</name>
    </author>
    <author>
      <name>Elizabeth Belding</name>
    </author>
    <author>
      <name>William Yang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1904.02418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.02293v1</id>
    <updated>2019-04-04T01:17:29Z</updated>
    <published>2019-04-04T01:17:29Z</published>
    <title>Generative Adversarial Networks for text using word2vec intermediaries</title>
    <summary>  Generative adversarial networks (GANs) have shown considerable success,
especially in the realistic generation of images. In this work, we apply
similar techniques for the generation of text. We propose a novel approach to
handle the discrete nature of text, during training, using word embeddings. Our
method is agnostic to vocabulary size and achieves competitive results relative
to methods with various discrete gradient estimators.
</summary>
    <author>
      <name>Akshay Budhkar</name>
    </author>
    <author>
      <name>Krishnapriya Vishnubhotla</name>
    </author>
    <author>
      <name>Safwan Hossain</name>
    </author>
    <author>
      <name>Frank Rudzicz</name>
    </author>
    <link href="http://arxiv.org/abs/1904.02293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.02293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.01664v1</id>
    <updated>2019-04-02T20:51:27Z</updated>
    <published>2019-04-02T20:51:27Z</published>
    <title>Mirroring to Build Trust in Digital Assistants</title>
    <summary>  We describe experiments towards building a conversational digital assistant
that considers the preferred conversational style of the user. In particular,
these experiments are designed to measure whether users prefer and trust an
assistant whose conversational style matches their own. To this end we
conducted a user study where subjects interacted with a digital assistant that
responded in a way that either matched their conversational style, or did not.
Using self-reported personality attributes and subjects' feedback on the
interactions, we built models that can reliably predict a user's preferred
conversational style.
</summary>
    <author>
      <name>Katherine Metcalf</name>
    </author>
    <author>
      <name>Barry-John Theobald</name>
    </author>
    <author>
      <name>Garrett Weinberg</name>
    </author>
    <author>
      <name>Robert Lee</name>
    </author>
    <author>
      <name>Ing-Marie Jonsson</name>
    </author>
    <author>
      <name>Russ Webb</name>
    </author>
    <author>
      <name>Nicholas Apostoloff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.01664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.01664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.01650v2</id>
    <updated>2019-07-31T18:18:01Z</updated>
    <published>2019-04-02T20:18:52Z</published>
    <title>Improving Robot Success Detection using Static Object Data</title>
    <summary>  We use static object data to improve success detection for stacking objects
on and nesting objects in one another. Such actions are necessary for certain
robotics tasks, e.g., clearing a dining table or packing a warehouse bin.
However, using an RGB-D camera to detect success can be insufficient:
same-colored objects can be difficult to differentiate, and reflective
silverware cause noisy depth camera perception. We show that adding static data
about the objects themselves improves the performance of an end-to-end pipeline
for classifying action outcomes. Images of the objects, and language
expressions describing them, encode prior geometry, shape, and size information
that refine classification accuracy. We collect over 13 hours of egocentric
manipulation data for training a model to reason about whether a robot
successfully placed unseen objects in or on one another. The model achieves up
to a 57% absolute gain over the task baseline on pairs of previously unseen
objects.
</summary>
    <author>
      <name>Rosario Scalise</name>
    </author>
    <author>
      <name>Jesse Thomason</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Siddhartha Srinivasa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IROS 2019 + Appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.01650v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.01650v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.01201v2</id>
    <updated>2019-11-25T01:39:04Z</updated>
    <published>2019-04-02T03:52:27Z</published>
    <title>Habitat: A Platform for Embodied AI Research</title>
    <summary>  We present Habitat, a platform for research in embodied artificial
intelligence (AI). Habitat enables training embodied agents (virtual robots) in
highly efficient photorealistic 3D simulation. Specifically, Habitat consists
of: (i) Habitat-Sim: a flexible, high-performance 3D simulator with
configurable agents, sensors, and generic 3D dataset handling. Habitat-Sim is
fast -- when rendering a scene from Matterport3D, it achieves several thousand
frames per second (fps) running single-threaded, and can reach over 10,000 fps
multi-process on a single GPU. (ii) Habitat-API: a modular high-level library
for end-to-end development of embodied AI algorithms -- defining tasks (e.g.,
navigation, instruction following, question answering), configuring, training,
and benchmarking embodied agents.
  These large-scale engineering contributions enable us to answer scientific
questions requiring experiments that were till now impracticable or 'merely'
impractical. Specifically, in the context of point-goal navigation: (1) we
revisit the comparison between learning and SLAM approaches from two recent
works and find evidence for the opposite conclusion -- that learning
outperforms SLAM if scaled to an order of magnitude more experience than
previous investigations, and (2) we conduct the first cross-dataset
generalization experiments {train, test} x {Matterport3D, Gibson} for multiple
sensors {blind, RGB, RGBD, D} and find that only agents with depth (D) sensors
generalize across datasets. We hope that our open-source platform and these
findings will advance research in embodied AI.
</summary>
    <author>
      <name>Manolis Savva</name>
    </author>
    <author>
      <name>Abhishek Kadian</name>
    </author>
    <author>
      <name>Oleksandr Maksymets</name>
    </author>
    <author>
      <name>Yili Zhao</name>
    </author>
    <author>
      <name>Erik Wijmans</name>
    </author>
    <author>
      <name>Bhavana Jain</name>
    </author>
    <author>
      <name>Julian Straub</name>
    </author>
    <author>
      <name>Jia Liu</name>
    </author>
    <author>
      <name>Vladlen Koltun</name>
    </author>
    <author>
      <name>Jitendra Malik</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICCV 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.01201v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.01201v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.01138v2</id>
    <updated>2019-07-06T23:05:09Z</updated>
    <published>2019-04-01T23:08:05Z</published>
    <title>Benchmarking Approximate Inference Methods for Neural Structured
  Prediction</title>
    <summary>  Exact structured inference with neural network scoring functions is
computationally challenging but several methods have been proposed for
approximating inference. One approach is to perform gradient descent with
respect to the output structure directly (Belanger and McCallum, 2016). Another
approach, proposed recently, is to train a neural network (an "inference
network") to perform inference (Tu and Gimpel, 2018). In this paper, we compare
these two families of inference methods on three sequence labeling datasets. We
choose sequence labeling because it permits us to use exact inference as a
benchmark in terms of speed, accuracy, and search error. Across datasets, we
demonstrate that inference networks achieve a better speed/accuracy/search
error trade-off than gradient descent, while also being faster than exact
inference at similar accuracy levels. We find further benefit by combining
inference networks and gradient descent, using the former to provide a warm
start for the latter.
</summary>
    <author>
      <name>Lifu Tu</name>
    </author>
    <author>
      <name>Kevin Gimpel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL2019 camera-ready version</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.01138v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.01138v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.00962v5</id>
    <updated>2020-01-03T06:53:00Z</updated>
    <published>2019-04-01T16:53:35Z</published>
    <title>Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</title>
    <summary>  Training large deep neural networks on massive datasets is computationally
very challenging. There has been recent surge in interest in using large batch
stochastic optimization methods to tackle this issue. The most prominent
algorithm in this line of research is LARS, which by employing layerwise
adaptive learning rates trains ResNet on ImageNet in a few minutes. However,
LARS performs poorly for attention models like BERT, indicating that its
performance gains are not consistent across tasks. In this paper, we first
study a principled layerwise adaptation strategy to accelerate training of deep
neural networks using large mini-batches. Using this strategy, we develop a new
layerwise adaptive large batch optimization technique called LAMB; we then
provide convergence analysis of LAMB as well as LARS, showing convergence to a
stationary point in general nonconvex settings. Our empirical results
demonstrate the superior performance of LAMB across various tasks such as BERT
and ResNet-50 training with very little hyperparameter tuning. In particular,
for BERT training, our optimizer enables use of very large batch sizes of 32868
without any degradation of performance. By increasing the batch size to the
memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to
just 76 minutes (Table 1). The LAMB implementation is available at
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py
</summary>
    <author>
      <name>Yang You</name>
    </author>
    <author>
      <name>Jing Li</name>
    </author>
    <author>
      <name>Sashank Reddi</name>
    </author>
    <author>
      <name>Jonathan Hseu</name>
    </author>
    <author>
      <name>Sanjiv Kumar</name>
    </author>
    <author>
      <name>Srinadh Bhojanapalli</name>
    </author>
    <author>
      <name>Xiaodan Song</name>
    </author>
    <author>
      <name>James Demmel</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <author>
      <name>Cho-Jui Hsieh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at ICLR 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.00962v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.00962v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.00143v1</id>
    <updated>2019-03-30T03:55:20Z</updated>
    <published>2019-03-30T03:55:20Z</published>
    <title>Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag
  Attentions</title>
    <summary>  This paper presents a neural relation extraction method to deal with the
noisy training data generated by distant supervision. Previous studies mainly
focus on sentence-level de-noising by designing neural networks with intra-bag
attentions. In this paper, both intra-bag and inter-bag attentions are
considered in order to deal with the noise at sentence-level and bag-level
respectively. First, relation-aware bag representations are calculated by
weighting sentence embeddings using intra-bag attentions. Here, each possible
relation is utilized as the query for attention calculation instead of only
using the target relation in conventional methods. Furthermore, the
representation of a group of bags in the training set which share the same
relation label is calculated by weighting bag representations using a
similarity-based inter-bag attention module. Finally, a bag group is utilized
as a training sample when building our relation extractor. Experimental results
on the New York Times dataset demonstrate the effectiveness of our proposed
intra-bag and inter-bag attention modules. Our method also achieves better
relation extraction accuracy than state-of-the-art methods on this dataset.
</summary>
    <author>
      <name>Zhi-Xiu Ye</name>
    </author>
    <author>
      <name>Zhen-Hua Ling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.00143v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.00143v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.12356v1</id>
    <updated>2019-03-29T05:15:58Z</updated>
    <published>2019-03-29T05:15:58Z</published>
    <title>A General FOFE-net Framework for Simple and Effective Question Answering
  over Knowledge Bases</title>
    <summary>  Question answering over knowledge base (KB-QA) has recently become a popular
research topic in NLP. One popular way to solve the KB-QA problem is to make
use of a pipeline of several NLP modules, including entity discovery and
linking (EDL) and relation detection. Recent success on KB-QA task usually
involves complex network structures with sophisticated heuristics. Inspired by
a previous work that builds a strong KB-QA baseline, we propose a simple but
general neural model composed of fixed-size ordinally forgetting encoding
(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at
different stages. For evaluation, we use two popular KB-QA datasets,
SimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The
experimental results show that FOFE-net performs well on KB-QA subtasks, entity
discovery and linking (EDL) and relation detection, and in turn pushing overall
KB-QA system to achieve strong results on all datasets.
</summary>
    <author>
      <name>Dekun Wu</name>
    </author>
    <author>
      <name>Nana Nosirova</name>
    </author>
    <author>
      <name>Hui Jiang</name>
    </author>
    <author>
      <name>Mingbin Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.12356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.12356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.12354v2</id>
    <updated>2019-09-23T08:40:06Z</updated>
    <published>2019-03-29T05:02:51Z</published>
    <title>Training neural networks to encode symbols enables combinatorial
  generalization</title>
    <summary>  Combinatorial generalization - the ability to understand and produce novel
combinations of already familiar elements - is considered to be a core capacity
of the human mind and a major challenge to neural network models. A significant
body of research suggests that conventional neural networks can't solve this
problem unless they are endowed with mechanisms specifically engineered for the
purpose of representing symbols. In this paper we introduce a novel way of
representing symbolic structures in connectionist terms - the vectors approach
to representing symbols (VARS), which allows training standard neural
architectures to encode symbolic knowledge explicitly at their output layers.
In two simulations, we show that neural networks not only can learn to produce
VARS representations, but in doing so they achieve combinatorial generalization
in their symbolic and non-symbolic output. This adds to other recent work that
has shown improved combinatorial generalization under specific training
conditions, and raises the question of whether specific mechanisms or training
routines are needed to support symbolic processing.
</summary>
    <author>
      <name>Ivan Vankov</name>
    </author>
    <author>
      <name>Jeffrey Bowers</name>
    </author>
    <link href="http://arxiv.org/abs/1903.12354v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.12354v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.11570v1</id>
    <updated>2019-03-27T17:33:33Z</updated>
    <published>2019-03-27T17:33:33Z</published>
    <title>Visualization and Interpretation of Latent Spaces for Controlling
  Expressive Speech Synthesis through Audio Analysis</title>
    <summary>  The field of Text-to-Speech has experienced huge improvements last years
benefiting from deep learning techniques. Producing realistic speech becomes
possible now. As a consequence, the research on the control of the
expressiveness, allowing to generate speech in different styles or manners, has
attracted increasing attention lately. Systems able to control style have been
developed and show impressive results. However the control parameters often
consist of latent variables and remain complex to interpret. In this paper, we
analyze and compare different latent spaces and obtain an interpretation of
their influence on expressive speech. This will enable the possibility to build
controllable speech synthesis systems with an understandable behaviour.
</summary>
    <author>
      <name>Noé Tits</name>
    </author>
    <author>
      <name>Fengna Wang</name>
    </author>
    <author>
      <name>Kevin El Haddad</name>
    </author>
    <author>
      <name>Vincent Pagel</name>
    </author>
    <author>
      <name>Thierry Dutoit</name>
    </author>
    <link href="http://arxiv.org/abs/1903.11570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.11570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.11367v2</id>
    <updated>2019-03-28T08:40:05Z</updated>
    <published>2019-03-27T12:00:20Z</published>
    <title>Does My Rebuttal Matter? Insights from a Major NLP Conference</title>
    <summary>  Peer review is a core element of the scientific process, particularly in
conference-centered fields such as ML and NLP. However, only few studies have
evaluated its properties empirically. Aiming to fill this gap, we present a
corpus that contains over 4k reviews and 1.2k author responses from ACL-2018.
We quantitatively and qualitatively assess the corpus. This includes a pilot
study on paper weaknesses given by reviewers and on quality of author
responses. We then focus on the role of the rebuttal phase, and propose a novel
task to predict after-rebuttal (i.e., final) scores from initial reviews and
author responses. Although author responses do have a marginal (and
statistically significant) influence on the final scores, especially for
borderline papers, our results suggest that a reviewer's final score is largely
determined by her initial score and the distance to the other reviewers'
initial scores. In this context, we discuss the conformity bias inherent to
peer reviewing, a bias that has largely been overlooked in previous research.
We hope our analyses will help better assess the usefulness of the rebuttal
phase in NLP conferences.
</summary>
    <author>
      <name>Yang Gao</name>
    </author>
    <author>
      <name>Steffen Eger</name>
    </author>
    <author>
      <name>Ilia Kuznetsov</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <author>
      <name>Yusuke Miyao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to NAACL-HLT 2019. Main paper plus supplementary material</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.11367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.11367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10716v4</id>
    <updated>2019-09-11T12:58:44Z</updated>
    <published>2019-03-26T07:44:39Z</published>
    <title>Domain Representation for Knowledge Graph Embedding</title>
    <summary>  Embedding entities and relations into a continuous multi-dimensional vector
space have become the dominant method for knowledge graph embedding in
representation learning. However, most existing models ignore to represent
hierarchical knowledge, such as the similarities and dissimilarities of
entities in one domain. We proposed to learn a Domain Representations over
existing knowledge graph embedding models, such that entities that have similar
attributes are organized into the same domain. Such hierarchical knowledge of
domains can give further evidence in link prediction. Experimental results show
that domain embeddings give a significant improvement over the most recent
state-of-art baseline knowledge graph embedding models.
</summary>
    <author>
      <name>Cunxiang Wang</name>
    </author>
    <author>
      <name>Feiliang Ren</name>
    </author>
    <author>
      <name>Zhichao Lin</name>
    </author>
    <author>
      <name>Chenxv Zhao</name>
    </author>
    <author>
      <name>Tian Xie</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Acceptted by NLPCC2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10716v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10716v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10630v1</id>
    <updated>2019-03-25T23:12:56Z</updated>
    <published>2019-03-25T23:12:56Z</published>
    <title>Diversifying Reply Suggestions using a Matching-Conditional Variational
  Autoencoder</title>
    <summary>  We consider the problem of diversifying automated reply suggestions for a
commercial instant-messaging (IM) system (Skype). Our conversation model is a
standard matching based information retrieval architecture, which consists of
two parallel encoders to project messages and replies into a common feature
representation. During inference, we select replies from a fixed response set
using nearest neighbors in the feature space. To diversify responses, we
formulate the model as a generative latent variable model with Conditional
Variational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach
to make the variational inference in M-CVAE efficient for our production
system. In offline experiments, M-CVAE consistently increased diversity by
~30-40% without significant impact on relevance. This translated to a 5% gain
in click-rate in our online production system.
</summary>
    <author>
      <name>Budhaditya Deb</name>
    </author>
    <author>
      <name>Peter Bailey</name>
    </author>
    <author>
      <name>Milad Shokouhi</name>
    </author>
    <link href="http://arxiv.org/abs/1903.10630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10246v1</id>
    <updated>2019-03-25T11:28:36Z</updated>
    <published>2019-03-25T11:28:36Z</published>
    <title>Computational and Robotic Models of Early Language Development: A Review</title>
    <summary>  We review computational and robotics models of early language learning and
development. We first explain why and how these models are used to understand
better how children learn language. We argue that they provide concrete
theories of language learning as a complex dynamic system, complementing
traditional methods in psychology and linguistics. We review different modeling
formalisms, grounded in techniques from machine learning and artificial
intelligence such as Bayesian and neural network approaches. We then discuss
their role in understanding several key mechanisms of language development:
cross-situational statistical learning, embodiment, situated social
interaction, intrinsically motivated learning, and cultural evolution. We
conclude by discussing future challenges for research, including modeling of
large-scale empirical data about language acquisition in real-world
environments.
  Keywords: Early language learning, Computational and robotic models, machine
learning, development, embodiment, social interaction, intrinsic motivation,
self-organization, dynamical systems, complexity.
</summary>
    <author>
      <name>Pierre-Yves Oudeyer</name>
    </author>
    <author>
      <name>George Kachergis</name>
    </author>
    <author>
      <name>William Schueller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in International Handbook on Language Development, ed. J.
  Horst and J. von Koss Torkildsen, Routledge</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10245v4</id>
    <updated>2019-09-03T04:36:06Z</updated>
    <published>2019-03-25T11:23:17Z</published>
    <title>Knowledge Aware Conversation Generation with Explainable Reasoning over
  Augmented Graphs</title>
    <summary>  Two types of knowledge, triples from knowledge graphs and texts from
documents, have been studied for knowledge aware open-domain conversation
generation, in which graph paths can narrow down vertex candidates for
knowledge selection decision, and texts can provide rich information for
response generation. Fusion of a knowledge graph and texts might yield mutually
reinforcing advantages, but there is less study on that. To address this
challenge, we propose a knowledge aware chatting machine with three components,
an augmented knowledge graph with both triples and texts, knowledge selector,
and knowledge aware response generator. For knowledge selection on the graph,
we formulate it as a problem of multi-hop graph reasoning to effectively
capture conversation flow, which is more explainable and flexible in comparison
with previous work. To fully leverage long text information that differentiates
our graph from others, we improve a state of the art reasoning algorithm with
machine reading comprehension technology. We demonstrate the effectiveness of
our system on two datasets in comparison with state-of-the-art models.
</summary>
    <author>
      <name>Zhibin Liu</name>
    </author>
    <author>
      <name>Zheng-Yu Niu</name>
    </author>
    <author>
      <name>Hua Wu</name>
    </author>
    <author>
      <name>Haifeng Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10245v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10245v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10145v3</id>
    <updated>2019-06-10T21:43:02Z</updated>
    <published>2019-03-25T06:28:24Z</published>
    <title>Cyclical Annealing Schedule: A Simple Approach to Mitigating KL
  Vanishing</title>
    <summary>  Variational autoencoders (VAEs) with an auto-regressive decoder have been
applied for many natural language processing (NLP) tasks. The VAE objective
consists of two terms, (i) reconstruction and (ii) KL regularization, balanced
by a weighting hyper-parameter \beta. One notorious training difficulty is that
the KL term tends to vanish. In this paper we study scheduling schemes for
\beta, and show that KL vanishing is caused by the lack of good latent codes in
training the decoder at the beginning of optimization. To remedy this, we
propose a cyclical annealing schedule, which repeats the process of increasing
\beta multiple times. This new procedure allows the progressive learning of
more meaningful latent codes, by leveraging the informative representations of
previous cycles as warm re-starts. The effectiveness of cyclical annealing is
validated on a broad range of NLP tasks, including language modeling, dialog
response generation and unsupervised language pre-training.
</summary>
    <author>
      <name>Hao Fu</name>
    </author>
    <author>
      <name>Chunyuan Li</name>
    </author>
    <author>
      <name>Xiaodong Liu</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Asli Celikyilmaz</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in NAACL 2019; The first two authors contribute equally;
  Code: https://github.com/haofuml/cyclical_annealing</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10145v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10145v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.09942v2</id>
    <updated>2019-07-22T13:39:33Z</updated>
    <published>2019-03-24T08:11:58Z</published>
    <title>Deep recommender engine based on efficient product embeddings neural
  pipeline</title>
    <summary>  Predictive analytics systems are currently one of the most important areas of
research and development within the Artificial Intelligence domain and
particularly in Machine Learning. One of the "holy grails" of predictive
analytics is the research and development of the "perfect" recommendation
system. In our paper, we propose an advanced pipeline model for the multi-task
objective of determining product complementarity, similarity and sales
prediction using deep neural models applied to big-data sequential transaction
systems. Our highly parallelized hybrid model pipeline consists of both
unsupervised and supervised models, used for the objectives of generating
semantic product embeddings and predicting sales, respectively. Our
experimentation and benchmarking processes have been done using pharma industry
retail real-life transactional Big-Data streams.
</summary>
    <author>
      <name>Laurentiu Piciu</name>
    </author>
    <author>
      <name>Andrei Damian</name>
    </author>
    <author>
      <name>Nicolae Tapus</name>
    </author>
    <author>
      <name>Andrei Simion-Constantinescu</name>
    </author>
    <author>
      <name>Bogdan Dumitrescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2018 17th RoEduNet Conference: Networking in Education and Research
  (RoEduNet)</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.09942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.09333v2</id>
    <updated>2019-03-28T21:58:38Z</updated>
    <published>2019-03-22T03:06:36Z</published>
    <title>A Type-coherent, Expressive Representation as an Initial Step to
  Language Understanding</title>
    <summary>  A growing interest in tasks involving language understanding by the NLP
community has led to the need for effective semantic parsing and inference.
Modern NLP systems use semantic representations that do not quite fulfill the
nuanced needs for language understanding: adequately modeling language
semantics, enabling general inferences, and being accurately recoverable. This
document describes underspecified logical forms (ULF) for Episodic Logic (EL),
which is an initial form for a semantic representation that balances these
needs. ULFs fully resolve the semantic type structure while leaving issues such
as quantifier scope, word sense, and anaphora unresolved; they provide a
starting point for further resolution into EL, and enable certain structural
inferences without further resolution. This document also presents preliminary
results of creating a hand-annotated corpus of ULFs for the purpose of training
a precise ULF parser, showing a three-person pairwise interannotator agreement
of 0.88 on confident annotations. We hypothesize that a divide-and-conquer
approach to semantic parsing starting with derivation of ULFs will lead to
semantic analyses that do justice to subtle aspects of linguistic meaning, and
will enable construction of more accurate semantic parsers.
</summary>
    <author>
      <name>Gene Louis Kim</name>
    </author>
    <author>
      <name>Lenhart Schubert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at The 13th International Conference on
  Computational Semantics (IWCS 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.09333v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09333v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.09243v1</id>
    <updated>2019-03-21T21:38:20Z</updated>
    <published>2019-03-21T21:38:20Z</published>
    <title>Inferring Compact Representations for Efficient Natural Language
  Understanding of Robot Instructions</title>
    <summary>  The speed and accuracy with which robots are able to interpret natural
language is fundamental to realizing effective human-robot interaction. A great
deal of attention has been paid to developing models and approximate inference
algorithms that improve the efficiency of language understanding. However,
existing methods still attempt to reason over a representation of the
environment that is flat and unnecessarily detailed, which limits scalability.
An open problem is then to develop methods capable of producing the most
compact environment model sufficient for accurate and efficient natural
language understanding. We propose a model that leverages environment-related
information encoded within instructions to identify the subset of observations
and perceptual classifiers necessary to perceive a succinct,
instruction-specific environment representation. The framework uses three
probabilistic graphical models trained from a corpus of annotated instructions
to infer salient scene semantics, perceptual classifiers, and grounded symbols.
Experimental results on two robots operating in different environments
demonstrate that by exploiting the content and the structure of the
instructions, our method learns compact environment representations that
significantly improve the efficiency of natural language symbol grounding.
</summary>
    <author>
      <name>Siddharth Patki</name>
    </author>
    <author>
      <name>Andrea F. Daniele</name>
    </author>
    <author>
      <name>Matthew R. Walter</name>
    </author>
    <author>
      <name>Thomas M. Howard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICRA 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.09243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.09025v1</id>
    <updated>2019-03-21T14:30:55Z</updated>
    <published>2019-03-21T14:30:55Z</published>
    <title>Recent advances in conversational NLP : Towards the standardization of
  Chatbot building</title>
    <summary>  Dialogue systems have become recently essential in our life. Their use is
getting more and more fluid and easy throughout the time. This boils down to
the improvements made in NLP and AI fields. In this paper, we try to provide an
overview to the current state of the art of dialogue systems, their categories
and the different approaches to build them. We end up with a discussion that
compares all the techniques and analyzes the strengths and weaknesses of each.
Finally, we present an opinion piece suggesting to orientate the research
towards the standardization of dialogue systems building.
</summary>
    <author>
      <name>Maali Mnasri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages with references, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.09025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08948v1</id>
    <updated>2019-03-21T12:26:44Z</updated>
    <published>2019-03-21T12:26:44Z</published>
    <title>Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning</title>
    <summary>  Reasoning is essential for the development of large knowledge graphs,
especially for completion, which aims to infer new triples based on existing
ones. Both rules and embeddings can be used for knowledge graph reasoning and
they have their own advantages and difficulties. Rule-based reasoning is
accurate and explainable but rule learning with searching over the graph always
suffers from efficiency due to huge search space. Embedding-based reasoning is
more scalable and efficient as the reasoning is conducted via computation
between embeddings, but it has difficulty learning good representations for
sparse entities because a good embedding relies heavily on data richness. Based
on this observation, in this paper we explore how embedding and rule learning
can be combined together and complement each other's difficulties with their
advantages. We propose a novel framework IterE iteratively learning embeddings
and rules, in which rules are learned from embeddings with proper pruning
strategy and embeddings are learned from existing triples and new triples
inferred by rules. Evaluations on embedding qualities of IterE show that rules
help improve the quality of sparse entity embeddings and their link prediction
results. We also evaluate the efficiency of rule learning and quality of rules
from IterE compared with AMIE+, showing that IterE is capable of generating
high quality rules more efficiently. Experiments show that iteratively learning
embeddings and rules benefit each other during learning and prediction.
</summary>
    <author>
      <name>Wen Zhang</name>
    </author>
    <author>
      <name>Bibek Paudel</name>
    </author>
    <author>
      <name>Liang Wang</name>
    </author>
    <author>
      <name>Jiaoyan Chen</name>
    </author>
    <author>
      <name>Hai Zhu</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Abraham Bernstein</name>
    </author>
    <author>
      <name>Huajun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is accepted by WWW'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.08948v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08948v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08389v1</id>
    <updated>2019-03-20T08:53:05Z</updated>
    <published>2019-03-20T08:53:05Z</published>
    <title>Contextual Compositionality Detection with External Knowledge Bases
  andWord Embeddings</title>
    <summary>  When the meaning of a phrase cannot be inferred from the individual meanings
of its words (e.g., hot dog), that phrase is said to be non-compositional.
Automatic compositionality detection in multi-word phrases is critical in any
application of semantic processing, such as search engines; failing to detect
non-compositional phrases can hurt system effectiveness notably. Existing
research treats phrases as either compositional or non-compositional in a
deterministic manner. In this paper, we operationalize the viewpoint that
compositionality is contextual rather than deterministic, i.e., that whether a
phrase is compositional or non-compositional depends on its context. For
example, the phrase `green card' is compositional when referring to a green
colored card, whereas it is non-compositional when meaning permanent residence
authorization. We address the challenge of detecting this type of contextual
compositionality as follows: given a multi-word phrase, we enrich the word
embedding representing its semantics with evidence about its global context
(terms it often collocates with) as well as its local context (narratives where
that phrase is used, which we call usage scenarios). We further extend this
representation with information extracted from external knowledge bases. The
resulting representation incorporates both localized context and more general
usage of the phrase and allows to detect its compositionality in a
non-deterministic and contextual way. Empirical evaluation of our model on a
dataset of phrase compositionality, manually collected by crowdsourcing
contextual compositionality assessments, shows that our model outperforms
state-of-the-art baselines notably on detecting phrase compositionality.
</summary>
    <author>
      <name>Dongsheng Wang</name>
    </author>
    <author>
      <name>Quichi Li</name>
    </author>
    <author>
      <name>Lucas Chaves Lima</name>
    </author>
    <author>
      <name>Jakob grue Simonsen</name>
    </author>
    <author>
      <name>Christina Lioma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WWW '19 Companion, May 13-17, 2019, San Francisco, CA, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.08389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08309v1</id>
    <updated>2019-03-20T01:52:37Z</updated>
    <published>2019-03-20T01:52:37Z</published>
    <title>Prospection: Interpretable Plans From Language By Predicting the Future</title>
    <summary>  High-level human instructions often correspond to behaviors with multiple
implicit steps. In order for robots to be useful in the real world, they must
be able to to reason over both motions and intermediate goals implied by human
instructions. In this work, we propose a framework for learning representations
that convert from a natural-language command to a sequence of intermediate
goals for execution on a robot. A key feature of this framework is prospection,
training an agent not just to correctly execute the prescribed command, but to
predict a horizon of consequences of an action before taking it. We demonstrate
the fidelity of plans generated by our framework when interpreting real,
crowd-sourced natural language commands for a robot in simulated scenes.
</summary>
    <author>
      <name>Chris Paxton</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Jesse Thomason</name>
    </author>
    <author>
      <name>Arunkumar Byravan</name>
    </author>
    <author>
      <name>Dieter Fox</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICRA 2019; extended version with appendix containing
  additional results</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.08309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.07766v2</id>
    <updated>2019-03-20T16:21:41Z</updated>
    <published>2019-03-18T23:35:31Z</published>
    <title>Lemotif: Abstract Visual Depictions of your Emotional States in Life</title>
    <summary>  We present Lemotif. Lemotif generates a motif for your emotional life. You
tell Lemotif a little bit about your day -- what were salient events or aspects
and how they made you feel. Lemotif will generate a lemotif -- a creative
abstract visual depiction of your emotions and their sources. Over time,
Lemotif can create visual motifs to capture a summary of your emotional states
over arbitrary periods of time -- making patterns in your emotions and their
sources apparent, presenting opportunities to take actions, and measure their
effectiveness. The underlying principles in Lemotif are that the lemotif should
(1) separate out the sources of the emotions, (2) depict these sources
visually, (3) depict the emotions visually, and (4) have a creative aspect to
them. We verify via human studies that each of these factors contributes to the
proposed lemotifs being favored over corresponding baselines.
</summary>
    <author>
      <name>Devi Parikh</name>
    </author>
    <link href="http://arxiv.org/abs/1903.07766v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.07766v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.07091v1</id>
    <updated>2019-03-17T14:01:53Z</updated>
    <published>2019-03-17T14:01:53Z</published>
    <title>The Missing Ingredient in Zero-Shot Neural Machine Translation</title>
    <summary>  Multilingual Neural Machine Translation (NMT) models are capable of
translating between multiple source and target languages. Despite various
approaches to train such models, they have difficulty with zero-shot
translation: translating between language pairs that were not together seen
during training. In this paper we first diagnose why state-of-the-art
multilingual NMT models that rely purely on parameter sharing, fail to
generalize to unseen language pairs. We then propose auxiliary losses on the
NMT encoder that impose representational invariance across languages. Our
simple approach vastly improves zero-shot translation quality without
regressing on supervised directions. For the first time, on WMT14
English-FrenchGerman, we achieve zero-shot performance that is on par with
pivoting. We also demonstrate the easy scalability of our approach to multiple
languages on the IWSLT 2017 shared task.
</summary>
    <author>
      <name>Naveen Arivazhagan</name>
    </author>
    <author>
      <name>Ankur Bapna</name>
    </author>
    <author>
      <name>Orhan Firat</name>
    </author>
    <author>
      <name>Roee Aharoni</name>
    </author>
    <author>
      <name>Melvin Johnson</name>
    </author>
    <author>
      <name>Wolfgang Macherey</name>
    </author>
    <link href="http://arxiv.org/abs/1903.07091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.07091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.05543v1</id>
    <updated>2019-03-13T15:29:22Z</updated>
    <published>2019-03-13T15:29:22Z</published>
    <title>Adversarial attacks against Fact Extraction and VERification</title>
    <summary>  This paper describes a baseline for the second iteration of the Fact
Extraction and VERification shared task (FEVER2.0) which explores the
resilience of systems through adversarial evaluation. We present a collection
of simple adversarial attacks against systems that participated in the first
FEVER shared task. FEVER modeled the assessment of truthfulness of written
claims as a joint information retrieval and natural language inference task
using evidence from Wikipedia. A large number of participants made use of deep
neural networks in their submissions to the shared task. The extent as to
whether such models understand language has been the subject of a number of
recent investigations and discussion in literature. In this paper, we present a
simple method of generating entailment-preserving and entailment-altering
perturbations of instances by common patterns within the training data. We find
that a number of systems are greatly affected with absolute losses in
classification accuracy of up to $29\%$ on the newly perturbed instances. Using
these newly generated instances, we construct a sample submission for the
FEVER2.0 shared task. Addressing these types of attacks will aid in building
more robust fact-checking models, as well as suggest directions to expand the
datasets.
</summary>
    <author>
      <name>James Thorne</name>
    </author>
    <author>
      <name>Andreas Vlachos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.05543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.05543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.05485v1</id>
    <updated>2019-03-13T13:48:32Z</updated>
    <published>2019-03-13T13:48:32Z</published>
    <title>MMKG: Multi-Modal Knowledge Graphs</title>
    <summary>  We present MMKG, a collection of three knowledge graphs that contain both
numerical features and (links to) images for all entities as well as entity
alignments between pairs of KGs. Therefore, multi-relational link prediction
and entity matching communities can benefit from this resource. We believe this
data set has the potential to facilitate the development of novel multi-modal
learning approaches for knowledge graphs.We validate the utility ofMMKG in the
sameAs link prediction task with an extensive set of experiments. These
experiments show that the task at hand benefits from learning of multiple
feature types.
</summary>
    <author>
      <name>Ye Liu</name>
    </author>
    <author>
      <name>Hui Li</name>
    </author>
    <author>
      <name>Alberto Garcia-Duran</name>
    </author>
    <author>
      <name>Mathias Niepert</name>
    </author>
    <author>
      <name>Daniel Onoro-Rubio</name>
    </author>
    <author>
      <name>David S. Rosenblum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ESWC 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.05485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.05485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.05168v1</id>
    <updated>2019-03-12T19:33:49Z</updated>
    <published>2019-03-12T19:33:49Z</published>
    <title>On the Pitfalls of Measuring Emergent Communication</title>
    <summary>  How do we know if communication is emerging in a multi-agent system? The vast
majority of recent papers on emergent communication show that adding a
communication channel leads to an increase in reward or task success. This is a
useful indicator, but provides only a coarse measure of the agent's learned
communication abilities. As we move towards more complex environments, it
becomes imperative to have a set of finer tools that allow qualitative and
quantitative insights into the emergence of communication. This may be
especially useful to allow humans to monitor agents' behaviour, whether for
fault detection, assessing performance, or even building trust. In this paper,
we examine a few intuitive existing metrics for measuring communication, and
show that they can be misleading. Specifically, by training deep reinforcement
learning agents to play simple matrix games augmented with a communication
channel, we find a scenario where agents appear to communicate (their messages
provide information about their subsequent action), and yet the messages do not
impact the environment or other agent in any way. We explain this phenomenon
using ablation studies and by visualizing the representations of the learned
policies. We also survey some commonly used metrics for measuring emergent
communication, and provide recommendations as to when these metrics should be
used.
</summary>
    <author>
      <name>Ryan Lowe</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Y-Lan Boureau</name>
    </author>
    <author>
      <name>Joelle Pineau</name>
    </author>
    <author>
      <name>Yann Dauphin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAMAS 2019. 13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.05168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.05168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.04750v1</id>
    <updated>2019-03-12T07:12:46Z</updated>
    <published>2019-03-12T07:12:46Z</published>
    <title>Interaction Embeddings for Prediction and Explanation in Knowledge
  Graphs</title>
    <summary>  Knowledge graph embedding aims to learn distributed representations for
entities and relations, and is proven to be effective in many applications.
Crossover interactions --- bi-directional effects between entities and
relations --- help select related information when predicting a new triple, but
haven't been formally discussed before. In this paper, we propose CrossE, a
novel knowledge graph embedding which explicitly simulates crossover
interactions. It not only learns one general embedding for each entity and
relation as most previous methods do, but also generates multiple triple
specific embeddings for both of them, named interaction embeddings. We evaluate
embeddings on typical link prediction tasks and find that CrossE achieves
state-of-the-art results on complex and more challenging datasets. Furthermore,
we evaluate embeddings from a new perspective --- giving explanations for
predicted triples, which is important for real applications. In this work, an
explanation for a triple is regarded as a reliable closed-path between the head
and the tail entity. Compared to other baselines, we show experimentally that
CrossE, benefiting from interaction embeddings, is more capable of generating
reliable explanations to support its predictions.
</summary>
    <author>
      <name>Wen Zhang</name>
    </author>
    <author>
      <name>Bibek Paudel</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Abraham Bernstein</name>
    </author>
    <author>
      <name>Huajun Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3289600.3291014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3289600.3291014" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is accepted by WSDM2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.04750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.04750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03995v3</id>
    <updated>2019-10-23T21:32:15Z</updated>
    <published>2019-03-10T14:05:08Z</published>
    <title>Efficiently Reusing Natural Language Processing Models for
  Phenotype-Mention Identification in Free-text Electronic Medical Records:
  Methodology Study</title>
    <summary>  Background: Many efforts have been put into the use of automated approaches,
such as natural language processing (NLP), to mine or extract data from
free-text medical records to construct comprehensive patient profiles for
delivering better health-care. Reusing NLP models in new settings, however,
remains cumbersome - requiring validation and/or retraining on new data
iteratively to achieve convergent results.
  Objective: The aim of this work is to minimize the effort involved in reusing
NLP models on free-text medical records.
  Methods: We formally define and analyse the model adaptation problem in
phenotype-mention identification tasks. We identify "duplicate waste" and
"imbalance waste", which collectively impede efficient model reuse. We propose
a phenotype embedding based approach to minimize these sources of waste without
the need for labelled data from new settings.
  Results: We conduct experiments on data from a large mental health registry
to reuse NLP models in four phenotype-mention identification tasks. The
proposed approach can choose the best model for a new task, identifying up to
76% (duplicate waste), i.e. phenotype mentions without the need for validation
and model retraining, and with very good performance (93-97% accuracy). It can
also provide guidance for validating and retraining the selected model for
novel language patterns in new tasks, saving around 80% (imbalance waste), i.e.
the effort required in "blind" model-adaptation approaches.
  Conclusions: Adapting pre-trained NLP models for new tasks can be more
efficient and effective if the language pattern landscapes of old settings and
new settings can be made explicit and comparable. Our experiments show that the
phenotype-mention embedding approach is an effective way to model language
patterns for phenotype-mention identification tasks and that its use can guide
efficient NLP model reuse.
</summary>
    <author>
      <name>Honghan Wu</name>
    </author>
    <author>
      <name>Karen Hodgson</name>
    </author>
    <author>
      <name>Sue Dyson</name>
    </author>
    <author>
      <name>Katherine I. Morley</name>
    </author>
    <author>
      <name>Zina M. Ibrahim</name>
    </author>
    <author>
      <name>Ehtesham Iqbal</name>
    </author>
    <author>
      <name>Robert Stewart</name>
    </author>
    <author>
      <name>Richard JB Dobson</name>
    </author>
    <author>
      <name>Cathie Sudlow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2196/14782</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2196/14782" rel="related"/>
    <link href="http://arxiv.org/abs/1903.03995v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03995v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03985v2</id>
    <updated>2019-06-05T15:55:53Z</updated>
    <published>2019-03-10T13:16:37Z</published>
    <title>Named Entity Recognition for Electronic Health Records: A Comparison of
  Rule-based and Machine Learning Approaches</title>
    <summary>  This work investigates multiple approaches to Named Entity Recognition (NER)
for text in Electronic Health Record (EHR) data. In particular, we look into
the application of (i) rule-based, (ii) deep learning and (iii) transfer
learning systems for the task of NER on brain imaging reports with a focus on
records from patients with stroke. We explore the strengths and weaknesses of
each approach, develop rules and train on a common dataset, and evaluate each
system's performance on common test sets of Scottish radiology reports from two
sources (brain imaging reports in ESS -- Edinburgh Stroke Study data collected
by NHS Lothian as well as radiology reports created in NHS Tayside). Our
comparison shows that a hand-crafted system is the most accurate way to
automatically label EHR, but machine learning approaches can provide a feasible
alternative where resources for a manual system are not readily available.
</summary>
    <author>
      <name>Philip John Gorinski</name>
    </author>
    <author>
      <name>Honghan Wu</name>
    </author>
    <author>
      <name>Claire Grover</name>
    </author>
    <author>
      <name>Richard Tobin</name>
    </author>
    <author>
      <name>Conn Talbot</name>
    </author>
    <author>
      <name>Heather Whalley</name>
    </author>
    <author>
      <name>Cathie Sudlow</name>
    </author>
    <author>
      <name>William Whiteley</name>
    </author>
    <author>
      <name>Beatrice Alex</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, presented at HealTAC 2019, Cardiff, 24-25/04/2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.03985v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03985v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03772v1</id>
    <updated>2019-03-09T10:01:12Z</updated>
    <published>2019-03-09T10:01:12Z</published>
    <title>Logic Rules Powered Knowledge Graph Embedding</title>
    <summary>  Large scale knowledge graph embedding has attracted much attention from both
academia and industry in the field of Artificial Intelligence. However, most
existing methods concentrate solely on fact triples contained in the given
knowledge graph. Inspired by the fact that logic rules can provide a flexible
and declarative language for expressing rich background knowledge, it is
natural to integrate logic rules into knowledge graph embedding, to transfer
human knowledge to entity and relation embedding, and strengthen the learning
process. In this paper, we propose a novel logic rule-enhanced method which can
be easily integrated with any translation based knowledge graph embedding
model, such as TransE . We first introduce a method to automatically mine the
logic rules and corresponding confidences from the triples. And then, to put
both triples and mined logic rules within the same semantic space, all triples
in the knowledge graph are represented as first-order logic. Finally, we define
several operations on the first-order logic and minimize a global loss over
both of the mined logic rules and the transformed first-order logics. We
conduct extensive experiments for link prediction and triple classification on
three datasets: WN18, FB166, and FB15K. Experiments show that the rule-enhanced
method can significantly improve the performance of several baselines. The
highlight of our model is that the filtered Hits@1, which is a pivotal
evaluation in the knowledge inference task, has a significant improvement (up
to 700% improvement).
</summary>
    <author>
      <name>Pengwei Wang</name>
    </author>
    <author>
      <name>Dejing Dou</name>
    </author>
    <author>
      <name>Fangzhao Wu</name>
    </author>
    <author>
      <name>Nisansa de Silva</name>
    </author>
    <author>
      <name>Lianwen Jin</name>
    </author>
    <link href="http://arxiv.org/abs/1903.03772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03289v1</id>
    <updated>2019-03-08T05:10:00Z</updated>
    <published>2019-03-08T05:10:00Z</published>
    <title>Towards Time-Aware Distant Supervision for Relation Extraction</title>
    <summary>  Distant supervision for relation extraction heavily suffers from the wrong
labeling problem. To alleviate this issue in news data with the timestamp, we
take a new factor time into consideration and propose a novel time-aware
distant supervision framework (Time-DS). Time-DS is composed of a time series
instance-popularity and two strategies. Instance-popularity is to encode the
strong relevance of time and true relation mention. Therefore,
instance-popularity would be an effective clue to reduce the noises generated
through distant supervision labeling. The two strategies, i.e., hard filter and
curriculum learning are both ways to implement instance-popularity for better
relation extraction in the manner of Time-DS. The curriculum learning is a more
sophisticated and flexible way to exploit instance-popularity to eliminate the
bad effects of noises, thus get better relation extraction performance.
Experiments on our collected multi-source news corpus show that Time-DS
achieves significant improvements for relation extraction.
</summary>
    <author>
      <name>Tianwen Jiang</name>
    </author>
    <author>
      <name>Sendong Zhao</name>
    </author>
    <author>
      <name>Jing Liu</name>
    </author>
    <author>
      <name>Jin-Ge Yao</name>
    </author>
    <author>
      <name>Ming Liu</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Chin-Yew Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1903.03289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03282v1</id>
    <updated>2019-03-08T04:44:59Z</updated>
    <published>2019-03-08T04:44:59Z</published>
    <title>Attribute Acquisition in Ontology based on Representation Learning of
  Hierarchical Classes and Attributes</title>
    <summary>  Attribute acquisition for classes is a key step in ontology construction,
which is often achieved by community members manually. This paper investigates
an attention-based automatic paradigm called TransATT for attribute
acquisition, by learning the representation of hierarchical classes and
attributes in Chinese ontology. The attributes of an entity can be acquired by
merely inspecting its classes, because the entity can be regard as the instance
of its classes and inherit their attributes. For explicitly describing of the
class of an entity unambiguously, we propose class-path to represent the
hierarchical classes in ontology, instead of the terminal class word of the
hypernym-hyponym relation (i.e., is-a relation) based hierarchy. The high
performance of TransATT on attribute acquisition indicates the promising
ability of the learned representation of class-paths and attributes. Moreover,
we construct a dataset named \textbf{BigCilin11k}. To the best of our
knowledge, this is the first Chinese dataset with abundant hierarchical classes
and entities with attributes.
</summary>
    <author>
      <name>Tianwen Jiang</name>
    </author>
    <author>
      <name>Ming Liu</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1903.03282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03166v2</id>
    <updated>2019-09-18T18:04:43Z</updated>
    <published>2019-03-07T20:18:39Z</published>
    <title>CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual
  Dialog</title>
    <summary>  Visual Dialog is a multimodal task of answering a sequence of questions
grounded in an image, using the conversation history as context. It entails
challenges in vision, language, reasoning, and grounding. However, studying
these subtasks in isolation on large, real datasets is infeasible as it
requires prohibitively-expensive complete annotation of the 'state' of all
images and dialogs.
  We develop CLEVR-Dialog, a large diagnostic dataset for studying multi-round
reasoning in visual dialog. Specifically, we construct a dialog grammar that is
grounded in the scene graphs of the images from the CLEVR dataset. This
combination results in a dataset where all aspects of the visual dialog are
fully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round
dialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs.
  We use CLEVR-Dialog to benchmark performance of standard visual dialog
models; in particular, on visual coreference resolution (as a function of the
coreference distance). This is the first analysis of its kind for visual dialog
models that was not possible without this dataset. We hope the findings from
CLEVR-Dialog will help inform the development of future models for visual
dialog. Our dataset and code are publicly available.
</summary>
    <author>
      <name>Satwik Kottur</name>
    </author>
    <author>
      <name>José M. F. Moura</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <author>
      <name>Marcus Rohrbach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 11 figures, 3 tables, accepted as a short paper at NAACL
  2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.03166v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03166v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03094v1</id>
    <updated>2019-03-07T18:45:52Z</updated>
    <published>2019-03-07T18:45:52Z</published>
    <title>Learning to Speak and Act in a Fantasy Text Adventure Game</title>
    <summary>  We introduce a large scale crowdsourced text adventure game as a research
platform for studying grounded dialogue. In it, agents can perceive, emote, and
act whilst conducting dialogue with other agents. Models and humans can both
act as characters within the game. We describe the results of training
state-of-the-art generative and retrieval models in this setting. We show that
in addition to using past dialogue, these models are able to effectively use
the state of the underlying world to condition their predictions. In
particular, we show that grounding on the details of the local environment,
including location descriptions, and the objects (and their affordances) and
characters (and their previous actions) present within it allows better
predictions of agent behavior and dialogue. We analyze the ingredients
necessary for successful grounding in this setting, and how each of these
factors relate to agents that can talk and act successfully.
</summary>
    <author>
      <name>Jack Urbanek</name>
    </author>
    <author>
      <name>Angela Fan</name>
    </author>
    <author>
      <name>Siddharth Karamcheti</name>
    </author>
    <author>
      <name>Saachi Jain</name>
    </author>
    <author>
      <name>Samuel Humeau</name>
    </author>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Tim Rocktäschel</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1903.03094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.02978v1</id>
    <updated>2019-03-07T15:14:42Z</updated>
    <published>2019-03-07T15:14:42Z</published>
    <title>Integrating Artificial and Human Intelligence for Efficient Translation</title>
    <summary>  Current advances in machine translation increase the need for translators to
switch from traditional translation to post-editing of machine-translated text,
a process that saves time and improves quality. Human and artificial
intelligence need to be integrated in an efficient way to leverage the
advantages of both for the translation task. This paper outlines approaches at
this boundary of AI and HCI and discusses open research questions to further
advance the field.
</summary>
    <author>
      <name>Nico Herbig</name>
    </author>
    <author>
      <name>Santanu Pal</name>
    </author>
    <author>
      <name>Josef van Genabith</name>
    </author>
    <author>
      <name>Antonio Krüger</name>
    </author>
    <link href="http://arxiv.org/abs/1903.02978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.02978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.02172v1</id>
    <updated>2019-03-06T04:49:07Z</updated>
    <published>2019-03-06T04:49:07Z</published>
    <title>AAAI-2019 Workshop on Games and Simulations for Artificial Intelligence</title>
    <summary>  This volume represents the accepted submissions from the AAAI-2019 Workshop
on Games and Simulations for Artificial Intelligence held on January 29, 2019
in Honolulu, Hawaii, USA. https://www.gamesim.ai
</summary>
    <author>
      <name>Marwan Mattar</name>
    </author>
    <author>
      <name>Roozbeh Mottaghi</name>
    </author>
    <author>
      <name>Julian Togelius</name>
    </author>
    <author>
      <name>Danny Lange</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI-2019 Workshop on Games and Simulations for Artificial
  Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.02172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.02172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.02156v2</id>
    <updated>2019-03-13T12:42:59Z</updated>
    <published>2019-03-06T03:36:29Z</published>
    <title>Persona-Aware Tips Generation</title>
    <summary>  Tips, as a compacted and concise form of reviews, were paid less attention by
researchers. In this paper, we investigate the task of tips generation by
considering the `persona' information which captures the intrinsic language
style of the users or the different characteristics of the product items. In
order to exploit the persona information, we propose a framework based on
adversarial variational auto-encoders (aVAE) for persona modeling from the
historical tips and reviews of users and items. The latent variables from aVAE
are regarded as persona embeddings. Besides representing persona using the
latent embeddings, we design a persona memory for storing the persona related
words for users and items. Pointer Network is used to retrieve persona wordings
from the memory when generating tips. Moreover, the persona embeddings are used
as latent factors by a rating prediction component to predict the sentiment of
a user over an item. Finally, the persona embeddings and the sentiment
information are incorporated into a recurrent neural networks based tips
generation component. Extensive experimental results are reported and discussed
to elaborate the peculiarities of our framework.
</summary>
    <author>
      <name>Piji Li</name>
    </author>
    <author>
      <name>Zihao Wang</name>
    </author>
    <author>
      <name>Lidong Bing</name>
    </author>
    <author>
      <name>Wai Lam</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313496</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313496" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to WWW'2019, 11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.02156v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.02156v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.00401v2</id>
    <updated>2019-11-21T22:38:35Z</updated>
    <published>2019-03-01T16:50:02Z</published>
    <title>Learning To Follow Directions in Street View</title>
    <summary>  Navigating and understanding the real world remains a key challenge in
machine learning and inspires a great variety of research in areas such as
language grounding, planning, navigation and computer vision. We propose an
instruction-following task that requires all of the above, and which combines
the practicality of simulated environments with the challenges of ambiguous,
noisy real world data. StreetNav is built on top of Google Street View and
provides visually accurate environments representing real places. Agents are
given driving instructions which they must learn to interpret in order to
successfully navigate in this environment. Since humans equipped with driving
instructions can readily navigate in previously unseen cities, we set a high
bar and test our trained agents for similar cognitive capabilities. Although
deep reinforcement learning (RL) methods are frequently evaluated only on data
that closely follow the training distribution, our dataset extends to multiple
cities and has a clean train/test separation. This allows for thorough testing
of generalisation ability. This paper presents the StreetNav environment and
tasks, models that establish strong baselines, and extensive analysis of the
task and the trained agents.
</summary>
    <author>
      <name>Karl Moritz Hermann</name>
    </author>
    <author>
      <name>Mateusz Malinowski</name>
    </author>
    <author>
      <name>Piotr Mirowski</name>
    </author>
    <author>
      <name>Andras Banki-Horvath</name>
    </author>
    <author>
      <name>Keith Anderson</name>
    </author>
    <author>
      <name>Raia Hadsell</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1903.00401v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.00401v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.11205v3</id>
    <updated>2019-04-04T18:09:05Z</updated>
    <published>2019-02-28T16:45:19Z</published>
    <title>Jointly Optimizing Diversity and Relevance in Neural Response Generation</title>
    <summary>  Although recent neural conversation models have shown great potential, they
often generate bland and generic responses. While various approaches have been
explored to diversify the output of the conversation model, the improvement
often comes at the cost of decreased relevance. In this paper, we propose a
SpaceFusion model to jointly optimize diversity and relevance that essentially
fuses the latent space of a sequence-to-sequence model and that of an
autoencoder model by leveraging novel regularization terms. As a result, our
approach induces a latent space in which the distance and direction from the
predicted response vector roughly match the relevance and diversity,
respectively. This property also lends itself well to an intuitive
visualization of the latent space. Both automatic and human evaluation results
demonstrate that the proposed approach brings significant improvement compared
to strong baselines in both diversity and relevance.
</summary>
    <author>
      <name>Xiang Gao</name>
    </author>
    <author>
      <name>Sungjin Lee</name>
    </author>
    <author>
      <name>Yizhe Zhang</name>
    </author>
    <author>
      <name>Chris Brockett</name>
    </author>
    <author>
      <name>Michel Galley</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Bill Dolan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long paper accepted at NAACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.11205v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.11205v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.10667v2</id>
    <updated>2019-04-25T13:41:57Z</updated>
    <published>2019-02-27T18:01:53Z</published>
    <title>Bridging the Gap: Attending to Discontinuity in Identification of
  Multiword Expressions</title>
    <summary>  We introduce a new method to tag Multiword Expressions (MWEs) using a
linguistically interpretable language-independent deep learning architecture.
We specifically target discontinuity, an under-explored aspect that poses a
significant challenge to computational treatment of MWEs. Two neural
architectures are explored: Graph Convolutional Network (GCN) and multi-head
self-attention. GCN leverages dependency parse information, and self-attention
attends to long-range relations. We finally propose a combined model that
integrates complementary information from both through a gating mechanism. The
experiments on a standard multilingual dataset for verbal MWEs show that our
model outperforms the baselines not only in the case of discontinuous MWEs but
also in overall F-score.
</summary>
    <author>
      <name>Omid Rohanian</name>
    </author>
    <author>
      <name>Shiva Taslimipoor</name>
    </author>
    <author>
      <name>Samaneh Kouchaki</name>
    </author>
    <author>
      <name>Le An Ha</name>
    </author>
    <author>
      <name>Ruslan Mitkov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.10667v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.10667v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.10186v3</id>
    <updated>2019-05-08T18:05:56Z</updated>
    <published>2019-02-26T19:59:15Z</published>
    <title>Attention is not Explanation</title>
    <summary>  Attention mechanisms have seen wide adoption in neural NLP models. In
addition to improving predictive performance, these are often touted as
affording transparency: models equipped with attention provide a distribution
over attended-to input units, and this is often presented (at least implicitly)
as communicating the relative importance of inputs. However, it is unclear what
relationship exists between attention weights and model outputs. In this work,
we perform extensive experiments across a variety of NLP tasks that aim to
assess the degree to which attention weights provide meaningful `explanations'
for predictions. We find that they largely do not. For example, learned
attention weights are frequently uncorrelated with gradient-based measures of
feature importance, and one can identify very different attention distributions
that nonetheless yield equivalent predictions. Our findings show that standard
attention modules do not provide meaningful explanations and should not be
treated as though they do. Code for all experiments is available at
https://github.com/successar/AttentionExplanation.
</summary>
    <author>
      <name>Sarthak Jain</name>
    </author>
    <author>
      <name>Byron C. Wallace</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as NAACL 2019 Long Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.10186v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.10186v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09713v2</id>
    <updated>2019-10-05T05:45:39Z</updated>
    <published>2019-02-26T02:54:03Z</published>
    <title>Interpretable Structure-aware Document Encoders with Hierarchical
  Attention</title>
    <summary>  We propose a method to create document representations that reflect their
internal structure. We modify Tree-LSTMs to hierarchically merge basic elements
such as words and sentences into blocks of increasing complexity. Our Structure
Tree-LSTM implements a hierarchical attention mechanism over individual
components and combinations thereof. We thus emphasize the usefulness of
Tree-LSTMs for texts larger than a sentence. We show that structure-aware
encoders can be used to improve the performance of document classification. We
demonstrate that our method is resilient to changes to the basic building
blocks, as it performs well with both sentence and word embeddings. The
Structure Tree-LSTM outperforms all the baselines on two datasets by leveraging
structural clues. We show our model's interpretability by visualizing how our
model distributes attention inside a document. On a third dataset from the
medical domain, our model achieves competitive performance with the state of
the art. This result shows the Structure Tree-LSTM can leverage dependency
relations other than text structure, such as a set of reports on the same
patient.
</summary>
    <author>
      <name>Khalil Mrini</name>
    </author>
    <author>
      <name>Claudiu Musat</name>
    </author>
    <author>
      <name>Michael Baeriswyl</name>
    </author>
    <author>
      <name>Martin Jaggi</name>
    </author>
    <link href="http://arxiv.org/abs/1902.09713v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09713v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09705v1</id>
    <updated>2019-02-26T02:14:10Z</updated>
    <published>2019-02-26T02:14:10Z</published>
    <title>Beyond the Self: Using Grounded Affordances to Interpret and Describe
  Others' Actions</title>
    <summary>  We propose a developmental approach that allows a robot to interpret and
describe the actions of human agents by reusing previous experience. The robot
first learns the association between words and object affordances by
manipulating the objects in its environment. It then uses this information to
learn a mapping between its own actions and those performed by a human in a
shared environment. It finally fuses the information from these two models to
interpret and describe human actions in light of its own experience. In our
experiments, we show that the model can be used flexibly to do inference on
different aspects of the scene. We can predict the effects of an action on the
basis of object properties. We can revise the belief that a certain action
occurred, given the observed effects of the human action. In an early action
recognition fashion, we can anticipate the effects when the action has only
been partially observed. By estimating the probability of words given the
evidence and feeding them into a pre-defined grammar, we can generate relevant
descriptions of the scene. We believe that this is a step towards providing
robots with the fundamental skills to engage in social collaboration with
humans.
</summary>
    <author>
      <name>Giovanni Saponaro</name>
    </author>
    <author>
      <name>Lorenzo Jamone</name>
    </author>
    <author>
      <name>Alexandre Bernardino</name>
    </author>
    <author>
      <name>Giampiero Salvi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCDS.2018.2882140</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCDS.2018.2882140" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">code available at https://github.com/gsaponaro/tcds-gestures, IEEE
  Transactions on Cognitive and Developmental Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.10126v2</id>
    <updated>2019-03-21T08:43:35Z</updated>
    <published>2019-02-25T19:53:01Z</published>
    <title>BUT-FIT at SemEval-2019 Task 7: Determining the Rumour Stance with
  Pre-Trained Deep Bidirectional Transformers</title>
    <summary>  This paper describes our system submitted to SemEval 2019 Task 7: RumourEval
2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell
et al., 2019). The challenge focused on classifying whether posts from Twitter
and Reddit support, deny, query, or comment a hidden rumour, truthfulness of
which is the topic of an underlying discussion thread. We formulate the problem
as a stance classification, determining the rumour stance of a post with
respect to the previous thread post and the source thread post. The recent BERT
architecture was employed to build an end-to-end system which has reached the
F1 score of 61.67% on the provided test data. It finished at the 2nd place in
the competition, without any hand-crafted features, only 0.2% behind the
winner.
</summary>
    <author>
      <name>Martin Fajcik</name>
    </author>
    <author>
      <name>Lukáš Burget</name>
    </author>
    <author>
      <name>Pavel Smrz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been submitted to NAACL SemEval workshop. Work in
  progress</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 13th International Workshop on Semantic
  Evaluation 13 (2019) 1097-1104</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.10126v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.10126v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09506v3</id>
    <updated>2019-05-10T22:24:55Z</updated>
    <published>2019-02-25T18:37:49Z</published>
    <title>GQA: A New Dataset for Real-World Visual Reasoning and Compositional
  Question Answering</title>
    <summary>  We introduce GQA, a new dataset for real-world visual reasoning and
compositional question answering, seeking to address key shortcomings of
previous VQA datasets. We have developed a strong and robust question engine
that leverages scene graph structures to create 22M diverse reasoning
questions, all come with functional programs that represent their semantics. We
use the programs to gain tight control over the answer distribution and present
a new tunable smoothing technique to mitigate question biases. Accompanying the
dataset is a suite of new metrics that evaluate essential qualities such as
consistency, grounding and plausibility. An extensive analysis is performed for
baselines as well as state-of-the-art models, providing fine-grained results
for different question types and topologies. Whereas a blind LSTM obtains mere
42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%,
offering ample opportunity for new research to explore. We strongly hope GQA
will provide an enabling resource for the next generation of models with
enhanced robustness, improved consistency, and deeper semantic understanding
for images and language.
</summary>
    <author>
      <name>Drew A. Hudson</name>
    </author>
    <author>
      <name>Christopher D. Manning</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at CVPR 2019 (oral)</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09506v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09506v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09487v1</id>
    <updated>2019-02-25T18:04:05Z</updated>
    <published>2019-02-25T18:04:05Z</published>
    <title>MUREL: Multimodal Relational Reasoning for Visual Question Answering</title>
    <summary>  Multimodal attentional networks are currently state-of-the-art models for
Visual Question Answering (VQA) tasks involving real images. Although attention
allows to focus on the visual content relevant to the question, this simple
mechanism is arguably insufficient to model complex reasoning features required
for VQA or other high-level tasks.
  In this paper, we propose MuRel, a multimodal relational network which is
learned end-to-end to reason over real images. Our first contribution is the
introduction of the MuRel cell, an atomic reasoning primitive representing
interactions between question and image regions by a rich vectorial
representation, and modeling region relations with pairwise combinations.
Secondly, we incorporate the cell into a full MuRel network, which
progressively refines visual and question interactions, and can be leveraged to
define visualization schemes finer than mere attention maps.
  We validate the relevance of our approach with various ablation studies, and
show its superiority to attention-based methods on three datasets: VQA 2.0,
VQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms
state-of-the-art results in this challenging context.
  Our code is available: https://github.com/Cadene/murel.bootstrap.pytorch
</summary>
    <author>
      <name>Remi Cadene</name>
    </author>
    <author>
      <name>Hedi Ben-younes</name>
    </author>
    <author>
      <name>Matthieu Cord</name>
    </author>
    <author>
      <name>Nicolas Thome</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CVPR2019 accepted paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09393v2</id>
    <updated>2019-05-29T12:42:17Z</updated>
    <published>2019-02-25T15:56:34Z</published>
    <title>Cooperative Learning of Disjoint Syntax and Semantics</title>
    <summary>  There has been considerable attention devoted to models that learn to jointly
infer an expression's syntactic structure and its semantics. Yet,
\citet{NangiaB18} has recently shown that the current best systems fail to
learn the correct parsing strategy on mathematical expressions generated from a
simple context-free grammar. In this work, we present a recursive model
inspired by \newcite{ChoiYL18} that reaches near perfect accuracy on this task.
Our model is composed of two separated modules for syntax and semantics. They
are cooperatively trained with standard continuous and discrete optimization
schemes. Our model does not require any linguistic structure for supervision
and its recursive nature allows for out-of-domain generalization with little
loss in performance. Additionally, our approach performs competitively on
several natural language tasks, such as Natural Language Inference or Sentiment
Analysis.
</summary>
    <author>
      <name>Serhii Havrylov</name>
    </author>
    <author>
      <name>Germán Kruszewski</name>
    </author>
    <author>
      <name>Armand Joulin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper was accepted at NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09393v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09393v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09243v2</id>
    <updated>2019-04-12T05:00:20Z</updated>
    <published>2019-02-25T13:07:32Z</published>
    <title>Pretraining-Based Natural Language Generation for Text Summarization</title>
    <summary>  In this paper, we propose a novel pretraining-based encoder-decoder
framework, which can generate the output sequence based on the input sequence
in a two-stage manner. For the encoder of our model, we encode the input
sequence into context representations using BERT. For the decoder, there are
two stages in our model, in the first stage, we use a Transformer-based decoder
to generate a draft output sequence. In the second stage, we mask each word of
the draft sequence and feed it to BERT, then by combining the input sequence
and the draft representation generated by BERT, we use a Transformer-based
decoder to predict the refined word for each masked position. To the best of
our knowledge, our approach is the first method which applies the BERT into
text generation tasks. As the first step in this direction, we evaluate our
proposed method on the text summarization task. Experimental results show that
our model achieves new state-of-the-art on both CNN/Daily Mail and New York
Times datasets.
</summary>
    <author>
      <name>Haoyu Zhang</name>
    </author>
    <author>
      <name>Jianjun Xu</name>
    </author>
    <author>
      <name>Ji Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CoNLL'2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.09243v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09243v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09093v1</id>
    <updated>2019-02-25T05:04:26Z</updated>
    <published>2019-02-25T05:04:26Z</published>
    <title>Multi-Relational Question Answering from Narratives: Machine Reading and
  Reasoning in Simulated Worlds</title>
    <summary>  Question Answering (QA), as a research field, has primarily focused on either
knowledge bases (KBs) or free text as a source of knowledge. These two sources
have historically shaped the kinds of questions that are asked over these
sources, and the methods developed to answer them. In this work, we look
towards a practical use-case of QA over user-instructed knowledge that uniquely
combines elements of both structured QA over knowledge bases, and unstructured
QA over narrative, introducing the task of multi-relational QA over personal
narrative. As a first step towards this goal, we make three key contributions:
(i) we generate and release TextWorldsQA, a set of five diverse datasets, where
each dataset contains dynamic narrative that describes entities and relations
in a simulated world, paired with variably compositional questions over that
knowledge, (ii) we perform a thorough evaluation and analysis of several
state-of-the-art QA models and their variants at this task, and (iii) we
release a lightweight Python-based framework we call TextWorlds for easily
generating arbitrary additional worlds and narrative, with the goal of allowing
the community to create and share a growing collection of diverse worlds as a
test-bed for this task.
</summary>
    <author>
      <name>Igor Labutov</name>
    </author>
    <author>
      <name>Bishan Yang</name>
    </author>
    <author>
      <name>Anusha Prakash</name>
    </author>
    <author>
      <name>Amos Azaria</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published at ACL 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.09093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09092v1</id>
    <updated>2019-02-25T05:04:11Z</updated>
    <published>2019-02-25T05:04:11Z</published>
    <title>Transfer Learning for Sequences via Learning to Collocate</title>
    <summary>  Transfer learning aims to solve the data sparsity for a target domain by
applying information of the source domain. Given a sequence (e.g. a natural
language sentence), the transfer learning, usually enabled by recurrent neural
network (RNN), represents the sequential information transfer. RNN uses a chain
of repeating cells to model the sequence data. However, previous studies of
neural network based transfer learning simply represents the whole sentence by
a single vector, which is unfeasible for seq2seq and sequence labeling.
Meanwhile, such layer-wise transfer learning mechanisms lose the fine-grained
cell-level information from the source domain.
  In this paper, we proposed the aligned recurrent transfer, ART, to achieve
cell-level information transfer. ART is under the pre-training framework. Each
cell attentively accepts transferred information from a set of positions in the
source domain. Therefore, ART learns the cross-domain word collocations in a
more flexible way. We conducted extensive experiments on both sequence labeling
tasks (POS tagging, NER) and sentence classification (sentiment analysis). ART
outperforms the state-of-the-arts over all experiments.
</summary>
    <author>
      <name>Wanyun Cui</name>
    </author>
    <author>
      <name>Guangyu Zheng</name>
    </author>
    <author>
      <name>Zhiqiang Shen</name>
    </author>
    <author>
      <name>Sihang Jiang</name>
    </author>
    <author>
      <name>Wei Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at ICLR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09091v1</id>
    <updated>2019-02-25T05:04:00Z</updated>
    <published>2019-02-25T05:04:00Z</published>
    <title>Leveraging Knowledge Bases in LSTMs for Improving Machine Reading</title>
    <summary>  This paper focuses on how to take advantage of external knowledge bases (KBs)
to improve recurrent neural networks for machine reading. Traditional methods
that exploit knowledge from KBs encode knowledge as discrete indicator
features. Not only do these features generalize poorly, but they require
task-specific feature engineering to achieve good performance. We propose
KBLSTM, a novel neural model that leverages continuous representations of KBs
to enhance the learning of recurrent neural networks for machine reading. To
effectively integrate background knowledge with information from the currently
processed text, our model employs an attention mechanism with a sentinel to
adaptively decide whether to attend to background knowledge and which
information from KBs is useful. Experimental results show that our model
achieves accuracies that surpass the previous state-of-the-art results for both
entity extraction and event extraction on the widely used ACE2005 dataset.
</summary>
    <author>
      <name>Bishan Yang</name>
    </author>
    <author>
      <name>Tom Mitchell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published at ACL 2017</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.09091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09006v2</id>
    <updated>2019-11-02T00:21:08Z</updated>
    <published>2019-02-24T20:05:07Z</published>
    <title>Learning to Perform Role-Filler Binding with Schematic Knowledge</title>
    <summary>  Through specific experiences, humans learn structural relationships
underlying events in the world. Generalizing knowledge of structural
relationships to new situations requires dynamic role-filler binding, the
ability to associate specific "fillers" with abstract "roles". Previous work
found that artificial neural networks can learn this ability when explicitly
told what the roles and fillers are. We show that networks can learn these
relationships even without explicitly labeled roles and fillers, and show that
analyses inspired by neural decoding can provide a means of understanding what
the networks have learned.
</summary>
    <author>
      <name>Catherine Chen</name>
    </author>
    <author>
      <name>Qihong Lu</name>
    </author>
    <author>
      <name>Andre Beukers</name>
    </author>
    <author>
      <name>Christopher Baldassano</name>
    </author>
    <author>
      <name>Kenneth A. Norman</name>
    </author>
    <link href="http://arxiv.org/abs/1902.09006v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09006v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.08858v2</id>
    <updated>2019-04-15T17:07:43Z</updated>
    <published>2019-02-23T22:27:45Z</published>
    <title>Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog
  Agents with Latent Variable Models</title>
    <summary>  Defining action spaces for conversational agents and optimizing their
decision-making process with reinforcement learning is an enduring challenge.
Common practice has been to use handcrafted dialog acts, or the output
vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have
their own limitations. This paper proposes a novel latent action framework that
treats the action spaces of an end-to-end dialog agent as latent variables and
develops unsupervised methods in order to induce its own action space from the
data. Comprehensive experiments are conducted examining both continuous and
discrete action types and two different optimization methods based on
stochastic variational inference. Results show that the proposed latent actions
achieve superior empirical performance improvement over previous word-level
policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed
analysis also provides insights about various latent variable approaches for
policy learning and can serve as a foundation for developing better latent
actions in future research.
</summary>
    <author>
      <name>Tiancheng Zhao</name>
    </author>
    <author>
      <name>Kaige Xie</name>
    </author>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Camera ready version for NAACL 2019 long paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.08858v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.08858v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.08649v3</id>
    <updated>2019-04-04T04:42:28Z</updated>
    <published>2019-02-22T19:38:36Z</published>
    <title>Saliency Learning: Teaching the Model Where to Pay Attention</title>
    <summary>  Deep learning has emerged as a compelling solution to many NLP tasks with
remarkable performances. However, due to their opacity, such models are hard to
interpret and trust. Recent work on explaining deep models has introduced
approaches to provide insights toward the model's behaviour and predictions,
which are helpful for assessing the reliability of the model's predictions.
However, such methods do not improve the model's reliability. In this paper, we
aim to teach the model to make the right prediction for the right reason by
providing explanation training and ensuring the alignment of the model's
explanation with the ground truth explanation. Our experimental results on
multiple tasks and datasets demonstrate the effectiveness of the proposed
method, which produces more reliable predictions while delivering better
results compared to traditionally trained models.
</summary>
    <author>
      <name>Reza Ghaeini</name>
    </author>
    <author>
      <name>Xiaoli Z. Fern</name>
    </author>
    <author>
      <name>Hamed Shahbazi</name>
    </author>
    <author>
      <name>Prasad Tadepalli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a short paper at NAACL 2019. 10 pages, 2 figures, 6
  tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.08649v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.08649v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.07867v2</id>
    <updated>2019-04-02T02:29:57Z</updated>
    <published>2019-02-21T05:16:45Z</published>
    <title>ntuer at SemEval-2019 Task 3: Emotion Classification with Word and
  Sentence Representations in RCNN</title>
    <summary>  In this paper we present our model on the task of emotion detection in
textual conversations in SemEval-2019. Our model extends the Recurrent
Convolutional Neural Network (RCNN) by using external fine-tuned word
representations and DeepMoji sentence representations. We also explored several
other competitive pre-trained word and sentence representations including ELMo,
BERT and InferSent but found inferior performance. In addition, we conducted
extensive sensitivity analysis, which empirically shows that our model is
relatively robust to hyper-parameters. Our model requires no handcrafted
features or emotion lexicons but achieved good performance with a micro-F1
score of 0.7463.
</summary>
    <author>
      <name>Peixiang Zhong</name>
    </author>
    <author>
      <name>Chunyan Miao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SemEval 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.07867v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.07867v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.07831v1</id>
    <updated>2019-02-21T01:12:07Z</updated>
    <published>2019-02-21T01:12:07Z</published>
    <title>Predicting ConceptNet Path Quality Using Crowdsourced Assessments of
  Naturalness</title>
    <summary>  In many applications, it is important to characterize the way in which two
concepts are semantically related. Knowledge graphs such as ConceptNet provide
a rich source of information for such characterizations by encoding relations
between concepts as edges in a graph. When two concepts are not directly
connected by an edge, their relationship can still be described in terms of the
paths that connect them. Unfortunately, many of these paths are uninformative
and noisy, which means that the success of applications that use such path
features crucially relies on their ability to select high-quality paths. In
existing applications, this path selection process is based on relatively
simple heuristics. In this paper we instead propose to learn to predict path
quality from crowdsourced human assessments. Since we are interested in a
generic task-independent notion of quality, we simply ask human participants to
rank paths according to their subjective assessment of the paths' naturalness,
without attempting to define naturalness or steering the participants towards
particular indicators of quality. We show that a neural network model trained
on these assessments is able to predict human judgments on unseen paths with
near optimal performance. Most notably, we find that the resulting path
selection method is substantially better than the current heuristic approaches
at identifying meaningful paths.
</summary>
    <author>
      <name>Yilun Zhou</name>
    </author>
    <author>
      <name>Steven Schockaert</name>
    </author>
    <author>
      <name>Julie A. Shah</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313486</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313486" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Web Conference (WWW) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.07831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.07831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.07282v1</id>
    <updated>2019-02-19T21:03:35Z</updated>
    <published>2019-02-19T21:03:35Z</published>
    <title>Semantic Neural Machine Translation using AMR</title>
    <summary>  It is intuitive that semantic representations can be useful for machine
translation, mainly because they can help in enforcing meaning preservation and
handling data sparsity (many sentences correspond to one meaning) of machine
translation models. On the other hand, little work has been done on leveraging
semantics for neural machine translation (NMT). In this work, we study the
usefulness of AMR (short for abstract meaning representation) on NMT.
Experiments on a standard English-to-German dataset show that incorporating AMR
as additional knowledge can significantly improve a strong attention-based
sequence-to-sequence neural translation model.
</summary>
    <author>
      <name>Linfeng Song</name>
    </author>
    <author>
      <name>Daniel Gildea</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Zhiguo Wang</name>
    </author>
    <author>
      <name>Jinsong Su</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/tacl_a_00252</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/tacl_a_00252" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Transaction of ACL 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Transactions of the Association for Computational Linguistics, 7,
  pages19-31, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.07282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.07282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.07198v4</id>
    <updated>2019-05-31T20:54:19Z</updated>
    <published>2019-02-19T18:51:10Z</published>
    <title>Learning to Generalize from Sparse and Underspecified Rewards</title>
    <summary>  We consider the problem of learning from sparse and underspecified rewards,
where an agent receives a complex input, such as a natural language
instruction, and needs to generate a complex response, such as an action
sequence, while only receiving binary success-failure feedback. Such
success-failure rewards are often underspecified: they do not distinguish
between purposeful and accidental success. Generalization from underspecified
rewards hinges on discounting spurious trajectories that attain accidental
success, while learning from sparse feedback requires effective exploration. We
address exploration by using a mode covering direction of KL divergence to
collect a diverse set of successful trajectories, followed by a mode seeking KL
divergence to train a robust policy. We propose Meta Reward Learning (MeRL) to
construct an auxiliary reward function that provides more refined feedback for
learning. The parameters of the auxiliary reward function are optimized with
respect to the validation performance of a trained policy. The MeRL approach
outperforms our alternative reward learning technique based on Bayesian
Optimization, and achieves the state-of-the-art on weakly-supervised semantic
parsing. It improves previous work by 1.2% and 2.4% on WikiTableQuestions and
WikiSQL datasets respectively.
</summary>
    <author>
      <name>Rishabh Agarwal</name>
    </author>
    <author>
      <name>Chen Liang</name>
    </author>
    <author>
      <name>Dale Schuurmans</name>
    </author>
    <author>
      <name>Mohammad Norouzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.07198v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.07198v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.07178v1</id>
    <updated>2019-02-19T18:18:59Z</updated>
    <published>2019-02-19T18:18:59Z</published>
    <title>A spelling correction model for end-to-end speech recognition</title>
    <summary>  Attention-based sequence-to-sequence models for speech recognition jointly
train an acoustic model, language model (LM), and alignment mechanism using a
single neural network and require only parallel audio-text pairs. Thus, the
language model component of the end-to-end model is only trained on transcribed
audio-text pairs, which leads to performance degradation especially on rare
words. While there have been a variety of work that look at incorporating an
external LM trained on text-only data into the end-to-end framework, none of
them have taken into account the characteristic error distribution made by the
model. In this paper, we propose a novel approach to utilizing text-only data,
by training a spelling correction (SC) model to explicitly correct those
errors. On the LibriSpeech dataset, we demonstrate that the proposed model
results in an 18.6% relative improvement in WER over the baseline model when
directly correcting top ASR hypothesis, and a 29.0% relative improvement when
further rescoring an expanded n-best list using an external LM.
</summary>
    <author>
      <name>Jinxi Guo</name>
    </author>
    <author>
      <name>Tara N. Sainath</name>
    </author>
    <author>
      <name>Ron J. Weiss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICASSP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.07178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.07178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.06897v1</id>
    <updated>2019-02-19T05:14:14Z</updated>
    <published>2019-02-19T05:14:14Z</published>
    <title>On Voting Strategies and Emergent Communication</title>
    <summary>  Humans use language to collectively execute complex strategies in addition to
using it as a referential tool for referring to physical entities. While
existing approaches that study the emergence of language in settings where the
language mainly acts as a referential tool, in this paper, we study the role of
emergent languages in discovering and implementing strategies in a multi-agent
setting. The agents in our setup are connected via a network and are allowed to
exchange messages in the form of sequences of discrete symbols. We formulate
the problem as a voting game, where two candidate agents are contesting in an
election and their goal is to convince the population members (other agents) in
the network to vote for them by sending them messages. We use neural networks
to parameterize the policies followed by agents in the game. We investigate the
effect of choosing different training objectives and strategies for agents in
the game and make observations about the emergent language in each case. To the
best of our knowledge this is the first work that explores emergence of
language for discovering and implementing strategies in a setting where agents
are connected via an underlying network.
</summary>
    <author>
      <name>Shubham Gupta</name>
    </author>
    <author>
      <name>Ambedkar Dukkipati</name>
    </author>
    <link href="http://arxiv.org/abs/1902.06897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.06897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.06377v2</id>
    <updated>2019-07-27T02:07:10Z</updated>
    <published>2019-02-18T02:00:23Z</published>
    <title>SCEF: A Support-Confidence-aware Embedding Framework for Knowledge Graph
  Refinement</title>
    <summary>  Knowledge graph (KG) refinement mainly aims at KG completion and correction
(i.e., error detection). However, most conventional KG embedding models only
focus on KG completion with an unreasonable assumption that all facts in KG
hold without noises, ignoring error detection which also should be significant
and essential for KG refinement.In this paper, we propose a novel
support-confidence-aware KG embedding framework (SCEF), which implements KG
completion and correction simultaneously by learning knowledge representations
with both triple support and triple confidence. Specifically, we build model
energy function by incorporating conventional translation-based model with
support and confidence. To make our triple support-confidence more sufficient
and robust, we not only consider the internal structural information in KG,
studying the approximate relation entailment as triple confidence constraints,
but also the external textual evidence, proposing two kinds of triple supports
with entity types and descriptions respectively.Through extensive experiments
on real-world datasets, we demonstrate SCEF's effectiveness.
</summary>
    <author>
      <name>Yu Zhao</name>
    </author>
    <author>
      <name>Ji Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">(1)the model are unreasonable;(2)the experiments are unfair to
  baselines;</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.06377v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.06377v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.06000v1</id>
    <updated>2019-02-15T22:54:32Z</updated>
    <published>2019-02-15T22:54:32Z</published>
    <title>Improving Semantic Parsing for Task Oriented Dialog</title>
    <summary>  Semantic parsing using hierarchical representations has recently been
proposed for task oriented dialog with promising results [Gupta et al 2018]. In
this paper, we present three different improvements to the model:
contextualized embeddings, ensembling, and pairwise re-ranking based on a
language model. We taxonomize the errors possible for the hierarchical
representation, such as wrong top intent, missing spans or split spans, and
show that the three approaches correct different kinds of errors. The best
model combines the three techniques and gives 6.4% better exact match accuracy
than the state-of-the-art, with an error reduction of 33%, resulting in a new
state-of-the-art result on the Task Oriented Parsing (TOP) dataset.
</summary>
    <author>
      <name>Arash Einolghozati</name>
    </author>
    <author>
      <name>Panupong Pasupat</name>
    </author>
    <author>
      <name>Sonal Gupta</name>
    </author>
    <author>
      <name>Rushin Shah</name>
    </author>
    <author>
      <name>Mrinal Mohit</name>
    </author>
    <author>
      <name>Mike Lewis</name>
    </author>
    <author>
      <name>Luke Zettlemoyer</name>
    </author>
    <link href="http://arxiv.org/abs/1902.06000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.06000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.05770v1</id>
    <updated>2019-02-15T11:14:35Z</updated>
    <published>2019-02-15T11:14:35Z</published>
    <title>Dynamic Layer Aggregation for Neural Machine Translation with
  Routing-by-Agreement</title>
    <summary>  With the promising progress of deep neural networks, layer aggregation has
been used to fuse information across layers in various fields, such as computer
vision and machine translation. However, most of the previous methods combine
layers in a static fashion in that their aggregation strategy is independent of
specific hidden states. Inspired by recent progress on capsule networks, in
this paper we propose to use routing-by-agreement strategies to aggregate
layers dynamically. Specifically, the algorithm learns the probability of a
part (individual layer representations) assigned to a whole (aggregated
representations) in an iterative way and combines parts accordingly. We
implement our algorithm on top of the state-of-the-art neural machine
translation model TRANSFORMER and conduct experiments on the widely-used WMT14
English-German and WMT17 Chinese-English translation datasets. Experimental
results across language pairs show that the proposed approach consistently
outperforms the strong baseline model and a representative static aggregation
model.
</summary>
    <author>
      <name>Zi-Yi Dou</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <author>
      <name>Xing Wang</name>
    </author>
    <author>
      <name>Longyue Wang</name>
    </author>
    <author>
      <name>Shuming Shi</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.05770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.05770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.05715v1</id>
    <updated>2019-02-15T07:59:11Z</updated>
    <published>2019-02-15T07:59:11Z</published>
    <title>Generating Natural Language Explanations for Visual Question Answering
  using Scene Graphs and Visual Attention</title>
    <summary>  In this paper, we present a novel approach for the task of eXplainable
Question Answering (XQA), i.e., generating natural language (NL) explanations
for the Visual Question Answering (VQA) problem. We generate NL explanations
comprising of the evidence to support the answer to a question asked to an
image using two sources of information: (a) annotations of entities in an image
(e.g., object labels, region descriptions, relation phrases) generated from the
scene graph of the image, and (b) the attention map generated by a VQA model
when answering the question. We show how combining the visual attention map
with the NL representation of relevant scene graph entities, carefully selected
using a language model, can give reasonable textual explanations without the
need of any additional collected data (explanation captions, etc). We run our
algorithms on the Visual Genome (VG) dataset and conduct internal user-studies
to demonstrate the efficacy of our approach over a strong baseline. We have
also released a live web demo showcasing our VQA and textual explanation
generation using scene graphs and visual attention.
</summary>
    <author>
      <name>Shalini Ghosh</name>
    </author>
    <author>
      <name>Giedrius Burachas</name>
    </author>
    <author>
      <name>Arijit Ray</name>
    </author>
    <author>
      <name>Avi Ziskind</name>
    </author>
    <link href="http://arxiv.org/abs/1902.05715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.05715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.05070v1</id>
    <updated>2019-02-13T11:17:43Z</updated>
    <published>2019-02-13T11:17:43Z</published>
    <title>Optimization problems with low SWaP tactical Computing</title>
    <summary>  In a resource-constrained, contested environment, computing resources need to
be aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware
computational efficiency depends upon optimization of computational resources
and intelligent time versus efficiency tradeoffs in decision making. In this
paper we address the complexity of various optimization strategies related to
low SWaP computing. Due to these restrictions, only a small subset of less
complicated and fast computable algorithms can be used for tactical, adaptive
computing.
</summary>
    <author>
      <name>Mee Seong Im</name>
    </author>
    <author>
      <name>Venkat R. Dasari</name>
    </author>
    <author>
      <name>Lubjana Beshaj</name>
    </author>
    <author>
      <name>Dale Shires</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure. To appear in Proc. SPIE</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.05070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.05070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.04187v1</id>
    <updated>2019-02-11T23:58:22Z</updated>
    <published>2019-02-11T23:58:22Z</published>
    <title>LS-Tree: Model Interpretation When the Data Are Linguistic</title>
    <summary>  We study the problem of interpreting trained classification models in the
setting of linguistic data sets. Leveraging a parse tree, we propose to assign
least-squares based importance scores to each word of an instance by exploiting
syntactic constituency structure. We establish an axiomatic characterization of
these importance scores by relating them to the Banzhaf value in coalitional
game theory. Based on these importance scores, we develop a principled method
for detecting and quantifying interactions between words in a sentence. We
demonstrate that the proposed method can aid in interpretability and
diagnostics for several widely-used language models.
</summary>
    <author>
      <name>Jianbo Chen</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <link href="http://arxiv.org/abs/1902.04187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.04187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.03570v1</id>
    <updated>2019-02-10T10:34:54Z</updated>
    <published>2019-02-10T10:34:54Z</published>
    <title>EvalAI: Towards Better Evaluation Systems for AI Agents</title>
    <summary>  We introduce EvalAI, an open source platform for evaluating and comparing
machine learning (ML) and artificial intelligence algorithms (AI) at scale.
EvalAI is built to provide a scalable solution to the research community to
fulfill the critical need of evaluating machine learning models and agents
acting in an environment against annotations or with a human-in-the-loop. This
will help researchers, students, and data scientists to create, collaborate,
and participate in AI challenges organized around the globe. By simplifying and
standardizing the process of benchmarking these models, EvalAI seeks to lower
the barrier to entry for participating in the global scientific effort to push
the frontiers of machine learning and artificial intelligence, thereby
increasing the rate of measurable progress in this domain.
</summary>
    <author>
      <name>Deshraj Yadav</name>
    </author>
    <author>
      <name>Rishabh Jain</name>
    </author>
    <author>
      <name>Harsh Agrawal</name>
    </author>
    <author>
      <name>Prithvijit Chattopadhyay</name>
    </author>
    <author>
      <name>Taranjeet Singh</name>
    </author>
    <author>
      <name>Akash Jain</name>
    </author>
    <author>
      <name>Shiv Baran Singh</name>
    </author>
    <author>
      <name>Stefan Lee</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <link href="http://arxiv.org/abs/1902.03570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.03570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02113v1</id>
    <updated>2019-02-06T11:15:08Z</updated>
    <published>2019-02-06T11:15:08Z</published>
    <title>Latent Space Cartography: Generalised Metric-Inspired Measures and
  Measure-Based Transformations for Generative Models</title>
    <summary>  Deep generative models are universal tools for learning data distributions on
high dimensional data spaces via a mapping to lower dimensional latent spaces.
We provide a study of latent space geometries and extend and build upon
previous results on Riemannian metrics. We show how a class of heuristic
measures gives more flexibility in finding meaningful, problem-specific
distances, and how it can be applied to diverse generator types such as
autoregressive generators commonly used in e.g. language and other sequence
modeling. We further demonstrate how a diffusion-inspired transformation
previously studied in cartography can be used to smooth out latent spaces,
stretching them according to a chosen measure. In addition to providing more
meaningful distances directly in latent space, this also provides a unique tool
for novel kinds of data visualizations. We believe that the proposed methods
can be a valuable tool for studying the structure of latent spaces and learned
data distributions of generative models.
</summary>
    <author>
      <name>Max F. Frenzel</name>
    </author>
    <author>
      <name>Bogdan Teleaga</name>
    </author>
    <author>
      <name>Asahi Ushio</name>
    </author>
    <link href="http://arxiv.org/abs/1902.02113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01529v1</id>
    <updated>2019-02-05T03:25:24Z</updated>
    <published>2019-02-05T03:25:24Z</published>
    <title>An Ensemble Dialogue System for Facts-Based Sentence Generation</title>
    <summary>  This study aims to generate responses based on real-world facts by
conditioning context and external facts extracted from information websites.
Our system is an ensemble system that combines three modules: generated-based
module, retrieval-based module, and reranking module. Therefore, this system
can return diverse and meaningful responses from various perspectives. The
experiments and evaluations are conducted with the sentence generation task in
Dialog System Technology Challenges 7 (DSTC7-Task2). As a result, the proposed
system performed significantly better than sole modules, and worked fine at the
DSTC7-Task2, specifically on the objective evaluation.
</summary>
    <author>
      <name>Ryota Tanaka</name>
    </author>
    <author>
      <name>Akihide Ozeki</name>
    </author>
    <author>
      <name>Shugo Kato</name>
    </author>
    <author>
      <name>Akinobu Lee</name>
    </author>
    <link href="http://arxiv.org/abs/1902.01529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01385v1</id>
    <updated>2019-02-04T18:53:14Z</updated>
    <published>2019-02-04T18:53:14Z</published>
    <title>Embodied Multimodal Multitask Learning</title>
    <summary>  Recent efforts on training visual navigation agents conditioned on language
using deep reinforcement learning have been successful in learning policies for
different multimodal tasks, such as semantic goal navigation and embodied
question answering. In this paper, we propose a multitask model capable of
jointly learning these multimodal tasks, and transferring knowledge of words
and their grounding in visual objects across the tasks. The proposed model uses
a novel Dual-Attention unit to disentangle the knowledge of words in the
textual representations and visual concepts in the visual representations, and
align them with each other. This disentangled task-invariant alignment of
representations facilitates grounding and knowledge transfer across both tasks.
We show that the proposed model outperforms a range of baselines on both tasks
in simulated 3D environments. We also show that this disentanglement of
representations makes our model modular, interpretable, and allows for transfer
to instructions containing new words by leveraging object detectors.
</summary>
    <author>
      <name>Devendra Singh Chaplot</name>
    </author>
    <author>
      <name>Lisa Lee</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">See https://devendrachaplot.github.io/projects/EMML for demo videos</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.01385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02181v1</id>
    <updated>2019-02-04T17:14:13Z</updated>
    <published>2019-02-04T17:14:13Z</published>
    <title>Attention, please! A Critical Review of Neural Attention Models in
  Natural Language Processing</title>
    <summary>  Attention is an increasingly popular mechanism used in a wide range of neural
architectures. Because of the fast-paced advances in this domain, a systematic
overview of attention is still missing. In this article, we define a unified
model for attention architectures for natural language processing, with a focus
on architectures designed to work with vector representation of the textual
data. We discuss the dimensions along which proposals differ, the possible uses
of attention, and chart the major research activities and open challenges in
the area.
</summary>
    <author>
      <name>Andrea Galassi</name>
    </author>
    <author>
      <name>Marco Lippi</name>
    </author>
    <author>
      <name>Paolo Torroni</name>
    </author>
    <link href="http://arxiv.org/abs/1902.02181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01313v2</id>
    <updated>2019-07-24T22:23:38Z</updated>
    <published>2019-02-04T17:08:32Z</published>
    <title>An Effective Approach to Unsupervised Machine Translation</title>
    <summary>  While machine translation has traditionally relied on large amounts of
parallel corpora, a recent research line has managed to train both Neural
Machine Translation (NMT) and Statistical Machine Translation (SMT) systems
using monolingual corpora only. In this paper, we identify and address several
deficiencies of existing unsupervised SMT approaches by exploiting subword
information, developing a theoretically well founded unsupervised tuning
method, and incorporating a joint refinement procedure. Moreover, we use our
improved SMT system to initialize a dual NMT model, which is further fine-tuned
through on-the-fly back-translation. Together, we obtain large improvements
over the previous state-of-the-art in unsupervised machine translation. For
instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points
more than the previous best unsupervised system, and 0.5 points more than the
(supervised) shared task winner back in 2014.
</summary>
    <author>
      <name>Mikel Artetxe</name>
    </author>
    <author>
      <name>Gorka Labaka</name>
    </author>
    <author>
      <name>Eneko Agirre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.01313v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01313v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01119v2</id>
    <updated>2019-05-19T07:35:28Z</updated>
    <published>2019-02-04T10:46:53Z</published>
    <title>The Natural Language of Actions</title>
    <summary>  We introduce Act2Vec, a general framework for learning context-based action
representation for Reinforcement Learning. Representing actions in a vector
space help reinforcement learning algorithms achieve better performance by
grouping similar actions and utilizing relations between different actions. We
show how prior knowledge of an environment can be extracted from demonstrations
and injected into action vector representations that encode natural compatible
behavior. We then use these for augmenting state representations as well as
improving function approximation of Q-values. We visualize and test action
embeddings in three domains including a drawing task, a high dimensional
navigation task, and the large action space domain of StarCraft II.
</summary>
    <author>
      <name>Guy Tennenholtz</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the proceedings of the 36th International Conference on
  Machine Learning (ICML 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.01119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01030v2</id>
    <updated>2019-06-03T14:43:32Z</updated>
    <published>2019-02-04T04:42:08Z</published>
    <title>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</title>
    <summary>  Most approaches to extraction multiple relations from a paragraph require
multiple passes over the paragraph. In practice, multiple passes are
computationally expensive and this makes difficult to scale to longer
paragraphs and larger text corpora. In this work, we focus on the task of
multiple relation extraction by encoding the paragraph only once (one-pass). We
build our solution on the pre-trained self-attentive (Transformer) models,
where we first add a structured prediction layer to handle extraction between
multiple entity pairs, then enhance the paragraph embedding to capture multiple
relational information associated with each entity with an entity-aware
attention technique. We show that our approach is not only scalable but can
also perform state-of-the-art on the standard benchmark ACE 2005.
</summary>
    <author>
      <name>Haoyu Wang</name>
    </author>
    <author>
      <name>Ming Tan</name>
    </author>
    <author>
      <name>Mo Yu</name>
    </author>
    <author>
      <name>Shiyu Chang</name>
    </author>
    <author>
      <name>Dakuo Wang</name>
    </author>
    <author>
      <name>Kun Xu</name>
    </author>
    <author>
      <name>Xiaoxiao Guo</name>
    </author>
    <author>
      <name>Saloni Potdar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.01030v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01030v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.00672v1</id>
    <updated>2019-02-02T08:52:44Z</updated>
    <published>2019-02-02T08:52:44Z</published>
    <title>Query-oriented text summarization based on hypergraph transversals</title>
    <summary>  Existing graph- and hypergraph-based algorithms for document summarization
represent the sentences of a corpus as the nodes of a graph or a hypergraph in
which the edges represent relationships of lexical similarities between
sentences. Each sentence of the corpus is then scored individually, using
popular node ranking algorithms, and a summary is produced by extracting highly
scored sentences. This approach fails to select a subset of jointly relevant
sentences and it may produce redundant summaries that are missing important
topics of the corpus. To alleviate this issue, a new hypergraph-based
summarizer is proposed in this paper, in which each node is a sentence and each
hyperedge is a theme, namely a group of sentences sharing a topic. Themes are
weighted in terms of their prominence in the corpus and their relevance to a
user-defined query. It is further shown that the problem of identifying a
subset of sentences covering the relevant themes of the corpus is equivalent to
that of finding a hypergraph transversal in our theme-based hypergraph. Two
extensions of the notion of hypergraph transversal are proposed for the purpose
of summarization, and polynomial time algorithms building on the theory of
submodular functions are proposed for solving the associated discrete
optimization problems. The worst-case time complexity of the proposed
algorithms is squared in the number of terms, which makes it cheaper than the
existing hypergraph-based methods. A thorough comparative analysis with related
models on DUC benchmark datasets demonstrates the effectiveness of our
approach, which outperforms existing graph- or hypergraph-based methods by at
least 6% of ROUGE-SU4 score.
</summary>
    <author>
      <name>Hadrien Van Lierde</name>
    </author>
    <author>
      <name>Tommy W. S. Chow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ipm.2019.03.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ipm.2019.03.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the unrefereed Author's Original Version (or pre-print
  Version) of the article</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Processing &amp; Management, Volume 56, Issue 4, July
  2019, Pages 1317-1338</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.00672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.00672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.00175v1</id>
    <updated>2019-02-01T04:30:42Z</updated>
    <published>2019-02-01T04:30:42Z</published>
    <title>Dating Documents using Graph Convolution Networks</title>
    <summary>  Document date is essential for many important tasks, such as document
retrieval, summarization, event detection, etc. While existing approaches for
these tasks assume accurate knowledge of the document date, this is not always
available, especially for arbitrary documents from the Web. Document Dating is
a challenging problem which requires inference over the temporal structure of
the document. Prior document dating systems have largely relied on handcrafted
features while ignoring such document internal structures. In this paper, we
propose NeuralDater, a Graph Convolutional Network (GCN) based document dating
approach which jointly exploits syntactic and temporal graph structures of
document in a principled way. To the best of our knowledge, this is the first
application of deep learning for the problem of document dating. Through
extensive experiments on real-world datasets, we find that NeuralDater
significantly outperforms state-of-the-art baseline by 19% absolute (45%
relative) accuracy points.
</summary>
    <author>
      <name>Shikhar Vashishth</name>
    </author>
    <author>
      <name>Shib Sankar Dasgupta</name>
    </author>
    <author>
      <name>Swayambhu Nath Ray</name>
    </author>
    <author>
      <name>Partha Talukdar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ACL 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 56th Annual Meeting of the Association for
  Computational Linguistics 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1902.00175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.00175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.00098v1</id>
    <updated>2019-01-31T22:14:34Z</updated>
    <published>2019-01-31T22:14:34Z</published>
    <title>The Second Conversational Intelligence Challenge (ConvAI2)</title>
    <summary>  We describe the setting and results of the ConvAI2 NeurIPS competition that
aims to further the state-of-the-art in open-domain chatbots. Some key
takeaways from the competition are: (i) pretrained Transformer variants are
currently the best performing models on this task, (ii) but to improve
performance on multi-turn conversations with humans, future systems must go
beyond single word metrics like perplexity to measure the performance across
sequences of utterances (conversations) -- in terms of repetition, consistency
and balance of dialogue acts (e.g. how many questions asked vs. answered).
</summary>
    <author>
      <name>Emily Dinan</name>
    </author>
    <author>
      <name>Varvara Logacheva</name>
    </author>
    <author>
      <name>Valentin Malykh</name>
    </author>
    <author>
      <name>Alexander Miller</name>
    </author>
    <author>
      <name>Kurt Shuster</name>
    </author>
    <author>
      <name>Jack Urbanek</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Iulian Serban</name>
    </author>
    <author>
      <name>Ryan Lowe</name>
    </author>
    <author>
      <name>Shrimai Prabhumoye</name>
    </author>
    <author>
      <name>Alan W Black</name>
    </author>
    <author>
      <name>Alexander Rudnicky</name>
    </author>
    <author>
      <name>Jason Williams</name>
    </author>
    <author>
      <name>Joelle Pineau</name>
    </author>
    <author>
      <name>Mikhail Burtsev</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <link href="http://arxiv.org/abs/1902.00098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.00098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11528v1</id>
    <updated>2019-01-31T18:48:19Z</updated>
    <published>2019-01-31T18:48:19Z</published>
    <title>Shaping the Narrative Arc: An Information-Theoretic Approach to
  Collaborative Dialogue</title>
    <summary>  We consider the problem of designing an artificial agent capable of
interacting with humans in collaborative dialogue to produce creative, engaging
narratives. In this task, the goal is to establish universe details, and to
collaborate on an interesting story in that universe, through a series of
natural dialogue exchanges. Our model can augment any probabilistic
conversational agent by allowing it to reason about universe information
established and what potential next utterances might reveal. Ideally, with each
utterance, agents would reveal just enough information to add specificity and
reduce ambiguity without limiting the conversation. We empirically show that
our model allows control over the rate at which the agent reveals information
and that doing so significantly improves accuracy in predicting the next line
of dialogues from movies. We close with a case-study with four professional
theatre performers, who preferred interactions with our model-augmented agent
over an unaugmented agent.
</summary>
    <author>
      <name>Kory W. Mathewson</name>
    </author>
    <author>
      <name>Pablo Samuel Castro</name>
    </author>
    <author>
      <name>Colin Cherry</name>
    </author>
    <author>
      <name>George Foster</name>
    </author>
    <author>
      <name>Marc G. Bellemare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.11528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02169v1</id>
    <updated>2019-01-31T17:18:42Z</updated>
    <published>2019-01-31T17:18:42Z</published>
    <title>Learning Taxonomies of Concepts and not Words using Contextualized Word
  Representations: A Position Paper</title>
    <summary>  Taxonomies are semantic hierarchies of concepts. One limitation of current
taxonomy learning systems is that they define concepts as single words. This
position paper argues that contextualized word representations, which recently
achieved state-of-the-art results on many competitive NLP tasks, are a
promising method to address this limitation. We outline a novel approach for
taxonomy learning that (1) defines concepts as synsets, (2) learns
density-based approximations of contextualized word representations, and (3)
can measure similarity and hypernymy among them.
</summary>
    <author>
      <name>Lukas Schmelzeisen</name>
    </author>
    <author>
      <name>Steffen Staab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.02169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11467v1</id>
    <updated>2019-01-31T16:51:49Z</updated>
    <published>2019-01-31T16:51:49Z</published>
    <title>Towards Controlled Transformation of Sentiment in Sentences</title>
    <summary>  An obstacle to the development of many natural language processing products
is the vast amount of training examples necessary to get satisfactory results.
The generation of these examples is often a tedious and time-consuming task.
This paper this paper proposes a method to transform the sentiment of sentences
in order to limit the work necessary to generate more training data. This means
that one sentence can be transformed to an opposite sentiment sentence and
should reduce by half the work required in the generation of text. The proposed
pipeline consists of a sentiment classifier with an attention mechanism to
highlight the short phrases that determine the sentiment of a sentence. Then,
these phrases are changed to phrases of the opposite sentiment using a baseline
model and an autoencoder approach. Experiments are run on both the separate
parts of the pipeline as well as on the end-to-end model. The sentiment
classifier is tested on its accuracy and is found to perform adequately. The
autoencoder is tested on how well it is able to change the sentiment of an
encoded phrase and it was found that such a task is possible. We use human
evaluation to judge the performance of the full (end-to-end) pipeline and that
reveals that a model using word vectors outperforms the encoder model.
Numerical evaluation shows that a success rate of 54.7% is achieved on the
sentiment change.
</summary>
    <author>
      <name>Wouter Leeftink</name>
    </author>
    <author>
      <name>Gerasimos Spanakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICAART 2019, 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.11467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11462v1</id>
    <updated>2019-01-31T16:40:26Z</updated>
    <published>2019-01-31T16:40:26Z</published>
    <title>Exploring the context of recurrent neural network based conversational
  agents</title>
    <summary>  Conversational agents have begun to rise both in the academic (in terms of
research) and commercial (in terms of applications) world. This paper
investigates the task of building a non-goal driven conversational agent, using
neural network generative models and analyzes how the conversation context is
handled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent
Encoder-Decoder architecture, which includes an additional module to model the
context of the conversation using previous utterances information. We found
that the hierarchical model was able to extract relevant context information
and include them in the generation of the output. However, it performed worse
(35-40%) than the simple Encoder-Decoder model regarding both grammatically
correct output and meaningful response. Despite these results, experiments
demonstrate how conversations about similar topics appear close to each other
in the context space due to the increased frequency of specific topic-related
words, thus leaving promising directions for future research and how the
context of a conversation can be exploited.
</summary>
    <author>
      <name>Raffaele Piccini</name>
    </author>
    <author>
      <name>Gerasimos Spanakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICAART 2019, 10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.11462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11344v1</id>
    <updated>2019-01-31T13:26:28Z</updated>
    <published>2019-01-31T13:26:28Z</published>
    <title>Learning Efficient Lexically-Constrained Neural Machine Translation with
  External Memory</title>
    <summary>  Recent years has witnessed dramatic progress of neural machine translation
(NMT), however, the method of manually guiding the translation procedure
remains to be better explored. Previous works proposed to handle such problem
through lexcially-constrained beam search in the decoding phase. Unfortunately,
these lexically-constrained beam search methods suffer two fatal disadvantages:
high computational complexity and hard beam search which generates unexpected
translations. In this paper, we propose to learn the ability of
lexically-constrained translation with external memory, which can overcome the
above mentioned disadvantages. For the training process, automatically
extracted phrase pairs are extracted from alignment and sentence parsing, then
further be encoded into an external memory. This memory is then used to provide
lexically-constrained information for training through a memory-attention
machanism. Various experiments are conducted on WMT Chinese to English and
English to German tasks. All the results can demonstrate the effectiveness of
our method.
</summary>
    <author>
      <name>Ya Li</name>
    </author>
    <author>
      <name>Xinyu Liu</name>
    </author>
    <author>
      <name>Dan Liu</name>
    </author>
    <author>
      <name>Xueqiang Zhang</name>
    </author>
    <author>
      <name>Junhua Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1901.11344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11333v4</id>
    <updated>2020-01-24T05:12:45Z</updated>
    <published>2019-01-31T12:41:57Z</published>
    <title>IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and
  Translation</title>
    <summary>  Text attribute transfer aims to automatically rewrite sentences such that
they possess certain linguistic attributes, while simultaneously preserving
their semantic content. This task remains challenging due to a lack of
supervised parallel data. Existing approaches try to explicitly disentangle
content and attribute information, but this is difficult and often results in
poor content-preservation and ungrammaticality. In contrast, we propose a
simpler approach, Iterative Matching and Translation (IMaT), which: (1)
constructs a pseudo-parallel corpus by aligning a subset of semantically
similar sentences from the source and the target corpora; (2) applies a
standard sequence-to-sequence model to learn the attribute transfer; (3)
iteratively improves the learned transfer function by refining imperfections in
the alignment. In sentiment modification and formality transfer tasks, our
method outperforms complex state-of-the-art systems by a large margin. As an
auxiliary contribution, we produce a publicly-available test set with
human-generated transfer references.
</summary>
    <author>
      <name>Zhijing Jin</name>
    </author>
    <author>
      <name>Di Jin</name>
    </author>
    <author>
      <name>Jonas Mueller</name>
    </author>
    <author>
      <name>Nicholas Matthews</name>
    </author>
    <author>
      <name>Enrico Santus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019 (Long Paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.11333v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11333v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10723v1</id>
    <updated>2019-01-30T09:32:51Z</updated>
    <published>2019-01-30T09:32:51Z</published>
    <title>Compositionality for Recursive Neural Networks</title>
    <summary>  Modelling compositionality has been a longstanding area of research in the
field of vector space semantics. The categorical approach to compositionality
maps grammar onto vector spaces in a principled way, but comes under fire for
requiring the formation of very high-dimensional matrices and tensors, and
therefore being computationally infeasible. In this paper I show how a linear
simplification of recursive neural tensor network models can be mapped directly
onto the categorical approach, giving a way of computing the required matrices
and tensors. This mapping suggests a number of lines of research for both
categorical compositional vector space models of meaning and for recursive
neural network models of compositionality.
</summary>
    <author>
      <name>Martha Lewis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at NeSy2018, Thirteenth International Workshop on
  Neural-Symbolic Learning and Reasoning, co-located with Human-Level AI 2018,
  Prague, CZ, August 23-24, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.10723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10263v1</id>
    <updated>2019-01-29T13:07:13Z</updated>
    <published>2019-01-29T13:07:13Z</published>
    <title>TiFi: Taxonomy Induction for Fictional Domains [Extended version]</title>
    <summary>  Taxonomies are important building blocks of structured knowledge bases, and
their construction from text sources and Wikipedia has received much attention.
In this paper we focus on the construction of taxonomies for fictional domains,
using noisy category systems from fan wikis or text extraction as input. Such
fictional domains are archetypes of entity universes that are poorly covered by
Wikipedia, such as also enterprise-specific knowledge bases or highly
specialized verticals. Our fiction-targeted approach, called TiFi, consists of
three phases: (i) category cleaning, by identifying candidate categories that
truly represent classes in the domain of interest, (ii) edge cleaning, by
selecting subcategory relationships that correspond to class subsumption, and
(iii) top-level construction, by mapping classes onto a subset of high-level
WordNet categories. A comprehensive evaluation shows that TiFi is able to
construct taxonomies for a diverse range of fictional domains such as Lord of
the Rings, The Simpsons or Greek Mythology with very high precision and that it
outperforms state-of-the-art baselines for taxonomy induction by a substantial
margin.
</summary>
    <author>
      <name>Cuong Xuan Chu</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of The Web Conference 2019 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.10263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10125v4</id>
    <updated>2019-09-04T12:15:19Z</updated>
    <published>2019-01-29T06:15:36Z</published>
    <title>Glyce: Glyph-vectors for Chinese Character Representations</title>
    <summary>  It is intuitive that NLP tasks for logographic languages like Chinese should
benefit from the use of the glyph information in those languages. However, due
to the lack of rich pictographic evidence in glyphs and the weak generalization
ability of standard computer vision models on character data, an effective way
to utilize the glyph information remains to be found. In this paper, we address
this gap by presenting Glyce, the glyph-vectors for Chinese character
representations. We make three major innovations: (1) We use historical Chinese
scripts (e.g., bronzeware script, seal script, traditional Chinese, etc) to
enrich the pictographic evidence in characters; (2) We design CNN structures
(called tianzege-CNN) tailored to Chinese character image processing; and (3)
We use image-classification as an auxiliary task in a multi-task learning setup
to increase the model's ability to generalize. We show that glyph-based models
are able to consistently outperform word/char ID-based models in a wide range
of Chinese NLP tasks. We are able to set new state-of-the-art results for a
variety of Chinese NLP tasks, including tagging (NER, CWS, POS), sentence pair
classification, single sentence classification tasks, dependency parsing, and
semantic role labeling. For example, the proposed model achieves an F1 score of
80.6 on the OntoNotes dataset of NER, +1.5 over BERT; it achieves an almost
perfect accuracy of 99.8\% on the Fudan corpus for text classification. Code
found at https://github.com/ShannonAI/glyce.
</summary>
    <author>
      <name>Yuxian Meng</name>
    </author>
    <author>
      <name>Wei Wu</name>
    </author>
    <author>
      <name>Fei Wang</name>
    </author>
    <author>
      <name>Xiaoya Li</name>
    </author>
    <author>
      <name>Ping Nie</name>
    </author>
    <author>
      <name>Fan Yin</name>
    </author>
    <author>
      <name>Muyu Li</name>
    </author>
    <author>
      <name>Qinghong Han</name>
    </author>
    <author>
      <name>Xiaofei Sun</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by NeurIPS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.10125v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10125v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.09501v2</id>
    <updated>2019-02-08T17:08:56Z</updated>
    <published>2019-01-28T03:38:08Z</published>
    <title>Toward Unsupervised Text Content Manipulation</title>
    <summary>  Controlled generation of text is of high practical use. Recent efforts have
made impressive progress in generating or editing sentences with given textual
attributes (e.g., sentiment). This work studies a new practical setting of text
content manipulation. Given a structured record, such as `(PLAYER: Lebron,
POINTS: 20, ASSISTS: 10)', and a reference sentence, such as `Kobe easily
dropped 30 points', we aim to generate a sentence that accurately describes the
full content in the record, with the same writing style (e.g., wording,
transitions) of the reference. The problem is unsupervised due to lack of
parallel data in practice, and is challenging to minimally yet effectively
manipulate the text (by rewriting/adding/deleting text portions) to ensure
fidelity to the structured content. We derive a dataset from a basketball game
report corpus as our testbed, and develop a neural method with unsupervised
competing objectives and explicit content coverage constraints. Automatic and
human evaluations show superiority of our approach over competitive methods
including a strong rule-based baseline and prior approaches designed for style
transfer.
</summary>
    <author>
      <name>Wentao Wang</name>
    </author>
    <author>
      <name>Zhiting Hu</name>
    </author>
    <author>
      <name>Zichao Yang</name>
    </author>
    <author>
      <name>Haoran Shi</name>
    </author>
    <author>
      <name>Frank Xu</name>
    </author>
    <author>
      <name>Eric Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first 2 authors contributed equally. Dataset is released at
  https://github.com/ZhitingHu/text_content_manipulation</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.09501v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.09501v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.08706v2</id>
    <updated>2020-02-28T19:32:05Z</updated>
    <published>2019-01-25T01:18:04Z</published>
    <title>Emergent Linguistic Phenomena in Multi-Agent Communication Games</title>
    <summary>  In this work, we propose a computational framework in which agents equipped
with communication capabilities simultaneously play a series of referential
games, where agents are trained using deep reinforcement learning. We
demonstrate that the framework mirrors linguistic phenomena observed in natural
language: i) the outcome of contact between communities is a function of inter-
and intra-group connectivity; ii) linguistic contact either converges to the
majority protocol, or in balanced cases leads to novel creole languages of
lower complexity; and iii) a linguistic continuum emerges where neighboring
languages are more mutually intelligible than farther removed languages. We
conclude that intricate properties of language evolution need not depend on
complex evolved linguistic capabilities, but can emerge from simple social
exchanges between perceptually-enabled agents playing communication games.
</summary>
    <author>
      <name>Laura Graesser</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <author>
      <name>Douwe Kiela</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.08706v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.08706v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.08259v1</id>
    <updated>2019-01-24T07:25:16Z</updated>
    <published>2019-01-24T07:25:16Z</published>
    <title>FANDA: A Novel Approach to Perform Follow-up Query Analysis</title>
    <summary>  Recent work on Natural Language Interfaces to Databases (NLIDB) has attracted
considerable attention. NLIDB allow users to search databases using natural
language instead of SQL-like query languages. While saving the users from
having to learn query languages, multi-turn interaction with NLIDB usually
involves multiple queries where contextual information is vital to understand
the users' query intents. In this paper, we address a typical contextual
understanding problem, termed as follow-up query analysis. In spite of its
ubiquity, follow-up query analysis has not been well studied due to two primary
obstacles: the multifarious nature of follow-up query scenarios and the lack of
high-quality datasets. Our work summarizes typical follow-up query scenarios
and provides a new FollowUp dataset with $1000$ query triples on 120 tables.
Moreover, we propose a novel approach FANDA, which takes into account the
structures of queries and employs a ranking model with weakly supervised
max-margin learning. The experimental results on FollowUp demonstrate the
superiority of FANDA over multiple baselines across multiple metrics.
</summary>
    <author>
      <name>Qian Liu</name>
    </author>
    <author>
      <name>Bei Chen</name>
    </author>
    <author>
      <name>Jian-Guang Lou</name>
    </author>
    <author>
      <name>Ge Jin</name>
    </author>
    <author>
      <name>Dongmei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.08259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.08259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.08079v1</id>
    <updated>2019-01-23T19:02:27Z</updated>
    <published>2019-01-23T19:02:27Z</published>
    <title>A Question-Entailment Approach to Question Answering</title>
    <summary>  One of the challenges in large-scale information retrieval (IR) is to develop
fine-grained and domain-specific methods to answer natural language questions.
Despite the availability of numerous sources and datasets for answer retrieval,
Question Answering (QA) remains a challenging problem due to the difficulty of
the question understanding and answer extraction tasks. One of the promising
tracks investigated in QA is to map new questions to formerly answered
questions that are `similar'. In this paper, we propose a novel QA approach
based on Recognizing Question Entailment (RQE) and we describe the QA system
and resources that we built and evaluated on real medical questions. First, we
compare machine learning and deep learning methods for RQE using different
kinds of datasets, including textual inference, question similarity and
entailment in both the open and clinical domains. Second, we combine IR models
with the best RQE method to select entailed questions and rank the retrieved
answers. To study the end-to-end QA approach, we built the MedQuAD collection
of 47,457 question-answer pairs from trusted medical sources, that we introduce
and share in the scope of this paper. Following the evaluation process used in
TREC 2017 LiveQA, we find that our approach exceeds the best results of the
medical task with a 29.8% increase over the best official score. The evaluation
results also support the relevance of question entailment for QA and highlight
the effectiveness of combining IR and RQE for future QA efforts. Our findings
also show that relying on a restricted set of reliable answer sources can bring
a substantial improvement in medical QA.
</summary>
    <author>
      <name>Asma Ben Abacha</name>
    </author>
    <author>
      <name>Dina Demner-Fushman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/s12859-019-3119-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/s12859-019-3119-4" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">BMC Bioinformatics 20, 511 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.08079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.08079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07910v3</id>
    <updated>2019-06-04T13:03:00Z</updated>
    <published>2019-01-23T14:18:26Z</published>
    <title>NLSC: Unrestricted Natural Language-based Service Composition through
  Sentence Embeddings</title>
    <summary>  Current approaches for service composition (assemblies of atomic services)
require developers to use: (a) domain-specific semantics to formalize services
that restrict the vocabulary for their descriptions, and (b) translation
mechanisms for service retrieval to convert unstructured user requests to
strongly-typed semantic representations. In our work, we argue that effort to
developing service descriptions, request translations, and matching mechanisms
could be reduced using unrestricted natural language; allowing both: (1)
end-users to intuitively express their needs using natural language, and (2)
service developers to develop services without relying on syntactic/semantic
description languages. Although there are some natural language-based service
composition approaches, they restrict service retrieval to syntactic/semantic
matching. With recent developments in Machine learning and Natural Language
Processing, we motivate the use of Sentence Embeddings by leveraging richer
semantic representations of sentences for service description, matching and
retrieval. Experimental results show that service composition development
effort may be reduced by more than 44\% while keeping a high precision/recall
when matching high-level user requests with low-level service method
invocations.
</summary>
    <author>
      <name>Oscar J. Romero</name>
    </author>
    <author>
      <name>Ankit Dangi</name>
    </author>
    <author>
      <name>Sushma A. Akoju</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/SCC.2019.00031</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/SCC.2019.00031" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper will appear on SCC'19 (IEEE International Conference on
  Services Computing) on July 13</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE International Conference on Services Computing (SCC)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.07910v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07910v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07829v1</id>
    <updated>2019-01-23T11:38:15Z</updated>
    <published>2019-01-23T11:38:15Z</published>
    <title>AspeRa: Aspect-based Rating Prediction Model</title>
    <summary>  We propose a novel end-to-end Aspect-based Rating Prediction model (AspeRa)
that estimates user rating based on review texts for the items and at the same
time discovers coherent aspects of reviews that can be used to explain
predictions or profile users. The AspeRa model uses max-margin losses for joint
item and user embedding learning and a dual-headed architecture; it
significantly outperforms recently proposed state-of-the-art models such as
DeepCoNN, HFT, NARRE, and TransRev on two real world data sets of user reviews.
With qualitative examination of the aspects and quantitative evaluation of
rating prediction models based on these aspects, we show how aspect embeddings
can be used in a recommender system.
</summary>
    <author>
      <name>Sergey I. Nikolenko</name>
    </author>
    <author>
      <name>Elena Tutubalina</name>
    </author>
    <author>
      <name>Valentin Malykh</name>
    </author>
    <author>
      <name>Ilya Shenbin</name>
    </author>
    <author>
      <name>Anton Alekseev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted to ECIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.07829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07786v1</id>
    <updated>2019-01-23T09:39:45Z</updated>
    <published>2019-01-23T09:39:45Z</published>
    <title>Self-Attentive Model for Headline Generation</title>
    <summary>  Headline generation is a special type of text summarization task. While the
amount of available training data for this task is almost unlimited, it still
remains challenging, as learning to generate headlines for news articles
implies that the model has strong reasoning about natural language. To overcome
this issue, we applied recent Universal Transformer architecture paired with
byte-pair encoding technique and achieved new state-of-the-art results on the
New York Times Annotated corpus with ROUGE-L F1-score 24.84 and ROUGE-2
F1-score 13.48. We also present the new RIA corpus and reach ROUGE-L F1-score
36.81 and ROUGE-2 F1-score 22.15 on it.
</summary>
    <author>
      <name>Daniil Gavrilov</name>
    </author>
    <author>
      <name>Pavel Kalaidin</name>
    </author>
    <author>
      <name>Valentin Malykh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted for ECIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.07786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07696v2</id>
    <updated>2019-01-24T04:31:56Z</updated>
    <published>2019-01-23T02:33:52Z</published>
    <title>Product-Aware Answer Generation in E-Commerce Question-Answering</title>
    <summary>  In e-commerce portals, generating answers for product-related questions has
become a crucial task. In this paper, we propose the task of product-aware
answer generation, which tends to generate an accurate and complete answer from
large-scale unlabeled e-commerce reviews and product attributes. Unlike
existing question-answering problems, answer generation in e-commerce confronts
three main challenges: (1) Reviews are informal and noisy; (2) joint modeling
of reviews and key-value product attributes is challenging; (3) traditional
methods easily generate meaningless answers. To tackle above challenges, we
propose an adversarial learning based model, named PAAG, which is composed of
three components: a question-aware review representation module, a key-value
memory network encoding attributes, and a recurrent neural network as a
sequence generator. Specifically, we employ a convolutional discriminator to
distinguish whether our generated answer matches the facts. To extract the
salience part of reviews, an attention-based review reader is proposed to
capture the most relevant words given the question. Conducted on a large-scale
real-world e-commerce dataset, our extensive experiments verify the
effectiveness of each module in our proposed model. Moreover, our experiments
show that our model achieves the state-of-the-art performance in terms of both
automatic metrics and human evaluations.
</summary>
    <author>
      <name>Shen Gao</name>
    </author>
    <author>
      <name>Zhaochun Ren</name>
    </author>
    <author>
      <name>Yihong Eric Zhao</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Dawei Yin</name>
    </author>
    <author>
      <name>Rui Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by WSDM 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.07696v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07696v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07005v3</id>
    <updated>2019-03-02T14:20:55Z</updated>
    <published>2019-01-21T17:36:19Z</published>
    <title>DLocRL: A Deep Learning Pipeline for Fine-Grained Location Recognition
  and Linking in Tweets</title>
    <summary>  In recent years, with the prevalence of social media and smart devices,
people causally reveal their locations such as shops, hotels, and restaurants
in their tweets. Recognizing and linking such fine-grained location mentions to
well-defined location profiles are beneficial for retrieval and recommendation
systems. In this paper, we propose DLocRL, a new deep learning pipeline for
fine-grained location recognition and linking in tweets, and verify its
effectiveness on a real-world Twitter dataset.
</summary>
    <author>
      <name>Canwen Xu</name>
    </author>
    <author>
      <name>Jing Li</name>
    </author>
    <author>
      <name>Xiangyang Luo</name>
    </author>
    <author>
      <name>Jiaxin Pei</name>
    </author>
    <author>
      <name>Chenliang Li</name>
    </author>
    <author>
      <name>Donghong Ji</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313491</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313491" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures, accepted by The Web Conf (WWW) 2019; final
  version</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.07005v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07005v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.06613v2</id>
    <updated>2019-03-18T12:28:57Z</updated>
    <published>2019-01-20T02:25:23Z</published>
    <title>Beyond Turing: Intelligent Agents Centered on the User</title>
    <summary>  Most research on intelligent agents centers on the agent and not on the user.
We look at the origins of agent-centric research for slot-filling, gaming and
chatbot agents. We then argue that it is important to concentrate more on the
user. After reviewing relevant literature, some approaches for creating and
assessing user-centric systems are proposed.
</summary>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <author>
      <name>Shikib Mehri</name>
    </author>
    <author>
      <name>Evgeniia Razumovskaia</name>
    </author>
    <author>
      <name>Tiancheng Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.06613v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.06613v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.06610v2</id>
    <updated>2019-06-28T17:49:18Z</updated>
    <published>2019-01-20T01:48:43Z</published>
    <title>Hierarchical Attentional Hybrid Neural Networks for Document
  Classification</title>
    <summary>  Document classification is a challenging task with important applications.
The deep learning approaches to the problem have gained much attention
recently. Despite the progress, the proposed models do not incorporate the
knowledge of the document structure in the architecture efficiently and not
take into account the contexting importance of words and sentences. In this
paper, we propose a new approach based on a combination of convolutional neural
networks, gated recurrent units, and attention mechanisms for document
classification tasks. The main contribution of this work is the use of
convolution layers to extract more meaningful, generalizable and abstract
features by the hierarchical representation. The proposed method in this paper
improves the results of the current attention-based approaches for document
classification.
</summary>
    <author>
      <name>Jader Abreu</name>
    </author>
    <author>
      <name>Luis Fred</name>
    </author>
    <author>
      <name>David Macêdo</name>
    </author>
    <author>
      <name>Cleber Zanchettin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-30493-5_39</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-30493-5_39" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted at International Conference on Artificial Neural
  Networks - ICANN 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2019 International Conference on Artificial Neural Networks
  (ICANN)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.06610v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.06610v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.06595v2</id>
    <updated>2019-04-05T16:34:48Z</updated>
    <published>2019-01-19T22:12:01Z</published>
    <title>Evaluating Text-to-Image Matching using Binary Image Selection (BISON)</title>
    <summary>  Providing systems the ability to relate linguistic and visual content is one
of the hallmarks of computer vision. Tasks such as text-based image retrieval
and image captioning were designed to test this ability but come with
evaluation measures that have a high variance or are difficult to interpret. We
study an alternative task for systems that match text and images: given a text
query, the system is asked to select the image that best matches the query from
a pair of semantically similar images. The system's accuracy on this Binary
Image SelectiON (BISON) task is interpretable, eliminates the reliability
problems of retrieval evaluations, and focuses on the system's ability to
understand fine-grained visual structure. We gather a BISON dataset that
complements the COCO dataset and use it to evaluate modern text-based image
retrieval and image captioning systems. Our results provide novel insights into
the performance of these systems. The COCO-BISON dataset and corresponding
evaluation code are publicly available from \url{http://hexianghu.com/bison/}.
</summary>
    <author>
      <name>Hexiang Hu</name>
    </author>
    <author>
      <name>Ishan Misra</name>
    </author>
    <author>
      <name>Laurens van der Maaten</name>
    </author>
    <link href="http://arxiv.org/abs/1901.06595v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.06595v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02162v1</id>
    <updated>2019-01-19T17:40:08Z</updated>
    <published>2019-01-19T17:40:08Z</published>
    <title>Adaptive Artificial Intelligent Q&amp;A Platform</title>
    <summary>  The paper presents an approach to build a question and answer system that is
capable of processing the information in a large dataset and allows the user to
gain knowledge from this dataset by asking questions in natural language form.
Key content of this research covers four dimensions which are; Corpus
Preprocessing, Question Preprocessing, Deep Neural Network for Answer
Extraction and Answer Generation. The system is capable of understanding the
question, responds to the user's query in natural language form as well. The
goal is to make the user feel as if they were interacting with a person than a
machine.
</summary>
    <author>
      <name>M. R</name>
    </author>
    <author>
      <name> Akram</name>
    </author>
    <author>
      <name>C. P</name>
    </author>
    <author>
      <name> Singhabahu</name>
    </author>
    <author>
      <name>M. S. M Saad</name>
    </author>
    <author>
      <name> P</name>
    </author>
    <author>
      <name> Deleepa</name>
    </author>
    <author>
      <name> Anupiya</name>
    </author>
    <author>
      <name> Nugaliyadde</name>
    </author>
    <author>
      <name> Yashas</name>
    </author>
    <author>
      <name> Mallawarachchi</name>
    </author>
    <link href="http://arxiv.org/abs/1902.02162v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02162v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.05415v4</id>
    <updated>2019-06-13T06:01:04Z</updated>
    <published>2019-01-16T18:02:44Z</published>
    <title>Learning from Dialogue after Deployment: Feed Yourself, Chatbot!</title>
    <summary>  The majority of conversations a dialogue agent sees over its lifetime occur
after it has already been trained and deployed, leaving a vast store of
potential training signal untapped. In this work, we propose the self-feeding
chatbot, a dialogue agent with the ability to extract new training examples
from the conversations it participates in. As our agent engages in
conversation, it also estimates user satisfaction in its responses. When the
conversation appears to be going well, the user's responses become new training
examples to imitate. When the agent believes it has made a mistake, it asks for
feedback; learning to predict the feedback that will be given improves the
chatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with
over 131k training examples, we find that learning from dialogue with a
self-feeding chatbot significantly improves performance, regardless of the
amount of traditional supervision.
</summary>
    <author>
      <name>Braden Hancock</name>
    </author>
    <author>
      <name>Antoine Bordes</name>
    </author>
    <author>
      <name>Pierre-Emmanuel Mazaré</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.05415v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.05415v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04936v1</id>
    <updated>2019-01-15T17:03:32Z</updated>
    <published>2019-01-15T17:03:32Z</published>
    <title>Incremental Reading for Question Answering</title>
    <summary>  Any system which performs goal-directed continual learning must not only
learn incrementally but process and absorb information incrementally. Such a
system also has to understand when its goals have been achieved. In this paper,
we consider these issues in the context of question answering. Current
state-of-the-art question answering models reason over an entire passage, not
incrementally. As we will show, naive approaches to incremental reading, such
as restriction to unidirectional language models in the model, perform poorly.
We present extensions to the DocQA [2] model to allow incremental reading
without loss of accuracy. The model also jointly learns to provide the best
answer given the text that is seen so far and predict whether this best-so-far
answer is sufficient.
</summary>
    <author>
      <name>Samira Abnar</name>
    </author>
    <author>
      <name>Tania Bedrax-weiss</name>
    </author>
    <author>
      <name>Tom Kwiatkowski</name>
    </author>
    <author>
      <name>William W. Cohen</name>
    </author>
    <link href="http://arxiv.org/abs/1901.04936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04831v1</id>
    <updated>2019-01-15T14:10:25Z</updated>
    <published>2019-01-15T14:10:25Z</published>
    <title>Exploiting Synchronized Lyrics And Vocal Features For Music Emotion
  Detection</title>
    <summary>  One of the key points in music recommendation is authoring engaging playlists
according to sentiment and emotions. While previous works were mostly based on
audio for music discovery and playlists generation, we take advantage of our
synchronized lyrics dataset to combine text representations and music features
in a novel way; we therefore introduce the Synchronized Lyrics Emotion Dataset.
Unlike other approaches that randomly exploited the audio samples and the whole
text, our data is split according to the temporal information provided by the
synchronization between lyrics and audio. This work shows a comparison between
text-based and audio-based deep learning classification models using different
techniques from Natural Language Processing and Music Information Retrieval
domains. From the experiments on audio we conclude that using vocals only,
instead of the whole audio data improves the overall performances of the audio
classifier. In the lyrics experiments we exploit the state-of-the-art word
representations applied to the main Deep Learning architectures available in
literature. In our benchmarks the results show how the Bilinear LSTM classifier
with Attention based on fastText word embedding performs better than the CNN
applied on audio.
</summary>
    <author>
      <name>Loreto Parisi</name>
    </author>
    <author>
      <name>Simone Francia</name>
    </author>
    <author>
      <name>Silvio Olivastri</name>
    </author>
    <author>
      <name>Maria Stella Tavella</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.04831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04713v2</id>
    <updated>2019-03-29T05:13:11Z</updated>
    <published>2019-01-15T08:55:53Z</published>
    <title>Global-to-local Memory Pointer Networks for Task-Oriented Dialogue</title>
    <summary>  End-to-end task-oriented dialogue is challenging since knowledge bases are
usually large, dynamic and hard to incorporate into a learning framework. We
propose the global-to-local memory pointer (GLMP) networks to address this
issue. In our model, a global memory encoder and a local memory decoder are
proposed to share external knowledge. The encoder encodes dialogue history,
modifies global contextual representation, and generates a global memory
pointer. The decoder first generates a sketch response with unfilled slots.
Next, it passes the global memory pointer to filter the external knowledge for
relevant information, then instantiates the slots via the local memory
pointers. We empirically show that our model can improve copy accuracy and
mitigate the common out-of-vocabulary problem. As a result, GLMP is able to
improve over the previous state-of-the-art models in both simulated bAbI
Dialogue dataset and human-human Stanford Multi-domain Dialogue dataset on
automatic and human evaluation.
</summary>
    <author>
      <name>Chien-Sheng Wu</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.04713v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04713v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04140v1</id>
    <updated>2019-01-14T05:42:51Z</updated>
    <published>2019-01-14T05:42:51Z</published>
    <title>Image Based Review Text Generation with Emotional Guidance</title>
    <summary>  In the current field of computer vision, automatically generating texts from
given images has been a fully worked technique. Up till now, most works of this
area focus on image content describing, namely image-captioning. However, rare
researches focus on generating product review texts, which is ubiquitous in the
online shopping malls and is crucial for online shopping selection and
evaluation. Different from content describing, review texts include more
subjective information of customers, which may bring difference to the results.
Therefore, we aimed at a new field concerning generating review text from
customers based on images together with the ratings of online shopping
products, which appear as non-image attributes. We made several adjustments to
the existing image-captioning model to fit our task, in which we should also
take non-image features into consideration. We also did experiments based on
our model and get effective primary results.
</summary>
    <author>
      <name>Xuehui Sun</name>
    </author>
    <author>
      <name>Zihan Zhou</name>
    </author>
    <author>
      <name>Yuda Fan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.04140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.03253v3</id>
    <updated>2019-08-13T09:35:52Z</updated>
    <published>2019-01-10T16:25:53Z</published>
    <title>Reverse-Engineering Satire, or "Paper on Computational Humor Accepted
  Despite Making Serious Advances"</title>
    <summary>  Humor is an essential human trait. Efforts to understand humor have called
out links between humor and the foundations of cognition, as well as the
importance of humor in social engagement. As such, it is a promising and
important subject of study, with relevance for artificial intelligence and
human-computer interaction. Previous computational work on humor has mostly
operated at a coarse level of granularity, e.g., predicting whether an entire
sentence, paragraph, document, etc., is humorous. As a step toward deep
understanding of humor, we seek fine-grained models of attributes that make a
given text humorous. Starting from the observation that satirical news
headlines tend to resemble serious news headlines, we build and analyze a
corpus of satirical headlines paired with nearly identical but serious
headlines. The corpus is constructed via Unfun.me, an online game that
incentivizes players to make minimal edits to satirical headlines with the goal
of making other players believe the results are serious headlines. The edit
operations used to successfully remove humor pinpoint the words and concepts
that play a key role in making the original, satirical headline funny. Our
analysis reveals that the humor tends to reside toward the end of headlines,
and primarily in noun phrases, and that most satirical headlines follow a
certain logical pattern, which we term false analogy. Overall, this paper
deepens our understanding of the syntactic and semantic structure of satirical
news headlines and provides insights for building humor-producing systems.
</summary>
    <author>
      <name>Robert West</name>
    </author>
    <author>
      <name>Eric Horvitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 33rd AAAI Conference on Artificial Intelligence,
  2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.03253v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.03253v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.03035v1</id>
    <updated>2019-01-10T06:46:50Z</updated>
    <published>2019-01-10T06:46:50Z</published>
    <title>Self-Monitoring Navigation Agent via Auxiliary Progress Estimation</title>
    <summary>  The Vision-and-Language Navigation (VLN) task entails an agent following
navigational instruction in photo-realistic unknown environments. This
challenging task demands that the agent be aware of which instruction was
completed, which instruction is needed next, which way to go, and its
navigation progress towards the goal. In this paper, we introduce a
self-monitoring agent with two complementary components: (1) visual-textual
co-grounding module to locate the instruction completed in the past, the
instruction required for the next action, and the next moving direction from
surrounding images and (2) progress monitor to ensure the grounded instruction
correctly reflects the navigation progress. We test our self-monitoring agent
on a standard benchmark and analyze our proposed approach through a series of
ablation studies that elucidate the contributions of the primary components.
Using our proposed method, we set the new state of the art by a significant
margin (8% absolute increase in success rate on the unseen test set). Code is
available at https://github.com/chihyaoma/selfmonitoring-agent .
</summary>
    <author>
      <name>Chih-Yao Ma</name>
    </author>
    <author>
      <name>Jiasen Lu</name>
    </author>
    <author>
      <name>Zuxuan Wu</name>
    </author>
    <author>
      <name>Ghassan AlRegib</name>
    </author>
    <author>
      <name>Zsolt Kira</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2019, code is available at
  https://github.com/chihyaoma/selfmonitoring-agent</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.03035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.03035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.02543v1</id>
    <updated>2019-01-08T22:35:03Z</updated>
    <published>2019-01-08T22:35:03Z</published>
    <title>Computational Register Analysis and Synthesis</title>
    <summary>  The study of register in computational language research has historically
been divided into register analysis, seeking to determine the registerial
character of a text or corpus, and register synthesis, seeking to generate a
text in a desired register. This article surveys the different approaches to
these disparate tasks. Register synthesis has tended to use more theoretically
articulated notions of register and genre than analysis work, which often seeks
to categorize on the basis of intuitive and somewhat incoherent notions of
prelabeled 'text types'. I argue that an integration of computational register
analysis and synthesis will benefit register studies as a whole, by enabling a
new large-scale research program in register studies. It will enable
comprehensive global mapping of functional language varieties in multiple
languages, including the relationships between them. Furthermore, computational
methods together with high coverage systematically collected and analyzed data
will thus enable rigorous empirical validation and refinement of different
theories of register, which will have also implications for our understanding
of linguistic variation in general.
</summary>
    <author>
      <name>Shlomo Engelson Argamon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A version of this article is to appear in Register Studies, 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.02543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.02543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.02522v2</id>
    <updated>2019-09-11T05:00:14Z</updated>
    <published>2019-01-08T21:19:34Z</published>
    <title>On the Capabilities and Limitations of Reasoning for Natural Language
  Understanding</title>
    <summary>  Recent systems for natural language understanding are strong at overcoming
linguistic variability for lookup style reasoning. Yet, their accuracy drops
dramatically as the number of reasoning steps increases. We present the first
formal framework to study such empirical observations, addressing the
ambiguity, redundancy, incompleteness, and inaccuracy that the use of language
introduces when representing a hidden conceptual space. Our formal model uses
two interrelated spaces: a conceptual meaning space that is unambiguous and
complete but hidden, and a linguistic symbol space that captures a noisy
grounding of the meaning space in the symbols or words of a language.
  We apply this framework to study the connectivity problem in undirected
graphs---a core reasoning problem that forms the basis for more complex
multi-hop reasoning. We show that it is indeed possible to construct a
high-quality algorithm for detecting connectivity in the (latent) meaning
graph, based on an observed noisy symbol graph, as long as the noise is below
our quantified noise level and only a few hops are needed. On the other hand,
we also prove an impossibility result: if a query requires a large number
(specifically, logarithmic in the size of the meaning graph) of hops, no
reasoning system operating over the symbol graph is likely to recover any
useful property of the meaning graph. This highlights a fundamental barrier for
a class of reasoning problems and systems, and suggests the need to limit the
distance between the two spaces, rather than investing in multi-hop reasoning
with "many" hops.
</summary>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <author>
      <name>Erfan Sadeqi Azer</name>
    </author>
    <author>
      <name>Tushar Khot</name>
    </author>
    <author>
      <name>Ashish Sabharwal</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1605.06201</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.02522v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.02522v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.01592v2</id>
    <updated>2019-07-29T15:26:21Z</updated>
    <published>2019-01-06T18:53:12Z</published>
    <title>Named Entity Recognition in Electronic Health Records Using Transfer
  Learning Bootstrapped Neural Networks</title>
    <summary>  Neural networks (NNs) have become the state of the art in many machine
learning applications, especially in image and sound processing [1]. The same,
although to a lesser extent [2,3], could be said in natural language processing
(NLP) tasks, such as named entity recognition. However, the success of NNs
remains dependent on the availability of large labelled datasets, which is a
significant hurdle in many important applications. One such case are electronic
health records (EHRs), which are arguably the largest source of medical data,
most of which lies hidden in natural text [4,5]. Data access is difficult due
to data privacy concerns, and therefore annotated datasets are scarce. With
scarce data, NNs will likely not be able to extract this hidden information
with practical accuracy. In our study, we develop an approach that solves these
problems for named entity recognition, obtaining 94.6 F1 score in I2B2 2009
Medical Extraction Challenge [6], 4.3 above the architecture that won the
competition. Beyond the official I2B2 challenge, we further achieve 82.4 F1 on
extracting relationships between medical terms. To reach this state-of-the-art
accuracy, our approach applies transfer learning to leverage on datasets
annotated for other I2B2 tasks, and designs and trains embeddings that
specially benefit from such transfer.
</summary>
    <author>
      <name>Luka Gligic</name>
    </author>
    <author>
      <name>Andrey Kormilitzin</name>
    </author>
    <author>
      <name>Paul Goldberg</name>
    </author>
    <author>
      <name>Alejo Nevado-Holgado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures, 8 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.01592v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.01592v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.01010v2</id>
    <updated>2019-01-14T00:46:42Z</updated>
    <published>2019-01-04T08:05:56Z</published>
    <title>A Joint Model for Multimodal Document Quality Assessment</title>
    <summary>  The quality of a document is affected by various factors, including
grammaticality, readability, stylistics, and expertise depth, making the task
of document quality assessment a complex one. In this paper, we explore this
task in the context of assessing the quality of Wikipedia articles and academic
papers. Observing that the visual rendering of a document can capture implicit
quality indicators that are not present in the document text --- such as
images, font choices, and visual layout --- we propose a joint model that
combines the text content with a visual rendering of the document for document
quality assessment. Experimental results over two datasets reveal that textual
and visual features are complementary, achieving state-of-the-art results.
</summary>
    <author>
      <name>Aili Shen</name>
    </author>
    <author>
      <name>Bahar Salehi</name>
    </author>
    <author>
      <name>Timothy Baldwin</name>
    </author>
    <author>
      <name>Jianzhong Qi</name>
    </author>
    <link href="http://arxiv.org/abs/1901.01010v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.01010v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.00603v2</id>
    <updated>2019-05-13T17:33:02Z</updated>
    <published>2019-01-03T03:55:49Z</published>
    <title>Coarse-grain Fine-grain Coattention Network for Multi-evidence Question
  Answering</title>
    <summary>  End-to-end neural models have made significant progress in question
answering, however recent studies show that these models implicitly assume that
the answer and evidence appear close together in a single document. In this
work, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new
question answering model that combines information from evidence across
multiple documents. The CFC consists of a coarse-grain module that interprets
documents with respect to the query then finds a relevant answer, and a
fine-grain module which scores each candidate answer by comparing its
occurrences across all of the documents with the query. We design these modules
using hierarchies of coattention and self-attention, which learn to emphasize
different parts of the input. On the Qangaroo WikiHop multi-evidence question
answering task, the CFC obtains a new state-of-the-art result of 70.6% on the
blind test set, outperforming the previous best by 3% accuracy despite not
using pretrained contextual encoders.
</summary>
    <author>
      <name>Victor Zhong</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Nitish Shirish Keskar</name>
    </author>
    <author>
      <name>Richard Socher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2019; 9 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.00603v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.00603v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.00158v2</id>
    <updated>2019-01-18T17:55:36Z</updated>
    <published>2019-01-01T14:41:17Z</published>
    <title>Text Infilling</title>
    <summary>  Recent years have seen remarkable progress of text generation in different
contexts, such as the most common setting of generating text from scratch, and
the emerging paradigm of retrieval-and-rewriting. Text infilling, which fills
missing text portions of a sentence or paragraph, is also of numerous use in
real life, yet is under-explored. Previous work has focused on restricted
settings by either assuming single word per missing portion or limiting to a
single missing portion to the end of the text. This paper studies the general
task of text infilling, where the input text can have an arbitrary number of
portions to be filled, each of which may require an arbitrary unknown number of
tokens. We study various approaches for the task, including a self-attention
model with segment-aware position encoding and bidirectional context modeling.
We create extensive supervised data by masking out text with varying
strategies. Experiments show the self-attention model greatly outperforms
others, creating a strong baseline for future research.
</summary>
    <author>
      <name>Wanrong Zhu</name>
    </author>
    <author>
      <name>Zhiting Hu</name>
    </author>
    <author>
      <name>Eric Xing</name>
    </author>
    <link href="http://arxiv.org/abs/1901.00158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.00158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.00056v1</id>
    <updated>2018-12-31T22:05:05Z</updated>
    <published>2018-12-31T22:05:05Z</published>
    <title>SynonymNet: Multi-context Bilateral Matching for Entity Synonyms</title>
    <summary>  Being able to automatically discover synonymous entities from a large
free-text corpus has transformative effects on structured knowledge discovery.
Existing works either require structured annotations, or fail to incorporate
context information effectively, which lower the efficiency of information
usage. In this paper, we propose a framework for synonym discovery from
free-text corpus without structured annotation. As one of the key components in
synonym discovery, we introduce a novel neural network model SynonymNet to
determine whether or not two given entities are synonym with each other.
Instead of using entities features, SynonymNet makes use of multiple pieces of
contexts in which the entity is mentioned, and compares the context-level
similarity via a bilateral matching schema to determine synonymity.
Experimental results demonstrate that the proposed model achieves
state-of-the-art results on both generic and domain-specific synonym datasets:
Wiki+Freebase, PubMed+UMLS and MedBook+MKG, with up to 4.16% improvement in
terms of Area Under the Curve (AUC) and 3.19% in terms of Mean Average
Precision (MAP) compare to the best baseline method.
</summary>
    <author>
      <name>Chenwei Zhang</name>
    </author>
    <author>
      <name>Yaliang Li</name>
    </author>
    <author>
      <name>Nan Du</name>
    </author>
    <author>
      <name>Wei Fan</name>
    </author>
    <author>
      <name>Philip S. Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1901.00056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.00056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11737v2</id>
    <updated>2019-06-04T08:22:29Z</updated>
    <published>2018-12-31T09:41:04Z</published>
    <title>The meaning of "most" for visual question answering models</title>
    <summary>  The correct interpretation of quantifier statements in the context of a
visual scene requires non-trivial inference mechanisms. For the example of
"most", we discuss two strategies which rely on fundamentally different
cognitive concepts. Our aim is to identify what strategy deep learning models
for visual question answering learn when trained on such questions. To this
end, we carefully design data to replicate experiments from psycholinguistics
where the same question was investigated for humans. Focusing on the FiLM
visual question answering model, our experiments indicate that a form of
approximate number system emerges whose performance declines with more
difficult scenes as predicted by Weber's law. Moreover, we identify confounding
factors, like spatial arrangement of the scene, which impede the effectiveness
of this system.
</summary>
    <author>
      <name>Alexander Kuhnle</name>
    </author>
    <author>
      <name>Ann Copestake</name>
    </author>
    <link href="http://arxiv.org/abs/1812.11737v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11737v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11270v1</id>
    <updated>2018-12-29T03:04:26Z</updated>
    <published>2018-12-29T03:04:26Z</published>
    <title>Weakly-Supervised Hierarchical Text Classification</title>
    <summary>  Hierarchical text classification, which aims to classify text documents into
a given hierarchy, is an important task in many real-world applications.
Recently, deep neural models are gaining increasing popularity for text
classification due to their expressive power and minimum requirement for
feature engineering. However, applying deep neural networks for hierarchical
text classification remains challenging, because they heavily rely on a large
amount of training data and meanwhile cannot easily determine appropriate
levels of documents in the hierarchical setting. In this paper, we propose a
weakly-supervised neural method for hierarchical text classification. Our
method does not require a large amount of training data but requires only
easy-to-provide weak supervision signals such as a few class-related documents
or keywords. Our method effectively leverages such weak supervision signals to
generate pseudo documents for model pre-training, and then performs
self-training on real unlabeled data to iteratively refine the model. During
the training process, our model features a hierarchical neural structure, which
mimics the given hierarchy and is capable of determining the proper levels for
documents with a blocking mechanism. Experiments on three datasets from
different domains demonstrate the efficacy of our method compared with a
comprehensive set of baselines.
</summary>
    <author>
      <name>Yu Meng</name>
    </author>
    <author>
      <name>Jiaming Shen</name>
    </author>
    <author>
      <name>Chao Zhang</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.11270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11158v1</id>
    <updated>2018-12-28T18:44:49Z</updated>
    <published>2018-12-28T18:44:49Z</published>
    <title>MEETING BOT: Reinforcement Learning for Dialogue Based Meeting
  Scheduling</title>
    <summary>  In this paper we present Meeting Bot, a reinforcement learning based
conversational system that interacts with multiple users to schedule meetings.
The system is able to interpret user utterences and map them to preferred time
slots, which are then fed to a reinforcement learning (RL) system with the goal
of converging on an agreeable time slot. The RL system is able to adapt to user
preferences and environmental changes in meeting arrival rate while still
scheduling effectively. Learning is performed via policy gradient with
exploration, by utilizing an MLP as an approximator of the policy function.
Results demonstrate that the system outperforms standard scheduling algorithms
in terms of overall scheduling efficiency. Additionally, the system is able to
adapt its strategy to situations when users consistently reject or accept
meetings in certain slots (such as Friday afternoon versus Thursday morning),
or when the meeting is called by members who are at a more senior designation.
</summary>
    <author>
      <name>Vishwanath D</name>
    </author>
    <author>
      <name>Lovekesh Vig</name>
    </author>
    <author>
      <name>Gautam Shroff</name>
    </author>
    <author>
      <name>Puneet Agarwal</name>
    </author>
    <link href="http://arxiv.org/abs/1812.11158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10757v1</id>
    <updated>2018-12-27T16:17:30Z</updated>
    <published>2018-12-27T16:17:30Z</published>
    <title>Advancing the State of the Art in Open Domain Dialog Systems through the
  Alexa Prize</title>
    <summary>  Building open domain conversational systems that allow users to have engaging
conversations on topics of their choice is a challenging task. Alexa Prize was
launched in 2016 to tackle the problem of achieving natural, sustained,
coherent and engaging open-domain dialogs. In the second iteration of the
competition in 2018, university teams advanced the state of the art by using
context in dialog models, leveraging knowledge graphs for language
understanding, handling complex utterances, building statistical and
hierarchical dialog managers, and leveraging model-driven signals from user
responses. The 2018 competition also included the provision of a suite of tools
and models to the competitors including the CoBot (conversational bot) toolkit,
topic and dialog act detection models, conversation evaluators, and a sensitive
content detection model so that the competing teams could focus on building
knowledge-rich, coherent and engaging multi-turn dialog systems. This paper
outlines the advances developed by the university teams as well as the Alexa
Prize team to achieve the common goal of advancing the science of
Conversational AI. We address several key open-ended problems such as
conversational speech recognition, open domain natural language understanding,
commonsense reasoning, statistical dialog management, and dialog evaluation.
These collaborative efforts have driven improved experiences by Alexa users to
an average rating of 3.61, the median duration of 2 mins 18 seconds, and
average turns to 14.6, increases of 14%, 92%, 54% respectively since the launch
of the 2018 competition. For conversational speech recognition, we have
improved our relative Word Error Rate by 55% and our relative Entity Error Rate
by 34% since the launch of the Alexa Prize. Socialbots improved in quality
significantly more rapidly in 2018, in part due to the release of the CoBot
toolkit.
</summary>
    <author>
      <name>Chandra Khatri</name>
    </author>
    <author>
      <name>Behnam Hedayatnia</name>
    </author>
    <author>
      <name>Anu Venkatesh</name>
    </author>
    <author>
      <name>Jeff Nunn</name>
    </author>
    <author>
      <name>Yi Pan</name>
    </author>
    <author>
      <name>Qing Liu</name>
    </author>
    <author>
      <name>Han Song</name>
    </author>
    <author>
      <name>Anna Gottardi</name>
    </author>
    <author>
      <name>Sanjeev Kwatra</name>
    </author>
    <author>
      <name>Sanju Pancholi</name>
    </author>
    <author>
      <name>Ming Cheng</name>
    </author>
    <author>
      <name>Qinglang Chen</name>
    </author>
    <author>
      <name>Lauren Stubel</name>
    </author>
    <author>
      <name>Karthik Gopalakrishnan</name>
    </author>
    <author>
      <name>Kate Bland</name>
    </author>
    <author>
      <name>Raefer Gabriel</name>
    </author>
    <author>
      <name>Arindam Mandal</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <author>
      <name>Gene Hwang</name>
    </author>
    <author>
      <name>Nate Michel</name>
    </author>
    <author>
      <name>Eric King</name>
    </author>
    <author>
      <name>Rohit Prasad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2018 Alexa Prize Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10628v2</id>
    <updated>2019-01-10T20:23:54Z</updated>
    <published>2018-12-27T05:14:49Z</published>
    <title>Intent Detection and Slots Prompt in a Closed-Domain Chatbot</title>
    <summary>  In this paper, we introduce a methodology for predicting intent and slots of
a query for a chatbot that answers career-related queries. We take a
multi-staged approach where both the processes (intent-classification and
slot-tagging) inform each other's decision-making in different stages. The
model breaks down the problem into stages, solving one problem at a time and
passing on relevant results of the current stage to the next, thereby reducing
search space for subsequent stages, and eventually making classification and
tagging more viable after each stage. We also observe that relaxing rules for a
fuzzy entity-matching in slot-tagging after each stage (by maintaining a
separate Named Entity Tagger per stage) helps us improve performance, although
at a slight cost of false-positives. Our model has achieved state-of-the-art
performance with F1-score of 77.63% for intent-classification and 82.24% for
slot-tagging on our dataset that we would publicly release along with the
paper.
</summary>
    <author>
      <name>Amber Nigam</name>
    </author>
    <author>
      <name>Prashik Sahare</name>
    </author>
    <author>
      <name>Kushagra Pandya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted paper for IEEE ICSC 2019 (4 pages, 1 figure, 6 tables)</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10628v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10628v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10464v2</id>
    <updated>2019-09-25T13:16:12Z</updated>
    <published>2018-12-26T18:58:39Z</published>
    <title>Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual
  Transfer and Beyond</title>
    <summary>  We introduce an architecture to learn joint multilingual sentence
representations for 93 languages, belonging to more than 30 different families
and written in 28 different scripts. Our system uses a single BiLSTM encoder
with a shared BPE vocabulary for all languages, which is coupled with an
auxiliary decoder and trained on publicly available parallel corpora. This
enables us to learn a classifier on top of the resulting embeddings using
English annotated data only, and transfer it to any of the 93 languages without
any modification. Our experiments in cross-lingual natural language inference
(XNLI dataset), cross-lingual document classification (MLDoc dataset) and
parallel corpus mining (BUCC dataset) show the effectiveness of our approach.
We also introduce a new test set of aligned sentences in 112 languages, and
show that our sentence embeddings obtain strong results in multilingual
similarity search even for low-resource languages. Our implementation, the
pre-trained encoder and the multilingual test set are available at
https://github.com/facebookresearch/LASER
</summary>
    <author>
      <name>Mikel Artetxe</name>
    </author>
    <author>
      <name>Holger Schwenk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10464v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10464v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10235v1</id>
    <updated>2018-12-26T05:55:42Z</updated>
    <published>2018-12-26T05:55:42Z</published>
    <title>A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection
  and Slot Filling</title>
    <summary>  Intent detection and slot filling are two main tasks for building a spoken
language understanding(SLU) system. Multiple deep learning based models have
demonstrated good results on these tasks . The most effective algorithms are
based on the structures of sequence to sequence models (or "encoder-decoder"
models), and generate the intents and semantic tags either using separate
models or a joint model. Most of the previous studies, however, either treat
the intent detection and slot filling as two separate parallel tasks, or use a
sequence to sequence model to generate both semantic tags and intent. Most of
these approaches use one (joint) NN based model (including encoder-decoder
structure) to model two tasks, hence may not fully take advantage of the
cross-impact between them. In this paper, new Bi-model based RNN semantic frame
parsing network structures are designed to perform the intent detection and
slot filling tasks jointly, by considering their cross-impact to each other
using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a
decoder achieves state-of-the-art result on the benchmark ATIS data, with about
0.5$\%$ intent accuracy improvement and 0.9 $\%$ slot filling improvement.
</summary>
    <author>
      <name>Yu Wang</name>
    </author>
    <author>
      <name>Yilin Shen</name>
    </author>
    <author>
      <name>Hongxia Jin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, published at 2018 NAACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10230v1</id>
    <updated>2018-12-26T05:17:03Z</updated>
    <published>2018-12-26T05:17:03Z</published>
    <title>Learning to Refine Source Representations for Neural Machine Translation</title>
    <summary>  Neural machine translation (NMT) models generally adopt an encoder-decoder
architecture for modeling the entire translation process. The encoder
summarizes the representation of input sentence from scratch, which is
potentially a problem if the sentence is ambiguous. When translating a text,
humans often create an initial understanding of the source sentence and then
incrementally refine it along the translation on the target side. Starting from
this intuition, we propose a novel encoder-refiner-decoder framework, which
dynamically refines the source representations based on the generated
target-side information at each decoding step. Since the refining operations
are time-consuming, we propose a strategy, leveraging the power of
reinforcement learning models, to decide when to refine at specific decoding
steps. Experimental results on both Chinese-English and English-German
translation tasks show that the proposed approach significantly and
consistently improves translation performance over the standard encoder-decoder
framework. Furthermore, when refining strategy is applied, results still show
reasonable improvement over the baseline without much decrease in decoding
speed.
</summary>
    <author>
      <name>Xinwei Geng</name>
    </author>
    <author>
      <name>Longyue Wang</name>
    </author>
    <author>
      <name>Xing Wang</name>
    </author>
    <author>
      <name>Bing Qin</name>
    </author>
    <author>
      <name>Ting Liu</name>
    </author>
    <author>
      <name>Zhaopeng Tu</name>
    </author>
    <link href="http://arxiv.org/abs/1812.10230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.09718v2</id>
    <updated>2019-01-11T17:27:16Z</updated>
    <published>2018-12-23T14:35:58Z</published>
    <title>Optimizing Answer Set Computation via Heuristic-Based Decomposition</title>
    <summary>  Answer Set Programming (ASP) is a purely declarative formalism developed in
the field of logic programming and nonmonotonic reasoning: computational
problems are encoded by logic programs whose answer sets, corresponding to
solutions, are computed by an ASP system. Different, semantically equivalent,
programs can be defined for the same problem; however, performance of systems
evaluating them might significantly vary. We propose an approach for
automatically transforming an input logic program into an equivalent one that
can be evaluated more efficiently. One can make use of existing
tree-decomposition techniques for rewriting selected rules into a set of
multiple ones; the idea is to guide and adaptively apply them on the basis of
proper new heuristics, to obtain a smart rewriting algorithm to be integrated
into an ASP system. The method is rather general: it can be adapted to any
system and implement different preference policies. Furthermore, we define a
set of new heuristics tailored at optimizing grounding, one of the main phases
of the ASP computation; we use them in order to implement the approach into the
ASP system DLV, in particular into its grounding subsystem I-DLV, and carry out
an extensive experimental activity for assessing the impact of the proposal.
Under consideration in Theory and Practice of Logic Programming (TPLP).
</summary>
    <author>
      <name>Francesco Calimeri</name>
    </author>
    <author>
      <name>Simona Perri</name>
    </author>
    <author>
      <name>Jessica Zangari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S1471068419000036</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S1471068419000036" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 6 figures, 4 tables, BEST PAPER AWARD at PADL 2018 (Los
  Angeles, CA, USA), Under consideration in Theory and Practice of Logic
  Programming (TPLP)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Theory and Practice of Logic Programming 19 (2019) 603-628</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.09718v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.09718v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.09652v1</id>
    <updated>2018-12-23T03:44:03Z</updated>
    <published>2018-12-23T03:44:03Z</published>
    <title>A Cross-Architecture Instruction Embedding Model for Natural Language
  Processing-Inspired Binary Code Analysis</title>
    <summary>  Given a closed-source program, such as most of proprietary software and
viruses, binary code analysis is indispensable for many tasks, such as code
plagiarism detection and malware analysis. Today, source code is very often
compiled for various architectures, making cross-architecture binary code
analysis increasingly important. A binary, after being disassembled, is
expressed in an assembly languages. Thus, recent work starts exploring Natural
Language Processing (NLP) inspired binary code analysis. In NLP, words are
usually represented in high-dimensional vectors (i.e., embeddings) to
facilitate further processing, which is one of the most common and critical
steps in many NLP tasks. We regard instructions as words in NLP-inspired binary
code analysis, and aim to represent instructions as embeddings as well.
  To facilitate cross-architecture binary code analysis, our goal is that
similar instructions, regardless of their architectures, have embeddings close
to each other. To this end, we propose a joint learning approach to generating
instruction embeddings that capture not only the semantics of instructions
within an architecture, but also their semantic relationships across
architectures. To the best of our knowledge, this is the first work on building
cross-architecture instruction embedding model. As a showcase, we apply the
model to resolving one of the most fundamental problems for binary code
similarity comparison---semantics-based basic block comparison, and the
solution outperforms the code statistics based approach. It demonstrates that
it is promising to apply the model to other cross-architecture binary code
analysis tasks.
</summary>
    <author>
      <name>Kimberly Redmond</name>
    </author>
    <author>
      <name>Lannan Luo</name>
    </author>
    <author>
      <name>Qiang Zeng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.09652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.09652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.09193v1</id>
    <updated>2018-12-21T15:30:17Z</updated>
    <published>2018-12-21T15:30:17Z</published>
    <title>Sources of Complexity in Semantic Frame Parsing for Information
  Extraction</title>
    <summary>  This paper describes a Semantic Frame parsing System based on sequence
labeling methods, precisely BiLSTM models with highway connections, for
performing information extraction on a corpus of French encyclopedic history
texts annotated according to the Berkeley FrameNet formalism. The approach
proposed in this study relies on an integrated sequence labeling model which
jointly optimizes frame identification and semantic role segmentation and
identification. The purpose of this study is to analyze the task complexity, to
highlight the factors that make Semantic Frame parsing a difficult task and to
provide detailed evaluations of the performance on different types of frames
and sentences.
</summary>
    <author>
      <name>Gabriel Marzinotto</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALEP</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Béchet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, TALEP</arxiv:affiliation>
    </author>
    <author>
      <name>Géraldine Damnati</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, TALEP</arxiv:affiliation>
    </author>
    <author>
      <name>Alexis Nasr</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS, TALEP</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International FrameNet Workshop 2018, May 2018, Miyazaki, Japan</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.09193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.09193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08989v2</id>
    <updated>2019-09-14T21:23:51Z</updated>
    <published>2018-12-21T08:01:31Z</published>
    <title>The Design and Implementation of XiaoIce, an Empathetic Social Chatbot</title>
    <summary>  This paper describes the development of Microsoft XiaoIce, the most popular
social chatbot in the world. XiaoIce is uniquely designed as an AI companion
with an emotional connection to satisfy the human need for communication,
affection, and social belonging. We take into account both intelligent quotient
(IQ) and emotional quotient (EQ) in system design, cast human-machine social
chat as decision-making over Markov Decision Processes (MDPs), and optimize
XiaoIce for long-term user engagement, measured in expected Conversation-turns
Per Session (CPS). We detail the system architecture and key components
including dialogue manager, core chat, skills, and an empathetic computing
module. We show how XiaoIce dynamically recognizes human feelings and states,
understands user intent, and responds to user needs throughout long
conversations. Since her launch in 2014, XiaoIce has communicated with over 660
million active users and succeeded in establishing long-term relationships with
many of them. Analysis of large scale online logs shows that XiaoIce has
achieved an average CPS of 23, which is significantly higher than that of other
chatbots and even human conversations.
</summary>
    <author>
      <name>Li Zhou</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Di Li</name>
    </author>
    <author>
      <name>Heung-Yeung Shum</name>
    </author>
    <link href="http://arxiv.org/abs/1812.08989v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08989v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08947v1</id>
    <updated>2018-12-21T05:02:02Z</updated>
    <published>2018-12-21T05:02:02Z</published>
    <title>Enhancing Person-Job Fit for Talent Recruitment: An Ability-aware Neural
  Network Approach</title>
    <summary>  The wide spread use of online recruitment services has led to information
explosion in the job market. As a result, the recruiters have to seek the
intelligent ways for Person Job Fit, which is the bridge for adapting the right
job seekers to the right positions. Existing studies on Person Job Fit have a
focus on measuring the matching degree between the talent qualification and the
job requirements mainly based on the manual inspection of human resource
experts despite of the subjective, incomplete, and inefficient nature of the
human judgement. To this end, in this paper, we propose a novel end to end
Ability aware Person Job Fit Neural Network model, which has a goal of reducing
the dependence on manual labour and can provide better interpretation about the
fitting results. The key idea is to exploit the rich information available at
abundant historical job application data. Specifically, we propose a word level
semantic representation for both job requirements and job seekers' experiences
based on Recurrent Neural Network. Along this line, four hierarchical ability
aware attention strategies are designed to measure the different importance of
job requirements for semantic representation, as well as measuring the
different contribution of each job experience to a specific ability
requirement. Finally, extensive experiments on a large scale real world data
set clearly validate the effectiveness and interpretability of the APJFNN
framework compared with several baselines.
</summary>
    <author>
      <name>Chuan Qin</name>
    </author>
    <author>
      <name>Hengshu Zhu</name>
    </author>
    <author>
      <name>Tong Xu</name>
    </author>
    <author>
      <name>Chen Zhu</name>
    </author>
    <author>
      <name>Liang Jiang</name>
    </author>
    <author>
      <name>Enhong Chen</name>
    </author>
    <author>
      <name>Hui Xiong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3209978.3210025</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3209978.3210025" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an extended version of our SIGIR18 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.08947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08879v1</id>
    <updated>2018-12-20T22:53:33Z</updated>
    <published>2018-12-20T22:53:33Z</published>
    <title>Variational Cross-domain Natural Language Generation for Spoken Dialogue
  Systems</title>
    <summary>  Cross-domain natural language generation (NLG) is still a difficult task
within spoken dialogue modelling. Given a semantic representation provided by
the dialogue manager, the language generator should generate sentences that
convey desired information. Traditional template-based generators can produce
sentences with all necessary information, but these sentences are not
sufficiently diverse. With RNN-based models, the diversity of the generated
sentences can be high, however, in the process some information is lost. In
this work, we improve an RNN-based generator by considering latent information
at the sentence level during generation using the conditional variational
autoencoder architecture. We demonstrate that our model outperforms the
original RNN-based generator, while yielding highly diverse sentences. In
addition, our model performs better when the training data is limited.
</summary>
    <author>
      <name>Bo-Hsiang Tseng</name>
    </author>
    <author>
      <name>Florian Kreyssig</name>
    </author>
    <author>
      <name>Pawel Budzianowski</name>
    </author>
    <author>
      <name>Inigo Casanueva</name>
    </author>
    <author>
      <name>Yen-Chen Wu</name>
    </author>
    <author>
      <name>Stefan Ultes</name>
    </author>
    <author>
      <name>Milica Gasic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Sigdial 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.08879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08658v3</id>
    <updated>2019-09-30T20:10:33Z</updated>
    <published>2018-12-20T16:04:05Z</published>
    <title>nocaps: novel object captioning at scale</title>
    <summary>  Image captioning models have achieved impressive results on datasets
containing limited visual concepts and large amounts of paired image-caption
training data. However, if these models are to ever function in the wild, a
much larger variety of visual concepts must be learned, ideally from less
supervision. To encourage the development of image captioning models that can
learn visual concepts from alternative data sources, such as object detection
datasets, we present the first large-scale benchmark for this task. Dubbed
'nocaps', for novel object captioning at scale, our benchmark consists of
166,100 human-generated captions describing 15,100 images from the OpenImages
validation and test sets. The associated training data consists of COCO
image-caption pairs, plus OpenImages image-level labels and object bounding
boxes. Since OpenImages contains many more classes than COCO, nearly 400 object
classes seen in test images have no or very few associated training captions
(hence, nocaps). We extend existing novel object captioning models to establish
strong baselines for this benchmark and provide analysis to guide future work
on this task.
</summary>
    <author>
      <name>Harsh Agrawal</name>
    </author>
    <author>
      <name>Karan Desai</name>
    </author>
    <author>
      <name>Yufei Wang</name>
    </author>
    <author>
      <name>Xinlei Chen</name>
    </author>
    <author>
      <name>Rishabh Jain</name>
    </author>
    <author>
      <name>Mark Johnson</name>
    </author>
    <author>
      <name>Dhruv Batra</name>
    </author>
    <author>
      <name>Devi Parikh</name>
    </author>
    <author>
      <name>Stefan Lee</name>
    </author>
    <author>
      <name>Peter Anderson</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Computer Vision (ICCV) 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.08658v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08658v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08425v1</id>
    <updated>2018-12-20T08:56:52Z</updated>
    <published>2018-12-20T08:56:52Z</published>
    <title>A Survey of Hierarchy Identification in Social Networks</title>
    <summary>  Humans are social by nature. Throughout history, people have formed
communities and built relationships. Most relationships with coworkers,
friends, and family are developed during face-to-face interactions. These
relationships are established through explicit means of communications such as
words and implicit such as intonation, body language, etc. By analyzing human
interactions we can derive information about the relationships and influence
among conversation participants. However, with the development of the Internet,
people started to communicate through text in online social networks.
Interestingly, they brought their communicational habits to the Internet. Many
social network users form relationships with each other and establish
communities with leaders and followers. Recognizing these hierarchical
relationships is an important task because it will help to understand social
networks and predict future trends, improve recommendations, better target
advertisement, and improve national security by identifying leaders of
anonymous terror groups. In this work, I provide an overview of current
research in this area and present the state-of-the-art approaches to deal with
the problem of identifying hierarchical relationships in social networks.
</summary>
    <author>
      <name>Denys Katerenchuk</name>
    </author>
    <link href="http://arxiv.org/abs/1812.08425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08039v1</id>
    <updated>2018-12-19T15:54:41Z</updated>
    <published>2018-12-19T15:54:41Z</published>
    <title>Semantic Frame Parsing for Information Extraction : the CALOR corpus</title>
    <summary>  This paper presents a publicly available corpus of French encyclopedic
history texts annotated according to the Berkeley FrameNet formalism. The main
difference in our approach compared to previous works on semantic parsing with
FrameNet is that we are not interested here in full text parsing but rather on
partial parsing. The goal is to select from the FrameNet resources the minimal
set of frames that are going to be useful for the applicative framework
targeted, in our case Information Extraction from encyclopedic documents. Such
an approach leverages the manual annotation of larger corpora than those
obtained through full text parsing and therefore opens the door to alternative
methods for Frame parsing than those used so far on the FrameNet 1.5 benchmark
corpus. The approaches compared in this study rely on an integrated sequence
labeling model which jointly optimizes frame identification and semantic role
segmentation and identification. The models compared are CRFs and multitasks
bi-LSTMs.
</summary>
    <author>
      <name>Gabriel Marzinotto</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALEP</arxiv:affiliation>
    </author>
    <author>
      <name>Jeremy Auguste</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALEP</arxiv:affiliation>
    </author>
    <author>
      <name>Frederic Bechet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Géraldine Damnati</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">FTR\&amp;D</arxiv:affiliation>
    </author>
    <author>
      <name>Alexis Nasr</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LREC2018, May 2018, Miyazaki, France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.08039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06722v1</id>
    <updated>2018-12-17T11:59:53Z</updated>
    <published>2018-12-17T11:59:53Z</published>
    <title>TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph</title>
    <summary>  Knowledge graph is a kind of valuable knowledge base which would benefit lots
of AI-related applications. Up to now, lots of large-scale knowledge graphs
have been built. However, most of them are non-Chinese and designed for general
purpose. In this work, we introduce TechKG, a large scale Chinese knowledge
graph that is technology-oriented. It is built automatically from massive
technical papers that are published in Chinese academic journals of different
research domains. Some carefully designed heuristic rules are used to extract
high quality entities and relations. Totally, it comprises of over 260 million
triplets that are built upon more than 52 million entities which come from 38
research domains. Our preliminary ex-periments indicate that TechKG has high
adaptability and can be used as a dataset for many diverse AI-related
applications. We released TechKG at: http://www.techkg.cn.
</summary>
    <author>
      <name>Feiliang Ren</name>
    </author>
    <author>
      <name>Yining Hou</name>
    </author>
    <author>
      <name>Yan Li</name>
    </author>
    <author>
      <name>Linfeng Pan</name>
    </author>
    <author>
      <name>Yi Zhang</name>
    </author>
    <author>
      <name>Xiaobo Liang</name>
    </author>
    <author>
      <name>Yongkang Liu</name>
    </author>
    <author>
      <name>Yu Guo</name>
    </author>
    <author>
      <name>Rongsheng Zhao</name>
    </author>
    <author>
      <name>Ruicheng Ming</name>
    </author>
    <author>
      <name>Huiming Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1812.06722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06705v1</id>
    <updated>2018-12-17T11:26:42Z</updated>
    <published>2018-12-17T11:26:42Z</published>
    <title>Conditional BERT Contextual Augmentation</title>
    <summary>  We propose a novel data augmentation method for labeled sentences called
conditional BERT contextual augmentation. Data augmentation methods are often
applied to prevent overfitting and improve generalization of deep neural
network models. Recently proposed contextual augmentation augments labeled
sentences by randomly replacing words with more varied substitutions predicted
by language model. BERT demonstrates that a deep bidirectional language model
is more powerful than either an unidirectional language model or the shallow
concatenation of a forward and backward model. We retrofit BERT to conditional
BERT by introducing a new conditional masked language model\footnote{The term
"conditional masked language model" appeared once in original BERT paper, which
indicates context-conditional, is equivalent to term "masked language model".
In our paper, "conditional masked language model" indicates we apply extra
label-conditional constraint to the "masked language model".} task. The well
trained conditional BERT can be applied to enhance contextual augmentation.
Experiments on six various different text classification tasks show that our
method can be easily applied to both convolutional or recurrent neural networks
classifier to obtain obvious improvement.
</summary>
    <author>
      <name>Xing Wu</name>
    </author>
    <author>
      <name>Shangwen Lv</name>
    </author>
    <author>
      <name>Liangjun Zang</name>
    </author>
    <author>
      <name>Jizhong Han</name>
    </author>
    <author>
      <name>Songlin Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.06705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06410v2</id>
    <updated>2019-01-18T11:34:27Z</updated>
    <published>2018-12-16T07:32:02Z</published>
    <title>NSCaching: Simple and Efficient Negative Sampling for Knowledge Graph
  Embedding</title>
    <summary>  Knowledge Graph (KG) embedding is a fundamental problem in data mining
research with many real-world applications. It aims to encode the entities and
relations in the graph into low dimensional vector space, which can be used for
subsequent algorithms. Negative sampling, which samples negative triplets from
non-observed ones in the training data, is an important step in KG embedding.
Recently, generative adversarial network (GAN), has been introduced in negative
sampling. By sampling negative triplets with large scores, these methods avoid
the problem of vanishing gradient and thus obtain better performance. However,
using GAN makes the original model more complex and hard to train, where
reinforcement learning must be used. In this paper, motivated by the
observation that negative triplets with large scores are important but rare, we
propose to directly keep track of them with the cache. However, how to sample
from and update the cache are two important questions. We carefully design the
solutions, which are not only efficient but also achieve a good balance between
exploration and exploitation. In this way, our method acts as a "distilled"
version of previous GA-based methods, which does not waste training time on
additional parameters to fit the full distribution of negative triplets. The
extensive experiments show that our method can gain significant improvement in
various KG embedding models, and outperform the state-of-the-art negative
sampling methods based on GAN.
</summary>
    <author>
      <name>Yongqi Zhang</name>
    </author>
    <author>
      <name>Quanming Yao</name>
    </author>
    <author>
      <name>Yingxia Shao</name>
    </author>
    <author>
      <name>Lei Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1812.06410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06401v1</id>
    <updated>2018-12-16T06:12:45Z</updated>
    <published>2018-12-16T06:12:45Z</published>
    <title>What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions</title>
    <summary>  One of the core challenges in Visual Dialogue problems is asking the question
that will provide the most useful information towards achieving the required
objective. Encouraging an agent to ask the right questions is difficult because
we don't know a-priori what information the agent will need to achieve its
task, and we don't have an explicit model of what it knows already. We propose
a solution to this problem based on a Bayesian model of the uncertainty in the
implicit model maintained by the visual dialogue agent, and in the function
used to select an appropriate output. By selecting the question that minimises
the predicted regret with respect to this implicit model the agent actively
reduces ambiguity. The Bayesian model of uncertainty also enables a principled
method for identifying when enough information has been acquired, and an action
should be selected. We evaluate our approach on two goal-oriented dialogue
datasets, one for visual-based collaboration task and the other for a
negotiation-based task. Our uncertainty-aware information-seeking model
outperforms its counterparts in these two challenging problems.
</summary>
    <author>
      <name>Ehsan Abbasnejad</name>
    </author>
    <author>
      <name>Qi Wu</name>
    </author>
    <author>
      <name>Javen Shi</name>
    </author>
    <author>
      <name>Anton van den Hengel</name>
    </author>
    <link href="http://arxiv.org/abs/1812.06401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06176v1</id>
    <updated>2018-12-14T21:32:40Z</updated>
    <published>2018-12-14T21:32:40Z</published>
    <title>Bootstrapping Conversational Agents With Weak Supervision</title>
    <summary>  Many conversational agents in the market today follow a standard bot
development framework which requires training intent classifiers to recognize
user input. The need to create a proper set of training examples is often the
bottleneck in the development process. In many occasions agent developers have
access to historical chat logs that can provide a good quantity as well as
coverage of training examples. However, the cost of labeling them with tens to
hundreds of intents often prohibits taking full advantage of these chat logs.
In this paper, we present a framework called \textit{search, label, and
propagate} (SLP) for bootstrapping intents from existing chat logs using weak
supervision. The framework reduces hours to days of labeling effort down to
minutes of work by using a search engine to find examples, then relies on a
data programming approach to automatically expand the labels. We report on a
user study that shows positive user feedback for this new approach to build
conversational agents, and demonstrates the effectiveness of using data
programming for auto-labeling. While the system is developed for training
conversational agents, the framework has broader application in significantly
reducing labeling effort for training text classifiers.
</summary>
    <author>
      <name>Neil Mallinar</name>
    </author>
    <author>
      <name>Abhishek Shah</name>
    </author>
    <author>
      <name>Rajendra Ugrani</name>
    </author>
    <author>
      <name>Ayush Gupta</name>
    </author>
    <author>
      <name>Manikandan Gurusankar</name>
    </author>
    <author>
      <name>Tin Kam Ho</name>
    </author>
    <author>
      <name>Q. Vera Liao</name>
    </author>
    <author>
      <name>Yunfeng Zhang</name>
    </author>
    <author>
      <name>Rachel K. E. Bellamy</name>
    </author>
    <author>
      <name>Robert Yates</name>
    </author>
    <author>
      <name>Chris Desmarais</name>
    </author>
    <author>
      <name>Blake McGregor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, 1 table, Accepted for publication in IAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.06176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.05407v1</id>
    <updated>2018-12-13T13:13:23Z</updated>
    <published>2018-12-13T13:13:23Z</published>
    <title>Abstractive Text Summarization by Incorporating Reader Comments</title>
    <summary>  In neural abstractive summarization field, conventional sequence-to-sequence
based models often suffer from summarizing the wrong aspect of the document
with respect to the main aspect. To tackle this problem, we propose the task of
reader-aware abstractive summary generation, which utilizes the reader comments
to help the model produce better summary about the main aspect. Unlike
traditional abstractive summarization task, reader-aware summarization
confronts two main challenges: (1) Comments are informal and noisy; (2) jointly
modeling the news document and the reader comments is challenging. To tackle
the above challenges, we design an adversarial learning model named
reader-aware summary generator (RASG), which consists of four components: (1) a
sequence-to-sequence based summary generator; (2) a reader attention module
capturing the reader focused aspects; (3) a supervisor modeling the semantic
gap between the generated summary and reader focused aspects; (4) a goal
tracker producing the goal for each generation step. The supervisor and the
goal tacker are used to guide the training of our framework in an adversarial
manner. Extensive experiments are conducted on our large-scale real-world text
summarization dataset, and the results show that RASG achieves the
state-of-the-art performance in terms of both automatic metrics and human
evaluations. The experimental results also demonstrate the effectiveness of
each module in our framework. We release our large-scale dataset for further
research.
</summary>
    <author>
      <name>Shen Gao</name>
    </author>
    <author>
      <name>Xiuying Chen</name>
    </author>
    <author>
      <name>Piji Li</name>
    </author>
    <author>
      <name>Zhaochun Ren</name>
    </author>
    <author>
      <name>Lidong Bing</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Rui Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.05407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.05407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.04840v2</id>
    <updated>2020-02-06T14:58:27Z</updated>
    <published>2018-12-12T08:06:30Z</published>
    <title>Towards Understanding Language through Perception in Situated
  Human-Robot Interaction: From Word Grounding to Grammar Induction</title>
    <summary>  Robots are widely collaborating with human users in diferent tasks that
require high-level cognitive functions to make them able to discover the
surrounding environment. A difcult challenge that we briefy highlight in this
short paper is inferring the latent grammatical structure of language, which
includes grounding parts of speech (e.g., verbs, nouns, adjectives, and
prepositions) through visual perception, and induction of Combinatory
Categorial Grammar (CCG) for phrases. This paves the way towards grounding
phrases so as to make a robot able to understand human instructions
appropriately during interaction.
</summary>
    <author>
      <name>Amir Aly</name>
    </author>
    <author>
      <name>Tadahiro Taniguchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Social Cognition in
  Humans and Robots (socSMCs), Germany, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.04840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.04840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.07104v1</id>
    <updated>2018-12-11T13:10:14Z</updated>
    <published>2018-12-11T13:10:14Z</published>
    <title>Reading Industrial Inspection Sheets by Inferring Visual Relations</title>
    <summary>  The traditional mode of recording faults in heavy factory equipment has been
via hand marked inspection sheets, wherein a machine engineer manually marks
the faulty machine regions on a paper outline of the machine. Over the years,
millions of such inspection sheets have been recorded and the data within these
sheets has remained inaccessible. However, with industries going digital and
waking up to the potential value of fault data for machine health monitoring,
there is an increased impetus towards digitization of these hand marked
inspection records. To target this digitization, we propose a novel visual
pipeline combining state of the art deep learning models, with domain knowledge
and low level vision techniques, followed by inference of visual relationships.
Our framework is robust to the presence of both static and non-static
background in the document, variability in the machine template diagrams,
unstructured shape of graphical objects to be identified and variability in the
strokes of handwritten text. The proposed pipeline incorporates a capsule and
spatial transformer network based classifier for accurate text reading, and a
customized CTPN network for text detection in addition to hybrid techniques for
arrow detection and dialogue cloud removal. We have tested our approach on a
real world dataset of 50 inspection sheets for large containers and boilers.
The results are visually appealing and the pipeline achieved an accuracy of
87.1% for text detection and 94.6% for text reading.
</summary>
    <author>
      <name>Rohit Rahul</name>
    </author>
    <author>
      <name>Arindam Chowdhury</name>
    </author>
    <author>
      <name> Animesh</name>
    </author>
    <author>
      <name>Samarth Mittal</name>
    </author>
    <author>
      <name>Lovekesh Vig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in 3rd International Workshop on Robust Reading at Asian
  Conference on Computer Vision 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.07104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.04238v1</id>
    <updated>2018-12-11T07:04:44Z</updated>
    <published>2018-12-11T07:04:44Z</published>
    <title>Machine Translation : From Statistical to modern Deep-learning practices</title>
    <summary>  Machine translation (MT) is an area of study in Natural Language processing
which deals with the automatic translation of human language, from one language
to another by the computer. Having a rich research history spanning nearly
three decades, Machine translation is one of the most sought after area of
research in the linguistics and computational community. In this paper, we
investigate the models based on deep learning that have achieved substantial
progress in recent years and becoming the prominent method in MT. We shall
discuss the two main deep-learning based Machine Translation methods, one at
component or domain level which leverages deep learning models to enhance the
efficacy of Statistical Machine Translation (SMT) and end-to-end deep learning
models in MT which uses neural networks to find correspondence between the
source and target languages using the encoder-decoder architecture. We conclude
this paper by providing a time line of the major research problems solved by
the researchers and also provide a comprehensive overview of present areas of
research in Neural Machine Translation.
</summary>
    <author>
      <name>Siddhant Srivastava</name>
    </author>
    <author>
      <name>Anupam Shukla</name>
    </author>
    <author>
      <name>Ritu Tiwari</name>
    </author>
    <link href="http://arxiv.org/abs/1812.04238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.04238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.03509v1</id>
    <updated>2018-12-09T16:05:43Z</updated>
    <published>2018-12-09T16:05:43Z</published>
    <title>Dialogue Generation: From Imitation Learning to Inverse Reinforcement
  Learning</title>
    <summary>  The performance of adversarial dialogue generation models relies on the
quality of the reward signal produced by the discriminator. The reward signal
from a poor discriminator can be very sparse and unstable, which may lead the
generator to fall into a local optimum or to produce nonsense replies. To
alleviate the first problem, we first extend a recently proposed adversarial
dialogue generation method to an adversarial imitation learning solution. Then,
in the framework of adversarial inverse reinforcement learning, we propose a
new reward model for dialogue generation that can provide a more accurate and
precise reward signal for generator training. We evaluate the performance of
the resulting model with automatic metrics and human evaluations in two
annotation settings. Our experimental results demonstrate that our model can
generate more high-quality responses and achieve higher overall performance
than the state-of-the-art.
</summary>
    <author>
      <name>Ziming Li</name>
    </author>
    <author>
      <name>Julia Kiseleva</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.03509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.03509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.02536v2</id>
    <updated>2018-12-13T09:36:17Z</updated>
    <published>2018-12-06T14:11:25Z</published>
    <title>Evaluating Architectural Choices for Deep Learning Approaches for
  Question Answering over Knowledge Bases</title>
    <summary>  The task of answering natural language questions over knowledge bases has
received wide attention in recent years. Various deep learning architectures
have been proposed for this task. However, architectural design choices are
typically not systematically compared nor evaluated under the same conditions.
In this paper, we contribute to a better understanding of the impact of
architectural design choices by evaluating four different architectures under
the same conditions. We address the task of answering simple questions,
consisting in predicting the subject and predicate of a triple given a
question. In order to provide a fair comparison of different architectures, we
evaluate them under the same strategy for inferring the subject, and compare
different architectures for inferring the predicate. The architecture for
inferring the subject is based on a standard LSTM model trained to recognize
the span of the subject in the question and on a linking component that links
the subject span to an entity in the knowledge base. The architectures for
predicate inference are based on i) a standard softmax classifier ranging over
all predicates as output, iii) a model that predicts a low-dimensional encoding
of the property given entity representation and question, iii) a model that
learns to score a pair of subject and predicate given the question as well as
iv) a model based on the well-known FastText model. The comparison of
architectures shows that FastText provides better results than other
architectures.
</summary>
    <author>
      <name>Sherzod Hakimov</name>
    </author>
    <author>
      <name>Soufian Jebbara</name>
    </author>
    <author>
      <name>Philipp Cimiano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">the longer version than the original publication at ICSC 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.02536v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.02536v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01887v1</id>
    <updated>2018-12-05T10:08:29Z</updated>
    <published>2018-12-05T10:08:29Z</published>
    <title>Approach for Semi-automatic Construction of Anti-infective Drug Ontology
  Based on Entity Linking</title>
    <summary>  Ontology can be used for the interpretation of natural language. To construct
an anti-infective drug ontology, one needs to design and deploy a
methodological step to carry out the entity discovery and linking. Medical
synonym resources have been an important part of medical natural language
processing (NLP). However, there are problems such as low precision and low
recall rate. In this study, an NLP approach is adopted to generate candidate
entities. Open ontology is analyzed to extract semantic relations. Six-word
vector features and word-level features are selected to perform the entity
linking. The extraction results of synonyms with a single feature and different
combinations of features are studied. Experiments show that our selected
features have achieved a precision rate of 86.77%, a recall rate of 89.03% and
an F1 score of 87.89%. This paper finally presents the structure of the
proposed ontology and its relevant statistical data.
</summary>
    <author>
      <name>Ying Shen</name>
    </author>
    <author>
      <name>Yang Deng</name>
    </author>
    <author>
      <name>Kaiqi Yuan</name>
    </author>
    <author>
      <name>Li Liu</name>
    </author>
    <author>
      <name>Yong Liu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Smart Computing and Communication
  SmartCom 2017: Smart Computing and Communication pp 268-277</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.01887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01628v2</id>
    <updated>2019-03-25T17:15:45Z</updated>
    <published>2018-12-04T19:06:00Z</published>
    <title>Playing Text-Adventure Games with Graph-Based Deep Reinforcement
  Learning</title>
    <summary>  Text-based adventure games provide a platform on which to explore
reinforcement learning in the context of a combinatorial action space, such as
natural language. We present a deep reinforcement learning architecture that
represents the game state as a knowledge graph which is learned during
exploration. This graph is used to prune the action space, enabling more
efficient exploration. The question of which action to take can be reduced to a
question-answering task, a form of transfer learning that pre-trains certain
parts of our architecture. In experiments using the TextWorld framework, we
show that our proposed technique can learn a control policy faster than
baseline alternatives. We have also open-sourced our code at
https://github.com/rajammanabrolu/KG-DQN.
</summary>
    <author>
      <name>Prithviraj Ammanabrolu</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of NAACL-HLT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01628v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01628v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01260v1</id>
    <updated>2018-12-04T07:48:00Z</updated>
    <published>2018-12-04T07:48:00Z</published>
    <title>Tartan: A retrieval-based socialbot powered by a dynamic finite-state
  machine architecture</title>
    <summary>  This paper describes the Tartan conversational agent built for the 2018 Alexa
Prize Competition. Tartan is a non-goal-oriented socialbot focused around
providing users with an engaging and fluent casual conversation. Tartan's key
features include an emphasis on structured conversation based on flexible
finite-state models and an approach focused on understanding and using
conversational acts. To provide engaging conversations, Tartan blends
script-like yet dynamic responses with data-based generative and retrieval
models. Unique to Tartan is that our dialog manager is modeled as a dynamic
Finite State Machine. To our knowledge, no other conversational agent
implementation has followed this specific structure.
</summary>
    <author>
      <name>George Larionov</name>
    </author>
    <author>
      <name>Zachary Kaden</name>
    </author>
    <author>
      <name>Hima Varsha Dureddy</name>
    </author>
    <author>
      <name>Gabriel Bayomi T. Kalejaiye</name>
    </author>
    <author>
      <name>Mihir Kale</name>
    </author>
    <author>
      <name>Srividya Pranavi Potharaju</name>
    </author>
    <author>
      <name>Ankit Parag Shah</name>
    </author>
    <author>
      <name>Alexander I Rudnicky</name>
    </author>
    <link href="http://arxiv.org/abs/1812.01260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01245v2</id>
    <updated>2018-12-07T17:36:50Z</updated>
    <published>2018-12-04T06:42:49Z</published>
    <title>Transferable Natural Language Interface to Structured Queries aided by
  Adversarial Generation</title>
    <summary>  A natural language interface (NLI) to structured query is intriguing due to
its wide industrial applications and high economical values. In this work, we
tackle the problem of domain adaptation for NLI with limited data on target
domain. Two important approaches are considered: (a) effective
general-knowledge-learning on source domain semantic parsing, and (b) data
augmentation on target domain. We present a Structured Query Inference Network
(SQIN) to enhance learning for domain adaptation, by separating schema
information from NL and decoding SQL in a more structural-aware manner; we also
propose a GAN-based augmentation technique (AugmentGAN) to mitigate the issue
of lacking target domain data. We report solid results on GeoQuery, Overnight,
and WikiSQL to demonstrate state-of-the-art performances for both in-domain and
domain-transfer tasks.
</summary>
    <author>
      <name>Hongyu Xiong</name>
    </author>
    <author>
      <name>Ruixiao Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures; accepted by AAAI Workshop 2019; accepted by
  International Conference of Semantic Computing (ICSC) 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01245v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01245v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00350v1</id>
    <updated>2018-12-02T08:03:12Z</updated>
    <published>2018-12-02T08:03:12Z</published>
    <title>A Study on Dialogue Reward Prediction for Open-Ended Conversational
  Agents</title>
    <summary>  The amount of dialogue history to include in a conversational agent is often
underestimated and/or set in an empirical and thus possibly naive way. This
suggests that principled investigations into optimal context windows are
urgently needed given that the amount of dialogue history and corresponding
representations can play an important role in the overall performance of a
conversational system. This paper studies the amount of history required by
conversational agents for reliably predicting dialogue rewards. The task of
dialogue reward prediction is chosen for investigating the effects of varying
amounts of dialogue history and their impact on system performance.
Experimental results using a dataset of 18K human-human dialogues report that
lengthy dialogue histories of at least 10 sentences are preferred (25 sentences
being the best in our experiments) over short ones, and that lengthy histories
are useful for training dialogue reward predictors with strong positive
correlations between target dialogue rewards and predicted ones.
</summary>
    <author>
      <name>Heriberto Cuayáhuitl</name>
    </author>
    <author>
      <name>Seonghan Ryu</name>
    </author>
    <author>
      <name>Donghyeon Lee</name>
    </author>
    <author>
      <name>Jihie Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In NeurIPS Workshop on Conversational AI: "Today's Practice and
  Tomorrow's Potential", December 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00315v1</id>
    <updated>2018-12-02T03:27:15Z</updated>
    <published>2018-12-02T03:27:15Z</published>
    <title>Fake News: A Survey of Research, Detection Methods, and Opportunities</title>
    <summary>  The explosive growth in fake news and its erosion to democracy, justice, and
public trust has increased the demand for fake news analysis, detection and
intervention. This survey comprehensively and systematically reviews fake news
research. The survey identifies and specifies fundamental theories across
various disciplines, e.g., psychology and social science, to facilitate and
enhance the interdisciplinary research of fake news. Current fake news research
is reviewed, summarized and evaluated. These studies focus on fake news from
four perspective: (1) the false knowledge it carries, (2) its writing style,
(3) its propagation patterns, and (4) the credibility of its creators and
spreaders. We characterize each perspective with various analyzable and
utilizable information provided by news and its spreaders, various strategies
and frameworks that are adaptable, and techniques that are applicable. By
reviewing the characteristics of fake news and open issues in fake news
studies, we highlight some potential research tasks at the end of this survey.
</summary>
    <author>
      <name>Xinyi Zhou</name>
    </author>
    <author>
      <name>Reza Zafarani</name>
    </author>
    <link href="http://arxiv.org/abs/1812.00315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00176v1</id>
    <updated>2018-12-01T08:13:48Z</updated>
    <published>2018-12-01T08:13:48Z</published>
    <title>A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues</title>
    <summary>  Discourse structures are beneficial for various NLP tasks such as dialogue
understanding, question answering, sentiment analysis, and so on. This paper
presents a deep sequential model for parsing discourse dependency structures of
multi-party dialogues. The proposed model aims to construct a discourse
dependency tree by predicting dependency relations and constructing the
discourse structure jointly and alternately. It makes a sequential scan of the
Elementary Discourse Units (EDUs) in a dialogue. For each EDU, the model
decides to which previous EDU the current one should link and what the
corresponding relation type is. The predicted link and relation type are then
used to build the discourse structure incrementally with a structured encoder.
During link prediction and relation classification, the model utilizes not only
local information that represents the concerned EDUs, but also global
information that encodes the EDU sequence and the discourse structure that is
already built at the current step. Experiments show that the proposed model
outperforms all the state-of-the-art baselines.
</summary>
    <author>
      <name>Zhouxing Shi</name>
    </author>
    <author>
      <name>Minlie Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01431v1</id>
    <updated>2018-11-30T19:12:04Z</updated>
    <published>2018-11-30T19:12:04Z</published>
    <title>Modeling natural language emergence with integral transform theory and
  reinforcement learning</title>
    <summary>  Zipf's law predicts a power-law relationship between word rank and frequency
in language communication systems and has been widely reported in a variety of
natural language processing applications. However, the emergence of natural
language is often modeled as a function of bias between speaker and listener
interests, which lacks a direct way of relating information-theoretic bias to
Zipfian rank. A function of bias also serves as an unintuitive interpretation
of the communicative effort exchanged between a speaker and a listener. We
counter these shortcomings by proposing a novel integral transform and kernel
for mapping communicative bias functions to corresponding word frequency-rank
representations at any arbitrary phase transition point, resulting in a direct
way to link communicative effort (modeled by speaker/listener bias) to specific
vocabulary used (represented by word rank). We demonstrate the practical
utility of our integral transform by showing how a change from bias to rank
results in greater accuracy and performance at an image classification task for
assigning word labels to images randomly subsampled from CIFAR10. We model this
task as a reinforcement learning game between a speaker and listener and
compare the relative impact of bias and Zipfian word rank on communicative
performance (and accuracy) between the two agents.
</summary>
    <author>
      <name>Bohdan Khomtchouk</name>
    </author>
    <author>
      <name>Shyam Sudhakaran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, 2 tables. arXiv admin note: text overlap with
  arXiv:1603.03153</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01431v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01431v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.12891v1</id>
    <updated>2018-11-30T17:01:48Z</updated>
    <published>2018-11-30T17:01:48Z</published>
    <title>Flexible and Scalable State Tracking Framework for Goal-Oriented
  Dialogue Systems</title>
    <summary>  Goal-oriented dialogue systems typically rely on components specifically
developed for a single task or domain. This limits such systems in two
different ways: If there is an update in the task domain, the dialogue system
usually needs to be updated or completely re-trained. It is also harder to
extend such dialogue systems to different and multiple domains. The dialogue
state tracker in conventional dialogue systems is one such component - it is
usually designed to fit a well-defined application domain. For example, it is
common for a state variable to be a categorical distribution over a
manually-predefined set of entities (Henderson et al., 2013), resulting in an
inflexible and hard-to-extend dialogue system. In this paper, we propose a new
approach for dialogue state tracking that can generalize well over multiple
domains without incorporating any domain-specific knowledge. Under this
framework, discrete dialogue state variables are learned independently and the
information of a predefined set of possible values for dialogue state variables
is not required. Furthermore, it enables adding arbitrary dialogue context as
features and allows for multiple values to be associated with a single state
variable. These characteristics make it much easier to expand the dialogue
state space. We evaluate our framework using the widely used dialogue state
tracking challenge data set (DSTC2) and show that our framework yields
competitive results with other state-of-the-art results despite incorporating
little domain knowledge. We also show that this framework can benefit from
widely available external resources such as pre-trained word embeddings.
</summary>
    <author>
      <name>Rahul Goel</name>
    </author>
    <author>
      <name>Shachi Paul</name>
    </author>
    <author>
      <name>Tagyoung Chung</name>
    </author>
    <author>
      <name>Jeremie Lecomte</name>
    </author>
    <author>
      <name>Arindam Mandal</name>
    </author>
    <author>
      <name>Dilek Hakkani-Tur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS CONVAI Workshop 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.12891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.12891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.12889v3</id>
    <updated>2019-04-21T15:37:46Z</updated>
    <published>2018-11-30T17:01:28Z</published>
    <title>Systematic Generalization: What Is Required and Can It Be Learned?</title>
    <summary>  Numerous models for grounded language understanding have been recently
proposed, including (i) generic models that can be easily adapted to any given
task and (ii) intuitively appealing modular models that require background
knowledge to be instantiated. We compare both types of models in how much they
lend themselves to a particular form of systematic generalization. Using a
synthetic VQA test, we evaluate which models are capable of reasoning about all
possible object pairs after training on only a small subset of them. Our
findings show that the generalization of modular models is much more systematic
and that it is highly sensitive to the module layout, i.e. to how exactly the
modules are connected. We furthermore investigate if modular models that
generalize well could be made more end-to-end by learning their layout and
parametrization. We find that end-to-end methods from prior work often learn
inappropriate layouts or parametrizations that do not facilitate systematic
generalization. Our results suggest that, in addition to modularity, systematic
generalization in language understanding may require explicit regularizers or
priors.
</summary>
    <author>
      <name>Dzmitry Bahdanau</name>
    </author>
    <author>
      <name>Shikhar Murty</name>
    </author>
    <author>
      <name>Michael Noukhovitch</name>
    </author>
    <author>
      <name>Thien Huu Nguyen</name>
    </author>
    <author>
      <name>Harm de Vries</name>
    </author>
    <author>
      <name>Aaron Courville</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at ICLR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.12889v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.12889v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.12640v2</id>
    <updated>2019-01-23T00:39:00Z</updated>
    <published>2018-11-30T06:55:20Z</published>
    <title>Inferring Concept Prerequisite Relations from Online Educational
  Resources</title>
    <summary>  The Internet has rich and rapidly increasing sources of high quality
educational content. Inferring prerequisite relations between educational
concepts is required for modern large-scale online educational technology
applications such as personalized recommendations and automatic curriculum
creation. We present PREREQ, a new supervised learning method for inferring
concept prerequisite relations. PREREQ is designed using latent representations
of concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a
neural network based on the Siamese network architecture. PREREQ can learn
unknown concept prerequisites from course prerequisites and labeled concept
prerequisite data. It outperforms state-of-the-art approaches on benchmark
datasets and can effectively learn from very less training data. PREREQ can
also use unlabeled video playlists, a steadily growing source of training data,
to learn concept prerequisites, thus obviating the need for manual annotation
of course prerequisites.
</summary>
    <author>
      <name>Sudeshna Roy</name>
    </author>
    <author>
      <name>Meghana Madhyastha</name>
    </author>
    <author>
      <name>Sheril Lawrence</name>
    </author>
    <author>
      <name>Vaibhav Rajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the AAAI Conference on Innovative Applications of
  Artificial Intelligence (IAAI-19)</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.12640v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.12640v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
